{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Inaugment","provenance":[{"file_id":"1NBZijnKI-JSQWMRa_ie6TIGgiCotY-oF","timestamp":1620558492502},{"file_id":"18b80wpeQD1Wj6NjwZFFhZGDuMWWW1TIZ","timestamp":1619286623952},{"file_id":"1pSPNcOLDPSKONSeGALl1Jplu9ET9z-1q","timestamp":1619081668342}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6029efbcaeeb4dc9930d63056c4a3e0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9187f6f667043249260678a9994caa7","IPY_MODEL_81db727f79fd4d3082f7582fafb14e7c"],"layout":"IPY_MODEL_9575251c0cfe4f399fea6c6cc5dd3dd1"}},"e9187f6f667043249260678a9994caa7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_501ab8047d324274b0a1b8836fbbdb67","max":169001437,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af5c100527b2440e8690a575bb1258ad","value":169001437}},"81db727f79fd4d3082f7582fafb14e7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f228b0a81b54d7f8ed843eafe05154e","placeholder":"​","style":"IPY_MODEL_9ec16cfd7a1344fcb05ece7b6f313e6f","value":" 169001984/? [02:40&lt;00:00, 1052753.52it/s]"}},"9575251c0cfe4f399fea6c6cc5dd3dd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"501ab8047d324274b0a1b8836fbbdb67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af5c100527b2440e8690a575bb1258ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"3f228b0a81b54d7f8ed843eafe05154e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ec16cfd7a1344fcb05ece7b6f313e6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OSFGYaIDG6f0"},"source":["Cutout Data Augmentation.\n","\n","This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"]},{"cell_type":"markdown","metadata":{"id":"vCVSE5-UboYl"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"id":"5YBMwPsubsbX"},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L88afYXKMSdL"},"source":["##**Model - Define ResNet Model**\n"]},{"cell_type":"code","metadata":{"id":"eMFSLTnkMQdq"},"source":["'''ResNet18/34/50/101/152 in Pytorch.'''\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18(num_classes=10):\n","    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n","\n","def ResNet34(num_classes=10):\n","    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n","\n","def ResNet50(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n","\n","def ResNet101(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n","\n","def ResNet152(num_classes=10):\n","    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n","\n","def test_resnet():\n","    net = ResNet50()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test_resnet()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjM3cl279Lvg"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"gIvuSgE49Kvu"},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6y3zhSfMbdC"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"iMQI2K4AMopg"},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wwiHSMvG-W3_"},"source":["##**InAugment**"]},{"cell_type":"markdown","metadata":{"id":"3Qe0DfFrmMMj"},"source":["InAugment 구현을 위해 autoaugment코드와 randomcolorgitter 코드를 사용하였습니다."]},{"cell_type":"code","metadata":{"id":"pKjdnW7vmxNV"},"source":["from PIL import Image, ImageEnhance, ImageOps, ImageChops\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import random\n","import pdb\n","import cv2\n","import torchvision.transforms.functional as TF\n","\n","class CIFAR100Policy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n","        Example:\n","        >>> policy = CIFAR10Policy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     CIFAR10Policy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n","            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n","            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n","            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n","\n","            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n","            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n","            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n","            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n","            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n","            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n","            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n","            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n","\n","            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n","            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n","            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n","            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n","\n","            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n","            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment CIFAR10 Policy\"\n","\n","class SubPolicy(object):\n","    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n","        ranges = {\n","            \"shearX\": np.linspace(0, 0.3, 10),\n","            \"shearY\": np.linspace(0, 0.3, 10),\n","            \"translateX\": np.linspace(0, 150 / 331, 10),\n","            \"translateY\": np.linspace(0, 150 / 331, 10),\n","            \"rotate\": np.linspace(0, 30, 10),\n","            \"color\": np.linspace(0.0, 0.9, 10),\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n","            \"solarize\": np.linspace(256, 0, 10),\n","            \"contrast\": np.linspace(0.0, 0.9, 10),\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\n","            \"brightness\": np.linspace(0.0, 0.9, 10),\n","            \"autocontrast\": [0] * 10,\n","            \"equalize\": [0] * 10,\n","            \"invert\": [0] * 10\n","        }\n","\n","        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n","        def rotate_with_fill(img, magnitude):\n","            rot = img.convert(\"RGBA\").rotate(magnitude)\n","            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n","\n","        func = {\n","            \"shearX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"shearY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"translateX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n","                fillcolor=fillcolor),\n","            \"translateY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n","                fillcolor=fillcolor),\n","            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n","            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n","        }\n","\n","        self.p1 = p1\n","        self.operation1 = func[operation1]\n","        self.magnitude1 = ranges[operation1][magnitude_idx1]\n","        self.p2 = p2\n","        self.operation2 = func[operation2]\n","        self.magnitude2 = ranges[operation2][magnitude_idx2]\n","\n","\n","    def __call__(self, img):\n","        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n","        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUkFQM-VKEXn"},"source":["import random\n","import torchvision.transforms.functional as TF\n","\n","class RandomGamma(object):\n","    def __init__(self, gamma_p = 0.5, gamma_ratio=(0,1.5)):\n","        self.gamma_p = gamma_p\n","        self.gamma_ratio = gamma_ratio\n","\n","    def __call__(self,img):\n","        if random.uniform(0, 1) < self.gamma_p:\n","            gamma = random.uniform(self.gamma_ratio[0], self.gamma_ratio[1])\n","            img = TF.adjust_gamma(img, gamma, gain=1)\n","            return img\n","        else:\n","            return img\n","\n","class RandomColorJitter(object):\n","    def __init__(self, p = 0.5, brightness_ratio=(0,2), contrast_ratio=(0,2), \\\n","                saturation_ratio=(0,2), hue_ratio=(-0.5,0.5)):\n","        self.p = p\n","        self.brightness_ratio = brightness_ratio\n","        self.contrast_ratio = contrast_ratio\n","        self.saturation_ratio = saturation_ratio\n","        self.hue_ratio = hue_ratio\n","\n","    @staticmethod\n","    def process(img, brightness_ratio, contrast_ratio, saturation_ratio, hue_ratio):\n","        brightness = random.uniform(brightness_ratio[0], brightness_ratio[1])\n","        contrast = random.uniform(contrast_ratio[0], contrast_ratio[1])\n","        saturation = random.uniform(saturation_ratio[0], saturation_ratio[1])\n","        hue = random.uniform(hue_ratio[0], hue_ratio[1])\n","\n","        img = TF.adjust_brightness(img, brightness)\n","        img = TF.adjust_contrast(img, contrast)\n","        img = TF.adjust_saturation(img, saturation)\n","        img = TF.adjust_hue(img, hue)\n","\n","        return img\n","\n","    def __call__(self,img):\n","        if random.uniform(0, 1) < self.p:\n","            img = self.process(img, self.brightness_ratio, self.contrast_ratio, \\\n","                                self.saturation_ratio, self.hue_ratio)\n","            return img\n","        else:\n","            return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fAl0bU6P-WYq"},"source":["from PIL import Image\n","class InAugment(object):\n","  def __init__(self, num =1, length=16, re_length=20):\n","    self.num = num\n","    self.length = length\n","    self.re_length = re_length\n","  \n","  def __call__(self,img):\n","    imgs = []\n","    h = img.size[0]\n","    w = img.size[1]\n","    for n in range(self.num):\n","      y = np.random.randint(h)\n","      x = np.random.randint(w)\n","\n","      y1 = np.clip(y - self.length // 2, 0, h)\n","      y2 = np.clip(y + self.length // 2, 0, h)\n","      x1 = np.clip(x - self.length // 2, 0, w)\n","      x2 = np.clip(x + self.length // 2, 0, w)\n","      \n","      # 이미지 자르기 crop함수 이용 ex. crop(left, up, right, down)\n","      croppedImage = img.crop((x1,y1,x2,y2))\n","\n","      # 자른 사진에 대해서 autoaugment 적용\n","      # 트레이닝 시간이 오래 걸려 제외\n","      #policy = CIFAR100Policy()\n","      #augImage = policy(croppedImage)\n","\n","      # Autoaugment 대신에 RandomColorJitter()를 이용해서 변화를 주는 방식으로 대체\n","      r1 = RandomColorJitter()\n","      r2 = RandomGamma()\n","      augImage = r1(croppedImage)\n","      augImage = r2(augImage)\n","\n","      resizeImage = augImage.resize((self.re_length, self.re_length))\n","      imgs.append(resizeImage)\n","\n","    for n in range(self.num):\n","      img.paste(imgs[n], (random.randint(0,32),random.randint(0,32)))\n","\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s8oXpzdMvol"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"Pjeqawi9cNK6"},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'resnet34' # resnet18, resnet50, resnet101\n","batch_size = 128  # Input batch size for training (default: 128)\n","epochs = 150 # Number of epochs to train (default: 200)\n","learning_rate = 0.1 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","cutout = False # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","seed = 0 # Random seed (default: 0)\n","print_freq = 30\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","# What we need for our data augmentation\n","re_length = 20\n","inaugment = True\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXL_PBj6cVoe"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119,"referenced_widgets":["6029efbcaeeb4dc9930d63056c4a3e0b","e9187f6f667043249260678a9994caa7","81db727f79fd4d3082f7582fafb14e7c","9575251c0cfe4f399fea6c6cc5dd3dd1","501ab8047d324274b0a1b8836fbbdb67","af5c100527b2440e8690a575bb1258ad","3f228b0a81b54d7f8ed843eafe05154e","9ec16cfd7a1344fcb05ece7b6f313e6f"]},"id":"dvQjH3T9caYs","executionInfo":{"elapsed":8190,"status":"ok","timestamp":1620912491608,"user":{"displayName":"류다영","photoUrl":"","userId":"16798123234580172997"},"user_tz":-540},"outputId":"a1f64a02-78e9-4e14-ba24-ac2e9e43a30f"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","train_transform = transforms.Compose([])\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","\n","if inaugment:\n","    train_transform.transforms.append(InAugment(num=n_holes,length=length,re_length=re_length))\n","    \n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6029efbcaeeb4dc9930d63056c4a3e0b","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gITLQIAr9lAZ"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"s0-lYvAp9oHA","outputId":"e2d4520a-bf19-46ff-e4e3-4514fd80ef0b"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","model = ResNet34(num_classes=num_classes).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n","\n","scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","###########################################################\n","best_acc = 0\n","for epoch in range(epochs):\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), 'model_best.pt')\n","\n","torch.save(model.state_dict(),'model_latest.pt')\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","----- epoch: 0, lr: 0.1 -----\n","Epoch: [0][  0/391]\tTime  1.286 ( 1.286)\tLoss 4.7391e+00 (4.7391e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   5.47 (  5.47)\n","Epoch: [0][ 30/391]\tTime  0.163 ( 0.195)\tLoss 4.5795e+00 (5.2615e+00)\tAcc@1   2.34 (  0.96)\tAcc@5   7.03 (  5.44)\n","Epoch: [0][ 60/391]\tTime  0.163 ( 0.179)\tLoss 4.5570e+00 (4.9409e+00)\tAcc@1   2.34 (  1.08)\tAcc@5  12.50 (  5.93)\n","Epoch: [0][ 90/391]\tTime  0.164 ( 0.174)\tLoss 4.4568e+00 (4.7822e+00)\tAcc@1   3.12 (  1.73)\tAcc@5  12.50 (  7.92)\n","Epoch: [0][120/391]\tTime  0.166 ( 0.172)\tLoss 4.2102e+00 (4.6678e+00)\tAcc@1   5.47 (  2.17)\tAcc@5  18.75 (  9.72)\n","Epoch: [0][150/391]\tTime  0.165 ( 0.171)\tLoss 4.3123e+00 (4.5835e+00)\tAcc@1   3.12 (  2.82)\tAcc@5  18.75 ( 11.49)\n","Epoch: [0][180/391]\tTime  0.167 ( 0.170)\tLoss 4.1327e+00 (4.5131e+00)\tAcc@1   4.69 (  3.06)\tAcc@5  15.62 ( 12.84)\n","Epoch: [0][210/391]\tTime  0.171 ( 0.170)\tLoss 4.1920e+00 (4.4521e+00)\tAcc@1   4.69 (  3.45)\tAcc@5  24.22 ( 14.31)\n","Epoch: [0][240/391]\tTime  0.170 ( 0.170)\tLoss 4.1344e+00 (4.4008e+00)\tAcc@1   5.47 (  3.85)\tAcc@5  24.22 ( 15.61)\n","Epoch: [0][270/391]\tTime  0.172 ( 0.170)\tLoss 4.1206e+00 (4.3604e+00)\tAcc@1   7.03 (  4.20)\tAcc@5  21.09 ( 16.61)\n","Epoch: [0][300/391]\tTime  0.173 ( 0.171)\tLoss 3.8340e+00 (4.3215e+00)\tAcc@1  14.06 (  4.63)\tAcc@5  35.16 ( 17.71)\n","Epoch: [0][330/391]\tTime  0.174 ( 0.171)\tLoss 4.2136e+00 (4.2907e+00)\tAcc@1   2.34 (  4.95)\tAcc@5  18.75 ( 18.48)\n","Epoch: [0][360/391]\tTime  0.173 ( 0.171)\tLoss 3.9722e+00 (4.2604e+00)\tAcc@1   6.25 (  5.25)\tAcc@5  22.66 ( 19.29)\n","Epoch: [0][390/391]\tTime  0.723 ( 0.173)\tLoss 3.9655e+00 (4.2359e+00)\tAcc@1   6.25 (  5.45)\tAcc@5  27.50 ( 20.02)\n","==> Train Accuracy: Acc@1 5.452 || Acc@5 20.024\n","==> Test Accuracy:  Acc@1 10.930 || Acc@5 32.160\n","==> 71.88 seconds to train this epoch\n","\n","\n","----- epoch: 1, lr: 0.1 -----\n","Epoch: [1][  0/391]\tTime  0.282 ( 0.282)\tLoss 3.9308e+00 (3.9308e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  24.22 ( 24.22)\n","Epoch: [1][ 30/391]\tTime  0.169 ( 0.173)\tLoss 3.7810e+00 (3.8380e+00)\tAcc@1  10.16 (  9.85)\tAcc@5  34.38 ( 32.31)\n","Epoch: [1][ 60/391]\tTime  0.169 ( 0.171)\tLoss 3.7576e+00 (3.8252e+00)\tAcc@1  10.94 (  9.94)\tAcc@5  35.94 ( 32.06)\n","Epoch: [1][ 90/391]\tTime  0.168 ( 0.170)\tLoss 3.7232e+00 (3.8152e+00)\tAcc@1  10.16 (  9.77)\tAcc@5  34.38 ( 31.95)\n","Epoch: [1][120/391]\tTime  0.167 ( 0.170)\tLoss 3.8815e+00 (3.8060e+00)\tAcc@1   9.38 (  9.87)\tAcc@5  33.59 ( 32.40)\n","Epoch: [1][150/391]\tTime  0.163 ( 0.169)\tLoss 3.6018e+00 (3.7983e+00)\tAcc@1  13.28 ( 10.02)\tAcc@5  34.38 ( 32.59)\n","Epoch: [1][180/391]\tTime  0.169 ( 0.169)\tLoss 3.6996e+00 (3.7929e+00)\tAcc@1  14.84 ( 10.13)\tAcc@5  35.94 ( 32.76)\n","Epoch: [1][210/391]\tTime  0.168 ( 0.169)\tLoss 3.4672e+00 (3.7760e+00)\tAcc@1  15.62 ( 10.39)\tAcc@5  39.06 ( 33.11)\n","Epoch: [1][240/391]\tTime  0.171 ( 0.169)\tLoss 3.6063e+00 (3.7688e+00)\tAcc@1  14.06 ( 10.60)\tAcc@5  37.50 ( 33.38)\n","Epoch: [1][270/391]\tTime  0.170 ( 0.169)\tLoss 3.6362e+00 (3.7540e+00)\tAcc@1  11.72 ( 10.85)\tAcc@5  36.72 ( 33.73)\n","Epoch: [1][300/391]\tTime  0.170 ( 0.169)\tLoss 3.5963e+00 (3.7419e+00)\tAcc@1  11.72 ( 11.05)\tAcc@5  37.50 ( 34.02)\n","Epoch: [1][330/391]\tTime  0.171 ( 0.169)\tLoss 3.5858e+00 (3.7320e+00)\tAcc@1  14.06 ( 11.28)\tAcc@5  39.06 ( 34.38)\n","Epoch: [1][360/391]\tTime  0.170 ( 0.169)\tLoss 3.6593e+00 (3.7218e+00)\tAcc@1  15.62 ( 11.46)\tAcc@5  34.38 ( 34.83)\n","Epoch: [1][390/391]\tTime  0.153 ( 0.169)\tLoss 3.6949e+00 (3.7097e+00)\tAcc@1  13.75 ( 11.74)\tAcc@5  26.25 ( 35.23)\n","==> Train Accuracy: Acc@1 11.740 || Acc@5 35.230\n","==> Test Accuracy:  Acc@1 15.500 || Acc@5 41.920\n","==> 70.43 seconds to train this epoch\n","\n","\n","----- epoch: 2, lr: 0.1 -----\n","Epoch: [2][  0/391]\tTime  0.279 ( 0.279)\tLoss 3.4867e+00 (3.4867e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  45.31 ( 45.31)\n","Epoch: [2][ 30/391]\tTime  0.171 ( 0.174)\tLoss 3.4538e+00 (3.4964e+00)\tAcc@1  13.28 ( 15.50)\tAcc@5  39.06 ( 41.53)\n","Epoch: [2][ 60/391]\tTime  0.171 ( 0.172)\tLoss 3.2574e+00 (3.4899e+00)\tAcc@1  18.75 ( 15.51)\tAcc@5  50.00 ( 42.15)\n","Epoch: [2][ 90/391]\tTime  0.170 ( 0.171)\tLoss 3.6675e+00 (3.4841e+00)\tAcc@1  13.28 ( 15.62)\tAcc@5  36.72 ( 42.17)\n","Epoch: [2][120/391]\tTime  0.171 ( 0.171)\tLoss 3.5998e+00 (3.4802e+00)\tAcc@1  16.41 ( 15.82)\tAcc@5  36.72 ( 42.32)\n","Epoch: [2][150/391]\tTime  0.170 ( 0.171)\tLoss 3.3375e+00 (3.4675e+00)\tAcc@1  23.44 ( 15.96)\tAcc@5  50.00 ( 42.83)\n","Epoch: [2][180/391]\tTime  0.171 ( 0.170)\tLoss 3.3402e+00 (3.4624e+00)\tAcc@1  18.75 ( 16.05)\tAcc@5  45.31 ( 42.96)\n","Epoch: [2][210/391]\tTime  0.169 ( 0.170)\tLoss 3.4230e+00 (3.4556e+00)\tAcc@1  22.66 ( 16.27)\tAcc@5  44.53 ( 43.11)\n","Epoch: [2][240/391]\tTime  0.170 ( 0.170)\tLoss 3.3037e+00 (3.4406e+00)\tAcc@1  18.75 ( 16.60)\tAcc@5  44.53 ( 43.61)\n","Epoch: [2][270/391]\tTime  0.170 ( 0.170)\tLoss 3.3224e+00 (3.4266e+00)\tAcc@1  21.88 ( 16.85)\tAcc@5  46.88 ( 44.02)\n","Epoch: [2][300/391]\tTime  0.170 ( 0.170)\tLoss 3.3292e+00 (3.4119e+00)\tAcc@1  21.88 ( 17.13)\tAcc@5  43.75 ( 44.40)\n","Epoch: [2][330/391]\tTime  0.170 ( 0.170)\tLoss 3.2705e+00 (3.4038e+00)\tAcc@1  25.00 ( 17.34)\tAcc@5  54.69 ( 44.63)\n","Epoch: [2][360/391]\tTime  0.169 ( 0.170)\tLoss 3.0649e+00 (3.3948e+00)\tAcc@1  25.00 ( 17.47)\tAcc@5  53.91 ( 44.88)\n","Epoch: [2][390/391]\tTime  0.152 ( 0.170)\tLoss 3.1177e+00 (3.3830e+00)\tAcc@1  23.75 ( 17.64)\tAcc@5  57.50 ( 45.26)\n","==> Train Accuracy: Acc@1 17.640 || Acc@5 45.262\n","==> Test Accuracy:  Acc@1 20.600 || Acc@5 50.230\n","==> 70.70 seconds to train this epoch\n","\n","\n","----- epoch: 3, lr: 0.1 -----\n","Epoch: [3][  0/391]\tTime  0.278 ( 0.278)\tLoss 3.0821e+00 (3.0821e+00)\tAcc@1  21.88 ( 21.88)\tAcc@5  50.78 ( 50.78)\n","Epoch: [3][ 30/391]\tTime  0.171 ( 0.173)\tLoss 3.0195e+00 (3.2076e+00)\tAcc@1  24.22 ( 20.04)\tAcc@5  53.91 ( 50.28)\n","Epoch: [3][ 60/391]\tTime  0.172 ( 0.171)\tLoss 3.2150e+00 (3.1957e+00)\tAcc@1  17.19 ( 21.16)\tAcc@5  49.22 ( 50.53)\n","Epoch: [3][ 90/391]\tTime  0.171 ( 0.171)\tLoss 3.2618e+00 (3.1859e+00)\tAcc@1  17.19 ( 21.22)\tAcc@5  51.56 ( 50.54)\n","Epoch: [3][120/391]\tTime  0.170 ( 0.171)\tLoss 3.5039e+00 (3.1835e+00)\tAcc@1  11.72 ( 21.05)\tAcc@5  36.72 ( 50.64)\n","Epoch: [3][150/391]\tTime  0.171 ( 0.170)\tLoss 3.1843e+00 (3.1802e+00)\tAcc@1  16.41 ( 21.16)\tAcc@5  53.91 ( 50.70)\n","Epoch: [3][180/391]\tTime  0.170 ( 0.170)\tLoss 3.2226e+00 (3.1722e+00)\tAcc@1  19.53 ( 21.18)\tAcc@5  46.09 ( 51.13)\n","Epoch: [3][210/391]\tTime  0.171 ( 0.170)\tLoss 3.2524e+00 (3.1671e+00)\tAcc@1  19.53 ( 21.38)\tAcc@5  53.91 ( 51.37)\n","Epoch: [3][240/391]\tTime  0.168 ( 0.170)\tLoss 3.2635e+00 (3.1619e+00)\tAcc@1  20.31 ( 21.43)\tAcc@5  51.56 ( 51.51)\n","Epoch: [3][270/391]\tTime  0.171 ( 0.170)\tLoss 3.3226e+00 (3.1538e+00)\tAcc@1  16.41 ( 21.62)\tAcc@5  51.56 ( 51.62)\n","Epoch: [3][300/391]\tTime  0.170 ( 0.170)\tLoss 3.1007e+00 (3.1449e+00)\tAcc@1  21.88 ( 21.80)\tAcc@5  53.12 ( 51.83)\n","Epoch: [3][330/391]\tTime  0.171 ( 0.170)\tLoss 3.0145e+00 (3.1336e+00)\tAcc@1  28.91 ( 22.01)\tAcc@5  55.47 ( 52.14)\n","Epoch: [3][360/391]\tTime  0.169 ( 0.170)\tLoss 2.9063e+00 (3.1294e+00)\tAcc@1  28.91 ( 22.13)\tAcc@5  57.03 ( 52.18)\n","Epoch: [3][390/391]\tTime  0.151 ( 0.170)\tLoss 2.9592e+00 (3.1173e+00)\tAcc@1  25.00 ( 22.37)\tAcc@5  56.25 ( 52.47)\n","==> Train Accuracy: Acc@1 22.374 || Acc@5 52.472\n","==> Test Accuracy:  Acc@1 27.860 || Acc@5 59.560\n","==> 70.80 seconds to train this epoch\n","\n","\n","----- epoch: 4, lr: 0.1 -----\n","Epoch: [4][  0/391]\tTime  0.301 ( 0.301)\tLoss 2.9673e+00 (2.9673e+00)\tAcc@1  25.78 ( 25.78)\tAcc@5  61.72 ( 61.72)\n","Epoch: [4][ 30/391]\tTime  0.172 ( 0.174)\tLoss 3.1616e+00 (2.9298e+00)\tAcc@1  21.88 ( 26.46)\tAcc@5  54.69 ( 57.08)\n","Epoch: [4][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.8812e+00 (2.9474e+00)\tAcc@1  23.44 ( 26.20)\tAcc@5  57.81 ( 56.90)\n","Epoch: [4][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.7616e+00 (2.9344e+00)\tAcc@1  32.81 ( 26.43)\tAcc@5  65.62 ( 57.25)\n","Epoch: [4][120/391]\tTime  0.169 ( 0.171)\tLoss 2.7941e+00 (2.9254e+00)\tAcc@1  28.91 ( 26.76)\tAcc@5  63.28 ( 57.41)\n","Epoch: [4][150/391]\tTime  0.169 ( 0.171)\tLoss 2.9473e+00 (2.9248e+00)\tAcc@1  25.78 ( 26.47)\tAcc@5  57.81 ( 57.29)\n","Epoch: [4][180/391]\tTime  0.170 ( 0.171)\tLoss 3.0515e+00 (2.9194e+00)\tAcc@1  25.00 ( 26.39)\tAcc@5  50.00 ( 57.45)\n","Epoch: [4][210/391]\tTime  0.170 ( 0.171)\tLoss 2.8204e+00 (2.9140e+00)\tAcc@1  26.56 ( 26.58)\tAcc@5  61.72 ( 57.47)\n","Epoch: [4][240/391]\tTime  0.169 ( 0.171)\tLoss 2.8896e+00 (2.9107e+00)\tAcc@1  25.78 ( 26.66)\tAcc@5  62.50 ( 57.57)\n","Epoch: [4][270/391]\tTime  0.169 ( 0.170)\tLoss 2.9077e+00 (2.9034e+00)\tAcc@1  23.44 ( 26.72)\tAcc@5  62.50 ( 57.80)\n","Epoch: [4][300/391]\tTime  0.169 ( 0.170)\tLoss 2.9548e+00 (2.8975e+00)\tAcc@1  22.66 ( 26.78)\tAcc@5  54.69 ( 57.92)\n","Epoch: [4][330/391]\tTime  0.169 ( 0.170)\tLoss 2.7161e+00 (2.8922e+00)\tAcc@1  33.59 ( 26.96)\tAcc@5  63.28 ( 58.16)\n","Epoch: [4][360/391]\tTime  0.170 ( 0.170)\tLoss 2.9598e+00 (2.8904e+00)\tAcc@1  26.56 ( 27.03)\tAcc@5  57.03 ( 58.24)\n","Epoch: [4][390/391]\tTime  0.153 ( 0.170)\tLoss 2.7028e+00 (2.8834e+00)\tAcc@1  36.25 ( 27.23)\tAcc@5  60.00 ( 58.40)\n","==> Train Accuracy: Acc@1 27.234 || Acc@5 58.396\n","==> Test Accuracy:  Acc@1 27.130 || Acc@5 56.890\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 5, lr: 0.1 -----\n","Epoch: [5][  0/391]\tTime  0.272 ( 0.272)\tLoss 2.7572e+00 (2.7572e+00)\tAcc@1  32.03 ( 32.03)\tAcc@5  58.59 ( 58.59)\n","Epoch: [5][ 30/391]\tTime  0.172 ( 0.173)\tLoss 2.5341e+00 (2.7225e+00)\tAcc@1  31.25 ( 30.27)\tAcc@5  69.53 ( 62.85)\n","Epoch: [5][ 60/391]\tTime  0.172 ( 0.171)\tLoss 2.6685e+00 (2.7215e+00)\tAcc@1  32.81 ( 30.56)\tAcc@5  57.81 ( 62.44)\n","Epoch: [5][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.7609e+00 (2.7312e+00)\tAcc@1  27.34 ( 30.29)\tAcc@5  66.41 ( 62.32)\n","Epoch: [5][120/391]\tTime  0.170 ( 0.171)\tLoss 2.9766e+00 (2.7290e+00)\tAcc@1  28.91 ( 30.51)\tAcc@5  50.00 ( 62.25)\n","Epoch: [5][150/391]\tTime  0.169 ( 0.171)\tLoss 2.4375e+00 (2.7157e+00)\tAcc@1  36.72 ( 30.79)\tAcc@5  71.09 ( 62.40)\n","Epoch: [5][180/391]\tTime  0.169 ( 0.170)\tLoss 2.5991e+00 (2.7136e+00)\tAcc@1  34.38 ( 30.81)\tAcc@5  67.97 ( 62.49)\n","Epoch: [5][210/391]\tTime  0.169 ( 0.170)\tLoss 2.9048e+00 (2.7138e+00)\tAcc@1  28.12 ( 30.90)\tAcc@5  57.81 ( 62.42)\n","Epoch: [5][240/391]\tTime  0.169 ( 0.170)\tLoss 2.6431e+00 (2.7125e+00)\tAcc@1  32.03 ( 30.87)\tAcc@5  64.84 ( 62.47)\n","Epoch: [5][270/391]\tTime  0.173 ( 0.170)\tLoss 2.6578e+00 (2.7134e+00)\tAcc@1  32.03 ( 30.79)\tAcc@5  65.62 ( 62.50)\n","Epoch: [5][300/391]\tTime  0.171 ( 0.170)\tLoss 2.6374e+00 (2.7086e+00)\tAcc@1  38.28 ( 30.87)\tAcc@5  61.72 ( 62.63)\n","Epoch: [5][330/391]\tTime  0.168 ( 0.170)\tLoss 2.5711e+00 (2.7033e+00)\tAcc@1  39.06 ( 31.03)\tAcc@5  64.06 ( 62.76)\n","Epoch: [5][360/391]\tTime  0.171 ( 0.170)\tLoss 2.6524e+00 (2.6987e+00)\tAcc@1  33.59 ( 31.16)\tAcc@5  60.94 ( 62.78)\n","Epoch: [5][390/391]\tTime  0.154 ( 0.170)\tLoss 2.7540e+00 (2.6905e+00)\tAcc@1  35.00 ( 31.31)\tAcc@5  60.00 ( 62.91)\n","==> Train Accuracy: Acc@1 31.314 || Acc@5 62.912\n","==> Test Accuracy:  Acc@1 36.000 || Acc@5 68.780\n","==> 70.75 seconds to train this epoch\n","\n","\n","----- epoch: 6, lr: 0.1 -----\n","Epoch: [6][  0/391]\tTime  0.275 ( 0.275)\tLoss 2.7468e+00 (2.7468e+00)\tAcc@1  31.25 ( 31.25)\tAcc@5  64.06 ( 64.06)\n","Epoch: [6][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.5647e+00 (2.5386e+00)\tAcc@1  34.38 ( 33.87)\tAcc@5  69.53 ( 66.68)\n","Epoch: [6][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.5411e+00 (2.5563e+00)\tAcc@1  30.47 ( 33.04)\tAcc@5  70.31 ( 66.11)\n","Epoch: [6][ 90/391]\tTime  0.169 ( 0.171)\tLoss 2.5116e+00 (2.5616e+00)\tAcc@1  32.03 ( 33.21)\tAcc@5  70.31 ( 65.79)\n","Epoch: [6][120/391]\tTime  0.169 ( 0.171)\tLoss 2.4697e+00 (2.5543e+00)\tAcc@1  33.59 ( 33.37)\tAcc@5  71.09 ( 66.03)\n","Epoch: [6][150/391]\tTime  0.170 ( 0.171)\tLoss 2.4603e+00 (2.5360e+00)\tAcc@1  37.50 ( 34.02)\tAcc@5  70.31 ( 66.53)\n","Epoch: [6][180/391]\tTime  0.168 ( 0.171)\tLoss 2.2971e+00 (2.5318e+00)\tAcc@1  40.62 ( 34.09)\tAcc@5  70.31 ( 66.58)\n","Epoch: [6][210/391]\tTime  0.169 ( 0.170)\tLoss 2.5912e+00 (2.5289e+00)\tAcc@1  32.81 ( 34.21)\tAcc@5  67.19 ( 66.65)\n","Epoch: [6][240/391]\tTime  0.170 ( 0.170)\tLoss 2.4214e+00 (2.5297e+00)\tAcc@1  37.50 ( 34.18)\tAcc@5  69.53 ( 66.56)\n","Epoch: [6][270/391]\tTime  0.171 ( 0.170)\tLoss 2.4081e+00 (2.5268e+00)\tAcc@1  41.41 ( 34.19)\tAcc@5  70.31 ( 66.59)\n","Epoch: [6][300/391]\tTime  0.171 ( 0.170)\tLoss 2.4789e+00 (2.5210e+00)\tAcc@1  35.16 ( 34.35)\tAcc@5  66.41 ( 66.75)\n","Epoch: [6][330/391]\tTime  0.170 ( 0.170)\tLoss 2.7345e+00 (2.5190e+00)\tAcc@1  32.03 ( 34.42)\tAcc@5  59.38 ( 66.80)\n","Epoch: [6][360/391]\tTime  0.169 ( 0.170)\tLoss 2.6231e+00 (2.5138e+00)\tAcc@1  31.25 ( 34.53)\tAcc@5  62.50 ( 66.86)\n","Epoch: [6][390/391]\tTime  0.153 ( 0.170)\tLoss 2.6332e+00 (2.5058e+00)\tAcc@1  30.00 ( 34.79)\tAcc@5  57.50 ( 67.02)\n","==> Train Accuracy: Acc@1 34.788 || Acc@5 67.020\n","==> Test Accuracy:  Acc@1 36.470 || Acc@5 67.660\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 7, lr: 0.1 -----\n","Epoch: [7][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.3519e+00 (2.3519e+00)\tAcc@1  35.16 ( 35.16)\tAcc@5  71.88 ( 71.88)\n","Epoch: [7][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.6617e+00 (2.3417e+00)\tAcc@1  29.69 ( 37.93)\tAcc@5  60.94 ( 70.79)\n","Epoch: [7][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.6108e+00 (2.3602e+00)\tAcc@1  32.81 ( 37.55)\tAcc@5  67.19 ( 70.45)\n","Epoch: [7][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.3321e+00 (2.3717e+00)\tAcc@1  39.84 ( 37.34)\tAcc@5  71.88 ( 70.11)\n","Epoch: [7][120/391]\tTime  0.170 ( 0.171)\tLoss 2.3371e+00 (2.3759e+00)\tAcc@1  44.53 ( 37.31)\tAcc@5  71.88 ( 70.24)\n","Epoch: [7][150/391]\tTime  0.169 ( 0.171)\tLoss 2.6029e+00 (2.3713e+00)\tAcc@1  28.91 ( 37.53)\tAcc@5  63.28 ( 70.29)\n","Epoch: [7][180/391]\tTime  0.172 ( 0.170)\tLoss 2.3499e+00 (2.3681e+00)\tAcc@1  39.84 ( 37.62)\tAcc@5  68.75 ( 70.27)\n","Epoch: [7][210/391]\tTime  0.170 ( 0.170)\tLoss 2.2232e+00 (2.3639e+00)\tAcc@1  35.16 ( 37.59)\tAcc@5  72.66 ( 70.35)\n","Epoch: [7][240/391]\tTime  0.169 ( 0.170)\tLoss 2.7310e+00 (2.3625e+00)\tAcc@1  30.47 ( 37.63)\tAcc@5  60.94 ( 70.29)\n","Epoch: [7][270/391]\tTime  0.170 ( 0.170)\tLoss 2.4009e+00 (2.3659e+00)\tAcc@1  37.50 ( 37.62)\tAcc@5  67.19 ( 70.27)\n","Epoch: [7][300/391]\tTime  0.170 ( 0.170)\tLoss 2.4685e+00 (2.3663e+00)\tAcc@1  35.94 ( 37.67)\tAcc@5  64.84 ( 70.22)\n","Epoch: [7][330/391]\tTime  0.172 ( 0.170)\tLoss 2.2522e+00 (2.3671e+00)\tAcc@1  38.28 ( 37.70)\tAcc@5  72.66 ( 70.21)\n","Epoch: [7][360/391]\tTime  0.172 ( 0.170)\tLoss 2.2812e+00 (2.3653e+00)\tAcc@1  43.75 ( 37.75)\tAcc@5  71.09 ( 70.21)\n","Epoch: [7][390/391]\tTime  0.153 ( 0.170)\tLoss 2.0915e+00 (2.3614e+00)\tAcc@1  46.25 ( 37.94)\tAcc@5  76.25 ( 70.30)\n","==> Train Accuracy: Acc@1 37.940 || Acc@5 70.302\n","==> Test Accuracy:  Acc@1 41.920 || Acc@5 73.220\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 8, lr: 0.1 -----\n","Epoch: [8][  0/391]\tTime  0.278 ( 0.278)\tLoss 2.2963e+00 (2.2963e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  72.66 ( 72.66)\n","Epoch: [8][ 30/391]\tTime  0.174 ( 0.174)\tLoss 2.5038e+00 (2.2837e+00)\tAcc@1  35.16 ( 39.59)\tAcc@5  64.84 ( 71.95)\n","Epoch: [8][ 60/391]\tTime  0.171 ( 0.172)\tLoss 2.1949e+00 (2.2545e+00)\tAcc@1  40.62 ( 40.36)\tAcc@5  77.34 ( 72.69)\n","Epoch: [8][ 90/391]\tTime  0.168 ( 0.171)\tLoss 2.1750e+00 (2.2310e+00)\tAcc@1  41.41 ( 40.79)\tAcc@5  72.66 ( 73.08)\n","Epoch: [8][120/391]\tTime  0.169 ( 0.171)\tLoss 2.2793e+00 (2.2436e+00)\tAcc@1  36.72 ( 40.79)\tAcc@5  75.78 ( 72.90)\n","Epoch: [8][150/391]\tTime  0.170 ( 0.170)\tLoss 2.0989e+00 (2.2433e+00)\tAcc@1  46.88 ( 40.89)\tAcc@5  75.78 ( 72.89)\n","Epoch: [8][180/391]\tTime  0.169 ( 0.170)\tLoss 1.9959e+00 (2.2307e+00)\tAcc@1  50.00 ( 41.27)\tAcc@5  74.22 ( 73.12)\n","Epoch: [8][210/391]\tTime  0.171 ( 0.170)\tLoss 2.0498e+00 (2.2346e+00)\tAcc@1  48.44 ( 41.07)\tAcc@5  73.44 ( 73.03)\n","Epoch: [8][240/391]\tTime  0.169 ( 0.170)\tLoss 2.1026e+00 (2.2347e+00)\tAcc@1  39.06 ( 41.04)\tAcc@5  77.34 ( 72.96)\n","Epoch: [8][270/391]\tTime  0.170 ( 0.170)\tLoss 2.4847e+00 (2.2402e+00)\tAcc@1  38.28 ( 40.85)\tAcc@5  66.41 ( 72.80)\n","Epoch: [8][300/391]\tTime  0.170 ( 0.170)\tLoss 2.0555e+00 (2.2351e+00)\tAcc@1  42.19 ( 40.91)\tAcc@5  75.78 ( 72.85)\n","Epoch: [8][330/391]\tTime  0.170 ( 0.170)\tLoss 2.3742e+00 (2.2399e+00)\tAcc@1  42.19 ( 40.78)\tAcc@5  66.41 ( 72.78)\n","Epoch: [8][360/391]\tTime  0.170 ( 0.170)\tLoss 2.2920e+00 (2.2424e+00)\tAcc@1  39.06 ( 40.67)\tAcc@5  74.22 ( 72.82)\n","Epoch: [8][390/391]\tTime  0.152 ( 0.170)\tLoss 1.9846e+00 (2.2406e+00)\tAcc@1  46.25 ( 40.78)\tAcc@5  76.25 ( 72.83)\n","==> Train Accuracy: Acc@1 40.776 || Acc@5 72.832\n","==> Test Accuracy:  Acc@1 32.810 || Acc@5 62.650\n","==> 70.64 seconds to train this epoch\n","\n","\n","----- epoch: 9, lr: 0.1 -----\n","Epoch: [9][  0/391]\tTime  0.273 ( 0.273)\tLoss 2.1862e+00 (2.1862e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5  75.78 ( 75.78)\n","Epoch: [9][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.9912e+00 (2.1688e+00)\tAcc@1  44.53 ( 41.61)\tAcc@5  79.69 ( 73.92)\n","Epoch: [9][ 60/391]\tTime  0.169 ( 0.171)\tLoss 2.2894e+00 (2.1649e+00)\tAcc@1  37.50 ( 41.71)\tAcc@5  71.88 ( 74.37)\n","Epoch: [9][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.1611e+00 (2.1598e+00)\tAcc@1  41.41 ( 42.14)\tAcc@5  76.56 ( 74.55)\n","Epoch: [9][120/391]\tTime  0.168 ( 0.170)\tLoss 2.2091e+00 (2.1626e+00)\tAcc@1  44.53 ( 42.23)\tAcc@5  75.00 ( 74.55)\n","Epoch: [9][150/391]\tTime  0.169 ( 0.170)\tLoss 2.2310e+00 (2.1563e+00)\tAcc@1  43.75 ( 42.53)\tAcc@5  66.41 ( 74.45)\n","Epoch: [9][180/391]\tTime  0.170 ( 0.170)\tLoss 2.2170e+00 (2.1506e+00)\tAcc@1  41.41 ( 42.56)\tAcc@5  72.66 ( 74.57)\n","Epoch: [9][210/391]\tTime  0.170 ( 0.170)\tLoss 2.2568e+00 (2.1423e+00)\tAcc@1  38.28 ( 42.72)\tAcc@5  73.44 ( 74.67)\n","Epoch: [9][240/391]\tTime  0.170 ( 0.170)\tLoss 2.1052e+00 (2.1439e+00)\tAcc@1  46.09 ( 42.78)\tAcc@5  80.47 ( 74.66)\n","Epoch: [9][270/391]\tTime  0.169 ( 0.170)\tLoss 1.8893e+00 (2.1444e+00)\tAcc@1  45.31 ( 42.68)\tAcc@5  81.25 ( 74.71)\n","Epoch: [9][300/391]\tTime  0.169 ( 0.170)\tLoss 2.0483e+00 (2.1391e+00)\tAcc@1  42.97 ( 42.85)\tAcc@5  76.56 ( 74.81)\n","Epoch: [9][330/391]\tTime  0.169 ( 0.170)\tLoss 2.1917e+00 (2.1405e+00)\tAcc@1  41.41 ( 42.74)\tAcc@5  73.44 ( 74.80)\n","Epoch: [9][360/391]\tTime  0.169 ( 0.170)\tLoss 2.1310e+00 (2.1348e+00)\tAcc@1  42.19 ( 42.92)\tAcc@5  78.91 ( 74.97)\n","Epoch: [9][390/391]\tTime  0.154 ( 0.170)\tLoss 2.4393e+00 (2.1327e+00)\tAcc@1  37.50 ( 42.96)\tAcc@5  67.50 ( 74.96)\n","==> Train Accuracy: Acc@1 42.964 || Acc@5 74.964\n","==> Test Accuracy:  Acc@1 44.080 || Acc@5 77.180\n","==> 70.51 seconds to train this epoch\n","\n","\n","----- epoch: 10, lr: 0.1 -----\n","Epoch: [10][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.8856e+00 (1.8856e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  78.12 ( 78.12)\n","Epoch: [10][ 30/391]\tTime  0.170 ( 0.172)\tLoss 2.3372e+00 (2.0556e+00)\tAcc@1  35.16 ( 45.44)\tAcc@5  69.53 ( 75.55)\n","Epoch: [10][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.8971e+00 (2.0304e+00)\tAcc@1  50.00 ( 45.90)\tAcc@5  76.56 ( 76.14)\n","Epoch: [10][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.9092e+00 (2.0443e+00)\tAcc@1  46.09 ( 45.42)\tAcc@5  79.69 ( 76.19)\n","Epoch: [10][120/391]\tTime  0.170 ( 0.170)\tLoss 1.9572e+00 (2.0440e+00)\tAcc@1  48.44 ( 45.43)\tAcc@5  76.56 ( 76.20)\n","Epoch: [10][150/391]\tTime  0.168 ( 0.170)\tLoss 2.4344e+00 (2.0374e+00)\tAcc@1  35.16 ( 45.42)\tAcc@5  70.31 ( 76.37)\n","Epoch: [10][180/391]\tTime  0.170 ( 0.170)\tLoss 2.0252e+00 (2.0235e+00)\tAcc@1  46.09 ( 45.72)\tAcc@5  77.34 ( 76.74)\n","Epoch: [10][210/391]\tTime  0.170 ( 0.170)\tLoss 1.9614e+00 (2.0262e+00)\tAcc@1  46.09 ( 45.67)\tAcc@5  76.56 ( 76.64)\n","Epoch: [10][240/391]\tTime  0.169 ( 0.170)\tLoss 2.1447e+00 (2.0260e+00)\tAcc@1  43.75 ( 45.67)\tAcc@5  77.34 ( 76.73)\n","Epoch: [10][270/391]\tTime  0.169 ( 0.170)\tLoss 1.8443e+00 (2.0291e+00)\tAcc@1  51.56 ( 45.68)\tAcc@5  78.91 ( 76.71)\n","Epoch: [10][300/391]\tTime  0.169 ( 0.170)\tLoss 1.9651e+00 (2.0319e+00)\tAcc@1  44.53 ( 45.67)\tAcc@5  79.69 ( 76.65)\n","Epoch: [10][330/391]\tTime  0.169 ( 0.170)\tLoss 2.1336e+00 (2.0355e+00)\tAcc@1  50.00 ( 45.53)\tAcc@5  74.22 ( 76.59)\n","Epoch: [10][360/391]\tTime  0.169 ( 0.170)\tLoss 2.0057e+00 (2.0357e+00)\tAcc@1  43.75 ( 45.46)\tAcc@5  79.69 ( 76.61)\n","Epoch: [10][390/391]\tTime  0.154 ( 0.170)\tLoss 2.2814e+00 (2.0350e+00)\tAcc@1  35.00 ( 45.47)\tAcc@5  70.00 ( 76.61)\n","==> Train Accuracy: Acc@1 45.468 || Acc@5 76.606\n","==> Test Accuracy:  Acc@1 49.680 || Acc@5 79.680\n","==> 70.51 seconds to train this epoch\n","\n","\n","----- epoch: 11, lr: 0.1 -----\n","Epoch: [11][  0/391]\tTime  0.295 ( 0.295)\tLoss 2.2753e+00 (2.2753e+00)\tAcc@1  39.84 ( 39.84)\tAcc@5  75.78 ( 75.78)\n","Epoch: [11][ 30/391]\tTime  0.169 ( 0.173)\tLoss 2.0782e+00 (1.9387e+00)\tAcc@1  42.97 ( 47.98)\tAcc@5  74.22 ( 78.83)\n","Epoch: [11][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.8187e+00 (1.9097e+00)\tAcc@1  48.44 ( 48.39)\tAcc@5  78.12 ( 79.21)\n","Epoch: [11][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.9319e+00 (1.9198e+00)\tAcc@1  49.22 ( 47.89)\tAcc@5  75.78 ( 79.13)\n","Epoch: [11][120/391]\tTime  0.169 ( 0.170)\tLoss 2.2443e+00 (1.9339e+00)\tAcc@1  35.16 ( 47.67)\tAcc@5  69.53 ( 78.76)\n","Epoch: [11][150/391]\tTime  0.170 ( 0.170)\tLoss 1.9604e+00 (1.9301e+00)\tAcc@1  50.00 ( 47.68)\tAcc@5  79.69 ( 78.88)\n","Epoch: [11][180/391]\tTime  0.170 ( 0.170)\tLoss 2.0477e+00 (1.9328e+00)\tAcc@1  41.41 ( 47.44)\tAcc@5  80.47 ( 78.80)\n","Epoch: [11][210/391]\tTime  0.170 ( 0.170)\tLoss 1.9411e+00 (1.9374e+00)\tAcc@1  46.09 ( 47.37)\tAcc@5  78.91 ( 78.65)\n","Epoch: [11][240/391]\tTime  0.170 ( 0.170)\tLoss 2.0349e+00 (1.9360e+00)\tAcc@1  50.00 ( 47.33)\tAcc@5  75.00 ( 78.63)\n","Epoch: [11][270/391]\tTime  0.169 ( 0.170)\tLoss 2.0510e+00 (1.9383e+00)\tAcc@1  50.78 ( 47.24)\tAcc@5  77.34 ( 78.53)\n","Epoch: [11][300/391]\tTime  0.170 ( 0.170)\tLoss 1.8424e+00 (1.9410e+00)\tAcc@1  50.78 ( 47.23)\tAcc@5  76.56 ( 78.54)\n","Epoch: [11][330/391]\tTime  0.171 ( 0.170)\tLoss 1.8782e+00 (1.9469e+00)\tAcc@1  48.44 ( 47.11)\tAcc@5  84.38 ( 78.44)\n","Epoch: [11][360/391]\tTime  0.170 ( 0.170)\tLoss 2.1835e+00 (1.9474e+00)\tAcc@1  35.94 ( 47.09)\tAcc@5  73.44 ( 78.46)\n","Epoch: [11][390/391]\tTime  0.152 ( 0.170)\tLoss 2.1260e+00 (1.9455e+00)\tAcc@1  45.00 ( 47.14)\tAcc@5  78.75 ( 78.47)\n","==> Train Accuracy: Acc@1 47.144 || Acc@5 78.468\n","==> Test Accuracy:  Acc@1 48.390 || Acc@5 79.550\n","==> 70.56 seconds to train this epoch\n","\n","\n","----- epoch: 12, lr: 0.1 -----\n","Epoch: [12][  0/391]\tTime  0.266 ( 0.266)\tLoss 1.6559e+00 (1.6559e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  87.50 ( 87.50)\n","Epoch: [12][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.9021e+00 (1.8717e+00)\tAcc@1  42.19 ( 48.77)\tAcc@5  82.81 ( 79.96)\n","Epoch: [12][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.8251e+00 (1.8654e+00)\tAcc@1  47.66 ( 49.24)\tAcc@5  80.47 ( 80.14)\n","Epoch: [12][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.8090e+00 (1.8520e+00)\tAcc@1  57.03 ( 49.67)\tAcc@5  82.81 ( 80.12)\n","Epoch: [12][120/391]\tTime  0.168 ( 0.170)\tLoss 1.8199e+00 (1.8697e+00)\tAcc@1  45.31 ( 49.31)\tAcc@5  80.47 ( 79.78)\n","Epoch: [12][150/391]\tTime  0.169 ( 0.170)\tLoss 2.0004e+00 (1.8748e+00)\tAcc@1  49.22 ( 49.18)\tAcc@5  75.78 ( 79.62)\n","Epoch: [12][180/391]\tTime  0.171 ( 0.170)\tLoss 1.6829e+00 (1.8721e+00)\tAcc@1  50.78 ( 49.12)\tAcc@5  82.81 ( 79.62)\n","Epoch: [12][210/391]\tTime  0.168 ( 0.170)\tLoss 1.6283e+00 (1.8701e+00)\tAcc@1  56.25 ( 49.16)\tAcc@5  82.81 ( 79.74)\n","Epoch: [12][240/391]\tTime  0.170 ( 0.170)\tLoss 1.9141e+00 (1.8771e+00)\tAcc@1  48.44 ( 48.99)\tAcc@5  77.34 ( 79.61)\n","Epoch: [12][270/391]\tTime  0.169 ( 0.170)\tLoss 1.7361e+00 (1.8795e+00)\tAcc@1  57.03 ( 48.94)\tAcc@5  82.03 ( 79.53)\n","Epoch: [12][300/391]\tTime  0.170 ( 0.170)\tLoss 1.8851e+00 (1.8778e+00)\tAcc@1  46.88 ( 48.99)\tAcc@5  78.91 ( 79.55)\n","Epoch: [12][330/391]\tTime  0.170 ( 0.170)\tLoss 1.7656e+00 (1.8789e+00)\tAcc@1  49.22 ( 48.94)\tAcc@5  84.38 ( 79.55)\n","Epoch: [12][360/391]\tTime  0.171 ( 0.170)\tLoss 1.9546e+00 (1.8853e+00)\tAcc@1  50.78 ( 48.73)\tAcc@5  78.12 ( 79.44)\n","Epoch: [12][390/391]\tTime  0.153 ( 0.170)\tLoss 2.0503e+00 (1.8847e+00)\tAcc@1  45.00 ( 48.74)\tAcc@5  76.25 ( 79.43)\n","==> Train Accuracy: Acc@1 48.744 || Acc@5 79.434\n","==> Test Accuracy:  Acc@1 50.810 || Acc@5 81.620\n","==> 70.57 seconds to train this epoch\n","\n","\n","----- epoch: 13, lr: 0.1 -----\n","Epoch: [13][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.6684e+00 (1.6684e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  82.03 ( 82.03)\n","Epoch: [13][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.7915e+00 (1.7922e+00)\tAcc@1  50.78 ( 51.23)\tAcc@5  87.50 ( 81.30)\n","Epoch: [13][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.8989e+00 (1.7892e+00)\tAcc@1  53.12 ( 51.18)\tAcc@5  76.56 ( 81.16)\n","Epoch: [13][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.9875e+00 (1.8013e+00)\tAcc@1  44.53 ( 50.82)\tAcc@5  78.91 ( 81.09)\n","Epoch: [13][120/391]\tTime  0.169 ( 0.170)\tLoss 2.0352e+00 (1.8101e+00)\tAcc@1  44.53 ( 50.58)\tAcc@5  75.78 ( 80.89)\n","Epoch: [13][150/391]\tTime  0.170 ( 0.170)\tLoss 1.7894e+00 (1.8093e+00)\tAcc@1  50.78 ( 50.52)\tAcc@5  80.47 ( 80.96)\n","Epoch: [13][180/391]\tTime  0.172 ( 0.170)\tLoss 2.1236e+00 (1.8100e+00)\tAcc@1  46.09 ( 50.54)\tAcc@5  73.44 ( 81.01)\n","Epoch: [13][210/391]\tTime  0.170 ( 0.170)\tLoss 1.6917e+00 (1.8174e+00)\tAcc@1  49.22 ( 50.29)\tAcc@5  82.03 ( 80.87)\n","Epoch: [13][240/391]\tTime  0.169 ( 0.170)\tLoss 1.6159e+00 (1.8272e+00)\tAcc@1  56.25 ( 49.98)\tAcc@5  85.94 ( 80.72)\n","Epoch: [13][270/391]\tTime  0.170 ( 0.170)\tLoss 2.1265e+00 (1.8264e+00)\tAcc@1  48.44 ( 50.03)\tAcc@5  75.78 ( 80.69)\n","Epoch: [13][300/391]\tTime  0.171 ( 0.170)\tLoss 1.8722e+00 (1.8216e+00)\tAcc@1  54.69 ( 50.18)\tAcc@5  77.34 ( 80.72)\n","Epoch: [13][330/391]\tTime  0.169 ( 0.170)\tLoss 1.9466e+00 (1.8257e+00)\tAcc@1  53.91 ( 50.17)\tAcc@5  77.34 ( 80.62)\n","Epoch: [13][360/391]\tTime  0.169 ( 0.170)\tLoss 1.7648e+00 (1.8282e+00)\tAcc@1  55.47 ( 50.20)\tAcc@5  77.34 ( 80.53)\n","Epoch: [13][390/391]\tTime  0.152 ( 0.170)\tLoss 1.8475e+00 (1.8291e+00)\tAcc@1  48.75 ( 50.15)\tAcc@5  85.00 ( 80.53)\n","==> Train Accuracy: Acc@1 50.148 || Acc@5 80.526\n","==> Test Accuracy:  Acc@1 52.630 || Acc@5 81.650\n","==> 70.59 seconds to train this epoch\n","\n","\n","----- epoch: 14, lr: 0.1 -----\n","Epoch: [14][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.6783e+00 (1.6783e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  85.16 ( 85.16)\n","Epoch: [14][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.8457e+00 (1.7854e+00)\tAcc@1  45.31 ( 51.94)\tAcc@5  80.47 ( 81.45)\n","Epoch: [14][ 60/391]\tTime  0.174 ( 0.171)\tLoss 1.7263e+00 (1.8002e+00)\tAcc@1  48.44 ( 50.92)\tAcc@5  84.38 ( 80.84)\n","Epoch: [14][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.0510e+00 (1.7867e+00)\tAcc@1  42.97 ( 51.06)\tAcc@5  77.34 ( 81.42)\n","Epoch: [14][120/391]\tTime  0.170 ( 0.170)\tLoss 1.6332e+00 (1.7890e+00)\tAcc@1  57.03 ( 51.04)\tAcc@5  82.81 ( 81.57)\n","Epoch: [14][150/391]\tTime  0.171 ( 0.170)\tLoss 1.5825e+00 (1.7907e+00)\tAcc@1  57.81 ( 50.96)\tAcc@5  82.03 ( 81.48)\n","Epoch: [14][180/391]\tTime  0.170 ( 0.170)\tLoss 1.7743e+00 (1.7937e+00)\tAcc@1  52.34 ( 50.86)\tAcc@5  77.34 ( 81.36)\n","Epoch: [14][210/391]\tTime  0.169 ( 0.170)\tLoss 1.9436e+00 (1.7895e+00)\tAcc@1  46.88 ( 51.01)\tAcc@5  76.56 ( 81.32)\n","Epoch: [14][240/391]\tTime  0.163 ( 0.170)\tLoss 1.9580e+00 (1.7891e+00)\tAcc@1  49.22 ( 50.96)\tAcc@5  78.91 ( 81.37)\n","Epoch: [14][270/391]\tTime  0.170 ( 0.170)\tLoss 1.8556e+00 (1.7913e+00)\tAcc@1  50.00 ( 50.79)\tAcc@5  78.91 ( 81.35)\n","Epoch: [14][300/391]\tTime  0.173 ( 0.170)\tLoss 2.0082e+00 (1.7915e+00)\tAcc@1  46.88 ( 50.84)\tAcc@5  78.12 ( 81.32)\n","Epoch: [14][330/391]\tTime  0.170 ( 0.170)\tLoss 1.9051e+00 (1.7941e+00)\tAcc@1  45.31 ( 50.84)\tAcc@5  82.81 ( 81.22)\n","Epoch: [14][360/391]\tTime  0.171 ( 0.170)\tLoss 2.0734e+00 (1.7952e+00)\tAcc@1  42.19 ( 50.83)\tAcc@5  71.88 ( 81.15)\n","Epoch: [14][390/391]\tTime  0.153 ( 0.170)\tLoss 1.9649e+00 (1.7962e+00)\tAcc@1  38.75 ( 50.81)\tAcc@5  80.00 ( 81.10)\n","==> Train Accuracy: Acc@1 50.808 || Acc@5 81.096\n","==> Test Accuracy:  Acc@1 49.640 || Acc@5 79.400\n","==> 70.61 seconds to train this epoch\n","\n","\n","----- epoch: 15, lr: 0.1 -----\n","Epoch: [15][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.5980e+00 (1.5980e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  85.94 ( 85.94)\n","Epoch: [15][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.7722e+00 (1.6780e+00)\tAcc@1  52.34 ( 53.50)\tAcc@5  84.38 ( 83.37)\n","Epoch: [15][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.6891e+00 (1.6976e+00)\tAcc@1  52.34 ( 53.23)\tAcc@5  81.25 ( 82.72)\n","Epoch: [15][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.7194e+00 (1.7145e+00)\tAcc@1  47.66 ( 52.64)\tAcc@5  83.59 ( 82.28)\n","Epoch: [15][120/391]\tTime  0.170 ( 0.170)\tLoss 1.7048e+00 (1.7392e+00)\tAcc@1  54.69 ( 52.11)\tAcc@5  82.81 ( 81.99)\n","Epoch: [15][150/391]\tTime  0.169 ( 0.170)\tLoss 1.9169e+00 (1.7406e+00)\tAcc@1  47.66 ( 51.90)\tAcc@5  77.34 ( 81.95)\n","Epoch: [15][180/391]\tTime  0.170 ( 0.170)\tLoss 1.5922e+00 (1.7383e+00)\tAcc@1  58.59 ( 52.05)\tAcc@5  84.38 ( 81.94)\n","Epoch: [15][210/391]\tTime  0.168 ( 0.170)\tLoss 1.7311e+00 (1.7355e+00)\tAcc@1  48.44 ( 52.07)\tAcc@5  85.16 ( 82.06)\n","Epoch: [15][240/391]\tTime  0.170 ( 0.170)\tLoss 1.8234e+00 (1.7393e+00)\tAcc@1  51.56 ( 52.04)\tAcc@5  81.25 ( 81.96)\n","Epoch: [15][270/391]\tTime  0.171 ( 0.170)\tLoss 1.5581e+00 (1.7429e+00)\tAcc@1  60.94 ( 52.02)\tAcc@5  82.03 ( 81.92)\n","Epoch: [15][300/391]\tTime  0.171 ( 0.170)\tLoss 1.7986e+00 (1.7477e+00)\tAcc@1  54.69 ( 51.98)\tAcc@5  82.81 ( 81.81)\n","Epoch: [15][330/391]\tTime  0.170 ( 0.170)\tLoss 1.9874e+00 (1.7481e+00)\tAcc@1  49.22 ( 52.04)\tAcc@5  77.34 ( 81.77)\n","Epoch: [15][360/391]\tTime  0.169 ( 0.170)\tLoss 1.6901e+00 (1.7469e+00)\tAcc@1  51.56 ( 52.01)\tAcc@5  78.91 ( 81.83)\n","Epoch: [15][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6464e+00 (1.7467e+00)\tAcc@1  51.25 ( 52.04)\tAcc@5  85.00 ( 81.81)\n","==> Train Accuracy: Acc@1 52.036 || Acc@5 81.808\n","==> Test Accuracy:  Acc@1 51.560 || Acc@5 82.140\n","==> 70.61 seconds to train this epoch\n","\n","\n","----- epoch: 16, lr: 0.1 -----\n","Epoch: [16][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.7836e+00 (1.7836e+00)\tAcc@1  45.31 ( 45.31)\tAcc@5  82.81 ( 82.81)\n","Epoch: [16][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.6611e+00 (1.7115e+00)\tAcc@1  55.47 ( 52.22)\tAcc@5  85.16 ( 82.84)\n","Epoch: [16][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.7947e+00 (1.6906e+00)\tAcc@1  54.69 ( 53.43)\tAcc@5  78.91 ( 83.31)\n","Epoch: [16][ 90/391]\tTime  0.168 ( 0.171)\tLoss 1.6501e+00 (1.7017e+00)\tAcc@1  57.03 ( 53.45)\tAcc@5  86.72 ( 82.93)\n","Epoch: [16][120/391]\tTime  0.170 ( 0.171)\tLoss 1.6349e+00 (1.7011e+00)\tAcc@1  53.12 ( 53.27)\tAcc@5  88.28 ( 83.05)\n","Epoch: [16][150/391]\tTime  0.170 ( 0.170)\tLoss 1.6871e+00 (1.7070e+00)\tAcc@1  52.34 ( 53.09)\tAcc@5  82.03 ( 82.81)\n","Epoch: [16][180/391]\tTime  0.173 ( 0.170)\tLoss 1.3091e+00 (1.7031e+00)\tAcc@1  64.06 ( 53.17)\tAcc@5  91.41 ( 82.86)\n","Epoch: [16][210/391]\tTime  0.169 ( 0.170)\tLoss 1.7574e+00 (1.7043e+00)\tAcc@1  46.88 ( 53.01)\tAcc@5  83.59 ( 82.78)\n","Epoch: [16][240/391]\tTime  0.168 ( 0.170)\tLoss 1.7913e+00 (1.7054e+00)\tAcc@1  53.91 ( 53.12)\tAcc@5  80.47 ( 82.78)\n","Epoch: [16][270/391]\tTime  0.169 ( 0.170)\tLoss 1.7643e+00 (1.7058e+00)\tAcc@1  55.47 ( 53.17)\tAcc@5  80.47 ( 82.77)\n","Epoch: [16][300/391]\tTime  0.168 ( 0.170)\tLoss 1.5854e+00 (1.7101e+00)\tAcc@1  57.03 ( 53.03)\tAcc@5  82.03 ( 82.67)\n","Epoch: [16][330/391]\tTime  0.170 ( 0.170)\tLoss 2.0409e+00 (1.7184e+00)\tAcc@1  39.84 ( 52.70)\tAcc@5  75.78 ( 82.51)\n","Epoch: [16][360/391]\tTime  0.169 ( 0.170)\tLoss 1.7051e+00 (1.7200e+00)\tAcc@1  50.78 ( 52.61)\tAcc@5  82.03 ( 82.48)\n","Epoch: [16][390/391]\tTime  0.154 ( 0.170)\tLoss 1.5098e+00 (1.7212e+00)\tAcc@1  57.50 ( 52.59)\tAcc@5  82.50 ( 82.41)\n","==> Train Accuracy: Acc@1 52.586 || Acc@5 82.406\n","==> Test Accuracy:  Acc@1 50.710 || Acc@5 81.850\n","==> 70.63 seconds to train this epoch\n","\n","\n","----- epoch: 17, lr: 0.1 -----\n","Epoch: [17][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.4390e+00 (1.4390e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  85.94 ( 85.94)\n","Epoch: [17][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.6681e+00 (1.6293e+00)\tAcc@1  58.59 ( 54.16)\tAcc@5  78.91 ( 84.05)\n","Epoch: [17][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.8008e+00 (1.6690e+00)\tAcc@1  50.78 ( 53.34)\tAcc@5  81.25 ( 83.41)\n","Epoch: [17][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.6368e+00 (1.6690e+00)\tAcc@1  58.59 ( 53.51)\tAcc@5  81.25 ( 83.26)\n","Epoch: [17][120/391]\tTime  0.169 ( 0.170)\tLoss 1.7507e+00 (1.6731e+00)\tAcc@1  50.78 ( 53.52)\tAcc@5  83.59 ( 82.94)\n","Epoch: [17][150/391]\tTime  0.170 ( 0.170)\tLoss 1.7571e+00 (1.6744e+00)\tAcc@1  48.44 ( 53.36)\tAcc@5  83.59 ( 82.86)\n","Epoch: [17][180/391]\tTime  0.169 ( 0.170)\tLoss 1.9974e+00 (1.6877e+00)\tAcc@1  51.56 ( 53.17)\tAcc@5  75.00 ( 82.74)\n","Epoch: [17][210/391]\tTime  0.169 ( 0.170)\tLoss 1.5998e+00 (1.6865e+00)\tAcc@1  54.69 ( 53.26)\tAcc@5  88.28 ( 82.88)\n","Epoch: [17][240/391]\tTime  0.172 ( 0.170)\tLoss 1.6912e+00 (1.6837e+00)\tAcc@1  57.03 ( 53.43)\tAcc@5  82.03 ( 82.86)\n","Epoch: [17][270/391]\tTime  0.171 ( 0.170)\tLoss 1.6269e+00 (1.6871e+00)\tAcc@1  56.25 ( 53.31)\tAcc@5  82.03 ( 82.78)\n","Epoch: [17][300/391]\tTime  0.171 ( 0.170)\tLoss 1.8234e+00 (1.6923e+00)\tAcc@1  50.78 ( 53.20)\tAcc@5  78.12 ( 82.73)\n","Epoch: [17][330/391]\tTime  0.171 ( 0.170)\tLoss 1.8750e+00 (1.6931e+00)\tAcc@1  51.56 ( 53.39)\tAcc@5  78.12 ( 82.69)\n","Epoch: [17][360/391]\tTime  0.172 ( 0.170)\tLoss 1.6979e+00 (1.6927e+00)\tAcc@1  52.34 ( 53.33)\tAcc@5  84.38 ( 82.75)\n","Epoch: [17][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5309e+00 (1.6945e+00)\tAcc@1  48.75 ( 53.30)\tAcc@5  87.50 ( 82.75)\n","==> Train Accuracy: Acc@1 53.296 || Acc@5 82.750\n","==> Test Accuracy:  Acc@1 52.720 || Acc@5 82.090\n","==> 70.60 seconds to train this epoch\n","\n","\n","----- epoch: 18, lr: 0.1 -----\n","Epoch: [18][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.7161e+00 (1.7161e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  82.81 ( 82.81)\n","Epoch: [18][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.4082e+00 (1.6482e+00)\tAcc@1  64.84 ( 55.29)\tAcc@5  88.28 ( 83.42)\n","Epoch: [18][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.7867e+00 (1.6200e+00)\tAcc@1  50.00 ( 55.61)\tAcc@5  77.34 ( 83.70)\n","Epoch: [18][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4771e+00 (1.6208e+00)\tAcc@1  50.78 ( 55.50)\tAcc@5  86.72 ( 84.00)\n","Epoch: [18][120/391]\tTime  0.169 ( 0.170)\tLoss 1.5548e+00 (1.6255e+00)\tAcc@1  58.59 ( 55.31)\tAcc@5  86.72 ( 83.92)\n","Epoch: [18][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5559e+00 (1.6337e+00)\tAcc@1  57.81 ( 55.25)\tAcc@5  83.59 ( 83.75)\n","Epoch: [18][180/391]\tTime  0.169 ( 0.170)\tLoss 1.8056e+00 (1.6434e+00)\tAcc@1  52.34 ( 55.01)\tAcc@5  78.91 ( 83.70)\n","Epoch: [18][210/391]\tTime  0.171 ( 0.170)\tLoss 1.8335e+00 (1.6457e+00)\tAcc@1  47.66 ( 54.71)\tAcc@5  80.47 ( 83.72)\n","Epoch: [18][240/391]\tTime  0.170 ( 0.170)\tLoss 1.6910e+00 (1.6487e+00)\tAcc@1  51.56 ( 54.45)\tAcc@5  82.81 ( 83.74)\n","Epoch: [18][270/391]\tTime  0.169 ( 0.170)\tLoss 1.2792e+00 (1.6508e+00)\tAcc@1  65.62 ( 54.39)\tAcc@5  91.41 ( 83.65)\n","Epoch: [18][300/391]\tTime  0.170 ( 0.170)\tLoss 1.8075e+00 (1.6520e+00)\tAcc@1  48.44 ( 54.43)\tAcc@5  82.81 ( 83.57)\n","Epoch: [18][330/391]\tTime  0.170 ( 0.170)\tLoss 1.7963e+00 (1.6544e+00)\tAcc@1  51.56 ( 54.38)\tAcc@5  81.25 ( 83.51)\n","Epoch: [18][360/391]\tTime  0.168 ( 0.170)\tLoss 1.5836e+00 (1.6580e+00)\tAcc@1  53.12 ( 54.35)\tAcc@5  85.94 ( 83.41)\n","Epoch: [18][390/391]\tTime  0.152 ( 0.170)\tLoss 1.9191e+00 (1.6592e+00)\tAcc@1  52.50 ( 54.32)\tAcc@5  82.50 ( 83.33)\n","==> Train Accuracy: Acc@1 54.316 || Acc@5 83.334\n","==> Test Accuracy:  Acc@1 54.800 || Acc@5 83.300\n","==> 70.60 seconds to train this epoch\n","\n","\n","----- epoch: 19, lr: 0.1 -----\n","Epoch: [19][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.5705e+00 (1.5705e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  84.38 ( 84.38)\n","Epoch: [19][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.5281e+00 (1.5211e+00)\tAcc@1  62.50 ( 57.66)\tAcc@5  86.72 ( 85.94)\n","Epoch: [19][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.6309e+00 (1.5608e+00)\tAcc@1  54.69 ( 56.35)\tAcc@5  85.16 ( 85.21)\n","Epoch: [19][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.5585e+00 (1.5822e+00)\tAcc@1  58.59 ( 55.93)\tAcc@5  86.72 ( 84.71)\n","Epoch: [19][120/391]\tTime  0.170 ( 0.170)\tLoss 1.8289e+00 (1.5907e+00)\tAcc@1  46.09 ( 55.95)\tAcc@5  78.91 ( 84.69)\n","Epoch: [19][150/391]\tTime  0.169 ( 0.170)\tLoss 1.4805e+00 (1.5935e+00)\tAcc@1  60.16 ( 55.84)\tAcc@5  82.03 ( 84.59)\n","Epoch: [19][180/391]\tTime  0.169 ( 0.170)\tLoss 1.8809e+00 (1.6142e+00)\tAcc@1  50.00 ( 55.37)\tAcc@5  79.69 ( 84.29)\n","Epoch: [19][210/391]\tTime  0.170 ( 0.170)\tLoss 1.5992e+00 (1.6178e+00)\tAcc@1  55.47 ( 55.34)\tAcc@5  81.25 ( 84.22)\n","Epoch: [19][240/391]\tTime  0.172 ( 0.170)\tLoss 1.7723e+00 (1.6181e+00)\tAcc@1  51.56 ( 55.28)\tAcc@5  84.38 ( 84.21)\n","Epoch: [19][270/391]\tTime  0.170 ( 0.170)\tLoss 1.7376e+00 (1.6189e+00)\tAcc@1  57.81 ( 55.22)\tAcc@5  83.59 ( 84.23)\n","Epoch: [19][300/391]\tTime  0.170 ( 0.170)\tLoss 1.8628e+00 (1.6231e+00)\tAcc@1  50.78 ( 55.14)\tAcc@5  79.69 ( 84.13)\n","Epoch: [19][330/391]\tTime  0.169 ( 0.170)\tLoss 1.7686e+00 (1.6288e+00)\tAcc@1  48.44 ( 55.03)\tAcc@5  82.03 ( 84.02)\n","Epoch: [19][360/391]\tTime  0.170 ( 0.170)\tLoss 1.5309e+00 (1.6327e+00)\tAcc@1  58.59 ( 54.97)\tAcc@5  83.59 ( 83.94)\n","Epoch: [19][390/391]\tTime  0.152 ( 0.170)\tLoss 1.5494e+00 (1.6351e+00)\tAcc@1  62.50 ( 54.88)\tAcc@5  82.50 ( 83.87)\n","==> Train Accuracy: Acc@1 54.884 || Acc@5 83.866\n","==> Test Accuracy:  Acc@1 53.200 || Acc@5 82.200\n","==> 70.62 seconds to train this epoch\n","\n","\n","----- epoch: 20, lr: 0.1 -----\n","Epoch: [20][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.6891e+00 (1.6891e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  83.59 ( 83.59)\n","Epoch: [20][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.6344e+00 (1.6061e+00)\tAcc@1  56.25 ( 54.99)\tAcc@5  82.03 ( 84.55)\n","Epoch: [20][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.6303e+00 (1.5961e+00)\tAcc@1  53.91 ( 55.52)\tAcc@5  82.81 ( 84.58)\n","Epoch: [20][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.5967e+00 (1.6096e+00)\tAcc@1  59.38 ( 55.28)\tAcc@5  85.94 ( 84.23)\n","Epoch: [20][120/391]\tTime  0.170 ( 0.170)\tLoss 1.5025e+00 (1.6034e+00)\tAcc@1  64.06 ( 55.31)\tAcc@5  84.38 ( 84.57)\n","Epoch: [20][150/391]\tTime  0.168 ( 0.170)\tLoss 1.6371e+00 (1.6018e+00)\tAcc@1  57.03 ( 55.54)\tAcc@5  82.03 ( 84.53)\n","Epoch: [20][180/391]\tTime  0.169 ( 0.170)\tLoss 1.6696e+00 (1.6052e+00)\tAcc@1  52.34 ( 55.38)\tAcc@5  85.94 ( 84.50)\n","Epoch: [20][210/391]\tTime  0.169 ( 0.170)\tLoss 1.8371e+00 (1.6102e+00)\tAcc@1  49.22 ( 55.35)\tAcc@5  79.69 ( 84.38)\n","Epoch: [20][240/391]\tTime  0.168 ( 0.170)\tLoss 1.6039e+00 (1.6162e+00)\tAcc@1  54.69 ( 55.20)\tAcc@5  82.03 ( 84.17)\n","Epoch: [20][270/391]\tTime  0.169 ( 0.170)\tLoss 1.5491e+00 (1.6163e+00)\tAcc@1  60.16 ( 55.28)\tAcc@5  84.38 ( 84.17)\n","Epoch: [20][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5058e+00 (1.6112e+00)\tAcc@1  55.47 ( 55.42)\tAcc@5  87.50 ( 84.30)\n","Epoch: [20][330/391]\tTime  0.170 ( 0.170)\tLoss 1.4069e+00 (1.6182e+00)\tAcc@1  63.28 ( 55.27)\tAcc@5  87.50 ( 84.12)\n","Epoch: [20][360/391]\tTime  0.170 ( 0.170)\tLoss 1.7133e+00 (1.6249e+00)\tAcc@1  48.44 ( 55.11)\tAcc@5  78.12 ( 83.98)\n","Epoch: [20][390/391]\tTime  0.153 ( 0.170)\tLoss 1.7447e+00 (1.6262e+00)\tAcc@1  56.25 ( 55.06)\tAcc@5  80.00 ( 83.96)\n","==> Train Accuracy: Acc@1 55.064 || Acc@5 83.956\n","==> Test Accuracy:  Acc@1 54.190 || Acc@5 83.940\n","==> 70.61 seconds to train this epoch\n","\n","\n","----- epoch: 21, lr: 0.1 -----\n","Epoch: [21][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.6001e+00 (1.6001e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  84.38 ( 84.38)\n","Epoch: [21][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.4602e+00 (1.5472e+00)\tAcc@1  60.94 ( 56.75)\tAcc@5  88.28 ( 85.64)\n","Epoch: [21][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.7842e+00 (1.5448e+00)\tAcc@1  53.12 ( 56.81)\tAcc@5  82.03 ( 85.64)\n","Epoch: [21][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.8312e+00 (1.5489e+00)\tAcc@1  49.22 ( 56.89)\tAcc@5  78.91 ( 85.23)\n","Epoch: [21][120/391]\tTime  0.170 ( 0.170)\tLoss 1.8062e+00 (1.5663e+00)\tAcc@1  46.88 ( 56.46)\tAcc@5  84.38 ( 84.85)\n","Epoch: [21][150/391]\tTime  0.170 ( 0.170)\tLoss 1.3397e+00 (1.5688e+00)\tAcc@1  62.50 ( 56.29)\tAcc@5  90.62 ( 84.90)\n","Epoch: [21][180/391]\tTime  0.171 ( 0.170)\tLoss 1.5768e+00 (1.5809e+00)\tAcc@1  60.94 ( 56.09)\tAcc@5  82.81 ( 84.65)\n","Epoch: [21][210/391]\tTime  0.169 ( 0.170)\tLoss 1.5310e+00 (1.5894e+00)\tAcc@1  57.03 ( 55.80)\tAcc@5  85.94 ( 84.48)\n","Epoch: [21][240/391]\tTime  0.169 ( 0.170)\tLoss 1.7987e+00 (1.5883e+00)\tAcc@1  55.47 ( 55.83)\tAcc@5  76.56 ( 84.53)\n","Epoch: [21][270/391]\tTime  0.171 ( 0.170)\tLoss 1.5771e+00 (1.5894e+00)\tAcc@1  56.25 ( 55.78)\tAcc@5  85.94 ( 84.50)\n","Epoch: [21][300/391]\tTime  0.170 ( 0.170)\tLoss 1.6419e+00 (1.5934e+00)\tAcc@1  55.47 ( 55.72)\tAcc@5  86.72 ( 84.46)\n","Epoch: [21][330/391]\tTime  0.170 ( 0.170)\tLoss 1.5389e+00 (1.5990e+00)\tAcc@1  54.69 ( 55.56)\tAcc@5  87.50 ( 84.37)\n","Epoch: [21][360/391]\tTime  0.169 ( 0.170)\tLoss 1.7184e+00 (1.6015e+00)\tAcc@1  56.25 ( 55.57)\tAcc@5  82.03 ( 84.35)\n","Epoch: [21][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6844e+00 (1.6048e+00)\tAcc@1  51.25 ( 55.49)\tAcc@5  86.25 ( 84.27)\n","==> Train Accuracy: Acc@1 55.492 || Acc@5 84.270\n","==> Test Accuracy:  Acc@1 56.760 || Acc@5 84.760\n","==> 70.62 seconds to train this epoch\n","\n","\n","----- epoch: 22, lr: 0.1 -----\n","Epoch: [22][  0/391]\tTime  0.303 ( 0.303)\tLoss 1.3766e+00 (1.3766e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  86.72 ( 86.72)\n","Epoch: [22][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.7786e+00 (1.5007e+00)\tAcc@1  47.66 ( 57.94)\tAcc@5  82.81 ( 86.44)\n","Epoch: [22][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.6829e+00 (1.5429e+00)\tAcc@1  51.56 ( 57.18)\tAcc@5  84.38 ( 85.55)\n","Epoch: [22][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.5848e+00 (1.5533e+00)\tAcc@1  55.47 ( 56.74)\tAcc@5  85.94 ( 85.46)\n","Epoch: [22][120/391]\tTime  0.169 ( 0.170)\tLoss 1.2707e+00 (1.5567e+00)\tAcc@1  66.41 ( 56.82)\tAcc@5  86.72 ( 85.34)\n","Epoch: [22][150/391]\tTime  0.170 ( 0.170)\tLoss 1.6169e+00 (1.5587e+00)\tAcc@1  52.34 ( 56.93)\tAcc@5  82.03 ( 85.30)\n","Epoch: [22][180/391]\tTime  0.169 ( 0.170)\tLoss 1.7364e+00 (1.5658e+00)\tAcc@1  56.25 ( 56.71)\tAcc@5  79.69 ( 85.22)\n","Epoch: [22][210/391]\tTime  0.170 ( 0.170)\tLoss 1.4789e+00 (1.5703e+00)\tAcc@1  64.06 ( 56.62)\tAcc@5  85.16 ( 84.99)\n","Epoch: [22][240/391]\tTime  0.171 ( 0.170)\tLoss 1.7107e+00 (1.5784e+00)\tAcc@1  53.91 ( 56.38)\tAcc@5  83.59 ( 84.86)\n","Epoch: [22][270/391]\tTime  0.170 ( 0.170)\tLoss 1.8056e+00 (1.5802e+00)\tAcc@1  53.91 ( 56.28)\tAcc@5  78.91 ( 84.80)\n","Epoch: [22][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5851e+00 (1.5823e+00)\tAcc@1  54.69 ( 56.19)\tAcc@5  82.03 ( 84.76)\n","Epoch: [22][330/391]\tTime  0.170 ( 0.170)\tLoss 1.6341e+00 (1.5805e+00)\tAcc@1  53.91 ( 56.26)\tAcc@5  84.38 ( 84.75)\n","Epoch: [22][360/391]\tTime  0.169 ( 0.170)\tLoss 1.5942e+00 (1.5813e+00)\tAcc@1  60.94 ( 56.28)\tAcc@5  82.81 ( 84.67)\n","Epoch: [22][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5763e+00 (1.5806e+00)\tAcc@1  57.50 ( 56.29)\tAcc@5  83.75 ( 84.68)\n","==> Train Accuracy: Acc@1 56.294 || Acc@5 84.676\n","==> Test Accuracy:  Acc@1 55.570 || Acc@5 85.110\n","==> 70.59 seconds to train this epoch\n","\n","\n","----- epoch: 23, lr: 0.1 -----\n","Epoch: [23][  0/391]\tTime  0.289 ( 0.289)\tLoss 1.5930e+00 (1.5930e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  84.38 ( 84.38)\n","Epoch: [23][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.4852e+00 (1.5109e+00)\tAcc@1  58.59 ( 57.96)\tAcc@5  84.38 ( 85.89)\n","Epoch: [23][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.5202e+00 (1.5144e+00)\tAcc@1  57.03 ( 58.13)\tAcc@5  86.72 ( 85.54)\n","Epoch: [23][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3671e+00 (1.5304e+00)\tAcc@1  60.94 ( 57.55)\tAcc@5  86.72 ( 85.37)\n","Epoch: [23][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4496e+00 (1.5319e+00)\tAcc@1  57.81 ( 57.53)\tAcc@5  87.50 ( 85.25)\n","Epoch: [23][150/391]\tTime  0.169 ( 0.170)\tLoss 1.3979e+00 (1.5300e+00)\tAcc@1  63.28 ( 57.60)\tAcc@5  84.38 ( 85.34)\n","Epoch: [23][180/391]\tTime  0.170 ( 0.170)\tLoss 1.3321e+00 (1.5409e+00)\tAcc@1  59.38 ( 57.33)\tAcc@5  87.50 ( 85.13)\n","Epoch: [23][210/391]\tTime  0.169 ( 0.170)\tLoss 1.5676e+00 (1.5431e+00)\tAcc@1  56.25 ( 57.26)\tAcc@5  85.16 ( 85.06)\n","Epoch: [23][240/391]\tTime  0.170 ( 0.170)\tLoss 1.5073e+00 (1.5490e+00)\tAcc@1  59.38 ( 57.05)\tAcc@5  89.06 ( 85.05)\n","Epoch: [23][270/391]\tTime  0.170 ( 0.170)\tLoss 1.6464e+00 (1.5563e+00)\tAcc@1  55.47 ( 56.82)\tAcc@5  80.47 ( 84.95)\n","Epoch: [23][300/391]\tTime  0.168 ( 0.170)\tLoss 1.6826e+00 (1.5607e+00)\tAcc@1  50.00 ( 56.64)\tAcc@5  83.59 ( 84.85)\n","Epoch: [23][330/391]\tTime  0.170 ( 0.170)\tLoss 1.6356e+00 (1.5625e+00)\tAcc@1  54.69 ( 56.67)\tAcc@5  83.59 ( 84.78)\n","Epoch: [23][360/391]\tTime  0.168 ( 0.170)\tLoss 1.9084e+00 (1.5655e+00)\tAcc@1  47.66 ( 56.59)\tAcc@5  80.47 ( 84.78)\n","Epoch: [23][390/391]\tTime  0.153 ( 0.170)\tLoss 1.7612e+00 (1.5658e+00)\tAcc@1  47.50 ( 56.64)\tAcc@5  83.75 ( 84.79)\n","==> Train Accuracy: Acc@1 56.636 || Acc@5 84.794\n","==> Test Accuracy:  Acc@1 53.500 || Acc@5 82.110\n","==> 70.52 seconds to train this epoch\n","\n","\n","----- epoch: 24, lr: 0.1 -----\n","Epoch: [24][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.5429e+00 (1.5429e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  88.28 ( 88.28)\n","Epoch: [24][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.6309e+00 (1.4857e+00)\tAcc@1  54.69 ( 58.44)\tAcc@5  82.81 ( 86.24)\n","Epoch: [24][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.4472e+00 (1.4916e+00)\tAcc@1  60.94 ( 57.98)\tAcc@5  87.50 ( 86.04)\n","Epoch: [24][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.4071e+00 (1.5137e+00)\tAcc@1  60.94 ( 57.74)\tAcc@5  86.72 ( 85.67)\n","Epoch: [24][120/391]\tTime  0.169 ( 0.170)\tLoss 1.3211e+00 (1.5213e+00)\tAcc@1  61.72 ( 57.77)\tAcc@5  90.62 ( 85.51)\n","Epoch: [24][150/391]\tTime  0.171 ( 0.170)\tLoss 1.5353e+00 (1.5305e+00)\tAcc@1  55.47 ( 57.48)\tAcc@5  89.06 ( 85.61)\n","Epoch: [24][180/391]\tTime  0.173 ( 0.170)\tLoss 1.5805e+00 (1.5338e+00)\tAcc@1  57.03 ( 57.50)\tAcc@5  88.28 ( 85.54)\n","Epoch: [24][210/391]\tTime  0.171 ( 0.170)\tLoss 1.9286e+00 (1.5363e+00)\tAcc@1  42.97 ( 57.32)\tAcc@5  80.47 ( 85.54)\n","Epoch: [24][240/391]\tTime  0.169 ( 0.170)\tLoss 1.5261e+00 (1.5429e+00)\tAcc@1  58.59 ( 57.16)\tAcc@5  84.38 ( 85.45)\n","Epoch: [24][270/391]\tTime  0.168 ( 0.170)\tLoss 1.6079e+00 (1.5420e+00)\tAcc@1  53.12 ( 57.29)\tAcc@5  87.50 ( 85.42)\n","Epoch: [24][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4521e+00 (1.5461e+00)\tAcc@1  59.38 ( 57.21)\tAcc@5  85.94 ( 85.34)\n","Epoch: [24][330/391]\tTime  0.169 ( 0.170)\tLoss 1.5468e+00 (1.5506e+00)\tAcc@1  57.03 ( 57.01)\tAcc@5  89.06 ( 85.32)\n","Epoch: [24][360/391]\tTime  0.170 ( 0.170)\tLoss 1.7514e+00 (1.5519e+00)\tAcc@1  52.34 ( 57.00)\tAcc@5  82.81 ( 85.27)\n","Epoch: [24][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6015e+00 (1.5547e+00)\tAcc@1  56.25 ( 56.96)\tAcc@5  86.25 ( 85.28)\n","==> Train Accuracy: Acc@1 56.956 || Acc@5 85.278\n","==> Test Accuracy:  Acc@1 59.080 || Acc@5 86.600\n","==> 70.49 seconds to train this epoch\n","\n","\n","----- epoch: 25, lr: 0.1 -----\n","Epoch: [25][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.3636e+00 (1.3636e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  86.72 ( 86.72)\n","Epoch: [25][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.3084e+00 (1.5116e+00)\tAcc@1  57.81 ( 57.08)\tAcc@5  93.75 ( 86.69)\n","Epoch: [25][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.5031e+00 (1.5036e+00)\tAcc@1  62.50 ( 57.91)\tAcc@5  82.03 ( 86.22)\n","Epoch: [25][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.3720e+00 (1.5098e+00)\tAcc@1  59.38 ( 58.07)\tAcc@5  91.41 ( 86.10)\n","Epoch: [25][120/391]\tTime  0.168 ( 0.170)\tLoss 1.6788e+00 (1.5200e+00)\tAcc@1  57.81 ( 58.03)\tAcc@5  79.69 ( 85.72)\n","Epoch: [25][150/391]\tTime  0.169 ( 0.170)\tLoss 1.6436e+00 (1.5249e+00)\tAcc@1  53.91 ( 57.73)\tAcc@5  86.72 ( 85.69)\n","Epoch: [25][180/391]\tTime  0.169 ( 0.170)\tLoss 1.4912e+00 (1.5238e+00)\tAcc@1  60.16 ( 57.84)\tAcc@5  84.38 ( 85.72)\n","Epoch: [25][210/391]\tTime  0.170 ( 0.170)\tLoss 1.4636e+00 (1.5239e+00)\tAcc@1  59.38 ( 57.70)\tAcc@5  85.16 ( 85.70)\n","Epoch: [25][240/391]\tTime  0.171 ( 0.170)\tLoss 1.4242e+00 (1.5335e+00)\tAcc@1  60.16 ( 57.48)\tAcc@5  89.06 ( 85.55)\n","Epoch: [25][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4955e+00 (1.5323e+00)\tAcc@1  57.81 ( 57.48)\tAcc@5  88.28 ( 85.51)\n","Epoch: [25][300/391]\tTime  0.170 ( 0.170)\tLoss 1.3761e+00 (1.5391e+00)\tAcc@1  60.94 ( 57.25)\tAcc@5  90.62 ( 85.38)\n","Epoch: [25][330/391]\tTime  0.170 ( 0.170)\tLoss 1.4080e+00 (1.5475e+00)\tAcc@1  64.06 ( 57.08)\tAcc@5  87.50 ( 85.23)\n","Epoch: [25][360/391]\tTime  0.169 ( 0.170)\tLoss 1.3738e+00 (1.5468e+00)\tAcc@1  61.72 ( 57.15)\tAcc@5  90.62 ( 85.28)\n","Epoch: [25][390/391]\tTime  0.152 ( 0.169)\tLoss 1.4640e+00 (1.5481e+00)\tAcc@1  60.00 ( 57.16)\tAcc@5  86.25 ( 85.24)\n","==> Train Accuracy: Acc@1 57.162 || Acc@5 85.236\n","==> Test Accuracy:  Acc@1 55.540 || Acc@5 83.780\n","==> 70.46 seconds to train this epoch\n","\n","\n","----- epoch: 26, lr: 0.1 -----\n","Epoch: [26][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.5914e+00 (1.5914e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  84.38 ( 84.38)\n","Epoch: [26][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3707e+00 (1.4529e+00)\tAcc@1  60.16 ( 59.12)\tAcc@5  87.50 ( 86.44)\n","Epoch: [26][ 60/391]\tTime  0.167 ( 0.171)\tLoss 1.6767e+00 (1.4654e+00)\tAcc@1  50.78 ( 58.84)\tAcc@5  82.81 ( 86.54)\n","Epoch: [26][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.2406e+00 (1.4803e+00)\tAcc@1  63.28 ( 58.65)\tAcc@5  92.19 ( 86.38)\n","Epoch: [26][120/391]\tTime  0.174 ( 0.170)\tLoss 1.5835e+00 (1.4913e+00)\tAcc@1  57.81 ( 58.35)\tAcc@5  82.81 ( 86.19)\n","Epoch: [26][150/391]\tTime  0.170 ( 0.170)\tLoss 1.5714e+00 (1.4894e+00)\tAcc@1  54.69 ( 58.42)\tAcc@5  82.81 ( 86.20)\n","Epoch: [26][180/391]\tTime  0.173 ( 0.170)\tLoss 1.4584e+00 (1.5098e+00)\tAcc@1  60.16 ( 58.03)\tAcc@5  85.16 ( 85.82)\n","Epoch: [26][210/391]\tTime  0.171 ( 0.170)\tLoss 1.4691e+00 (1.5087e+00)\tAcc@1  60.16 ( 58.08)\tAcc@5  86.72 ( 85.75)\n","Epoch: [26][240/391]\tTime  0.169 ( 0.170)\tLoss 1.5214e+00 (1.5229e+00)\tAcc@1  60.16 ( 57.81)\tAcc@5  80.47 ( 85.49)\n","Epoch: [26][270/391]\tTime  0.170 ( 0.170)\tLoss 1.3831e+00 (1.5282e+00)\tAcc@1  66.41 ( 57.63)\tAcc@5  87.50 ( 85.36)\n","Epoch: [26][300/391]\tTime  0.170 ( 0.170)\tLoss 1.7028e+00 (1.5295e+00)\tAcc@1  47.66 ( 57.52)\tAcc@5  85.16 ( 85.35)\n","Epoch: [26][330/391]\tTime  0.170 ( 0.170)\tLoss 1.5732e+00 (1.5311e+00)\tAcc@1  60.94 ( 57.45)\tAcc@5  85.16 ( 85.32)\n","Epoch: [26][360/391]\tTime  0.170 ( 0.170)\tLoss 1.4282e+00 (1.5322e+00)\tAcc@1  62.50 ( 57.47)\tAcc@5  85.94 ( 85.33)\n","Epoch: [26][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6144e+00 (1.5305e+00)\tAcc@1  51.25 ( 57.42)\tAcc@5  88.75 ( 85.40)\n","==> Train Accuracy: Acc@1 57.420 || Acc@5 85.400\n","==> Test Accuracy:  Acc@1 57.390 || Acc@5 85.650\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 27, lr: 0.1 -----\n","Epoch: [27][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.3021e+00 (1.3021e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.06 ( 89.06)\n","Epoch: [27][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.5750e+00 (1.5123e+00)\tAcc@1  54.69 ( 58.39)\tAcc@5  85.16 ( 85.91)\n","Epoch: [27][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.2507e+00 (1.5104e+00)\tAcc@1  63.28 ( 57.79)\tAcc@5  90.62 ( 85.75)\n","Epoch: [27][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4685e+00 (1.5078e+00)\tAcc@1  60.16 ( 58.11)\tAcc@5  88.28 ( 85.70)\n","Epoch: [27][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4700e+00 (1.5103e+00)\tAcc@1  59.38 ( 58.22)\tAcc@5  85.94 ( 85.73)\n","Epoch: [27][150/391]\tTime  0.170 ( 0.170)\tLoss 1.6323e+00 (1.5119e+00)\tAcc@1  54.69 ( 58.06)\tAcc@5  82.03 ( 85.73)\n","Epoch: [27][180/391]\tTime  0.170 ( 0.170)\tLoss 1.5643e+00 (1.5079e+00)\tAcc@1  50.00 ( 58.01)\tAcc@5  82.81 ( 85.73)\n","Epoch: [27][210/391]\tTime  0.171 ( 0.170)\tLoss 1.2891e+00 (1.5104e+00)\tAcc@1  61.72 ( 57.98)\tAcc@5  89.06 ( 85.70)\n","Epoch: [27][240/391]\tTime  0.170 ( 0.170)\tLoss 1.2935e+00 (1.5137e+00)\tAcc@1  64.06 ( 57.95)\tAcc@5  86.72 ( 85.63)\n","Epoch: [27][270/391]\tTime  0.169 ( 0.170)\tLoss 1.5532e+00 (1.5137e+00)\tAcc@1  55.47 ( 58.00)\tAcc@5  87.50 ( 85.59)\n","Epoch: [27][300/391]\tTime  0.171 ( 0.170)\tLoss 1.6322e+00 (1.5144e+00)\tAcc@1  56.25 ( 57.92)\tAcc@5  82.81 ( 85.61)\n","Epoch: [27][330/391]\tTime  0.168 ( 0.170)\tLoss 1.7462e+00 (1.5145e+00)\tAcc@1  50.00 ( 57.96)\tAcc@5  81.25 ( 85.59)\n","Epoch: [27][360/391]\tTime  0.170 ( 0.170)\tLoss 1.7396e+00 (1.5145e+00)\tAcc@1  53.91 ( 57.99)\tAcc@5  78.91 ( 85.57)\n","Epoch: [27][390/391]\tTime  0.154 ( 0.170)\tLoss 1.4141e+00 (1.5169e+00)\tAcc@1  58.75 ( 58.00)\tAcc@5  86.25 ( 85.47)\n","==> Train Accuracy: Acc@1 58.000 || Acc@5 85.472\n","==> Test Accuracy:  Acc@1 49.400 || Acc@5 78.840\n","==> 70.59 seconds to train this epoch\n","\n","\n","----- epoch: 28, lr: 0.1 -----\n","Epoch: [28][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.6685e+00 (1.6685e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  85.94 ( 85.94)\n","Epoch: [28][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.3533e+00 (1.4501e+00)\tAcc@1  63.28 ( 59.50)\tAcc@5  88.28 ( 87.20)\n","Epoch: [28][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.6668e+00 (1.4811e+00)\tAcc@1  57.03 ( 58.99)\tAcc@5  86.72 ( 86.59)\n","Epoch: [28][ 90/391]\tTime  0.172 ( 0.171)\tLoss 1.4441e+00 (1.4855e+00)\tAcc@1  58.59 ( 58.68)\tAcc@5  86.72 ( 86.35)\n","Epoch: [28][120/391]\tTime  0.169 ( 0.170)\tLoss 1.5314e+00 (1.4896e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.16 ( 86.29)\n","Epoch: [28][150/391]\tTime  0.171 ( 0.170)\tLoss 1.3936e+00 (1.5032e+00)\tAcc@1  64.84 ( 58.21)\tAcc@5  84.38 ( 86.04)\n","Epoch: [28][180/391]\tTime  0.167 ( 0.170)\tLoss 1.7464e+00 (1.5124e+00)\tAcc@1  57.03 ( 58.01)\tAcc@5  77.34 ( 85.81)\n","Epoch: [28][210/391]\tTime  0.169 ( 0.170)\tLoss 1.2924e+00 (1.5125e+00)\tAcc@1  62.50 ( 57.98)\tAcc@5  85.16 ( 85.71)\n","Epoch: [28][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4509e+00 (1.5168e+00)\tAcc@1  57.03 ( 57.88)\tAcc@5  89.84 ( 85.57)\n","Epoch: [28][270/391]\tTime  0.171 ( 0.170)\tLoss 1.4900e+00 (1.5127e+00)\tAcc@1  59.38 ( 57.95)\tAcc@5  84.38 ( 85.63)\n","Epoch: [28][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5172e+00 (1.5157e+00)\tAcc@1  61.72 ( 57.93)\tAcc@5  82.81 ( 85.56)\n","Epoch: [28][330/391]\tTime  0.171 ( 0.170)\tLoss 1.7935e+00 (1.5150e+00)\tAcc@1  50.00 ( 57.92)\tAcc@5  82.03 ( 85.62)\n","Epoch: [28][360/391]\tTime  0.168 ( 0.170)\tLoss 1.6920e+00 (1.5186e+00)\tAcc@1  57.03 ( 57.81)\tAcc@5  79.69 ( 85.60)\n","Epoch: [28][390/391]\tTime  0.153 ( 0.170)\tLoss 1.4283e+00 (1.5238e+00)\tAcc@1  60.00 ( 57.72)\tAcc@5  88.75 ( 85.54)\n","==> Train Accuracy: Acc@1 57.724 || Acc@5 85.538\n","==> Test Accuracy:  Acc@1 57.500 || Acc@5 85.610\n","==> 70.60 seconds to train this epoch\n","\n","\n","----- epoch: 29, lr: 0.1 -----\n","Epoch: [29][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.3999e+00 (1.3999e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  88.28 ( 88.28)\n","Epoch: [29][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.6651e+00 (1.4401e+00)\tAcc@1  50.00 ( 59.60)\tAcc@5  89.06 ( 86.92)\n","Epoch: [29][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.7544e+00 (1.4524e+00)\tAcc@1  56.25 ( 59.11)\tAcc@5  82.03 ( 86.65)\n","Epoch: [29][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.7193e+00 (1.4712e+00)\tAcc@1  54.69 ( 58.80)\tAcc@5  78.91 ( 86.49)\n","Epoch: [29][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4169e+00 (1.4767e+00)\tAcc@1  62.50 ( 58.85)\tAcc@5  86.72 ( 86.31)\n","Epoch: [29][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5669e+00 (1.4693e+00)\tAcc@1  53.12 ( 59.05)\tAcc@5  89.06 ( 86.39)\n","Epoch: [29][180/391]\tTime  0.168 ( 0.170)\tLoss 1.4722e+00 (1.4621e+00)\tAcc@1  52.34 ( 59.10)\tAcc@5  89.84 ( 86.52)\n","Epoch: [29][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3598e+00 (1.4713e+00)\tAcc@1  58.59 ( 58.78)\tAcc@5  89.06 ( 86.34)\n","Epoch: [29][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4511e+00 (1.4730e+00)\tAcc@1  58.59 ( 58.87)\tAcc@5  85.94 ( 86.32)\n","Epoch: [29][270/391]\tTime  0.170 ( 0.170)\tLoss 1.6271e+00 (1.4740e+00)\tAcc@1  51.56 ( 58.86)\tAcc@5  85.16 ( 86.29)\n","Epoch: [29][300/391]\tTime  0.171 ( 0.170)\tLoss 1.5332e+00 (1.4751e+00)\tAcc@1  57.03 ( 58.76)\tAcc@5  85.16 ( 86.25)\n","Epoch: [29][330/391]\tTime  0.169 ( 0.170)\tLoss 1.3645e+00 (1.4811e+00)\tAcc@1  61.72 ( 58.55)\tAcc@5  89.84 ( 86.15)\n","Epoch: [29][360/391]\tTime  0.170 ( 0.170)\tLoss 1.4081e+00 (1.4880e+00)\tAcc@1  59.38 ( 58.35)\tAcc@5  87.50 ( 86.10)\n","Epoch: [29][390/391]\tTime  0.151 ( 0.170)\tLoss 1.5463e+00 (1.4935e+00)\tAcc@1  56.25 ( 58.19)\tAcc@5  81.25 ( 85.99)\n","==> Train Accuracy: Acc@1 58.194 || Acc@5 85.990\n","==> Test Accuracy:  Acc@1 56.800 || Acc@5 85.760\n","==> 70.62 seconds to train this epoch\n","\n","\n","----- epoch: 30, lr: 0.1 -----\n","Epoch: [30][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.5654e+00 (1.5654e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  82.03 ( 82.03)\n","Epoch: [30][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3314e+00 (1.4158e+00)\tAcc@1  61.72 ( 61.77)\tAcc@5  87.50 ( 87.47)\n","Epoch: [30][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.5646e+00 (1.4157e+00)\tAcc@1  57.81 ( 61.00)\tAcc@5  88.28 ( 87.18)\n","Epoch: [30][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.5507e+00 (1.4447e+00)\tAcc@1  57.81 ( 60.10)\tAcc@5  82.03 ( 86.56)\n","Epoch: [30][120/391]\tTime  0.170 ( 0.171)\tLoss 1.2638e+00 (1.4479e+00)\tAcc@1  64.84 ( 59.92)\tAcc@5  85.94 ( 86.60)\n","Epoch: [30][150/391]\tTime  0.169 ( 0.170)\tLoss 1.4128e+00 (1.4543e+00)\tAcc@1  60.94 ( 59.57)\tAcc@5  86.72 ( 86.56)\n","Epoch: [30][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4324e+00 (1.4514e+00)\tAcc@1  61.72 ( 59.61)\tAcc@5  85.94 ( 86.66)\n","Epoch: [30][210/391]\tTime  0.170 ( 0.170)\tLoss 1.5960e+00 (1.4665e+00)\tAcc@1  54.69 ( 59.07)\tAcc@5  82.81 ( 86.44)\n","Epoch: [30][240/391]\tTime  0.169 ( 0.170)\tLoss 1.7822e+00 (1.4744e+00)\tAcc@1  46.88 ( 58.95)\tAcc@5  83.59 ( 86.30)\n","Epoch: [30][270/391]\tTime  0.168 ( 0.170)\tLoss 1.5688e+00 (1.4790e+00)\tAcc@1  56.25 ( 58.90)\tAcc@5  87.50 ( 86.20)\n","Epoch: [30][300/391]\tTime  0.171 ( 0.170)\tLoss 1.3978e+00 (1.4799e+00)\tAcc@1  63.28 ( 58.84)\tAcc@5  87.50 ( 86.17)\n","Epoch: [30][330/391]\tTime  0.171 ( 0.170)\tLoss 1.4888e+00 (1.4862e+00)\tAcc@1  61.72 ( 58.77)\tAcc@5  86.72 ( 86.03)\n","Epoch: [30][360/391]\tTime  0.170 ( 0.170)\tLoss 1.4958e+00 (1.4851e+00)\tAcc@1  58.59 ( 58.77)\tAcc@5  85.16 ( 86.07)\n","Epoch: [30][390/391]\tTime  0.152 ( 0.170)\tLoss 1.5907e+00 (1.4880e+00)\tAcc@1  56.25 ( 58.69)\tAcc@5  83.75 ( 86.05)\n","==> Train Accuracy: Acc@1 58.690 || Acc@5 86.052\n","==> Test Accuracy:  Acc@1 53.990 || Acc@5 83.360\n","==> 70.63 seconds to train this epoch\n","\n","\n","----- epoch: 31, lr: 0.1 -----\n","Epoch: [31][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.5321e+00 (1.5321e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  85.94 ( 85.94)\n","Epoch: [31][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.5406e+00 (1.4210e+00)\tAcc@1  57.03 ( 59.78)\tAcc@5  82.03 ( 87.60)\n","Epoch: [31][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.2702e+00 (1.4143e+00)\tAcc@1  65.62 ( 60.27)\tAcc@5  90.62 ( 87.58)\n","Epoch: [31][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.4637e+00 (1.4374e+00)\tAcc@1  57.81 ( 59.83)\tAcc@5  86.72 ( 87.08)\n","Epoch: [31][120/391]\tTime  0.171 ( 0.170)\tLoss 1.6160e+00 (1.4433e+00)\tAcc@1  57.03 ( 59.53)\tAcc@5  84.38 ( 87.04)\n","Epoch: [31][150/391]\tTime  0.170 ( 0.170)\tLoss 1.3532e+00 (1.4566e+00)\tAcc@1  64.84 ( 59.20)\tAcc@5  87.50 ( 86.82)\n","Epoch: [31][180/391]\tTime  0.168 ( 0.170)\tLoss 1.4763e+00 (1.4713e+00)\tAcc@1  57.81 ( 58.93)\tAcc@5  83.59 ( 86.62)\n","Epoch: [31][210/391]\tTime  0.170 ( 0.170)\tLoss 1.4845e+00 (1.4774e+00)\tAcc@1  62.50 ( 58.94)\tAcc@5  83.59 ( 86.38)\n","Epoch: [31][240/391]\tTime  0.171 ( 0.170)\tLoss 1.6326e+00 (1.4797e+00)\tAcc@1  54.69 ( 58.87)\tAcc@5  80.47 ( 86.33)\n","Epoch: [31][270/391]\tTime  0.169 ( 0.170)\tLoss 1.5279e+00 (1.4843e+00)\tAcc@1  58.59 ( 58.72)\tAcc@5  88.28 ( 86.31)\n","Epoch: [31][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4293e+00 (1.4869e+00)\tAcc@1  58.59 ( 58.64)\tAcc@5  86.72 ( 86.19)\n","Epoch: [31][330/391]\tTime  0.169 ( 0.170)\tLoss 1.6042e+00 (1.4914e+00)\tAcc@1  54.69 ( 58.56)\tAcc@5  84.38 ( 86.10)\n","Epoch: [31][360/391]\tTime  0.171 ( 0.170)\tLoss 1.8797e+00 (1.4945e+00)\tAcc@1  50.78 ( 58.48)\tAcc@5  80.47 ( 86.04)\n","Epoch: [31][390/391]\tTime  0.153 ( 0.170)\tLoss 1.7509e+00 (1.4995e+00)\tAcc@1  53.75 ( 58.36)\tAcc@5  83.75 ( 85.93)\n","==> Train Accuracy: Acc@1 58.364 || Acc@5 85.930\n","==> Test Accuracy:  Acc@1 56.580 || Acc@5 84.240\n","==> 70.62 seconds to train this epoch\n","\n","\n","----- epoch: 32, lr: 0.1 -----\n","Epoch: [32][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.1838e+00 (1.1838e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  89.06 ( 89.06)\n","Epoch: [32][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.4879e+00 (1.3977e+00)\tAcc@1  57.81 ( 60.81)\tAcc@5  85.94 ( 87.93)\n","Epoch: [32][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.4216e+00 (1.4223e+00)\tAcc@1  58.59 ( 59.91)\tAcc@5  88.28 ( 87.41)\n","Epoch: [32][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4707e+00 (1.4238e+00)\tAcc@1  60.16 ( 59.99)\tAcc@5  88.28 ( 87.20)\n","Epoch: [32][120/391]\tTime  0.169 ( 0.170)\tLoss 1.6187e+00 (1.4176e+00)\tAcc@1  57.81 ( 60.34)\tAcc@5  81.25 ( 87.05)\n","Epoch: [32][150/391]\tTime  0.170 ( 0.170)\tLoss 1.5219e+00 (1.4424e+00)\tAcc@1  61.72 ( 59.62)\tAcc@5  85.16 ( 86.64)\n","Epoch: [32][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4110e+00 (1.4512e+00)\tAcc@1  60.16 ( 59.45)\tAcc@5  87.50 ( 86.53)\n","Epoch: [32][210/391]\tTime  0.171 ( 0.170)\tLoss 1.5504e+00 (1.4555e+00)\tAcc@1  53.12 ( 59.32)\tAcc@5  88.28 ( 86.45)\n","Epoch: [32][240/391]\tTime  0.170 ( 0.170)\tLoss 1.3834e+00 (1.4647e+00)\tAcc@1  59.38 ( 59.07)\tAcc@5  84.38 ( 86.24)\n","Epoch: [32][270/391]\tTime  0.169 ( 0.170)\tLoss 1.3228e+00 (1.4728e+00)\tAcc@1  65.62 ( 58.84)\tAcc@5  92.19 ( 86.18)\n","Epoch: [32][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4967e+00 (1.4761e+00)\tAcc@1  60.16 ( 58.73)\tAcc@5  83.59 ( 86.22)\n","Epoch: [32][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3590e+00 (1.4772e+00)\tAcc@1  59.38 ( 58.73)\tAcc@5  89.06 ( 86.31)\n","Epoch: [32][360/391]\tTime  0.169 ( 0.170)\tLoss 1.7093e+00 (1.4812e+00)\tAcc@1  53.12 ( 58.60)\tAcc@5  80.47 ( 86.21)\n","Epoch: [32][390/391]\tTime  0.153 ( 0.170)\tLoss 1.4566e+00 (1.4845e+00)\tAcc@1  47.50 ( 58.50)\tAcc@5  88.75 ( 86.19)\n","==> Train Accuracy: Acc@1 58.502 || Acc@5 86.186\n","==> Test Accuracy:  Acc@1 57.540 || Acc@5 85.290\n","==> 70.49 seconds to train this epoch\n","\n","\n","----- epoch: 33, lr: 0.1 -----\n","Epoch: [33][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.1741e+00 (1.1741e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  89.84 ( 89.84)\n","Epoch: [33][ 30/391]\tTime  0.171 ( 0.172)\tLoss 1.3728e+00 (1.4037e+00)\tAcc@1  63.28 ( 61.49)\tAcc@5  87.50 ( 87.27)\n","Epoch: [33][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.4739e+00 (1.4162e+00)\tAcc@1  64.84 ( 60.91)\tAcc@5  85.94 ( 87.27)\n","Epoch: [33][ 90/391]\tTime  0.171 ( 0.170)\tLoss 1.5343e+00 (1.4260e+00)\tAcc@1  57.81 ( 60.55)\tAcc@5  85.94 ( 87.04)\n","Epoch: [33][120/391]\tTime  0.168 ( 0.170)\tLoss 1.2114e+00 (1.4334e+00)\tAcc@1  67.19 ( 60.29)\tAcc@5  92.97 ( 86.98)\n","Epoch: [33][150/391]\tTime  0.169 ( 0.170)\tLoss 1.4298e+00 (1.4507e+00)\tAcc@1  59.38 ( 59.79)\tAcc@5  85.94 ( 86.72)\n","Epoch: [33][180/391]\tTime  0.168 ( 0.170)\tLoss 1.1945e+00 (1.4549e+00)\tAcc@1  69.53 ( 59.62)\tAcc@5  89.06 ( 86.65)\n","Epoch: [33][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3724e+00 (1.4630e+00)\tAcc@1  59.38 ( 59.33)\tAcc@5  89.84 ( 86.55)\n","Epoch: [33][240/391]\tTime  0.171 ( 0.170)\tLoss 1.4115e+00 (1.4682e+00)\tAcc@1  60.94 ( 59.19)\tAcc@5  85.16 ( 86.45)\n","Epoch: [33][270/391]\tTime  0.168 ( 0.170)\tLoss 1.7698e+00 (1.4739e+00)\tAcc@1  59.38 ( 58.99)\tAcc@5  78.12 ( 86.42)\n","Epoch: [33][300/391]\tTime  0.168 ( 0.169)\tLoss 1.2465e+00 (1.4734e+00)\tAcc@1  66.41 ( 58.95)\tAcc@5  89.84 ( 86.41)\n","Epoch: [33][330/391]\tTime  0.168 ( 0.169)\tLoss 1.4347e+00 (1.4718e+00)\tAcc@1  58.59 ( 58.89)\tAcc@5  85.94 ( 86.45)\n","Epoch: [33][360/391]\tTime  0.170 ( 0.169)\tLoss 1.4111e+00 (1.4726e+00)\tAcc@1  62.50 ( 58.88)\tAcc@5  83.59 ( 86.39)\n","Epoch: [33][390/391]\tTime  0.152 ( 0.169)\tLoss 1.4645e+00 (1.4788e+00)\tAcc@1  57.50 ( 58.68)\tAcc@5  85.00 ( 86.34)\n","==> Train Accuracy: Acc@1 58.684 || Acc@5 86.340\n","==> Test Accuracy:  Acc@1 55.660 || Acc@5 84.580\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 34, lr: 0.1 -----\n","Epoch: [34][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.4419e+00 (1.4419e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  88.28 ( 88.28)\n","Epoch: [34][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4308e+00 (1.3530e+00)\tAcc@1  60.94 ( 61.77)\tAcc@5  87.50 ( 88.61)\n","Epoch: [34][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.6508e+00 (1.3851e+00)\tAcc@1  51.56 ( 60.84)\tAcc@5  86.72 ( 88.32)\n","Epoch: [34][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.3809e+00 (1.3944e+00)\tAcc@1  59.38 ( 60.77)\tAcc@5  88.28 ( 88.08)\n","Epoch: [34][120/391]\tTime  0.167 ( 0.170)\tLoss 1.4716e+00 (1.4127e+00)\tAcc@1  61.72 ( 60.45)\tAcc@5  85.94 ( 87.71)\n","Epoch: [34][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5784e+00 (1.4206e+00)\tAcc@1  61.72 ( 60.23)\tAcc@5  86.72 ( 87.52)\n","Epoch: [34][180/391]\tTime  0.172 ( 0.170)\tLoss 1.5832e+00 (1.4295e+00)\tAcc@1  50.78 ( 59.87)\tAcc@5  85.16 ( 87.37)\n","Epoch: [34][210/391]\tTime  0.167 ( 0.170)\tLoss 1.3472e+00 (1.4363e+00)\tAcc@1  68.75 ( 59.85)\tAcc@5  87.50 ( 87.22)\n","Epoch: [34][240/391]\tTime  0.168 ( 0.170)\tLoss 1.5362e+00 (1.4452e+00)\tAcc@1  58.59 ( 59.61)\tAcc@5  83.59 ( 87.06)\n","Epoch: [34][270/391]\tTime  0.169 ( 0.169)\tLoss 1.5832e+00 (1.4539e+00)\tAcc@1  57.03 ( 59.31)\tAcc@5  80.47 ( 86.92)\n","Epoch: [34][300/391]\tTime  0.169 ( 0.169)\tLoss 1.6175e+00 (1.4604e+00)\tAcc@1  53.12 ( 59.23)\tAcc@5  82.03 ( 86.72)\n","Epoch: [34][330/391]\tTime  0.170 ( 0.169)\tLoss 1.5189e+00 (1.4645e+00)\tAcc@1  49.22 ( 59.15)\tAcc@5  85.16 ( 86.64)\n","Epoch: [34][360/391]\tTime  0.169 ( 0.169)\tLoss 1.6008e+00 (1.4666e+00)\tAcc@1  52.34 ( 59.09)\tAcc@5  82.81 ( 86.59)\n","Epoch: [34][390/391]\tTime  0.151 ( 0.169)\tLoss 1.6900e+00 (1.4688e+00)\tAcc@1  58.75 ( 59.00)\tAcc@5  82.50 ( 86.51)\n","==> Train Accuracy: Acc@1 58.998 || Acc@5 86.508\n","==> Test Accuracy:  Acc@1 55.360 || Acc@5 83.660\n","==> 70.44 seconds to train this epoch\n","\n","\n","----- epoch: 35, lr: 0.1 -----\n","Epoch: [35][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.2546e+00 (1.2546e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  92.19 ( 92.19)\n","Epoch: [35][ 30/391]\tTime  0.170 ( 0.172)\tLoss 1.4858e+00 (1.3773e+00)\tAcc@1  60.94 ( 60.71)\tAcc@5  84.38 ( 87.68)\n","Epoch: [35][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.4140e+00 (1.4033e+00)\tAcc@1  60.16 ( 60.51)\tAcc@5  86.72 ( 87.35)\n","Epoch: [35][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.3742e+00 (1.4146e+00)\tAcc@1  59.38 ( 60.42)\tAcc@5  90.62 ( 86.93)\n","Epoch: [35][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4553e+00 (1.4186e+00)\tAcc@1  61.72 ( 60.10)\tAcc@5  83.59 ( 87.13)\n","Epoch: [35][150/391]\tTime  0.169 ( 0.170)\tLoss 1.4190e+00 (1.4303e+00)\tAcc@1  60.94 ( 59.66)\tAcc@5  84.38 ( 86.97)\n","Epoch: [35][180/391]\tTime  0.167 ( 0.170)\tLoss 1.3346e+00 (1.4309e+00)\tAcc@1  58.59 ( 59.76)\tAcc@5  89.84 ( 87.04)\n","Epoch: [35][210/391]\tTime  0.170 ( 0.170)\tLoss 1.7560e+00 (1.4400e+00)\tAcc@1  53.91 ( 59.52)\tAcc@5  80.47 ( 86.98)\n","Epoch: [35][240/391]\tTime  0.169 ( 0.170)\tLoss 1.2808e+00 (1.4395e+00)\tAcc@1  66.41 ( 59.63)\tAcc@5  88.28 ( 86.90)\n","Epoch: [35][270/391]\tTime  0.170 ( 0.170)\tLoss 1.5498e+00 (1.4506e+00)\tAcc@1  60.16 ( 59.34)\tAcc@5  85.16 ( 86.74)\n","Epoch: [35][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4404e+00 (1.4527e+00)\tAcc@1  60.94 ( 59.25)\tAcc@5  87.50 ( 86.70)\n","Epoch: [35][330/391]\tTime  0.169 ( 0.170)\tLoss 1.2328e+00 (1.4563e+00)\tAcc@1  64.06 ( 59.13)\tAcc@5  91.41 ( 86.66)\n","Epoch: [35][360/391]\tTime  0.169 ( 0.170)\tLoss 1.4616e+00 (1.4619e+00)\tAcc@1  59.38 ( 59.01)\tAcc@5  88.28 ( 86.56)\n","Epoch: [35][390/391]\tTime  0.151 ( 0.170)\tLoss 1.6904e+00 (1.4614e+00)\tAcc@1  55.00 ( 59.04)\tAcc@5  87.50 ( 86.55)\n","==> Train Accuracy: Acc@1 59.036 || Acc@5 86.546\n","==> Test Accuracy:  Acc@1 55.360 || Acc@5 83.770\n","==> 70.49 seconds to train this epoch\n","\n","\n","----- epoch: 36, lr: 0.1 -----\n","Epoch: [36][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.2594e+00 (1.2594e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  89.84 ( 89.84)\n","Epoch: [36][ 30/391]\tTime  0.171 ( 0.172)\tLoss 1.4910e+00 (1.4129e+00)\tAcc@1  58.59 ( 59.98)\tAcc@5  85.94 ( 87.15)\n","Epoch: [36][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.5419e+00 (1.4289e+00)\tAcc@1  57.81 ( 59.68)\tAcc@5  82.03 ( 86.64)\n","Epoch: [36][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.4920e+00 (1.4268e+00)\tAcc@1  57.03 ( 59.51)\tAcc@5  82.81 ( 86.72)\n","Epoch: [36][120/391]\tTime  0.170 ( 0.170)\tLoss 1.1279e+00 (1.4291e+00)\tAcc@1  68.75 ( 59.43)\tAcc@5  89.84 ( 86.74)\n","Epoch: [36][150/391]\tTime  0.169 ( 0.170)\tLoss 1.6877e+00 (1.4358e+00)\tAcc@1  53.91 ( 59.31)\tAcc@5  82.81 ( 86.61)\n","Epoch: [36][180/391]\tTime  0.170 ( 0.170)\tLoss 1.6442e+00 (1.4504e+00)\tAcc@1  56.25 ( 58.99)\tAcc@5  80.47 ( 86.39)\n","Epoch: [36][210/391]\tTime  0.170 ( 0.170)\tLoss 1.4988e+00 (1.4474e+00)\tAcc@1  62.50 ( 59.20)\tAcc@5  82.03 ( 86.37)\n","Epoch: [36][240/391]\tTime  0.169 ( 0.170)\tLoss 1.2805e+00 (1.4533e+00)\tAcc@1  68.75 ( 59.13)\tAcc@5  85.16 ( 86.32)\n","Epoch: [36][270/391]\tTime  0.171 ( 0.170)\tLoss 1.6397e+00 (1.4589e+00)\tAcc@1  53.12 ( 59.00)\tAcc@5  84.38 ( 86.23)\n","Epoch: [36][300/391]\tTime  0.170 ( 0.170)\tLoss 1.3787e+00 (1.4649e+00)\tAcc@1  67.19 ( 58.97)\tAcc@5  86.72 ( 86.19)\n","Epoch: [36][330/391]\tTime  0.169 ( 0.170)\tLoss 1.3487e+00 (1.4669e+00)\tAcc@1  66.41 ( 58.88)\tAcc@5  86.72 ( 86.22)\n","Epoch: [36][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3771e+00 (1.4675e+00)\tAcc@1  63.28 ( 58.86)\tAcc@5  87.50 ( 86.26)\n","Epoch: [36][390/391]\tTime  0.152 ( 0.170)\tLoss 1.4658e+00 (1.4667e+00)\tAcc@1  60.00 ( 58.93)\tAcc@5  85.00 ( 86.27)\n","==> Train Accuracy: Acc@1 58.934 || Acc@5 86.266\n","==> Test Accuracy:  Acc@1 54.740 || Acc@5 82.620\n","==> 70.57 seconds to train this epoch\n","\n","\n","----- epoch: 37, lr: 0.1 -----\n","Epoch: [37][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.6106e+00 (1.6106e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  85.94 ( 85.94)\n","Epoch: [37][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.0279e+00 (1.3177e+00)\tAcc@1  68.75 ( 61.64)\tAcc@5  92.97 ( 89.49)\n","Epoch: [37][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.4832e+00 (1.3627e+00)\tAcc@1  63.28 ( 61.24)\tAcc@5  83.59 ( 88.69)\n","Epoch: [37][ 90/391]\tTime  0.168 ( 0.171)\tLoss 1.0814e+00 (1.3793e+00)\tAcc@1  67.19 ( 61.09)\tAcc@5  90.62 ( 88.03)\n","Epoch: [37][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4787e+00 (1.4045e+00)\tAcc@1  57.81 ( 60.51)\tAcc@5  85.94 ( 87.44)\n","Epoch: [37][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5966e+00 (1.4041e+00)\tAcc@1  57.81 ( 60.44)\tAcc@5  82.03 ( 87.57)\n","Epoch: [37][180/391]\tTime  0.169 ( 0.170)\tLoss 1.4565e+00 (1.4160e+00)\tAcc@1  64.84 ( 60.39)\tAcc@5  84.38 ( 87.34)\n","Epoch: [37][210/391]\tTime  0.169 ( 0.170)\tLoss 1.3900e+00 (1.4263e+00)\tAcc@1  55.47 ( 60.15)\tAcc@5  89.06 ( 87.15)\n","Epoch: [37][240/391]\tTime  0.170 ( 0.170)\tLoss 1.5314e+00 (1.4288e+00)\tAcc@1  56.25 ( 60.03)\tAcc@5  85.94 ( 87.16)\n","Epoch: [37][270/391]\tTime  0.169 ( 0.170)\tLoss 1.5507e+00 (1.4352e+00)\tAcc@1  55.47 ( 59.82)\tAcc@5  86.72 ( 87.07)\n","Epoch: [37][300/391]\tTime  0.169 ( 0.170)\tLoss 1.5192e+00 (1.4389e+00)\tAcc@1  59.38 ( 59.71)\tAcc@5  83.59 ( 87.06)\n","Epoch: [37][330/391]\tTime  0.171 ( 0.170)\tLoss 1.4461e+00 (1.4409e+00)\tAcc@1  60.94 ( 59.70)\tAcc@5  86.72 ( 86.97)\n","Epoch: [37][360/391]\tTime  0.170 ( 0.170)\tLoss 1.6410e+00 (1.4447e+00)\tAcc@1  57.03 ( 59.67)\tAcc@5  83.59 ( 86.91)\n","Epoch: [37][390/391]\tTime  0.152 ( 0.170)\tLoss 1.8487e+00 (1.4469e+00)\tAcc@1  41.25 ( 59.62)\tAcc@5  83.75 ( 86.86)\n","==> Train Accuracy: Acc@1 59.622 || Acc@5 86.856\n","==> Test Accuracy:  Acc@1 55.820 || Acc@5 84.490\n","==> 70.61 seconds to train this epoch\n","\n","\n","----- epoch: 38, lr: 0.1 -----\n","Epoch: [38][  0/391]\tTime  0.297 ( 0.297)\tLoss 1.2530e+00 (1.2530e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  90.62 ( 90.62)\n","Epoch: [38][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4107e+00 (1.3903e+00)\tAcc@1  56.25 ( 60.46)\tAcc@5  85.16 ( 87.02)\n","Epoch: [38][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.3603e+00 (1.3985e+00)\tAcc@1  62.50 ( 60.87)\tAcc@5  88.28 ( 86.78)\n","Epoch: [38][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.6897e+00 (1.4099e+00)\tAcc@1  53.91 ( 60.54)\tAcc@5  84.38 ( 87.12)\n","Epoch: [38][120/391]\tTime  0.169 ( 0.170)\tLoss 1.6140e+00 (1.4203e+00)\tAcc@1  53.91 ( 60.15)\tAcc@5  84.38 ( 87.09)\n","Epoch: [38][150/391]\tTime  0.171 ( 0.170)\tLoss 1.4200e+00 (1.4302e+00)\tAcc@1  58.59 ( 59.71)\tAcc@5  91.41 ( 87.09)\n","Epoch: [38][180/391]\tTime  0.170 ( 0.170)\tLoss 1.5504e+00 (1.4361e+00)\tAcc@1  57.03 ( 59.51)\tAcc@5  87.50 ( 86.95)\n","Epoch: [38][210/391]\tTime  0.168 ( 0.170)\tLoss 1.5769e+00 (1.4422e+00)\tAcc@1  57.03 ( 59.45)\tAcc@5  85.94 ( 86.89)\n","Epoch: [38][240/391]\tTime  0.168 ( 0.170)\tLoss 1.3132e+00 (1.4441e+00)\tAcc@1  59.38 ( 59.50)\tAcc@5  89.84 ( 86.83)\n","Epoch: [38][270/391]\tTime  0.169 ( 0.170)\tLoss 1.6983e+00 (1.4472e+00)\tAcc@1  49.22 ( 59.40)\tAcc@5  78.12 ( 86.73)\n","Epoch: [38][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4629e+00 (1.4488e+00)\tAcc@1  60.94 ( 59.44)\tAcc@5  85.94 ( 86.72)\n","Epoch: [38][330/391]\tTime  0.169 ( 0.170)\tLoss 1.4649e+00 (1.4470e+00)\tAcc@1  57.81 ( 59.59)\tAcc@5  87.50 ( 86.71)\n","Epoch: [38][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3879e+00 (1.4460e+00)\tAcc@1  58.59 ( 59.59)\tAcc@5  89.84 ( 86.77)\n","Epoch: [38][390/391]\tTime  0.152 ( 0.170)\tLoss 1.2763e+00 (1.4473e+00)\tAcc@1  57.50 ( 59.53)\tAcc@5  91.25 ( 86.76)\n","==> Train Accuracy: Acc@1 59.534 || Acc@5 86.762\n","==> Test Accuracy:  Acc@1 58.370 || Acc@5 86.100\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 39, lr: 0.1 -----\n","Epoch: [39][  0/391]\tTime  0.300 ( 0.300)\tLoss 1.4260e+00 (1.4260e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  87.50 ( 87.50)\n","Epoch: [39][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.5466e+00 (1.3648e+00)\tAcc@1  53.12 ( 61.92)\tAcc@5  82.81 ( 88.03)\n","Epoch: [39][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.3588e+00 (1.3885e+00)\tAcc@1  63.28 ( 60.76)\tAcc@5  85.94 ( 87.55)\n","Epoch: [39][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3085e+00 (1.3970e+00)\tAcc@1  58.59 ( 60.75)\tAcc@5  90.62 ( 87.41)\n","Epoch: [39][120/391]\tTime  0.169 ( 0.170)\tLoss 1.3346e+00 (1.4153e+00)\tAcc@1  64.84 ( 60.50)\tAcc@5  85.94 ( 87.20)\n","Epoch: [39][150/391]\tTime  0.170 ( 0.170)\tLoss 1.2828e+00 (1.4148e+00)\tAcc@1  67.19 ( 60.43)\tAcc@5  89.06 ( 87.23)\n","Epoch: [39][180/391]\tTime  0.169 ( 0.170)\tLoss 1.6781e+00 (1.4186e+00)\tAcc@1  50.00 ( 60.31)\tAcc@5  82.81 ( 87.21)\n","Epoch: [39][210/391]\tTime  0.170 ( 0.170)\tLoss 1.4093e+00 (1.4195e+00)\tAcc@1  60.16 ( 60.32)\tAcc@5  84.38 ( 87.20)\n","Epoch: [39][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4763e+00 (1.4233e+00)\tAcc@1  60.16 ( 60.21)\tAcc@5  85.16 ( 87.18)\n","Epoch: [39][270/391]\tTime  0.170 ( 0.170)\tLoss 1.2451e+00 (1.4253e+00)\tAcc@1  67.19 ( 60.22)\tAcc@5  91.41 ( 87.09)\n","Epoch: [39][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4553e+00 (1.4246e+00)\tAcc@1  60.94 ( 60.15)\tAcc@5  89.84 ( 87.18)\n","Epoch: [39][330/391]\tTime  0.169 ( 0.170)\tLoss 1.4662e+00 (1.4295e+00)\tAcc@1  56.25 ( 59.99)\tAcc@5  83.59 ( 87.10)\n","Epoch: [39][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3049e+00 (1.4301e+00)\tAcc@1  64.84 ( 59.99)\tAcc@5  89.06 ( 87.10)\n","Epoch: [39][390/391]\tTime  0.154 ( 0.170)\tLoss 1.5850e+00 (1.4337e+00)\tAcc@1  57.50 ( 59.87)\tAcc@5  81.25 ( 87.00)\n","==> Train Accuracy: Acc@1 59.874 || Acc@5 86.998\n","==> Test Accuracy:  Acc@1 53.240 || Acc@5 82.190\n","==> 70.54 seconds to train this epoch\n","\n","\n","----- epoch: 40, lr: 0.1 -----\n","Epoch: [40][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.5996e+00 (1.5996e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  79.69 ( 79.69)\n","Epoch: [40][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.4143e+00 (1.3868e+00)\tAcc@1  57.03 ( 60.96)\tAcc@5  83.59 ( 87.40)\n","Epoch: [40][ 60/391]\tTime  0.167 ( 0.171)\tLoss 1.4622e+00 (1.4007e+00)\tAcc@1  60.94 ( 61.01)\tAcc@5  88.28 ( 87.06)\n","Epoch: [40][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.5760e+00 (1.4088e+00)\tAcc@1  52.34 ( 60.65)\tAcc@5  86.72 ( 87.12)\n","Epoch: [40][120/391]\tTime  0.168 ( 0.170)\tLoss 1.3812e+00 (1.4012e+00)\tAcc@1  62.50 ( 60.81)\tAcc@5  85.16 ( 87.27)\n","Epoch: [40][150/391]\tTime  0.171 ( 0.170)\tLoss 1.2727e+00 (1.4014e+00)\tAcc@1  67.97 ( 60.81)\tAcc@5  89.06 ( 87.34)\n","Epoch: [40][180/391]\tTime  0.169 ( 0.170)\tLoss 1.4555e+00 (1.4065e+00)\tAcc@1  58.59 ( 60.70)\tAcc@5  88.28 ( 87.28)\n","Epoch: [40][210/391]\tTime  0.168 ( 0.170)\tLoss 1.4506e+00 (1.4066e+00)\tAcc@1  64.84 ( 60.73)\tAcc@5  88.28 ( 87.20)\n","Epoch: [40][240/391]\tTime  0.171 ( 0.170)\tLoss 1.5881e+00 (1.4070e+00)\tAcc@1  57.03 ( 60.73)\tAcc@5  85.94 ( 87.24)\n","Epoch: [40][270/391]\tTime  0.171 ( 0.170)\tLoss 1.4628e+00 (1.4205e+00)\tAcc@1  60.94 ( 60.40)\tAcc@5  84.38 ( 87.04)\n","Epoch: [40][300/391]\tTime  0.169 ( 0.170)\tLoss 1.7550e+00 (1.4261e+00)\tAcc@1  57.03 ( 60.17)\tAcc@5  85.94 ( 86.99)\n","Epoch: [40][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3978e+00 (1.4301e+00)\tAcc@1  59.38 ( 60.07)\tAcc@5  89.06 ( 86.92)\n","Epoch: [40][360/391]\tTime  0.169 ( 0.170)\tLoss 1.4630e+00 (1.4362e+00)\tAcc@1  60.16 ( 59.87)\tAcc@5  89.84 ( 86.84)\n","Epoch: [40][390/391]\tTime  0.151 ( 0.170)\tLoss 1.3559e+00 (1.4367e+00)\tAcc@1  55.00 ( 59.82)\tAcc@5  90.00 ( 86.83)\n","==> Train Accuracy: Acc@1 59.820 || Acc@5 86.832\n","==> Test Accuracy:  Acc@1 56.960 || Acc@5 85.530\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 41, lr: 0.1 -----\n","Epoch: [41][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.2309e+00 (1.2309e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  92.19 ( 92.19)\n","Epoch: [41][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.5926e+00 (1.3744e+00)\tAcc@1  57.81 ( 62.47)\tAcc@5  85.16 ( 87.70)\n","Epoch: [41][ 60/391]\tTime  0.171 ( 0.170)\tLoss 1.2752e+00 (1.3730e+00)\tAcc@1  64.84 ( 62.05)\tAcc@5  88.28 ( 87.81)\n","Epoch: [41][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.1953e+00 (1.3631e+00)\tAcc@1  67.19 ( 62.14)\tAcc@5  89.06 ( 87.75)\n","Epoch: [41][120/391]\tTime  0.168 ( 0.170)\tLoss 1.4646e+00 (1.3769e+00)\tAcc@1  60.16 ( 61.56)\tAcc@5  86.72 ( 87.52)\n","Epoch: [41][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5681e+00 (1.3894e+00)\tAcc@1  57.81 ( 61.25)\tAcc@5  85.16 ( 87.41)\n","Epoch: [41][180/391]\tTime  0.169 ( 0.169)\tLoss 1.5426e+00 (1.3941e+00)\tAcc@1  54.69 ( 61.17)\tAcc@5  85.94 ( 87.28)\n","Epoch: [41][210/391]\tTime  0.168 ( 0.169)\tLoss 1.3381e+00 (1.3969e+00)\tAcc@1  57.81 ( 61.06)\tAcc@5  89.06 ( 87.29)\n","Epoch: [41][240/391]\tTime  0.168 ( 0.169)\tLoss 1.5072e+00 (1.4000e+00)\tAcc@1  57.03 ( 61.05)\tAcc@5  86.72 ( 87.25)\n","Epoch: [41][270/391]\tTime  0.165 ( 0.169)\tLoss 1.3265e+00 (1.4095e+00)\tAcc@1  67.19 ( 60.76)\tAcc@5  85.94 ( 87.13)\n","Epoch: [41][300/391]\tTime  0.168 ( 0.169)\tLoss 1.4507e+00 (1.4166e+00)\tAcc@1  60.16 ( 60.64)\tAcc@5  85.94 ( 87.01)\n","Epoch: [41][330/391]\tTime  0.168 ( 0.169)\tLoss 1.3188e+00 (1.4213e+00)\tAcc@1  65.62 ( 60.41)\tAcc@5  84.38 ( 86.98)\n","Epoch: [41][360/391]\tTime  0.169 ( 0.169)\tLoss 1.5620e+00 (1.4241e+00)\tAcc@1  57.81 ( 60.36)\tAcc@5  82.81 ( 86.97)\n","Epoch: [41][390/391]\tTime  0.152 ( 0.169)\tLoss 1.8072e+00 (1.4294e+00)\tAcc@1  53.75 ( 60.19)\tAcc@5  78.75 ( 86.90)\n","==> Train Accuracy: Acc@1 60.188 || Acc@5 86.902\n","==> Test Accuracy:  Acc@1 57.910 || Acc@5 85.290\n","==> 70.39 seconds to train this epoch\n","\n","\n","----- epoch: 42, lr: 0.1 -----\n","Epoch: [42][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.5491e+00 (1.5491e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  83.59 ( 83.59)\n","Epoch: [42][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3501e+00 (1.3601e+00)\tAcc@1  59.38 ( 60.91)\tAcc@5  89.06 ( 88.36)\n","Epoch: [42][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.5055e+00 (1.3751e+00)\tAcc@1  55.47 ( 60.75)\tAcc@5  89.06 ( 87.99)\n","Epoch: [42][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.3996e+00 (1.3975e+00)\tAcc@1  60.94 ( 60.48)\tAcc@5  85.94 ( 87.62)\n","Epoch: [42][120/391]\tTime  0.168 ( 0.170)\tLoss 1.0630e+00 (1.3962e+00)\tAcc@1  71.09 ( 60.52)\tAcc@5  91.41 ( 87.66)\n","Epoch: [42][150/391]\tTime  0.169 ( 0.170)\tLoss 1.2112e+00 (1.4053e+00)\tAcc@1  63.28 ( 60.34)\tAcc@5  92.97 ( 87.55)\n","Epoch: [42][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4470e+00 (1.4099e+00)\tAcc@1  59.38 ( 60.31)\tAcc@5  83.59 ( 87.48)\n","Epoch: [42][210/391]\tTime  0.168 ( 0.170)\tLoss 1.4261e+00 (1.4126e+00)\tAcc@1  60.16 ( 60.22)\tAcc@5  84.38 ( 87.36)\n","Epoch: [42][240/391]\tTime  0.170 ( 0.170)\tLoss 1.3310e+00 (1.4136e+00)\tAcc@1  58.59 ( 60.17)\tAcc@5  90.62 ( 87.34)\n","Epoch: [42][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4286e+00 (1.4168e+00)\tAcc@1  61.72 ( 60.12)\tAcc@5  85.94 ( 87.31)\n","Epoch: [42][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4415e+00 (1.4202e+00)\tAcc@1  60.94 ( 60.09)\tAcc@5  83.59 ( 87.25)\n","Epoch: [42][330/391]\tTime  0.173 ( 0.170)\tLoss 1.5349e+00 (1.4230e+00)\tAcc@1  60.16 ( 60.08)\tAcc@5  83.59 ( 87.16)\n","Epoch: [42][360/391]\tTime  0.171 ( 0.170)\tLoss 1.1897e+00 (1.4266e+00)\tAcc@1  67.97 ( 59.98)\tAcc@5  89.84 ( 87.07)\n","Epoch: [42][390/391]\tTime  0.152 ( 0.170)\tLoss 1.4176e+00 (1.4243e+00)\tAcc@1  58.75 ( 60.01)\tAcc@5  83.75 ( 87.15)\n","==> Train Accuracy: Acc@1 60.008 || Acc@5 87.152\n","==> Test Accuracy:  Acc@1 54.830 || Acc@5 84.380\n","==> 70.55 seconds to train this epoch\n","\n","\n","----- epoch: 43, lr: 0.1 -----\n","Epoch: [43][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.5740e+00 (1.5740e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  85.16 ( 85.16)\n","Epoch: [43][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.4723e+00 (1.3438e+00)\tAcc@1  58.59 ( 61.97)\tAcc@5  89.06 ( 88.84)\n","Epoch: [43][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.2297e+00 (1.3520e+00)\tAcc@1  62.50 ( 61.82)\tAcc@5  91.41 ( 88.52)\n","Epoch: [43][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.7141e+00 (1.3650e+00)\tAcc@1  53.12 ( 61.46)\tAcc@5  87.50 ( 88.39)\n","Epoch: [43][120/391]\tTime  0.169 ( 0.170)\tLoss 1.3336e+00 (1.3785e+00)\tAcc@1  64.06 ( 61.22)\tAcc@5  87.50 ( 87.96)\n","Epoch: [43][150/391]\tTime  0.168 ( 0.170)\tLoss 1.4022e+00 (1.3877e+00)\tAcc@1  60.94 ( 61.07)\tAcc@5  92.97 ( 87.77)\n","Epoch: [43][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4562e+00 (1.3946e+00)\tAcc@1  60.16 ( 60.89)\tAcc@5  88.28 ( 87.65)\n","Epoch: [43][210/391]\tTime  0.171 ( 0.170)\tLoss 1.5694e+00 (1.3979e+00)\tAcc@1  58.59 ( 60.84)\tAcc@5  84.38 ( 87.61)\n","Epoch: [43][240/391]\tTime  0.170 ( 0.170)\tLoss 1.7308e+00 (1.4068e+00)\tAcc@1  50.78 ( 60.65)\tAcc@5  84.38 ( 87.55)\n","Epoch: [43][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4123e+00 (1.4146e+00)\tAcc@1  60.16 ( 60.37)\tAcc@5  88.28 ( 87.46)\n","Epoch: [43][300/391]\tTime  0.168 ( 0.170)\tLoss 1.2669e+00 (1.4172e+00)\tAcc@1  60.94 ( 60.29)\tAcc@5  90.62 ( 87.34)\n","Epoch: [43][330/391]\tTime  0.171 ( 0.170)\tLoss 1.4514e+00 (1.4229e+00)\tAcc@1  60.94 ( 60.15)\tAcc@5  87.50 ( 87.21)\n","Epoch: [43][360/391]\tTime  0.170 ( 0.170)\tLoss 1.7582e+00 (1.4272e+00)\tAcc@1  53.91 ( 60.10)\tAcc@5  78.91 ( 87.12)\n","Epoch: [43][390/391]\tTime  0.154 ( 0.170)\tLoss 1.4683e+00 (1.4310e+00)\tAcc@1  58.75 ( 60.05)\tAcc@5  86.25 ( 87.06)\n","==> Train Accuracy: Acc@1 60.052 || Acc@5 87.064\n","==> Test Accuracy:  Acc@1 56.510 || Acc@5 83.920\n","==> 70.64 seconds to train this epoch\n","\n","\n","----- epoch: 44, lr: 0.1 -----\n","Epoch: [44][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.6000e+00 (1.6000e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  82.81 ( 82.81)\n","Epoch: [44][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.3707e+00 (1.3638e+00)\tAcc@1  60.16 ( 62.10)\tAcc@5  89.06 ( 88.16)\n","Epoch: [44][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.5611e+00 (1.3790e+00)\tAcc@1  59.38 ( 61.72)\tAcc@5  84.38 ( 87.86)\n","Epoch: [44][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.2556e+00 (1.3956e+00)\tAcc@1  62.50 ( 61.02)\tAcc@5  90.62 ( 87.83)\n","Epoch: [44][120/391]\tTime  0.171 ( 0.171)\tLoss 1.4245e+00 (1.3883e+00)\tAcc@1  58.59 ( 61.12)\tAcc@5  89.06 ( 87.93)\n","Epoch: [44][150/391]\tTime  0.170 ( 0.170)\tLoss 1.3451e+00 (1.3862e+00)\tAcc@1  55.47 ( 61.13)\tAcc@5  88.28 ( 87.97)\n","Epoch: [44][180/391]\tTime  0.169 ( 0.170)\tLoss 1.2736e+00 (1.3827e+00)\tAcc@1  61.72 ( 61.19)\tAcc@5  89.06 ( 88.05)\n","Epoch: [44][210/391]\tTime  0.169 ( 0.170)\tLoss 1.4574e+00 (1.3860e+00)\tAcc@1  58.59 ( 61.05)\tAcc@5  83.59 ( 87.96)\n","Epoch: [44][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4184e+00 (1.3973e+00)\tAcc@1  60.94 ( 60.85)\tAcc@5  88.28 ( 87.74)\n","Epoch: [44][270/391]\tTime  0.171 ( 0.170)\tLoss 1.7305e+00 (1.4045e+00)\tAcc@1  55.47 ( 60.63)\tAcc@5  81.25 ( 87.63)\n","Epoch: [44][300/391]\tTime  0.169 ( 0.170)\tLoss 1.3915e+00 (1.4104e+00)\tAcc@1  62.50 ( 60.43)\tAcc@5  87.50 ( 87.50)\n","Epoch: [44][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3076e+00 (1.4165e+00)\tAcc@1  61.72 ( 60.28)\tAcc@5  87.50 ( 87.33)\n","Epoch: [44][360/391]\tTime  0.172 ( 0.170)\tLoss 1.3404e+00 (1.4201e+00)\tAcc@1  58.59 ( 60.20)\tAcc@5  91.41 ( 87.29)\n","Epoch: [44][390/391]\tTime  0.153 ( 0.170)\tLoss 1.6326e+00 (1.4189e+00)\tAcc@1  52.50 ( 60.24)\tAcc@5  82.50 ( 87.35)\n","==> Train Accuracy: Acc@1 60.242 || Acc@5 87.350\n","==> Test Accuracy:  Acc@1 55.850 || Acc@5 82.630\n","==> 70.65 seconds to train this epoch\n","\n","\n","----- epoch: 45, lr: 0.1 -----\n","Epoch: [45][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.3671e+00 (1.3671e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  90.62 ( 90.62)\n","Epoch: [45][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.0563e+00 (1.3543e+00)\tAcc@1  71.88 ( 62.85)\tAcc@5  93.75 ( 88.26)\n","Epoch: [45][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.5674e+00 (1.3633e+00)\tAcc@1  58.59 ( 61.96)\tAcc@5  85.94 ( 88.17)\n","Epoch: [45][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.3811e+00 (1.3782e+00)\tAcc@1  57.81 ( 61.32)\tAcc@5  89.84 ( 88.03)\n","Epoch: [45][120/391]\tTime  0.169 ( 0.171)\tLoss 1.3096e+00 (1.3773e+00)\tAcc@1  61.72 ( 61.36)\tAcc@5  87.50 ( 87.80)\n","Epoch: [45][150/391]\tTime  0.169 ( 0.170)\tLoss 1.4602e+00 (1.3872e+00)\tAcc@1  57.81 ( 61.26)\tAcc@5  87.50 ( 87.56)\n","Epoch: [45][180/391]\tTime  0.168 ( 0.170)\tLoss 1.5045e+00 (1.3910e+00)\tAcc@1  59.38 ( 61.24)\tAcc@5  84.38 ( 87.48)\n","Epoch: [45][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3435e+00 (1.3933e+00)\tAcc@1  64.84 ( 61.09)\tAcc@5  87.50 ( 87.54)\n","Epoch: [45][240/391]\tTime  0.171 ( 0.170)\tLoss 1.2554e+00 (1.3998e+00)\tAcc@1  62.50 ( 60.92)\tAcc@5  91.41 ( 87.51)\n","Epoch: [45][270/391]\tTime  0.169 ( 0.170)\tLoss 1.6858e+00 (1.4031e+00)\tAcc@1  52.34 ( 60.87)\tAcc@5  86.72 ( 87.53)\n","Epoch: [45][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5135e+00 (1.4046e+00)\tAcc@1  53.91 ( 60.87)\tAcc@5  87.50 ( 87.44)\n","Epoch: [45][330/391]\tTime  0.169 ( 0.170)\tLoss 1.4053e+00 (1.4070e+00)\tAcc@1  59.38 ( 60.76)\tAcc@5  90.62 ( 87.41)\n","Epoch: [45][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3995e+00 (1.4116e+00)\tAcc@1  60.16 ( 60.65)\tAcc@5  85.94 ( 87.31)\n","Epoch: [45][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5460e+00 (1.4141e+00)\tAcc@1  58.75 ( 60.55)\tAcc@5  81.25 ( 87.29)\n","==> Train Accuracy: Acc@1 60.546 || Acc@5 87.294\n","==> Test Accuracy:  Acc@1 57.360 || Acc@5 85.710\n","==> 70.63 seconds to train this epoch\n","\n","\n","----- epoch: 46, lr: 0.1 -----\n","Epoch: [46][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.1401e+00 (1.1401e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  91.41 ( 91.41)\n","Epoch: [46][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4606e+00 (1.3290e+00)\tAcc@1  61.72 ( 63.05)\tAcc@5  82.81 ( 88.89)\n","Epoch: [46][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.4528e+00 (1.3574e+00)\tAcc@1  59.38 ( 61.78)\tAcc@5  87.50 ( 88.41)\n","Epoch: [46][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.3711e+00 (1.3720e+00)\tAcc@1  62.50 ( 61.49)\tAcc@5  87.50 ( 88.22)\n","Epoch: [46][120/391]\tTime  0.168 ( 0.170)\tLoss 1.5947e+00 (1.3809e+00)\tAcc@1  50.78 ( 61.23)\tAcc@5  87.50 ( 87.96)\n","Epoch: [46][150/391]\tTime  0.170 ( 0.170)\tLoss 1.4237e+00 (1.3805e+00)\tAcc@1  55.47 ( 61.16)\tAcc@5  89.06 ( 87.90)\n","Epoch: [46][180/391]\tTime  0.168 ( 0.170)\tLoss 1.3086e+00 (1.3889e+00)\tAcc@1  57.81 ( 60.74)\tAcc@5  92.97 ( 87.75)\n","Epoch: [46][210/391]\tTime  0.169 ( 0.170)\tLoss 1.5840e+00 (1.3926e+00)\tAcc@1  57.03 ( 60.65)\tAcc@5  87.50 ( 87.70)\n","Epoch: [46][240/391]\tTime  0.169 ( 0.170)\tLoss 1.2140e+00 (1.3979e+00)\tAcc@1  66.41 ( 60.70)\tAcc@5  92.97 ( 87.58)\n","Epoch: [46][270/391]\tTime  0.170 ( 0.170)\tLoss 1.5699e+00 (1.3992e+00)\tAcc@1  59.38 ( 60.72)\tAcc@5  83.59 ( 87.51)\n","Epoch: [46][300/391]\tTime  0.169 ( 0.170)\tLoss 1.3970e+00 (1.4068e+00)\tAcc@1  59.38 ( 60.56)\tAcc@5  88.28 ( 87.37)\n","Epoch: [46][330/391]\tTime  0.170 ( 0.170)\tLoss 1.4017e+00 (1.4097e+00)\tAcc@1  60.94 ( 60.50)\tAcc@5  88.28 ( 87.31)\n","Epoch: [46][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3962e+00 (1.4145e+00)\tAcc@1  59.38 ( 60.40)\tAcc@5  86.72 ( 87.24)\n","Epoch: [46][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6805e+00 (1.4157e+00)\tAcc@1  56.25 ( 60.39)\tAcc@5  81.25 ( 87.19)\n","==> Train Accuracy: Acc@1 60.390 || Acc@5 87.190\n","==> Test Accuracy:  Acc@1 57.590 || Acc@5 85.640\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 47, lr: 0.1 -----\n","Epoch: [47][  0/391]\tTime  0.305 ( 0.305)\tLoss 1.3390e+00 (1.3390e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  86.72 ( 86.72)\n","Epoch: [47][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.5493e+00 (1.3493e+00)\tAcc@1  61.72 ( 61.59)\tAcc@5  82.81 ( 87.93)\n","Epoch: [47][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.5319e+00 (1.3659e+00)\tAcc@1  60.94 ( 61.28)\tAcc@5  86.72 ( 87.99)\n","Epoch: [47][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.3794e+00 (1.3583e+00)\tAcc@1  62.50 ( 61.86)\tAcc@5  87.50 ( 87.87)\n","Epoch: [47][120/391]\tTime  0.170 ( 0.170)\tLoss 1.5954e+00 (1.3700e+00)\tAcc@1  52.34 ( 61.31)\tAcc@5  86.72 ( 87.78)\n","Epoch: [47][150/391]\tTime  0.169 ( 0.170)\tLoss 1.4229e+00 (1.3783e+00)\tAcc@1  60.94 ( 61.26)\tAcc@5  86.72 ( 87.71)\n","Epoch: [47][180/391]\tTime  0.169 ( 0.170)\tLoss 1.2012e+00 (1.3934e+00)\tAcc@1  65.62 ( 60.91)\tAcc@5  89.84 ( 87.47)\n","Epoch: [47][210/391]\tTime  0.172 ( 0.170)\tLoss 1.4935e+00 (1.3914e+00)\tAcc@1  57.03 ( 60.91)\tAcc@5  85.16 ( 87.49)\n","Epoch: [47][240/391]\tTime  0.168 ( 0.170)\tLoss 1.4834e+00 (1.3938e+00)\tAcc@1  63.28 ( 60.95)\tAcc@5  85.94 ( 87.45)\n","Epoch: [47][270/391]\tTime  0.169 ( 0.170)\tLoss 1.5622e+00 (1.3962e+00)\tAcc@1  60.16 ( 60.85)\tAcc@5  84.38 ( 87.45)\n","Epoch: [47][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4293e+00 (1.4045e+00)\tAcc@1  54.69 ( 60.66)\tAcc@5  90.62 ( 87.32)\n","Epoch: [47][330/391]\tTime  0.170 ( 0.170)\tLoss 1.5352e+00 (1.4061e+00)\tAcc@1  60.94 ( 60.63)\tAcc@5  86.72 ( 87.24)\n","Epoch: [47][360/391]\tTime  0.170 ( 0.170)\tLoss 1.2801e+00 (1.4031e+00)\tAcc@1  60.94 ( 60.72)\tAcc@5  90.62 ( 87.38)\n","Epoch: [47][390/391]\tTime  0.152 ( 0.170)\tLoss 1.7609e+00 (1.4114e+00)\tAcc@1  50.00 ( 60.51)\tAcc@5  77.50 ( 87.25)\n","==> Train Accuracy: Acc@1 60.508 || Acc@5 87.252\n","==> Test Accuracy:  Acc@1 58.570 || Acc@5 86.640\n","==> 70.64 seconds to train this epoch\n","\n","\n","----- epoch: 48, lr: 0.1 -----\n","Epoch: [48][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.4584e+00 (1.4584e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  86.72 ( 86.72)\n","Epoch: [48][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.2184e+00 (1.3058e+00)\tAcc@1  64.84 ( 62.93)\tAcc@5  91.41 ( 89.29)\n","Epoch: [48][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.6387e+00 (1.3463e+00)\tAcc@1  56.25 ( 61.92)\tAcc@5  80.47 ( 88.42)\n","Epoch: [48][ 90/391]\tTime  0.172 ( 0.171)\tLoss 1.2880e+00 (1.3466e+00)\tAcc@1  60.94 ( 62.01)\tAcc@5  89.84 ( 88.28)\n","Epoch: [48][120/391]\tTime  0.168 ( 0.170)\tLoss 1.4014e+00 (1.3498e+00)\tAcc@1  60.94 ( 62.12)\tAcc@5  89.06 ( 88.25)\n","Epoch: [48][150/391]\tTime  0.172 ( 0.170)\tLoss 1.4590e+00 (1.3615e+00)\tAcc@1  60.16 ( 61.88)\tAcc@5  88.28 ( 88.20)\n","Epoch: [48][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4272e+00 (1.3706e+00)\tAcc@1  61.72 ( 61.58)\tAcc@5  88.28 ( 88.03)\n","Epoch: [48][210/391]\tTime  0.169 ( 0.170)\tLoss 1.5855e+00 (1.3864e+00)\tAcc@1  58.59 ( 61.21)\tAcc@5  85.94 ( 87.73)\n","Epoch: [48][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4366e+00 (1.3892e+00)\tAcc@1  55.47 ( 61.13)\tAcc@5  90.62 ( 87.70)\n","Epoch: [48][270/391]\tTime  0.169 ( 0.170)\tLoss 1.2337e+00 (1.3898e+00)\tAcc@1  64.84 ( 61.04)\tAcc@5  88.28 ( 87.70)\n","Epoch: [48][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4273e+00 (1.3934e+00)\tAcc@1  57.81 ( 60.92)\tAcc@5  84.38 ( 87.61)\n","Epoch: [48][330/391]\tTime  0.169 ( 0.170)\tLoss 1.5037e+00 (1.3979e+00)\tAcc@1  51.56 ( 60.82)\tAcc@5  89.06 ( 87.58)\n","Epoch: [48][360/391]\tTime  0.171 ( 0.170)\tLoss 1.2861e+00 (1.3978e+00)\tAcc@1  63.28 ( 60.81)\tAcc@5  85.94 ( 87.56)\n","Epoch: [48][390/391]\tTime  0.151 ( 0.170)\tLoss 1.6601e+00 (1.4032e+00)\tAcc@1  53.75 ( 60.72)\tAcc@5  83.75 ( 87.44)\n","==> Train Accuracy: Acc@1 60.724 || Acc@5 87.438\n","==> Test Accuracy:  Acc@1 58.600 || Acc@5 86.050\n","==> 70.61 seconds to train this epoch\n","\n","\n","----- epoch: 49, lr: 0.1 -----\n","Epoch: [49][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.5951e+00 (1.5951e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  83.59 ( 83.59)\n","Epoch: [49][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.2330e+00 (1.3153e+00)\tAcc@1  64.06 ( 63.41)\tAcc@5  91.41 ( 88.16)\n","Epoch: [49][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.4076e+00 (1.3400e+00)\tAcc@1  61.72 ( 62.49)\tAcc@5  89.06 ( 88.19)\n","Epoch: [49][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.5070e+00 (1.3445e+00)\tAcc@1  52.34 ( 61.92)\tAcc@5  85.94 ( 88.17)\n","Epoch: [49][120/391]\tTime  0.169 ( 0.170)\tLoss 1.3979e+00 (1.3575e+00)\tAcc@1  60.16 ( 61.87)\tAcc@5  89.06 ( 87.94)\n","Epoch: [49][150/391]\tTime  0.171 ( 0.170)\tLoss 1.5527e+00 (1.3651e+00)\tAcc@1  58.59 ( 61.81)\tAcc@5  84.38 ( 87.83)\n","Epoch: [49][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4563e+00 (1.3678e+00)\tAcc@1  59.38 ( 61.72)\tAcc@5  86.72 ( 87.74)\n","Epoch: [49][210/391]\tTime  0.170 ( 0.170)\tLoss 1.2040e+00 (1.3735e+00)\tAcc@1  67.97 ( 61.83)\tAcc@5  90.62 ( 87.52)\n","Epoch: [49][240/391]\tTime  0.170 ( 0.170)\tLoss 1.5179e+00 (1.3757e+00)\tAcc@1  56.25 ( 61.71)\tAcc@5  84.38 ( 87.51)\n","Epoch: [49][270/391]\tTime  0.170 ( 0.170)\tLoss 1.1676e+00 (1.3816e+00)\tAcc@1  67.19 ( 61.49)\tAcc@5  90.62 ( 87.49)\n","Epoch: [49][300/391]\tTime  0.171 ( 0.170)\tLoss 1.4958e+00 (1.3845e+00)\tAcc@1  58.59 ( 61.32)\tAcc@5  85.94 ( 87.49)\n","Epoch: [49][330/391]\tTime  0.168 ( 0.170)\tLoss 1.3191e+00 (1.3871e+00)\tAcc@1  64.06 ( 61.28)\tAcc@5  88.28 ( 87.43)\n","Epoch: [49][360/391]\tTime  0.169 ( 0.170)\tLoss 1.2083e+00 (1.3934e+00)\tAcc@1  65.62 ( 61.07)\tAcc@5  93.75 ( 87.41)\n","Epoch: [49][390/391]\tTime  0.152 ( 0.169)\tLoss 1.3618e+00 (1.3990e+00)\tAcc@1  58.75 ( 60.94)\tAcc@5  88.75 ( 87.35)\n","==> Train Accuracy: Acc@1 60.944 || Acc@5 87.350\n","==> Test Accuracy:  Acc@1 59.780 || Acc@5 86.740\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 50, lr: 0.1 -----\n","Epoch: [50][  0/391]\tTime  0.293 ( 0.293)\tLoss 1.2566e+00 (1.2566e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  90.62 ( 90.62)\n","Epoch: [50][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.6157e+00 (1.3414e+00)\tAcc@1  59.38 ( 61.62)\tAcc@5  85.16 ( 88.84)\n","Epoch: [50][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.3947e+00 (1.3346e+00)\tAcc@1  64.84 ( 62.04)\tAcc@5  85.16 ( 88.50)\n","Epoch: [50][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4012e+00 (1.3476e+00)\tAcc@1  63.28 ( 61.89)\tAcc@5  85.94 ( 88.19)\n","Epoch: [50][120/391]\tTime  0.168 ( 0.170)\tLoss 1.3707e+00 (1.3484e+00)\tAcc@1  59.38 ( 61.87)\tAcc@5  87.50 ( 88.26)\n","Epoch: [50][150/391]\tTime  0.171 ( 0.170)\tLoss 1.1300e+00 (1.3512e+00)\tAcc@1  68.75 ( 61.74)\tAcc@5  92.97 ( 88.30)\n","Epoch: [50][180/391]\tTime  0.171 ( 0.170)\tLoss 1.3985e+00 (1.3584e+00)\tAcc@1  64.06 ( 61.62)\tAcc@5  85.94 ( 88.19)\n","Epoch: [50][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3300e+00 (1.3690e+00)\tAcc@1  65.62 ( 61.45)\tAcc@5  89.06 ( 88.05)\n","Epoch: [50][240/391]\tTime  0.169 ( 0.170)\tLoss 1.3753e+00 (1.3755e+00)\tAcc@1  59.38 ( 61.34)\tAcc@5  86.72 ( 87.94)\n","Epoch: [50][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4557e+00 (1.3810e+00)\tAcc@1  64.06 ( 61.22)\tAcc@5  85.94 ( 87.85)\n","Epoch: [50][300/391]\tTime  0.168 ( 0.170)\tLoss 1.4598e+00 (1.3887e+00)\tAcc@1  57.81 ( 60.93)\tAcc@5  89.06 ( 87.75)\n","Epoch: [50][330/391]\tTime  0.168 ( 0.170)\tLoss 1.4653e+00 (1.3953e+00)\tAcc@1  60.16 ( 60.85)\tAcc@5  88.28 ( 87.71)\n","Epoch: [50][360/391]\tTime  0.169 ( 0.170)\tLoss 1.4427e+00 (1.4010e+00)\tAcc@1  60.94 ( 60.75)\tAcc@5  87.50 ( 87.62)\n","Epoch: [50][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6357e+00 (1.4054e+00)\tAcc@1  53.75 ( 60.59)\tAcc@5  83.75 ( 87.60)\n","==> Train Accuracy: Acc@1 60.592 || Acc@5 87.604\n","==> Test Accuracy:  Acc@1 59.910 || Acc@5 86.630\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 51, lr: 0.1 -----\n","Epoch: [51][  0/391]\tTime  0.278 ( 0.278)\tLoss 9.9750e-01 (9.9750e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  92.97 ( 92.97)\n","Epoch: [51][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.2955e+00 (1.3074e+00)\tAcc@1  58.59 ( 63.73)\tAcc@5  86.72 ( 88.61)\n","Epoch: [51][ 60/391]\tTime  0.167 ( 0.171)\tLoss 1.1441e+00 (1.3094e+00)\tAcc@1  68.75 ( 63.38)\tAcc@5  92.97 ( 88.77)\n","Epoch: [51][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.5796e+00 (1.3355e+00)\tAcc@1  60.94 ( 62.75)\tAcc@5  85.94 ( 88.45)\n","Epoch: [51][120/391]\tTime  0.168 ( 0.170)\tLoss 1.4817e+00 (1.3301e+00)\tAcc@1  57.81 ( 62.88)\tAcc@5  85.94 ( 88.48)\n","Epoch: [51][150/391]\tTime  0.171 ( 0.170)\tLoss 1.4216e+00 (1.3448e+00)\tAcc@1  59.38 ( 62.53)\tAcc@5  89.06 ( 88.22)\n","Epoch: [51][180/391]\tTime  0.169 ( 0.170)\tLoss 1.5563e+00 (1.3518e+00)\tAcc@1  56.25 ( 62.08)\tAcc@5  85.16 ( 88.18)\n","Epoch: [51][210/391]\tTime  0.170 ( 0.170)\tLoss 1.5895e+00 (1.3648e+00)\tAcc@1  57.81 ( 61.81)\tAcc@5  83.59 ( 87.93)\n","Epoch: [51][240/391]\tTime  0.169 ( 0.170)\tLoss 1.6285e+00 (1.3737e+00)\tAcc@1  52.34 ( 61.50)\tAcc@5  85.94 ( 87.84)\n","Epoch: [51][270/391]\tTime  0.170 ( 0.170)\tLoss 1.4222e+00 (1.3814e+00)\tAcc@1  58.59 ( 61.32)\tAcc@5  86.72 ( 87.71)\n","Epoch: [51][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4765e+00 (1.3859e+00)\tAcc@1  57.03 ( 61.19)\tAcc@5  88.28 ( 87.66)\n","Epoch: [51][330/391]\tTime  0.168 ( 0.170)\tLoss 1.4860e+00 (1.3923e+00)\tAcc@1  58.59 ( 61.02)\tAcc@5  85.16 ( 87.51)\n","Epoch: [51][360/391]\tTime  0.168 ( 0.170)\tLoss 1.4353e+00 (1.3957e+00)\tAcc@1  59.38 ( 60.88)\tAcc@5  83.59 ( 87.47)\n","Epoch: [51][390/391]\tTime  0.153 ( 0.170)\tLoss 1.7308e+00 (1.3986e+00)\tAcc@1  51.25 ( 60.79)\tAcc@5  83.75 ( 87.39)\n","==> Train Accuracy: Acc@1 60.794 || Acc@5 87.388\n","==> Test Accuracy:  Acc@1 58.410 || Acc@5 86.310\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 52, lr: 0.1 -----\n","Epoch: [52][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.0107e+00 (1.0107e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  94.53 ( 94.53)\n","Epoch: [52][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.5029e+00 (1.3194e+00)\tAcc@1  57.03 ( 62.83)\tAcc@5  84.38 ( 88.71)\n","Epoch: [52][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.2944e+00 (1.3396e+00)\tAcc@1  67.97 ( 62.00)\tAcc@5  89.06 ( 88.64)\n","Epoch: [52][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.5493e+00 (1.3405e+00)\tAcc@1  53.12 ( 62.09)\tAcc@5  85.94 ( 88.52)\n","Epoch: [52][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4033e+00 (1.3369e+00)\tAcc@1  62.50 ( 62.04)\tAcc@5  88.28 ( 88.57)\n","Epoch: [52][150/391]\tTime  0.170 ( 0.170)\tLoss 1.5319e+00 (1.3493e+00)\tAcc@1  56.25 ( 61.72)\tAcc@5  89.06 ( 88.47)\n","Epoch: [52][180/391]\tTime  0.169 ( 0.170)\tLoss 1.6259e+00 (1.3584e+00)\tAcc@1  52.34 ( 61.51)\tAcc@5  85.16 ( 88.32)\n","Epoch: [52][210/391]\tTime  0.170 ( 0.170)\tLoss 1.1463e+00 (1.3633e+00)\tAcc@1  64.06 ( 61.44)\tAcc@5  92.97 ( 88.28)\n","Epoch: [52][240/391]\tTime  0.169 ( 0.170)\tLoss 1.6821e+00 (1.3682e+00)\tAcc@1  54.69 ( 61.35)\tAcc@5  83.59 ( 88.22)\n","Epoch: [52][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4995e+00 (1.3725e+00)\tAcc@1  57.03 ( 61.18)\tAcc@5  87.50 ( 88.16)\n","Epoch: [52][300/391]\tTime  0.169 ( 0.170)\tLoss 1.6949e+00 (1.3758e+00)\tAcc@1  53.91 ( 61.10)\tAcc@5  80.47 ( 88.13)\n","Epoch: [52][330/391]\tTime  0.169 ( 0.169)\tLoss 1.3178e+00 (1.3807e+00)\tAcc@1  61.72 ( 61.06)\tAcc@5  89.06 ( 87.98)\n","Epoch: [52][360/391]\tTime  0.169 ( 0.169)\tLoss 1.3659e+00 (1.3840e+00)\tAcc@1  61.72 ( 61.08)\tAcc@5  87.50 ( 87.89)\n","Epoch: [52][390/391]\tTime  0.150 ( 0.169)\tLoss 1.4116e+00 (1.3853e+00)\tAcc@1  65.00 ( 61.02)\tAcc@5  90.00 ( 87.85)\n","==> Train Accuracy: Acc@1 61.020 || Acc@5 87.848\n","==> Test Accuracy:  Acc@1 55.870 || Acc@5 84.560\n","==> 70.42 seconds to train this epoch\n","\n","\n","----- epoch: 53, lr: 0.1 -----\n","Epoch: [53][  0/391]\tTime  0.298 ( 0.298)\tLoss 1.3054e+00 (1.3054e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  88.28 ( 88.28)\n","Epoch: [53][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.3443e+00 (1.3306e+00)\tAcc@1  64.84 ( 63.43)\tAcc@5  86.72 ( 88.41)\n","Epoch: [53][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.0965e+00 (1.3054e+00)\tAcc@1  69.53 ( 63.87)\tAcc@5  94.53 ( 88.97)\n","Epoch: [53][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.1476e+00 (1.3280e+00)\tAcc@1  69.53 ( 62.86)\tAcc@5  90.62 ( 88.53)\n","Epoch: [53][120/391]\tTime  0.169 ( 0.170)\tLoss 1.4170e+00 (1.3396e+00)\tAcc@1  56.25 ( 62.46)\tAcc@5  85.16 ( 88.18)\n","Epoch: [53][150/391]\tTime  0.170 ( 0.170)\tLoss 1.5835e+00 (1.3524e+00)\tAcc@1  59.38 ( 62.12)\tAcc@5  88.28 ( 88.12)\n","Epoch: [53][180/391]\tTime  0.169 ( 0.170)\tLoss 1.1959e+00 (1.3601e+00)\tAcc@1  69.53 ( 62.02)\tAcc@5  92.97 ( 88.08)\n","Epoch: [53][210/391]\tTime  0.169 ( 0.170)\tLoss 1.2126e+00 (1.3674e+00)\tAcc@1  61.72 ( 61.85)\tAcc@5  90.62 ( 88.00)\n","Epoch: [53][240/391]\tTime  0.167 ( 0.170)\tLoss 1.1701e+00 (1.3715e+00)\tAcc@1  66.41 ( 61.70)\tAcc@5  89.84 ( 87.96)\n","Epoch: [53][270/391]\tTime  0.169 ( 0.170)\tLoss 1.6614e+00 (1.3800e+00)\tAcc@1  52.34 ( 61.47)\tAcc@5  84.38 ( 87.80)\n","Epoch: [53][300/391]\tTime  0.169 ( 0.169)\tLoss 1.4299e+00 (1.3859e+00)\tAcc@1  60.94 ( 61.31)\tAcc@5  89.06 ( 87.75)\n","Epoch: [53][330/391]\tTime  0.169 ( 0.169)\tLoss 1.6206e+00 (1.3899e+00)\tAcc@1  50.00 ( 61.24)\tAcc@5  84.38 ( 87.68)\n","Epoch: [53][360/391]\tTime  0.170 ( 0.169)\tLoss 1.3036e+00 (1.3915e+00)\tAcc@1  62.50 ( 61.19)\tAcc@5  88.28 ( 87.64)\n","Epoch: [53][390/391]\tTime  0.152 ( 0.169)\tLoss 1.4893e+00 (1.3912e+00)\tAcc@1  65.00 ( 61.19)\tAcc@5  87.50 ( 87.63)\n","==> Train Accuracy: Acc@1 61.190 || Acc@5 87.634\n","==> Test Accuracy:  Acc@1 58.370 || Acc@5 86.270\n","==> 70.44 seconds to train this epoch\n","\n","\n","----- epoch: 54, lr: 0.1 -----\n","Epoch: [54][  0/391]\tTime  0.298 ( 0.298)\tLoss 1.3090e+00 (1.3090e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  87.50 ( 87.50)\n","Epoch: [54][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.1996e+00 (1.2528e+00)\tAcc@1  62.50 ( 65.20)\tAcc@5  89.06 ( 89.69)\n","Epoch: [54][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.2004e+00 (1.3028e+00)\tAcc@1  65.62 ( 63.73)\tAcc@5  92.97 ( 88.84)\n","Epoch: [54][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.3969e+00 (1.3083e+00)\tAcc@1  58.59 ( 63.27)\tAcc@5  88.28 ( 88.61)\n","Epoch: [54][120/391]\tTime  0.168 ( 0.170)\tLoss 1.1429e+00 (1.3174e+00)\tAcc@1  68.75 ( 62.86)\tAcc@5  89.84 ( 88.53)\n","Epoch: [54][150/391]\tTime  0.169 ( 0.170)\tLoss 1.6475e+00 (1.3294e+00)\tAcc@1  53.91 ( 62.38)\tAcc@5  81.25 ( 88.34)\n","Epoch: [54][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4649e+00 (1.3470e+00)\tAcc@1  61.72 ( 62.10)\tAcc@5  84.38 ( 88.03)\n","Epoch: [54][210/391]\tTime  0.169 ( 0.170)\tLoss 1.5276e+00 (1.3545e+00)\tAcc@1  60.16 ( 61.95)\tAcc@5  83.59 ( 87.85)\n","Epoch: [54][240/391]\tTime  0.169 ( 0.170)\tLoss 1.4847e+00 (1.3569e+00)\tAcc@1  52.34 ( 61.91)\tAcc@5  89.06 ( 87.83)\n","Epoch: [54][270/391]\tTime  0.170 ( 0.170)\tLoss 1.2203e+00 (1.3691e+00)\tAcc@1  67.97 ( 61.51)\tAcc@5  88.28 ( 87.64)\n","Epoch: [54][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4676e+00 (1.3780e+00)\tAcc@1  63.28 ( 61.22)\tAcc@5  84.38 ( 87.57)\n","Epoch: [54][330/391]\tTime  0.170 ( 0.170)\tLoss 1.4428e+00 (1.3783e+00)\tAcc@1  64.84 ( 61.25)\tAcc@5  82.03 ( 87.61)\n","Epoch: [54][360/391]\tTime  0.169 ( 0.170)\tLoss 1.5403e+00 (1.3833e+00)\tAcc@1  57.03 ( 61.19)\tAcc@5  86.72 ( 87.56)\n","Epoch: [54][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6628e+00 (1.3881e+00)\tAcc@1  55.00 ( 61.12)\tAcc@5  78.75 ( 87.55)\n","==> Train Accuracy: Acc@1 61.120 || Acc@5 87.546\n","==> Test Accuracy:  Acc@1 56.270 || Acc@5 84.460\n","==> 70.56 seconds to train this epoch\n","\n","\n","----- epoch: 55, lr: 0.1 -----\n","Epoch: [55][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.4260e+00 (1.4260e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  85.94 ( 85.94)\n","Epoch: [55][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.4955e+00 (1.3184e+00)\tAcc@1  57.03 ( 62.58)\tAcc@5  88.28 ( 88.28)\n","Epoch: [55][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.3038e+00 (1.3068e+00)\tAcc@1  60.94 ( 63.41)\tAcc@5  91.41 ( 88.56)\n","Epoch: [55][ 90/391]\tTime  0.168 ( 0.171)\tLoss 1.2271e+00 (1.3146e+00)\tAcc@1  65.62 ( 63.02)\tAcc@5  86.72 ( 88.58)\n","Epoch: [55][120/391]\tTime  0.169 ( 0.170)\tLoss 1.4075e+00 (1.3335e+00)\tAcc@1  60.16 ( 62.53)\tAcc@5  87.50 ( 88.30)\n","Epoch: [55][150/391]\tTime  0.168 ( 0.170)\tLoss 1.3956e+00 (1.3415e+00)\tAcc@1  58.59 ( 62.42)\tAcc@5  87.50 ( 88.02)\n","Epoch: [55][180/391]\tTime  0.170 ( 0.170)\tLoss 1.6161e+00 (1.3541e+00)\tAcc@1  56.25 ( 62.05)\tAcc@5  81.25 ( 87.79)\n","Epoch: [55][210/391]\tTime  0.169 ( 0.170)\tLoss 1.3444e+00 (1.3599e+00)\tAcc@1  62.50 ( 61.90)\tAcc@5  89.84 ( 87.76)\n","Epoch: [55][240/391]\tTime  0.168 ( 0.170)\tLoss 1.5191e+00 (1.3732e+00)\tAcc@1  56.25 ( 61.65)\tAcc@5  85.16 ( 87.62)\n","Epoch: [55][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4604e+00 (1.3789e+00)\tAcc@1  58.59 ( 61.43)\tAcc@5  86.72 ( 87.47)\n","Epoch: [55][300/391]\tTime  0.168 ( 0.170)\tLoss 1.6130e+00 (1.3825e+00)\tAcc@1  50.00 ( 61.33)\tAcc@5  87.50 ( 87.48)\n","Epoch: [55][330/391]\tTime  0.169 ( 0.170)\tLoss 1.0425e+00 (1.3800e+00)\tAcc@1  72.66 ( 61.39)\tAcc@5  91.41 ( 87.54)\n","Epoch: [55][360/391]\tTime  0.168 ( 0.170)\tLoss 1.5336e+00 (1.3797e+00)\tAcc@1  53.91 ( 61.43)\tAcc@5  85.16 ( 87.56)\n","Epoch: [55][390/391]\tTime  0.151 ( 0.169)\tLoss 1.1681e+00 (1.3860e+00)\tAcc@1  67.50 ( 61.28)\tAcc@5  90.00 ( 87.50)\n","==> Train Accuracy: Acc@1 61.280 || Acc@5 87.498\n","==> Test Accuracy:  Acc@1 54.720 || Acc@5 83.630\n","==> 70.44 seconds to train this epoch\n","\n","\n","----- epoch: 56, lr: 0.1 -----\n","Epoch: [56][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.4429e+00 (1.4429e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  86.72 ( 86.72)\n","Epoch: [56][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.2664e+00 (1.3226e+00)\tAcc@1  67.97 ( 62.68)\tAcc@5  87.50 ( 88.66)\n","Epoch: [56][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.3781e+00 (1.3270e+00)\tAcc@1  60.94 ( 62.51)\tAcc@5  89.06 ( 88.52)\n","Epoch: [56][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.1031e+00 (1.3435e+00)\tAcc@1  71.09 ( 62.33)\tAcc@5  91.41 ( 88.26)\n","Epoch: [56][120/391]\tTime  0.170 ( 0.170)\tLoss 1.2061e+00 (1.3428e+00)\tAcc@1  64.84 ( 62.30)\tAcc@5  91.41 ( 88.24)\n","Epoch: [56][150/391]\tTime  0.169 ( 0.170)\tLoss 1.6040e+00 (1.3412e+00)\tAcc@1  53.12 ( 62.24)\tAcc@5  85.94 ( 88.22)\n","Epoch: [56][180/391]\tTime  0.169 ( 0.170)\tLoss 1.5365e+00 (1.3460e+00)\tAcc@1  57.81 ( 62.17)\tAcc@5  84.38 ( 88.22)\n","Epoch: [56][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3488e+00 (1.3514e+00)\tAcc@1  59.38 ( 61.99)\tAcc@5  90.62 ( 88.23)\n","Epoch: [56][240/391]\tTime  0.168 ( 0.170)\tLoss 1.4655e+00 (1.3594e+00)\tAcc@1  56.25 ( 61.79)\tAcc@5  85.94 ( 88.11)\n","Epoch: [56][270/391]\tTime  0.169 ( 0.170)\tLoss 1.1574e+00 (1.3643e+00)\tAcc@1  67.97 ( 61.77)\tAcc@5  91.41 ( 88.06)\n","Epoch: [56][300/391]\tTime  0.170 ( 0.170)\tLoss 1.3882e+00 (1.3688e+00)\tAcc@1  60.94 ( 61.65)\tAcc@5  87.50 ( 88.00)\n","Epoch: [56][330/391]\tTime  0.169 ( 0.170)\tLoss 1.3816e+00 (1.3719e+00)\tAcc@1  63.28 ( 61.60)\tAcc@5  86.72 ( 87.96)\n","Epoch: [56][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3453e+00 (1.3756e+00)\tAcc@1  63.28 ( 61.50)\tAcc@5  87.50 ( 87.87)\n","Epoch: [56][390/391]\tTime  0.154 ( 0.170)\tLoss 1.2179e+00 (1.3790e+00)\tAcc@1  61.25 ( 61.42)\tAcc@5  93.75 ( 87.81)\n","==> Train Accuracy: Acc@1 61.422 || Acc@5 87.810\n","==> Test Accuracy:  Acc@1 56.640 || Acc@5 85.200\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 57, lr: 0.1 -----\n","Epoch: [57][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.3662e+00 (1.3662e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  89.84 ( 89.84)\n","Epoch: [57][ 30/391]\tTime  0.172 ( 0.172)\tLoss 1.3075e+00 (1.3123e+00)\tAcc@1  63.28 ( 63.73)\tAcc@5  86.72 ( 88.86)\n","Epoch: [57][ 60/391]\tTime  0.169 ( 0.170)\tLoss 1.3184e+00 (1.3229e+00)\tAcc@1  59.38 ( 63.27)\tAcc@5  92.19 ( 88.68)\n","Epoch: [57][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.5628e+00 (1.3386e+00)\tAcc@1  54.69 ( 62.84)\tAcc@5  86.72 ( 88.30)\n","Epoch: [57][120/391]\tTime  0.170 ( 0.170)\tLoss 1.5328e+00 (1.3611e+00)\tAcc@1  58.59 ( 62.15)\tAcc@5  85.16 ( 87.94)\n","Epoch: [57][150/391]\tTime  0.170 ( 0.170)\tLoss 1.6165e+00 (1.3628e+00)\tAcc@1  53.12 ( 62.12)\tAcc@5  81.25 ( 87.90)\n","Epoch: [57][180/391]\tTime  0.168 ( 0.170)\tLoss 1.4206e+00 (1.3669e+00)\tAcc@1  60.94 ( 61.93)\tAcc@5  84.38 ( 87.96)\n","Epoch: [57][210/391]\tTime  0.169 ( 0.169)\tLoss 1.4908e+00 (1.3710e+00)\tAcc@1  55.47 ( 61.74)\tAcc@5  85.94 ( 87.89)\n","Epoch: [57][240/391]\tTime  0.170 ( 0.169)\tLoss 1.4595e+00 (1.3758e+00)\tAcc@1  61.72 ( 61.61)\tAcc@5  82.81 ( 87.81)\n","Epoch: [57][270/391]\tTime  0.168 ( 0.169)\tLoss 1.6732e+00 (1.3853e+00)\tAcc@1  53.91 ( 61.30)\tAcc@5  82.81 ( 87.68)\n","Epoch: [57][300/391]\tTime  0.170 ( 0.169)\tLoss 1.1833e+00 (1.3835e+00)\tAcc@1  67.97 ( 61.31)\tAcc@5  89.84 ( 87.72)\n","Epoch: [57][330/391]\tTime  0.170 ( 0.169)\tLoss 1.5065e+00 (1.3858e+00)\tAcc@1  58.59 ( 61.24)\tAcc@5  82.03 ( 87.66)\n","Epoch: [57][360/391]\tTime  0.168 ( 0.169)\tLoss 1.6989e+00 (1.3900e+00)\tAcc@1  54.69 ( 61.14)\tAcc@5  85.94 ( 87.57)\n","Epoch: [57][390/391]\tTime  0.153 ( 0.169)\tLoss 1.3033e+00 (1.3938e+00)\tAcc@1  62.50 ( 61.03)\tAcc@5  91.25 ( 87.51)\n","==> Train Accuracy: Acc@1 61.032 || Acc@5 87.510\n","==> Test Accuracy:  Acc@1 59.260 || Acc@5 86.730\n","==> 70.41 seconds to train this epoch\n","\n","\n","----- epoch: 58, lr: 0.1 -----\n","Epoch: [58][  0/391]\tTime  0.309 ( 0.309)\tLoss 1.1415e+00 (1.1415e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  92.19 ( 92.19)\n","Epoch: [58][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.4354e+00 (1.3468e+00)\tAcc@1  58.59 ( 62.63)\tAcc@5  85.16 ( 88.18)\n","Epoch: [58][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.2192e+00 (1.3297e+00)\tAcc@1  64.84 ( 62.76)\tAcc@5  89.06 ( 88.54)\n","Epoch: [58][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.4970e+00 (1.3330e+00)\tAcc@1  59.38 ( 62.54)\tAcc@5  85.16 ( 88.48)\n","Epoch: [58][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4015e+00 (1.3461e+00)\tAcc@1  58.59 ( 62.12)\tAcc@5  86.72 ( 88.33)\n","Epoch: [58][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5274e+00 (1.3461e+00)\tAcc@1  53.91 ( 62.11)\tAcc@5  87.50 ( 88.37)\n","Epoch: [58][180/391]\tTime  0.170 ( 0.170)\tLoss 1.3451e+00 (1.3532e+00)\tAcc@1  62.50 ( 61.99)\tAcc@5  89.84 ( 88.33)\n","Epoch: [58][210/391]\tTime  0.170 ( 0.170)\tLoss 1.5243e+00 (1.3560e+00)\tAcc@1  49.22 ( 61.84)\tAcc@5  85.16 ( 88.32)\n","Epoch: [58][240/391]\tTime  0.170 ( 0.170)\tLoss 1.0839e+00 (1.3633e+00)\tAcc@1  67.97 ( 61.68)\tAcc@5  90.62 ( 88.17)\n","Epoch: [58][270/391]\tTime  0.171 ( 0.170)\tLoss 1.3361e+00 (1.3651e+00)\tAcc@1  64.06 ( 61.73)\tAcc@5  86.72 ( 88.11)\n","Epoch: [58][300/391]\tTime  0.170 ( 0.170)\tLoss 1.2277e+00 (1.3668e+00)\tAcc@1  66.41 ( 61.70)\tAcc@5  89.84 ( 88.07)\n","Epoch: [58][330/391]\tTime  0.171 ( 0.170)\tLoss 1.5490e+00 (1.3665e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  85.94 ( 88.03)\n","Epoch: [58][360/391]\tTime  0.168 ( 0.170)\tLoss 1.3419e+00 (1.3691e+00)\tAcc@1  62.50 ( 61.63)\tAcc@5  90.62 ( 88.03)\n","Epoch: [58][390/391]\tTime  0.153 ( 0.170)\tLoss 1.4201e+00 (1.3761e+00)\tAcc@1  65.00 ( 61.40)\tAcc@5  88.75 ( 87.87)\n","==> Train Accuracy: Acc@1 61.404 || Acc@5 87.870\n","==> Test Accuracy:  Acc@1 56.670 || Acc@5 85.310\n","==> 70.55 seconds to train this epoch\n","\n","\n","----- epoch: 59, lr: 0.1 -----\n","Epoch: [59][  0/391]\tTime  0.313 ( 0.313)\tLoss 1.4063e+00 (1.4063e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  86.72 ( 86.72)\n","Epoch: [59][ 30/391]\tTime  0.169 ( 0.174)\tLoss 1.3238e+00 (1.2939e+00)\tAcc@1  63.28 ( 63.38)\tAcc@5  91.41 ( 89.24)\n","Epoch: [59][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.4493e+00 (1.3050e+00)\tAcc@1  59.38 ( 62.86)\tAcc@5  87.50 ( 89.08)\n","Epoch: [59][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.2051e+00 (1.3245e+00)\tAcc@1  67.19 ( 62.41)\tAcc@5  90.62 ( 88.63)\n","Epoch: [59][120/391]\tTime  0.169 ( 0.170)\tLoss 1.6025e+00 (1.3449e+00)\tAcc@1  58.59 ( 62.03)\tAcc@5  82.81 ( 88.20)\n","Epoch: [59][150/391]\tTime  0.168 ( 0.170)\tLoss 1.3178e+00 (1.3530e+00)\tAcc@1  61.72 ( 61.93)\tAcc@5  87.50 ( 88.04)\n","Epoch: [59][180/391]\tTime  0.170 ( 0.170)\tLoss 1.2391e+00 (1.3590e+00)\tAcc@1  65.62 ( 61.85)\tAcc@5  87.50 ( 87.96)\n","Epoch: [59][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3691e+00 (1.3640e+00)\tAcc@1  60.94 ( 61.71)\tAcc@5  89.84 ( 87.85)\n","Epoch: [59][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4191e+00 (1.3717e+00)\tAcc@1  57.03 ( 61.44)\tAcc@5  88.28 ( 87.84)\n","Epoch: [59][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4606e+00 (1.3778e+00)\tAcc@1  59.38 ( 61.30)\tAcc@5  87.50 ( 87.78)\n","Epoch: [59][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5530e+00 (1.3759e+00)\tAcc@1  53.91 ( 61.39)\tAcc@5  83.59 ( 87.76)\n","Epoch: [59][330/391]\tTime  0.169 ( 0.170)\tLoss 1.2926e+00 (1.3770e+00)\tAcc@1  65.62 ( 61.32)\tAcc@5  89.06 ( 87.80)\n","Epoch: [59][360/391]\tTime  0.169 ( 0.170)\tLoss 1.5038e+00 (1.3761e+00)\tAcc@1  57.03 ( 61.31)\tAcc@5  86.72 ( 87.81)\n","Epoch: [59][390/391]\tTime  0.153 ( 0.170)\tLoss 1.6241e+00 (1.3840e+00)\tAcc@1  55.00 ( 61.14)\tAcc@5  78.75 ( 87.65)\n","==> Train Accuracy: Acc@1 61.140 || Acc@5 87.648\n","==> Test Accuracy:  Acc@1 60.070 || Acc@5 86.110\n","==> 70.60 seconds to train this epoch\n","\n","\n","----- epoch: 60, lr: 0.020000000000000004 -----\n","Epoch: [60][  0/391]\tTime  0.293 ( 0.293)\tLoss 1.5512e+00 (1.5512e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.94 ( 85.94)\n","Epoch: [60][ 30/391]\tTime  0.173 ( 0.173)\tLoss 8.9878e-01 (1.1787e+00)\tAcc@1  75.78 ( 66.78)\tAcc@5  93.75 ( 90.98)\n","Epoch: [60][ 60/391]\tTime  0.170 ( 0.171)\tLoss 9.3117e-01 (1.1138e+00)\tAcc@1  78.91 ( 68.72)\tAcc@5  92.97 ( 91.56)\n","Epoch: [60][ 90/391]\tTime  0.169 ( 0.171)\tLoss 9.9532e-01 (1.0774e+00)\tAcc@1  69.53 ( 69.60)\tAcc@5  92.97 ( 91.80)\n","Epoch: [60][120/391]\tTime  0.171 ( 0.171)\tLoss 1.0527e+00 (1.0478e+00)\tAcc@1  69.53 ( 70.37)\tAcc@5  89.84 ( 92.11)\n","Epoch: [60][150/391]\tTime  0.171 ( 0.170)\tLoss 9.9921e-01 (1.0293e+00)\tAcc@1  73.44 ( 70.82)\tAcc@5  88.28 ( 92.25)\n","Epoch: [60][180/391]\tTime  0.171 ( 0.170)\tLoss 9.5690e-01 (1.0114e+00)\tAcc@1  71.88 ( 71.21)\tAcc@5  93.75 ( 92.36)\n","Epoch: [60][210/391]\tTime  0.170 ( 0.170)\tLoss 1.0231e+00 (9.9900e-01)\tAcc@1  72.66 ( 71.48)\tAcc@5  94.53 ( 92.55)\n","Epoch: [60][240/391]\tTime  0.169 ( 0.170)\tLoss 1.1426e+00 (9.8798e-01)\tAcc@1  69.53 ( 71.76)\tAcc@5  89.84 ( 92.70)\n","Epoch: [60][270/391]\tTime  0.168 ( 0.170)\tLoss 8.0853e-01 (9.7831e-01)\tAcc@1  76.56 ( 72.10)\tAcc@5  95.31 ( 92.80)\n","Epoch: [60][300/391]\tTime  0.170 ( 0.170)\tLoss 9.0814e-01 (9.6864e-01)\tAcc@1  72.66 ( 72.36)\tAcc@5  93.75 ( 92.91)\n","Epoch: [60][330/391]\tTime  0.171 ( 0.170)\tLoss 9.0441e-01 (9.6501e-01)\tAcc@1  75.00 ( 72.46)\tAcc@5  92.97 ( 92.99)\n","Epoch: [60][360/391]\tTime  0.169 ( 0.170)\tLoss 8.9649e-01 (9.5964e-01)\tAcc@1  71.09 ( 72.60)\tAcc@5  93.75 ( 93.08)\n","Epoch: [60][390/391]\tTime  0.152 ( 0.170)\tLoss 8.7715e-01 (9.5062e-01)\tAcc@1  71.25 ( 72.81)\tAcc@5  92.50 ( 93.16)\n","==> Train Accuracy: Acc@1 72.808 || Acc@5 93.160\n","==> Test Accuracy:  Acc@1 73.260 || Acc@5 93.500\n","==> 70.61 seconds to train this epoch\n","\n","\n","----- epoch: 61, lr: 0.020000000000000004 -----\n","Epoch: [61][  0/391]\tTime  0.301 ( 0.301)\tLoss 6.8916e-01 (6.8916e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  95.31 ( 95.31)\n","Epoch: [61][ 30/391]\tTime  0.169 ( 0.173)\tLoss 7.2025e-01 (7.8330e-01)\tAcc@1  79.69 ( 76.54)\tAcc@5  95.31 ( 95.14)\n","Epoch: [61][ 60/391]\tTime  0.168 ( 0.171)\tLoss 8.3753e-01 (7.7426e-01)\tAcc@1  78.12 ( 77.20)\tAcc@5  92.19 ( 95.12)\n","Epoch: [61][ 90/391]\tTime  0.170 ( 0.170)\tLoss 6.8455e-01 (7.7374e-01)\tAcc@1  81.25 ( 77.12)\tAcc@5  96.09 ( 95.08)\n","Epoch: [61][120/391]\tTime  0.169 ( 0.170)\tLoss 8.6180e-01 (7.7671e-01)\tAcc@1  75.78 ( 77.10)\tAcc@5  91.41 ( 95.09)\n","Epoch: [61][150/391]\tTime  0.168 ( 0.170)\tLoss 8.6970e-01 (7.8501e-01)\tAcc@1  74.22 ( 76.83)\tAcc@5  92.97 ( 94.95)\n","Epoch: [61][180/391]\tTime  0.170 ( 0.170)\tLoss 9.3887e-01 (7.8721e-01)\tAcc@1  75.00 ( 76.79)\tAcc@5  89.06 ( 94.88)\n","Epoch: [61][210/391]\tTime  0.170 ( 0.170)\tLoss 7.2607e-01 (7.8717e-01)\tAcc@1  80.47 ( 76.82)\tAcc@5  96.09 ( 94.85)\n","Epoch: [61][240/391]\tTime  0.168 ( 0.170)\tLoss 5.0281e-01 (7.8881e-01)\tAcc@1  85.16 ( 76.84)\tAcc@5  96.88 ( 94.84)\n","Epoch: [61][270/391]\tTime  0.171 ( 0.170)\tLoss 6.6742e-01 (7.9239e-01)\tAcc@1  76.56 ( 76.74)\tAcc@5  98.44 ( 94.81)\n","Epoch: [61][300/391]\tTime  0.168 ( 0.170)\tLoss 7.5860e-01 (7.9001e-01)\tAcc@1  77.34 ( 76.83)\tAcc@5  95.31 ( 94.83)\n","Epoch: [61][330/391]\tTime  0.169 ( 0.169)\tLoss 7.4497e-01 (7.8793e-01)\tAcc@1  82.03 ( 76.85)\tAcc@5  96.88 ( 94.91)\n","Epoch: [61][360/391]\tTime  0.169 ( 0.169)\tLoss 6.1910e-01 (7.9154e-01)\tAcc@1  82.81 ( 76.77)\tAcc@5  96.88 ( 94.88)\n","Epoch: [61][390/391]\tTime  0.152 ( 0.169)\tLoss 9.1577e-01 (7.9420e-01)\tAcc@1  80.00 ( 76.72)\tAcc@5  91.25 ( 94.80)\n","==> Train Accuracy: Acc@1 76.716 || Acc@5 94.798\n","==> Test Accuracy:  Acc@1 73.250 || Acc@5 93.600\n","==> 70.45 seconds to train this epoch\n","\n","\n","----- epoch: 62, lr: 0.020000000000000004 -----\n","Epoch: [62][  0/391]\tTime  0.294 ( 0.294)\tLoss 7.8407e-01 (7.8407e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  97.66 ( 97.66)\n","Epoch: [62][ 30/391]\tTime  0.168 ( 0.173)\tLoss 7.5976e-01 (7.0392e-01)\tAcc@1  78.12 ( 79.46)\tAcc@5  94.53 ( 95.84)\n","Epoch: [62][ 60/391]\tTime  0.170 ( 0.171)\tLoss 6.4601e-01 (6.9821e-01)\tAcc@1  81.25 ( 79.53)\tAcc@5  97.66 ( 95.88)\n","Epoch: [62][ 90/391]\tTime  0.169 ( 0.171)\tLoss 6.2636e-01 (7.1308e-01)\tAcc@1  80.47 ( 79.07)\tAcc@5  97.66 ( 95.74)\n","Epoch: [62][120/391]\tTime  0.171 ( 0.170)\tLoss 8.5849e-01 (7.1943e-01)\tAcc@1  76.56 ( 78.99)\tAcc@5  93.75 ( 95.65)\n","Epoch: [62][150/391]\tTime  0.170 ( 0.170)\tLoss 7.1728e-01 (7.2764e-01)\tAcc@1  79.69 ( 78.76)\tAcc@5  96.09 ( 95.58)\n","Epoch: [62][180/391]\tTime  0.169 ( 0.170)\tLoss 7.3973e-01 (7.2686e-01)\tAcc@1  80.47 ( 78.76)\tAcc@5  93.75 ( 95.52)\n","Epoch: [62][210/391]\tTime  0.170 ( 0.170)\tLoss 5.1773e-01 (7.3711e-01)\tAcc@1  86.72 ( 78.40)\tAcc@5  96.88 ( 95.42)\n","Epoch: [62][240/391]\tTime  0.170 ( 0.170)\tLoss 7.9205e-01 (7.4036e-01)\tAcc@1  76.56 ( 78.35)\tAcc@5  93.75 ( 95.35)\n","Epoch: [62][270/391]\tTime  0.168 ( 0.170)\tLoss 9.0554e-01 (7.3957e-01)\tAcc@1  75.00 ( 78.29)\tAcc@5  93.75 ( 95.39)\n","Epoch: [62][300/391]\tTime  0.169 ( 0.170)\tLoss 9.0815e-01 (7.4361e-01)\tAcc@1  69.53 ( 78.10)\tAcc@5  95.31 ( 95.37)\n","Epoch: [62][330/391]\tTime  0.169 ( 0.170)\tLoss 6.7889e-01 (7.4412e-01)\tAcc@1  82.81 ( 78.06)\tAcc@5  94.53 ( 95.37)\n","Epoch: [62][360/391]\tTime  0.172 ( 0.170)\tLoss 7.7876e-01 (7.4819e-01)\tAcc@1  78.91 ( 77.96)\tAcc@5  92.19 ( 95.31)\n","Epoch: [62][390/391]\tTime  0.154 ( 0.170)\tLoss 6.7683e-01 (7.4991e-01)\tAcc@1  81.25 ( 77.95)\tAcc@5  93.75 ( 95.31)\n","==> Train Accuracy: Acc@1 77.950 || Acc@5 95.306\n","==> Test Accuracy:  Acc@1 74.110 || Acc@5 93.800\n","==> 70.54 seconds to train this epoch\n","\n","\n","----- epoch: 63, lr: 0.020000000000000004 -----\n","Epoch: [63][  0/391]\tTime  0.292 ( 0.292)\tLoss 5.9978e-01 (5.9978e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  96.09 ( 96.09)\n","Epoch: [63][ 30/391]\tTime  0.169 ( 0.173)\tLoss 7.3600e-01 (6.8406e-01)\tAcc@1  75.00 ( 80.67)\tAcc@5  96.09 ( 95.84)\n","Epoch: [63][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.7490e-01 (7.0330e-01)\tAcc@1  78.91 ( 79.65)\tAcc@5  94.53 ( 95.74)\n","Epoch: [63][ 90/391]\tTime  0.168 ( 0.171)\tLoss 8.2665e-01 (7.1081e-01)\tAcc@1  79.69 ( 79.40)\tAcc@5  92.19 ( 95.64)\n","Epoch: [63][120/391]\tTime  0.169 ( 0.170)\tLoss 6.2313e-01 (7.1122e-01)\tAcc@1  81.25 ( 79.40)\tAcc@5  96.88 ( 95.67)\n","Epoch: [63][150/391]\tTime  0.169 ( 0.170)\tLoss 9.6840e-01 (7.0964e-01)\tAcc@1  71.09 ( 79.40)\tAcc@5  93.75 ( 95.69)\n","Epoch: [63][180/391]\tTime  0.169 ( 0.170)\tLoss 7.5496e-01 (7.0894e-01)\tAcc@1  77.34 ( 79.26)\tAcc@5  93.75 ( 95.75)\n","Epoch: [63][210/391]\tTime  0.169 ( 0.170)\tLoss 5.6727e-01 (7.1033e-01)\tAcc@1  85.16 ( 79.14)\tAcc@5  97.66 ( 95.75)\n","Epoch: [63][240/391]\tTime  0.169 ( 0.170)\tLoss 5.2130e-01 (7.0927e-01)\tAcc@1  85.94 ( 79.21)\tAcc@5  96.88 ( 95.72)\n","Epoch: [63][270/391]\tTime  0.169 ( 0.170)\tLoss 7.9963e-01 (7.1005e-01)\tAcc@1  77.34 ( 79.19)\tAcc@5  96.88 ( 95.70)\n","Epoch: [63][300/391]\tTime  0.169 ( 0.170)\tLoss 7.6854e-01 (7.1028e-01)\tAcc@1  75.00 ( 79.25)\tAcc@5  98.44 ( 95.71)\n","Epoch: [63][330/391]\tTime  0.168 ( 0.170)\tLoss 6.7838e-01 (7.1530e-01)\tAcc@1  78.12 ( 79.10)\tAcc@5  96.88 ( 95.60)\n","Epoch: [63][360/391]\tTime  0.168 ( 0.170)\tLoss 7.2654e-01 (7.1351e-01)\tAcc@1  78.12 ( 79.14)\tAcc@5  95.31 ( 95.65)\n","Epoch: [63][390/391]\tTime  0.152 ( 0.170)\tLoss 7.3507e-01 (7.1133e-01)\tAcc@1  77.50 ( 79.17)\tAcc@5  96.25 ( 95.67)\n","==> Train Accuracy: Acc@1 79.166 || Acc@5 95.666\n","==> Test Accuracy:  Acc@1 74.200 || Acc@5 93.950\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 64, lr: 0.020000000000000004 -----\n","Epoch: [64][  0/391]\tTime  0.297 ( 0.297)\tLoss 7.6805e-01 (7.6805e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  93.75 ( 93.75)\n","Epoch: [64][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.4296e-01 (6.4268e-01)\tAcc@1  83.59 ( 80.92)\tAcc@5  97.66 ( 96.65)\n","Epoch: [64][ 60/391]\tTime  0.171 ( 0.171)\tLoss 5.9198e-01 (6.4673e-01)\tAcc@1  78.12 ( 80.92)\tAcc@5  96.88 ( 96.47)\n","Epoch: [64][ 90/391]\tTime  0.171 ( 0.170)\tLoss 5.0516e-01 (6.4868e-01)\tAcc@1  85.94 ( 80.76)\tAcc@5  99.22 ( 96.37)\n","Epoch: [64][120/391]\tTime  0.169 ( 0.170)\tLoss 6.7916e-01 (6.5114e-01)\tAcc@1  79.69 ( 80.71)\tAcc@5  96.88 ( 96.31)\n","Epoch: [64][150/391]\tTime  0.171 ( 0.170)\tLoss 6.0018e-01 (6.5567e-01)\tAcc@1  78.91 ( 80.55)\tAcc@5  98.44 ( 96.27)\n","Epoch: [64][180/391]\tTime  0.170 ( 0.170)\tLoss 8.4958e-01 (6.6029e-01)\tAcc@1  79.69 ( 80.56)\tAcc@5  92.97 ( 96.20)\n","Epoch: [64][210/391]\tTime  0.170 ( 0.170)\tLoss 5.9082e-01 (6.6774e-01)\tAcc@1  81.25 ( 80.34)\tAcc@5  97.66 ( 96.11)\n","Epoch: [64][240/391]\tTime  0.169 ( 0.170)\tLoss 8.1143e-01 (6.6784e-01)\tAcc@1  74.22 ( 80.29)\tAcc@5  95.31 ( 96.13)\n","Epoch: [64][270/391]\tTime  0.168 ( 0.170)\tLoss 6.3385e-01 (6.7502e-01)\tAcc@1  81.25 ( 80.08)\tAcc@5  97.66 ( 96.05)\n","Epoch: [64][300/391]\tTime  0.169 ( 0.170)\tLoss 7.6284e-01 (6.7971e-01)\tAcc@1  75.00 ( 79.92)\tAcc@5  94.53 ( 95.99)\n","Epoch: [64][330/391]\tTime  0.170 ( 0.170)\tLoss 7.1021e-01 (6.8063e-01)\tAcc@1  77.34 ( 79.88)\tAcc@5  96.09 ( 96.02)\n","Epoch: [64][360/391]\tTime  0.169 ( 0.170)\tLoss 7.7953e-01 (6.8417e-01)\tAcc@1  79.69 ( 79.81)\tAcc@5  96.09 ( 95.97)\n","Epoch: [64][390/391]\tTime  0.150 ( 0.170)\tLoss 7.9322e-01 (6.8620e-01)\tAcc@1  80.00 ( 79.74)\tAcc@5  92.50 ( 95.94)\n","==> Train Accuracy: Acc@1 79.740 || Acc@5 95.942\n","==> Test Accuracy:  Acc@1 72.820 || Acc@5 93.150\n","==> 70.52 seconds to train this epoch\n","\n","\n","----- epoch: 65, lr: 0.020000000000000004 -----\n","Epoch: [65][  0/391]\tTime  0.280 ( 0.280)\tLoss 6.5424e-01 (6.5424e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  94.53 ( 94.53)\n","Epoch: [65][ 30/391]\tTime  0.171 ( 0.173)\tLoss 6.7709e-01 (6.2818e-01)\tAcc@1  79.69 ( 81.40)\tAcc@5  96.09 ( 96.19)\n","Epoch: [65][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.2780e-01 (6.2920e-01)\tAcc@1  85.16 ( 81.57)\tAcc@5  95.31 ( 96.11)\n","Epoch: [65][ 90/391]\tTime  0.170 ( 0.171)\tLoss 7.5423e-01 (6.3332e-01)\tAcc@1  78.12 ( 81.29)\tAcc@5  96.88 ( 96.29)\n","Epoch: [65][120/391]\tTime  0.170 ( 0.170)\tLoss 6.8852e-01 (6.4041e-01)\tAcc@1  81.25 ( 81.12)\tAcc@5  95.31 ( 96.18)\n","Epoch: [65][150/391]\tTime  0.170 ( 0.170)\tLoss 6.4711e-01 (6.4076e-01)\tAcc@1  82.03 ( 81.18)\tAcc@5  93.75 ( 96.17)\n","Epoch: [65][180/391]\tTime  0.169 ( 0.170)\tLoss 6.1099e-01 (6.4867e-01)\tAcc@1  81.25 ( 80.95)\tAcc@5  97.66 ( 96.05)\n","Epoch: [65][210/391]\tTime  0.170 ( 0.170)\tLoss 5.4279e-01 (6.4754e-01)\tAcc@1  78.91 ( 80.86)\tAcc@5  99.22 ( 96.20)\n","Epoch: [65][240/391]\tTime  0.170 ( 0.170)\tLoss 7.3055e-01 (6.5423e-01)\tAcc@1  78.91 ( 80.72)\tAcc@5  93.75 ( 96.14)\n","Epoch: [65][270/391]\tTime  0.169 ( 0.170)\tLoss 5.6872e-01 (6.5706e-01)\tAcc@1  82.81 ( 80.62)\tAcc@5  97.66 ( 96.11)\n","Epoch: [65][300/391]\tTime  0.169 ( 0.170)\tLoss 8.1760e-01 (6.5943e-01)\tAcc@1  76.56 ( 80.58)\tAcc@5  94.53 ( 96.09)\n","Epoch: [65][330/391]\tTime  0.169 ( 0.170)\tLoss 7.7426e-01 (6.6135e-01)\tAcc@1  77.34 ( 80.50)\tAcc@5  94.53 ( 96.07)\n","Epoch: [65][360/391]\tTime  0.171 ( 0.170)\tLoss 6.4114e-01 (6.6276e-01)\tAcc@1  80.47 ( 80.43)\tAcc@5  96.88 ( 96.07)\n","Epoch: [65][390/391]\tTime  0.152 ( 0.170)\tLoss 8.2927e-01 (6.6594e-01)\tAcc@1  77.50 ( 80.33)\tAcc@5  91.25 ( 96.05)\n","==> Train Accuracy: Acc@1 80.334 || Acc@5 96.050\n","==> Test Accuracy:  Acc@1 72.960 || Acc@5 93.730\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 66, lr: 0.020000000000000004 -----\n","Epoch: [66][  0/391]\tTime  0.298 ( 0.298)\tLoss 6.5190e-01 (6.5190e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.09 ( 96.09)\n","Epoch: [66][ 30/391]\tTime  0.172 ( 0.173)\tLoss 5.0921e-01 (6.3279e-01)\tAcc@1  85.16 ( 81.33)\tAcc@5 100.00 ( 96.45)\n","Epoch: [66][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.9070e-01 (6.1091e-01)\tAcc@1  79.69 ( 81.97)\tAcc@5  96.09 ( 96.66)\n","Epoch: [66][ 90/391]\tTime  0.170 ( 0.171)\tLoss 5.5930e-01 (6.0427e-01)\tAcc@1  86.72 ( 82.14)\tAcc@5  93.75 ( 96.69)\n","Epoch: [66][120/391]\tTime  0.168 ( 0.170)\tLoss 5.3687e-01 (6.1662e-01)\tAcc@1  84.38 ( 81.77)\tAcc@5  96.09 ( 96.62)\n","Epoch: [66][150/391]\tTime  0.169 ( 0.170)\tLoss 6.2558e-01 (6.2585e-01)\tAcc@1  80.47 ( 81.62)\tAcc@5  97.66 ( 96.43)\n","Epoch: [66][180/391]\tTime  0.170 ( 0.170)\tLoss 9.1690e-01 (6.3117e-01)\tAcc@1  72.66 ( 81.32)\tAcc@5  93.75 ( 96.39)\n","Epoch: [66][210/391]\tTime  0.169 ( 0.170)\tLoss 5.1224e-01 (6.3207e-01)\tAcc@1  85.94 ( 81.30)\tAcc@5  97.66 ( 96.38)\n","Epoch: [66][240/391]\tTime  0.169 ( 0.170)\tLoss 7.2669e-01 (6.3440e-01)\tAcc@1  77.34 ( 81.22)\tAcc@5  94.53 ( 96.33)\n","Epoch: [66][270/391]\tTime  0.170 ( 0.170)\tLoss 8.9428e-01 (6.3794e-01)\tAcc@1  71.88 ( 81.13)\tAcc@5  91.41 ( 96.28)\n","Epoch: [66][300/391]\tTime  0.170 ( 0.170)\tLoss 6.9265e-01 (6.4088e-01)\tAcc@1  82.03 ( 81.03)\tAcc@5  96.09 ( 96.29)\n","Epoch: [66][330/391]\tTime  0.168 ( 0.170)\tLoss 6.7820e-01 (6.4146e-01)\tAcc@1  79.69 ( 81.05)\tAcc@5  96.88 ( 96.29)\n","Epoch: [66][360/391]\tTime  0.169 ( 0.170)\tLoss 6.3072e-01 (6.4623e-01)\tAcc@1  81.25 ( 80.91)\tAcc@5  95.31 ( 96.26)\n","Epoch: [66][390/391]\tTime  0.153 ( 0.170)\tLoss 7.3809e-01 (6.4772e-01)\tAcc@1  78.75 ( 80.89)\tAcc@5  97.50 ( 96.26)\n","==> Train Accuracy: Acc@1 80.890 || Acc@5 96.262\n","==> Test Accuracy:  Acc@1 73.030 || Acc@5 93.390\n","==> 70.59 seconds to train this epoch\n","\n","\n","----- epoch: 67, lr: 0.020000000000000004 -----\n","Epoch: [67][  0/391]\tTime  0.288 ( 0.288)\tLoss 5.0721e-01 (5.0721e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5 100.00 (100.00)\n","Epoch: [67][ 30/391]\tTime  0.168 ( 0.173)\tLoss 7.3207e-01 (6.0035e-01)\tAcc@1  82.03 ( 82.13)\tAcc@5  92.97 ( 96.82)\n","Epoch: [67][ 60/391]\tTime  0.168 ( 0.171)\tLoss 5.6647e-01 (6.1265e-01)\tAcc@1  85.94 ( 81.83)\tAcc@5  96.09 ( 96.61)\n","Epoch: [67][ 90/391]\tTime  0.169 ( 0.171)\tLoss 5.7839e-01 (6.1208e-01)\tAcc@1  82.81 ( 81.90)\tAcc@5  96.88 ( 96.55)\n","Epoch: [67][120/391]\tTime  0.169 ( 0.170)\tLoss 5.3322e-01 (6.1436e-01)\tAcc@1  85.16 ( 81.89)\tAcc@5  96.09 ( 96.57)\n","Epoch: [67][150/391]\tTime  0.170 ( 0.170)\tLoss 6.1502e-01 (6.1845e-01)\tAcc@1  82.81 ( 81.81)\tAcc@5  95.31 ( 96.46)\n","Epoch: [67][180/391]\tTime  0.171 ( 0.170)\tLoss 6.1660e-01 (6.2138e-01)\tAcc@1  82.03 ( 81.63)\tAcc@5  97.66 ( 96.47)\n","Epoch: [67][210/391]\tTime  0.170 ( 0.170)\tLoss 6.8484e-01 (6.2776e-01)\tAcc@1  80.47 ( 81.42)\tAcc@5  96.88 ( 96.38)\n","Epoch: [67][240/391]\tTime  0.170 ( 0.170)\tLoss 5.8307e-01 (6.3256e-01)\tAcc@1  83.59 ( 81.38)\tAcc@5  98.44 ( 96.40)\n","Epoch: [67][270/391]\tTime  0.170 ( 0.170)\tLoss 7.1232e-01 (6.3537e-01)\tAcc@1  74.22 ( 81.27)\tAcc@5  97.66 ( 96.45)\n","Epoch: [67][300/391]\tTime  0.170 ( 0.170)\tLoss 7.4830e-01 (6.3555e-01)\tAcc@1  77.34 ( 81.25)\tAcc@5  95.31 ( 96.43)\n","Epoch: [67][330/391]\tTime  0.170 ( 0.170)\tLoss 4.8788e-01 (6.3760e-01)\tAcc@1  84.38 ( 81.21)\tAcc@5 100.00 ( 96.41)\n","Epoch: [67][360/391]\tTime  0.168 ( 0.170)\tLoss 7.1811e-01 (6.4078e-01)\tAcc@1  77.34 ( 81.10)\tAcc@5  96.09 ( 96.40)\n","Epoch: [67][390/391]\tTime  0.152 ( 0.170)\tLoss 7.7041e-01 (6.4319e-01)\tAcc@1  76.25 ( 81.01)\tAcc@5  97.50 ( 96.41)\n","==> Train Accuracy: Acc@1 81.008 || Acc@5 96.414\n","==> Test Accuracy:  Acc@1 73.390 || Acc@5 93.340\n","==> 70.59 seconds to train this epoch\n","\n","\n","----- epoch: 68, lr: 0.020000000000000004 -----\n","Epoch: [68][  0/391]\tTime  0.285 ( 0.285)\tLoss 6.3019e-01 (6.3019e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.09 ( 96.09)\n","Epoch: [68][ 30/391]\tTime  0.170 ( 0.172)\tLoss 5.4150e-01 (6.1306e-01)\tAcc@1  83.59 ( 81.78)\tAcc@5  96.88 ( 96.85)\n","Epoch: [68][ 60/391]\tTime  0.169 ( 0.171)\tLoss 4.8315e-01 (6.1461e-01)\tAcc@1  82.03 ( 81.65)\tAcc@5 100.00 ( 96.77)\n","Epoch: [68][ 90/391]\tTime  0.169 ( 0.170)\tLoss 7.4141e-01 (6.1603e-01)\tAcc@1  78.12 ( 81.83)\tAcc@5  95.31 ( 96.79)\n","Epoch: [68][120/391]\tTime  0.170 ( 0.170)\tLoss 4.8080e-01 (6.1065e-01)\tAcc@1  86.72 ( 81.93)\tAcc@5  97.66 ( 96.74)\n","Epoch: [68][150/391]\tTime  0.169 ( 0.170)\tLoss 6.6962e-01 (6.2256e-01)\tAcc@1  79.69 ( 81.64)\tAcc@5  96.09 ( 96.57)\n","Epoch: [68][180/391]\tTime  0.169 ( 0.170)\tLoss 6.9863e-01 (6.2151e-01)\tAcc@1  77.34 ( 81.62)\tAcc@5  96.88 ( 96.62)\n","Epoch: [68][210/391]\tTime  0.168 ( 0.169)\tLoss 8.3837e-01 (6.2862e-01)\tAcc@1  75.00 ( 81.51)\tAcc@5  96.09 ( 96.52)\n","Epoch: [68][240/391]\tTime  0.169 ( 0.169)\tLoss 7.0485e-01 (6.3145e-01)\tAcc@1  78.12 ( 81.41)\tAcc@5  96.09 ( 96.50)\n","Epoch: [68][270/391]\tTime  0.169 ( 0.169)\tLoss 7.5326e-01 (6.3599e-01)\tAcc@1  77.34 ( 81.32)\tAcc@5  96.88 ( 96.45)\n","Epoch: [68][300/391]\tTime  0.168 ( 0.169)\tLoss 5.7228e-01 (6.3894e-01)\tAcc@1  82.81 ( 81.25)\tAcc@5  97.66 ( 96.41)\n","Epoch: [68][330/391]\tTime  0.171 ( 0.169)\tLoss 4.7504e-01 (6.4153e-01)\tAcc@1  86.72 ( 81.16)\tAcc@5  96.88 ( 96.38)\n","Epoch: [68][360/391]\tTime  0.167 ( 0.169)\tLoss 7.3723e-01 (6.4461e-01)\tAcc@1  79.69 ( 81.09)\tAcc@5  94.53 ( 96.35)\n","Epoch: [68][390/391]\tTime  0.152 ( 0.169)\tLoss 7.2515e-01 (6.4698e-01)\tAcc@1  80.00 ( 80.98)\tAcc@5  96.25 ( 96.34)\n","==> Train Accuracy: Acc@1 80.984 || Acc@5 96.338\n","==> Test Accuracy:  Acc@1 73.040 || Acc@5 93.330\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 69, lr: 0.020000000000000004 -----\n","Epoch: [69][  0/391]\tTime  0.291 ( 0.291)\tLoss 7.1121e-01 (7.1121e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  96.09 ( 96.09)\n","Epoch: [69][ 30/391]\tTime  0.173 ( 0.173)\tLoss 4.2376e-01 (5.8824e-01)\tAcc@1  90.62 ( 82.38)\tAcc@5  96.88 ( 96.80)\n","Epoch: [69][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.8817e-01 (5.9568e-01)\tAcc@1  79.69 ( 82.33)\tAcc@5  96.09 ( 96.84)\n","Epoch: [69][ 90/391]\tTime  0.169 ( 0.171)\tLoss 7.2792e-01 (5.9965e-01)\tAcc@1  80.47 ( 82.37)\tAcc@5  95.31 ( 96.67)\n","Epoch: [69][120/391]\tTime  0.168 ( 0.170)\tLoss 5.5573e-01 (5.9801e-01)\tAcc@1  84.38 ( 82.41)\tAcc@5  97.66 ( 96.69)\n","Epoch: [69][150/391]\tTime  0.172 ( 0.170)\tLoss 6.7101e-01 (6.0031e-01)\tAcc@1  78.91 ( 82.35)\tAcc@5  96.09 ( 96.66)\n","Epoch: [69][180/391]\tTime  0.170 ( 0.170)\tLoss 7.1090e-01 (6.0867e-01)\tAcc@1  78.91 ( 82.01)\tAcc@5  94.53 ( 96.59)\n","Epoch: [69][210/391]\tTime  0.171 ( 0.170)\tLoss 4.7186e-01 (6.1243e-01)\tAcc@1  86.72 ( 81.95)\tAcc@5  97.66 ( 96.51)\n","Epoch: [69][240/391]\tTime  0.171 ( 0.170)\tLoss 6.3528e-01 (6.1780e-01)\tAcc@1  82.81 ( 81.81)\tAcc@5  97.66 ( 96.50)\n","Epoch: [69][270/391]\tTime  0.170 ( 0.170)\tLoss 6.3816e-01 (6.2305e-01)\tAcc@1  79.69 ( 81.66)\tAcc@5  95.31 ( 96.49)\n","Epoch: [69][300/391]\tTime  0.169 ( 0.170)\tLoss 5.4323e-01 (6.2675e-01)\tAcc@1  84.38 ( 81.55)\tAcc@5  97.66 ( 96.47)\n","Epoch: [69][330/391]\tTime  0.169 ( 0.170)\tLoss 5.9239e-01 (6.2879e-01)\tAcc@1  85.16 ( 81.48)\tAcc@5  97.66 ( 96.46)\n","Epoch: [69][360/391]\tTime  0.168 ( 0.170)\tLoss 7.5156e-01 (6.3525e-01)\tAcc@1  78.12 ( 81.22)\tAcc@5  95.31 ( 96.43)\n","Epoch: [69][390/391]\tTime  0.151 ( 0.170)\tLoss 8.1993e-01 (6.3577e-01)\tAcc@1  73.75 ( 81.20)\tAcc@5  96.25 ( 96.42)\n","==> Train Accuracy: Acc@1 81.200 || Acc@5 96.418\n","==> Test Accuracy:  Acc@1 72.210 || Acc@5 92.810\n","==> 70.55 seconds to train this epoch\n","\n","\n","----- epoch: 70, lr: 0.020000000000000004 -----\n","Epoch: [70][  0/391]\tTime  0.278 ( 0.278)\tLoss 4.2728e-01 (4.2728e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  97.66 ( 97.66)\n","Epoch: [70][ 30/391]\tTime  0.169 ( 0.173)\tLoss 7.5173e-01 (6.0219e-01)\tAcc@1  79.69 ( 82.38)\tAcc@5  97.66 ( 96.88)\n","Epoch: [70][ 60/391]\tTime  0.173 ( 0.171)\tLoss 5.3357e-01 (5.9729e-01)\tAcc@1  88.28 ( 82.90)\tAcc@5  95.31 ( 96.55)\n","Epoch: [70][ 90/391]\tTime  0.170 ( 0.171)\tLoss 4.8139e-01 (5.9138e-01)\tAcc@1  87.50 ( 82.82)\tAcc@5  97.66 ( 96.72)\n","Epoch: [70][120/391]\tTime  0.168 ( 0.170)\tLoss 5.3308e-01 (5.9401e-01)\tAcc@1  83.59 ( 82.52)\tAcc@5  98.44 ( 96.66)\n","Epoch: [70][150/391]\tTime  0.168 ( 0.170)\tLoss 5.8300e-01 (5.9761e-01)\tAcc@1  83.59 ( 82.26)\tAcc@5  97.66 ( 96.77)\n","Epoch: [70][180/391]\tTime  0.169 ( 0.170)\tLoss 6.9267e-01 (6.0076e-01)\tAcc@1  82.03 ( 82.23)\tAcc@5  97.66 ( 96.73)\n","Epoch: [70][210/391]\tTime  0.170 ( 0.170)\tLoss 8.5212e-01 (6.0284e-01)\tAcc@1  73.44 ( 82.24)\tAcc@5  93.75 ( 96.69)\n","Epoch: [70][240/391]\tTime  0.170 ( 0.170)\tLoss 6.5631e-01 (6.0719e-01)\tAcc@1  82.03 ( 82.10)\tAcc@5  96.88 ( 96.68)\n","Epoch: [70][270/391]\tTime  0.170 ( 0.170)\tLoss 6.3590e-01 (6.1113e-01)\tAcc@1  78.91 ( 82.02)\tAcc@5  98.44 ( 96.68)\n","Epoch: [70][300/391]\tTime  0.170 ( 0.170)\tLoss 4.8516e-01 (6.1523e-01)\tAcc@1  88.28 ( 81.91)\tAcc@5 100.00 ( 96.62)\n","Epoch: [70][330/391]\tTime  0.168 ( 0.170)\tLoss 6.9442e-01 (6.1884e-01)\tAcc@1  75.78 ( 81.76)\tAcc@5  97.66 ( 96.63)\n","Epoch: [70][360/391]\tTime  0.168 ( 0.170)\tLoss 6.0813e-01 (6.2674e-01)\tAcc@1  84.38 ( 81.52)\tAcc@5  96.09 ( 96.55)\n","Epoch: [70][390/391]\tTime  0.151 ( 0.170)\tLoss 6.4772e-01 (6.3065e-01)\tAcc@1  82.50 ( 81.38)\tAcc@5  96.25 ( 96.49)\n","==> Train Accuracy: Acc@1 81.384 || Acc@5 96.494\n","==> Test Accuracy:  Acc@1 70.860 || Acc@5 91.950\n","==> 70.59 seconds to train this epoch\n","\n","\n","----- epoch: 71, lr: 0.020000000000000004 -----\n","Epoch: [71][  0/391]\tTime  0.286 ( 0.286)\tLoss 6.3082e-01 (6.3082e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  95.31 ( 95.31)\n","Epoch: [71][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.6105e-01 (6.1071e-01)\tAcc@1  84.38 ( 82.01)\tAcc@5  95.31 ( 96.60)\n","Epoch: [71][ 60/391]\tTime  0.170 ( 0.171)\tLoss 5.7675e-01 (5.9112e-01)\tAcc@1  85.16 ( 82.54)\tAcc@5  96.09 ( 96.88)\n","Epoch: [71][ 90/391]\tTime  0.168 ( 0.170)\tLoss 5.8754e-01 (5.9907e-01)\tAcc@1  84.38 ( 82.36)\tAcc@5  95.31 ( 96.76)\n","Epoch: [71][120/391]\tTime  0.168 ( 0.170)\tLoss 7.7048e-01 (6.0420e-01)\tAcc@1  78.91 ( 82.24)\tAcc@5  96.88 ( 96.78)\n","Epoch: [71][150/391]\tTime  0.168 ( 0.170)\tLoss 7.0415e-01 (6.0491e-01)\tAcc@1  77.34 ( 82.13)\tAcc@5  96.88 ( 96.77)\n","Epoch: [71][180/391]\tTime  0.169 ( 0.170)\tLoss 6.2271e-01 (6.1204e-01)\tAcc@1  77.34 ( 81.98)\tAcc@5  98.44 ( 96.69)\n","Epoch: [71][210/391]\tTime  0.168 ( 0.170)\tLoss 6.3606e-01 (6.1162e-01)\tAcc@1  84.38 ( 81.93)\tAcc@5  96.09 ( 96.69)\n","Epoch: [71][240/391]\tTime  0.170 ( 0.170)\tLoss 6.9974e-01 (6.1437e-01)\tAcc@1  78.91 ( 81.83)\tAcc@5  93.75 ( 96.62)\n","Epoch: [71][270/391]\tTime  0.169 ( 0.170)\tLoss 5.8988e-01 (6.1970e-01)\tAcc@1  84.38 ( 81.68)\tAcc@5  95.31 ( 96.56)\n","Epoch: [71][300/391]\tTime  0.168 ( 0.170)\tLoss 6.4911e-01 (6.2145e-01)\tAcc@1  82.03 ( 81.64)\tAcc@5  95.31 ( 96.53)\n","Epoch: [71][330/391]\tTime  0.171 ( 0.170)\tLoss 5.5785e-01 (6.2526e-01)\tAcc@1  82.03 ( 81.55)\tAcc@5  98.44 ( 96.47)\n","Epoch: [71][360/391]\tTime  0.168 ( 0.170)\tLoss 6.3796e-01 (6.2901e-01)\tAcc@1  82.03 ( 81.41)\tAcc@5  96.88 ( 96.45)\n","Epoch: [71][390/391]\tTime  0.152 ( 0.170)\tLoss 7.8165e-01 (6.3151e-01)\tAcc@1  81.25 ( 81.32)\tAcc@5  95.00 ( 96.43)\n","==> Train Accuracy: Acc@1 81.318 || Acc@5 96.428\n","==> Test Accuracy:  Acc@1 72.070 || Acc@5 93.160\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 72, lr: 0.020000000000000004 -----\n","Epoch: [72][  0/391]\tTime  0.285 ( 0.285)\tLoss 6.8845e-01 (6.8845e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  95.31 ( 95.31)\n","Epoch: [72][ 30/391]\tTime  0.168 ( 0.173)\tLoss 6.9812e-01 (6.1122e-01)\tAcc@1  78.12 ( 82.54)\tAcc@5  95.31 ( 96.50)\n","Epoch: [72][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.1451e-01 (6.0569e-01)\tAcc@1  82.03 ( 82.59)\tAcc@5  96.88 ( 96.62)\n","Epoch: [72][ 90/391]\tTime  0.171 ( 0.171)\tLoss 6.3775e-01 (5.9300e-01)\tAcc@1  83.59 ( 82.79)\tAcc@5  95.31 ( 96.78)\n","Epoch: [72][120/391]\tTime  0.171 ( 0.170)\tLoss 6.0068e-01 (5.9523e-01)\tAcc@1  82.81 ( 82.79)\tAcc@5  97.66 ( 96.64)\n","Epoch: [72][150/391]\tTime  0.170 ( 0.170)\tLoss 8.5769e-01 (5.9641e-01)\tAcc@1  78.12 ( 82.76)\tAcc@5  94.53 ( 96.62)\n","Epoch: [72][180/391]\tTime  0.170 ( 0.170)\tLoss 5.2952e-01 (6.0121e-01)\tAcc@1  82.81 ( 82.54)\tAcc@5  97.66 ( 96.60)\n","Epoch: [72][210/391]\tTime  0.168 ( 0.170)\tLoss 7.1914e-01 (6.0231e-01)\tAcc@1  74.22 ( 82.42)\tAcc@5  96.09 ( 96.63)\n","Epoch: [72][240/391]\tTime  0.169 ( 0.170)\tLoss 6.7774e-01 (6.1275e-01)\tAcc@1  79.69 ( 82.07)\tAcc@5  97.66 ( 96.56)\n","Epoch: [72][270/391]\tTime  0.168 ( 0.170)\tLoss 5.4828e-01 (6.2080e-01)\tAcc@1  80.47 ( 81.82)\tAcc@5 100.00 ( 96.47)\n","Epoch: [72][300/391]\tTime  0.169 ( 0.170)\tLoss 6.1744e-01 (6.2361e-01)\tAcc@1  85.16 ( 81.75)\tAcc@5  96.09 ( 96.44)\n","Epoch: [72][330/391]\tTime  0.171 ( 0.170)\tLoss 4.7310e-01 (6.2830e-01)\tAcc@1  86.72 ( 81.61)\tAcc@5  98.44 ( 96.37)\n","Epoch: [72][360/391]\tTime  0.171 ( 0.170)\tLoss 6.8336e-01 (6.3145e-01)\tAcc@1  77.34 ( 81.52)\tAcc@5  95.31 ( 96.33)\n","Epoch: [72][390/391]\tTime  0.150 ( 0.170)\tLoss 7.3777e-01 (6.3354e-01)\tAcc@1  76.25 ( 81.41)\tAcc@5  95.00 ( 96.34)\n","==> Train Accuracy: Acc@1 81.408 || Acc@5 96.336\n","==> Test Accuracy:  Acc@1 71.920 || Acc@5 92.760\n","==> 70.58 seconds to train this epoch\n","\n","\n","----- epoch: 73, lr: 0.020000000000000004 -----\n","Epoch: [73][  0/391]\tTime  0.282 ( 0.282)\tLoss 4.9637e-01 (4.9637e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  97.66 ( 97.66)\n","Epoch: [73][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.3690e-01 (5.7443e-01)\tAcc@1  83.59 ( 84.07)\tAcc@5  97.66 ( 96.70)\n","Epoch: [73][ 60/391]\tTime  0.170 ( 0.171)\tLoss 6.3495e-01 (5.6575e-01)\tAcc@1  82.03 ( 83.56)\tAcc@5  96.09 ( 96.90)\n","Epoch: [73][ 90/391]\tTime  0.169 ( 0.170)\tLoss 5.1333e-01 (5.7640e-01)\tAcc@1  83.59 ( 83.01)\tAcc@5  96.09 ( 96.88)\n","Epoch: [73][120/391]\tTime  0.170 ( 0.170)\tLoss 6.5759e-01 (5.8154e-01)\tAcc@1  82.03 ( 82.89)\tAcc@5  97.66 ( 96.81)\n","Epoch: [73][150/391]\tTime  0.169 ( 0.170)\tLoss 4.5836e-01 (5.8447e-01)\tAcc@1  85.16 ( 82.76)\tAcc@5  99.22 ( 96.76)\n","Epoch: [73][180/391]\tTime  0.168 ( 0.170)\tLoss 4.5716e-01 (5.8565e-01)\tAcc@1  86.72 ( 82.71)\tAcc@5  98.44 ( 96.78)\n","Epoch: [73][210/391]\tTime  0.168 ( 0.170)\tLoss 7.3434e-01 (5.9262e-01)\tAcc@1  76.56 ( 82.39)\tAcc@5  96.88 ( 96.81)\n","Epoch: [73][240/391]\tTime  0.169 ( 0.170)\tLoss 6.6343e-01 (6.0036e-01)\tAcc@1  78.12 ( 82.14)\tAcc@5  96.09 ( 96.75)\n","Epoch: [73][270/391]\tTime  0.170 ( 0.169)\tLoss 5.9793e-01 (6.0768e-01)\tAcc@1  82.03 ( 82.00)\tAcc@5  96.09 ( 96.66)\n","Epoch: [73][300/391]\tTime  0.171 ( 0.169)\tLoss 7.6158e-01 (6.1377e-01)\tAcc@1  78.91 ( 81.83)\tAcc@5  95.31 ( 96.60)\n","Epoch: [73][330/391]\tTime  0.169 ( 0.169)\tLoss 6.0300e-01 (6.2113e-01)\tAcc@1  82.81 ( 81.58)\tAcc@5  98.44 ( 96.58)\n","Epoch: [73][360/391]\tTime  0.170 ( 0.169)\tLoss 5.7595e-01 (6.2560e-01)\tAcc@1  80.47 ( 81.45)\tAcc@5  96.88 ( 96.54)\n","Epoch: [73][390/391]\tTime  0.152 ( 0.169)\tLoss 7.3936e-01 (6.2673e-01)\tAcc@1  75.00 ( 81.35)\tAcc@5  97.50 ( 96.56)\n","==> Train Accuracy: Acc@1 81.350 || Acc@5 96.556\n","==> Test Accuracy:  Acc@1 70.430 || Acc@5 92.080\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 74, lr: 0.020000000000000004 -----\n","Epoch: [74][  0/391]\tTime  0.286 ( 0.286)\tLoss 5.7150e-01 (5.7150e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  98.44 ( 98.44)\n","Epoch: [74][ 30/391]\tTime  0.169 ( 0.172)\tLoss 5.5255e-01 (6.1071e-01)\tAcc@1  83.59 ( 82.01)\tAcc@5  95.31 ( 96.70)\n","Epoch: [74][ 60/391]\tTime  0.170 ( 0.171)\tLoss 6.6863e-01 (6.0707e-01)\tAcc@1  81.25 ( 81.65)\tAcc@5  96.09 ( 96.76)\n","Epoch: [74][ 90/391]\tTime  0.170 ( 0.170)\tLoss 4.4653e-01 (5.9821e-01)\tAcc@1  88.28 ( 82.04)\tAcc@5  98.44 ( 96.77)\n","Epoch: [74][120/391]\tTime  0.170 ( 0.170)\tLoss 7.3410e-01 (6.0001e-01)\tAcc@1  76.56 ( 82.02)\tAcc@5  92.97 ( 96.64)\n","Epoch: [74][150/391]\tTime  0.170 ( 0.170)\tLoss 5.4347e-01 (6.0662e-01)\tAcc@1  85.16 ( 81.92)\tAcc@5  98.44 ( 96.56)\n","Epoch: [74][180/391]\tTime  0.169 ( 0.170)\tLoss 8.5167e-01 (6.1231e-01)\tAcc@1  78.12 ( 81.85)\tAcc@5  92.97 ( 96.47)\n","Epoch: [74][210/391]\tTime  0.168 ( 0.170)\tLoss 6.0173e-01 (6.1594e-01)\tAcc@1  81.25 ( 81.77)\tAcc@5  96.88 ( 96.48)\n","Epoch: [74][240/391]\tTime  0.170 ( 0.170)\tLoss 5.8829e-01 (6.2242e-01)\tAcc@1  80.47 ( 81.59)\tAcc@5  96.88 ( 96.40)\n","Epoch: [74][270/391]\tTime  0.169 ( 0.170)\tLoss 7.0986e-01 (6.2494e-01)\tAcc@1  78.91 ( 81.57)\tAcc@5  94.53 ( 96.41)\n","Epoch: [74][300/391]\tTime  0.170 ( 0.170)\tLoss 7.2055e-01 (6.2554e-01)\tAcc@1  77.34 ( 81.57)\tAcc@5  95.31 ( 96.43)\n","Epoch: [74][330/391]\tTime  0.171 ( 0.170)\tLoss 5.3145e-01 (6.2401e-01)\tAcc@1  83.59 ( 81.59)\tAcc@5  96.88 ( 96.47)\n","Epoch: [74][360/391]\tTime  0.170 ( 0.170)\tLoss 7.0262e-01 (6.2596e-01)\tAcc@1  80.47 ( 81.57)\tAcc@5  95.31 ( 96.45)\n","Epoch: [74][390/391]\tTime  0.152 ( 0.169)\tLoss 7.6889e-01 (6.2952e-01)\tAcc@1  80.00 ( 81.49)\tAcc@5  96.25 ( 96.44)\n","==> Train Accuracy: Acc@1 81.490 || Acc@5 96.438\n","==> Test Accuracy:  Acc@1 72.100 || Acc@5 92.650\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 75, lr: 0.020000000000000004 -----\n","Epoch: [75][  0/391]\tTime  0.286 ( 0.286)\tLoss 5.1534e-01 (5.1534e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  97.66 ( 97.66)\n","Epoch: [75][ 30/391]\tTime  0.169 ( 0.172)\tLoss 5.1037e-01 (5.6086e-01)\tAcc@1  81.25 ( 83.29)\tAcc@5  97.66 ( 97.05)\n","Epoch: [75][ 60/391]\tTime  0.170 ( 0.171)\tLoss 5.2197e-01 (5.9255e-01)\tAcc@1  83.59 ( 82.52)\tAcc@5  97.66 ( 96.80)\n","Epoch: [75][ 90/391]\tTime  0.169 ( 0.170)\tLoss 4.7295e-01 (6.0159e-01)\tAcc@1  83.59 ( 82.14)\tAcc@5  97.66 ( 96.86)\n","Epoch: [75][120/391]\tTime  0.169 ( 0.170)\tLoss 6.6700e-01 (6.0187e-01)\tAcc@1  82.03 ( 82.04)\tAcc@5  95.31 ( 96.82)\n","Epoch: [75][150/391]\tTime  0.168 ( 0.170)\tLoss 5.8647e-01 (6.0341e-01)\tAcc@1  80.47 ( 81.93)\tAcc@5  98.44 ( 96.86)\n","Epoch: [75][180/391]\tTime  0.171 ( 0.170)\tLoss 5.6246e-01 (6.0459e-01)\tAcc@1  83.59 ( 81.83)\tAcc@5  98.44 ( 96.88)\n","Epoch: [75][210/391]\tTime  0.170 ( 0.170)\tLoss 4.4298e-01 (6.0181e-01)\tAcc@1  87.50 ( 82.00)\tAcc@5  98.44 ( 96.89)\n","Epoch: [75][240/391]\tTime  0.169 ( 0.170)\tLoss 8.3729e-01 (6.0641e-01)\tAcc@1  75.00 ( 81.82)\tAcc@5  93.75 ( 96.87)\n","Epoch: [75][270/391]\tTime  0.169 ( 0.170)\tLoss 7.1980e-01 (6.0855e-01)\tAcc@1  81.25 ( 81.74)\tAcc@5  95.31 ( 96.83)\n","Epoch: [75][300/391]\tTime  0.169 ( 0.170)\tLoss 5.4088e-01 (6.1231e-01)\tAcc@1  87.50 ( 81.64)\tAcc@5  97.66 ( 96.80)\n","Epoch: [75][330/391]\tTime  0.167 ( 0.169)\tLoss 5.5810e-01 (6.1602e-01)\tAcc@1  82.81 ( 81.52)\tAcc@5  96.09 ( 96.74)\n","Epoch: [75][360/391]\tTime  0.169 ( 0.169)\tLoss 8.3128e-01 (6.1900e-01)\tAcc@1  71.88 ( 81.39)\tAcc@5  96.09 ( 96.71)\n","Epoch: [75][390/391]\tTime  0.152 ( 0.169)\tLoss 5.5641e-01 (6.2242e-01)\tAcc@1  78.75 ( 81.29)\tAcc@5  98.75 ( 96.69)\n","==> Train Accuracy: Acc@1 81.294 || Acc@5 96.688\n","==> Test Accuracy:  Acc@1 71.170 || Acc@5 92.520\n","==> 70.45 seconds to train this epoch\n","\n","\n","----- epoch: 76, lr: 0.020000000000000004 -----\n","Epoch: [76][  0/391]\tTime  0.286 ( 0.286)\tLoss 8.5139e-01 (8.5139e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  96.09 ( 96.09)\n","Epoch: [76][ 30/391]\tTime  0.168 ( 0.173)\tLoss 5.0684e-01 (5.8528e-01)\tAcc@1  85.16 ( 83.09)\tAcc@5  99.22 ( 97.05)\n","Epoch: [76][ 60/391]\tTime  0.168 ( 0.171)\tLoss 5.3705e-01 (5.7249e-01)\tAcc@1  84.38 ( 83.29)\tAcc@5  97.66 ( 97.16)\n","Epoch: [76][ 90/391]\tTime  0.168 ( 0.170)\tLoss 5.5265e-01 (5.7855e-01)\tAcc@1  82.81 ( 83.19)\tAcc@5  96.09 ( 97.12)\n","Epoch: [76][120/391]\tTime  0.170 ( 0.170)\tLoss 7.1620e-01 (5.7826e-01)\tAcc@1  77.34 ( 83.24)\tAcc@5  96.88 ( 97.04)\n","Epoch: [76][150/391]\tTime  0.171 ( 0.170)\tLoss 5.9409e-01 (5.8990e-01)\tAcc@1  81.25 ( 82.84)\tAcc@5  95.31 ( 96.89)\n","Epoch: [76][180/391]\tTime  0.168 ( 0.170)\tLoss 4.7104e-01 (5.9542e-01)\tAcc@1  85.16 ( 82.64)\tAcc@5  98.44 ( 96.85)\n","Epoch: [76][210/391]\tTime  0.169 ( 0.170)\tLoss 7.6240e-01 (5.9753e-01)\tAcc@1  75.00 ( 82.56)\tAcc@5  95.31 ( 96.80)\n","Epoch: [76][240/391]\tTime  0.168 ( 0.170)\tLoss 7.0536e-01 (6.0495e-01)\tAcc@1  81.25 ( 82.28)\tAcc@5  94.53 ( 96.75)\n","Epoch: [76][270/391]\tTime  0.170 ( 0.170)\tLoss 5.6402e-01 (6.0874e-01)\tAcc@1  82.03 ( 82.14)\tAcc@5  96.88 ( 96.64)\n","Epoch: [76][300/391]\tTime  0.169 ( 0.170)\tLoss 6.4589e-01 (6.1252e-01)\tAcc@1  80.47 ( 82.03)\tAcc@5  96.88 ( 96.59)\n","Epoch: [76][330/391]\tTime  0.170 ( 0.169)\tLoss 6.1750e-01 (6.1778e-01)\tAcc@1  82.81 ( 81.84)\tAcc@5  97.66 ( 96.55)\n","Epoch: [76][360/391]\tTime  0.168 ( 0.169)\tLoss 7.1419e-01 (6.2008e-01)\tAcc@1  78.12 ( 81.72)\tAcc@5  95.31 ( 96.53)\n","Epoch: [76][390/391]\tTime  0.152 ( 0.169)\tLoss 8.9261e-01 (6.2353e-01)\tAcc@1  72.50 ( 81.58)\tAcc@5  93.75 ( 96.50)\n","==> Train Accuracy: Acc@1 81.580 || Acc@5 96.496\n","==> Test Accuracy:  Acc@1 71.860 || Acc@5 92.540\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 77, lr: 0.020000000000000004 -----\n","Epoch: [77][  0/391]\tTime  0.276 ( 0.276)\tLoss 5.5156e-01 (5.5156e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  96.88 ( 96.88)\n","Epoch: [77][ 30/391]\tTime  0.168 ( 0.172)\tLoss 5.5807e-01 (5.7245e-01)\tAcc@1  85.16 ( 82.74)\tAcc@5  96.09 ( 97.30)\n","Epoch: [77][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.4361e-01 (5.7238e-01)\tAcc@1  85.16 ( 82.99)\tAcc@5  98.44 ( 97.21)\n","Epoch: [77][ 90/391]\tTime  0.169 ( 0.170)\tLoss 7.8778e-01 (5.8482e-01)\tAcc@1  78.91 ( 82.74)\tAcc@5  92.97 ( 96.98)\n","Epoch: [77][120/391]\tTime  0.170 ( 0.170)\tLoss 6.9926e-01 (5.8244e-01)\tAcc@1  79.69 ( 82.75)\tAcc@5  96.09 ( 96.99)\n","Epoch: [77][150/391]\tTime  0.170 ( 0.170)\tLoss 7.3929e-01 (5.8645e-01)\tAcc@1  75.00 ( 82.55)\tAcc@5  95.31 ( 96.98)\n","Epoch: [77][180/391]\tTime  0.172 ( 0.170)\tLoss 5.9403e-01 (5.8885e-01)\tAcc@1  82.03 ( 82.48)\tAcc@5  98.44 ( 96.91)\n","Epoch: [77][210/391]\tTime  0.171 ( 0.170)\tLoss 6.8551e-01 (5.9390e-01)\tAcc@1  82.03 ( 82.29)\tAcc@5  94.53 ( 96.89)\n","Epoch: [77][240/391]\tTime  0.170 ( 0.170)\tLoss 5.3629e-01 (5.9823e-01)\tAcc@1  83.59 ( 82.11)\tAcc@5  98.44 ( 96.92)\n","Epoch: [77][270/391]\tTime  0.170 ( 0.170)\tLoss 6.9293e-01 (6.0048e-01)\tAcc@1  81.25 ( 82.07)\tAcc@5  96.88 ( 96.89)\n","Epoch: [77][300/391]\tTime  0.171 ( 0.170)\tLoss 6.1407e-01 (6.0697e-01)\tAcc@1  80.47 ( 81.84)\tAcc@5  94.53 ( 96.80)\n","Epoch: [77][330/391]\tTime  0.172 ( 0.170)\tLoss 6.7135e-01 (6.1048e-01)\tAcc@1  84.38 ( 81.70)\tAcc@5  95.31 ( 96.78)\n","Epoch: [77][360/391]\tTime  0.169 ( 0.170)\tLoss 5.2318e-01 (6.1501e-01)\tAcc@1  84.38 ( 81.57)\tAcc@5  97.66 ( 96.73)\n","Epoch: [77][390/391]\tTime  0.151 ( 0.170)\tLoss 7.2857e-01 (6.1924e-01)\tAcc@1  83.75 ( 81.40)\tAcc@5  95.00 ( 96.68)\n","==> Train Accuracy: Acc@1 81.400 || Acc@5 96.682\n","==> Test Accuracy:  Acc@1 71.630 || Acc@5 92.290\n","==> 70.49 seconds to train this epoch\n","\n","\n","----- epoch: 78, lr: 0.020000000000000004 -----\n","Epoch: [78][  0/391]\tTime  0.300 ( 0.300)\tLoss 4.2751e-01 (4.2751e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n","Epoch: [78][ 30/391]\tTime  0.168 ( 0.173)\tLoss 3.7925e-01 (5.5017e-01)\tAcc@1  88.28 ( 83.95)\tAcc@5  99.22 ( 97.40)\n","Epoch: [78][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.7483e-01 (5.7541e-01)\tAcc@1  81.25 ( 83.38)\tAcc@5  98.44 ( 97.09)\n","Epoch: [78][ 90/391]\tTime  0.169 ( 0.171)\tLoss 6.7403e-01 (5.8588e-01)\tAcc@1  80.47 ( 83.16)\tAcc@5  96.88 ( 97.09)\n","Epoch: [78][120/391]\tTime  0.170 ( 0.170)\tLoss 5.5570e-01 (5.8955e-01)\tAcc@1  82.81 ( 82.77)\tAcc@5  98.44 ( 97.05)\n","Epoch: [78][150/391]\tTime  0.170 ( 0.170)\tLoss 5.8955e-01 (5.9831e-01)\tAcc@1  82.03 ( 82.49)\tAcc@5  98.44 ( 96.99)\n","Epoch: [78][180/391]\tTime  0.168 ( 0.170)\tLoss 5.1255e-01 (6.1064e-01)\tAcc@1  85.94 ( 82.04)\tAcc@5  96.09 ( 96.89)\n","Epoch: [78][210/391]\tTime  0.171 ( 0.170)\tLoss 7.0038e-01 (6.1221e-01)\tAcc@1  82.03 ( 81.99)\tAcc@5  92.97 ( 96.84)\n","Epoch: [78][240/391]\tTime  0.169 ( 0.170)\tLoss 5.7017e-01 (6.1413e-01)\tAcc@1  83.59 ( 81.94)\tAcc@5  96.09 ( 96.86)\n","Epoch: [78][270/391]\tTime  0.169 ( 0.170)\tLoss 7.8678e-01 (6.1722e-01)\tAcc@1  78.91 ( 81.89)\tAcc@5  96.09 ( 96.83)\n","Epoch: [78][300/391]\tTime  0.169 ( 0.170)\tLoss 6.7721e-01 (6.1716e-01)\tAcc@1  78.12 ( 81.86)\tAcc@5  95.31 ( 96.82)\n","Epoch: [78][330/391]\tTime  0.170 ( 0.170)\tLoss 5.9804e-01 (6.2200e-01)\tAcc@1  83.59 ( 81.74)\tAcc@5  99.22 ( 96.76)\n","Epoch: [78][360/391]\tTime  0.170 ( 0.170)\tLoss 7.8935e-01 (6.2317e-01)\tAcc@1  78.91 ( 81.68)\tAcc@5  95.31 ( 96.74)\n","Epoch: [78][390/391]\tTime  0.151 ( 0.170)\tLoss 6.4290e-01 (6.2393e-01)\tAcc@1  82.50 ( 81.65)\tAcc@5  96.25 ( 96.73)\n","==> Train Accuracy: Acc@1 81.646 || Acc@5 96.732\n","==> Test Accuracy:  Acc@1 71.050 || Acc@5 92.090\n","==> 70.52 seconds to train this epoch\n","\n","\n","----- epoch: 79, lr: 0.020000000000000004 -----\n","Epoch: [79][  0/391]\tTime  0.281 ( 0.281)\tLoss 5.3185e-01 (5.3185e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  97.66 ( 97.66)\n","Epoch: [79][ 30/391]\tTime  0.169 ( 0.173)\tLoss 6.2982e-01 (5.3970e-01)\tAcc@1  80.47 ( 84.73)\tAcc@5  96.88 ( 97.20)\n","Epoch: [79][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.3476e-01 (5.3139e-01)\tAcc@1  81.25 ( 84.44)\tAcc@5  98.44 ( 97.50)\n","Epoch: [79][ 90/391]\tTime  0.169 ( 0.171)\tLoss 5.8569e-01 (5.3175e-01)\tAcc@1  82.03 ( 84.34)\tAcc@5  97.66 ( 97.38)\n","Epoch: [79][120/391]\tTime  0.168 ( 0.170)\tLoss 7.8697e-01 (5.4892e-01)\tAcc@1  77.34 ( 83.80)\tAcc@5  94.53 ( 97.26)\n","Epoch: [79][150/391]\tTime  0.169 ( 0.170)\tLoss 5.8953e-01 (5.6220e-01)\tAcc@1  82.03 ( 83.37)\tAcc@5  96.88 ( 97.25)\n","Epoch: [79][180/391]\tTime  0.169 ( 0.170)\tLoss 5.1423e-01 (5.6867e-01)\tAcc@1  86.72 ( 83.16)\tAcc@5  97.66 ( 97.24)\n","Epoch: [79][210/391]\tTime  0.170 ( 0.170)\tLoss 4.8122e-01 (5.7175e-01)\tAcc@1  82.81 ( 83.12)\tAcc@5  98.44 ( 97.25)\n","Epoch: [79][240/391]\tTime  0.171 ( 0.170)\tLoss 5.4192e-01 (5.8311e-01)\tAcc@1  79.69 ( 82.76)\tAcc@5  99.22 ( 97.11)\n","Epoch: [79][270/391]\tTime  0.168 ( 0.170)\tLoss 6.1898e-01 (5.9287e-01)\tAcc@1  81.25 ( 82.51)\tAcc@5  97.66 ( 96.95)\n","Epoch: [79][300/391]\tTime  0.168 ( 0.170)\tLoss 7.9001e-01 (5.9755e-01)\tAcc@1  78.91 ( 82.35)\tAcc@5  94.53 ( 96.93)\n","Epoch: [79][330/391]\tTime  0.169 ( 0.169)\tLoss 5.4396e-01 (6.0206e-01)\tAcc@1  86.72 ( 82.20)\tAcc@5  98.44 ( 96.90)\n","Epoch: [79][360/391]\tTime  0.169 ( 0.169)\tLoss 7.7760e-01 (6.0810e-01)\tAcc@1  73.44 ( 82.01)\tAcc@5  98.44 ( 96.86)\n","Epoch: [79][390/391]\tTime  0.151 ( 0.169)\tLoss 6.9898e-01 (6.1133e-01)\tAcc@1  75.00 ( 81.93)\tAcc@5  97.50 ( 96.82)\n","==> Train Accuracy: Acc@1 81.926 || Acc@5 96.820\n","==> Test Accuracy:  Acc@1 71.240 || Acc@5 91.760\n","==> 70.44 seconds to train this epoch\n","\n","\n","----- epoch: 80, lr: 0.020000000000000004 -----\n","Epoch: [80][  0/391]\tTime  0.286 ( 0.286)\tLoss 4.6179e-01 (4.6179e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  98.44 ( 98.44)\n","Epoch: [80][ 30/391]\tTime  0.169 ( 0.172)\tLoss 5.9630e-01 (5.8357e-01)\tAcc@1  82.03 ( 82.79)\tAcc@5  96.88 ( 97.00)\n","Epoch: [80][ 60/391]\tTime  0.170 ( 0.171)\tLoss 6.1421e-01 (5.7736e-01)\tAcc@1  84.38 ( 83.39)\tAcc@5  96.09 ( 96.96)\n","Epoch: [80][ 90/391]\tTime  0.169 ( 0.170)\tLoss 5.7838e-01 (5.8904e-01)\tAcc@1  81.25 ( 82.87)\tAcc@5  96.09 ( 96.87)\n","Epoch: [80][120/391]\tTime  0.168 ( 0.170)\tLoss 7.4803e-01 (5.8248e-01)\tAcc@1  78.12 ( 82.97)\tAcc@5  96.09 ( 96.89)\n","Epoch: [80][150/391]\tTime  0.171 ( 0.170)\tLoss 6.2410e-01 (5.8035e-01)\tAcc@1  82.81 ( 83.02)\tAcc@5  97.66 ( 96.98)\n","Epoch: [80][180/391]\tTime  0.170 ( 0.170)\tLoss 9.3589e-01 (5.8403e-01)\tAcc@1  70.31 ( 82.84)\tAcc@5  94.53 ( 96.97)\n","Epoch: [80][210/391]\tTime  0.171 ( 0.170)\tLoss 6.2644e-01 (5.8720e-01)\tAcc@1  83.59 ( 82.72)\tAcc@5  96.09 ( 96.93)\n","Epoch: [80][240/391]\tTime  0.169 ( 0.170)\tLoss 7.0855e-01 (5.8819e-01)\tAcc@1  78.91 ( 82.70)\tAcc@5  95.31 ( 96.90)\n","Epoch: [80][270/391]\tTime  0.170 ( 0.170)\tLoss 4.8995e-01 (5.9499e-01)\tAcc@1  85.16 ( 82.47)\tAcc@5  98.44 ( 96.83)\n","Epoch: [80][300/391]\tTime  0.171 ( 0.170)\tLoss 6.3337e-01 (5.9638e-01)\tAcc@1  83.59 ( 82.43)\tAcc@5  93.75 ( 96.81)\n","Epoch: [80][330/391]\tTime  0.170 ( 0.170)\tLoss 4.9608e-01 (5.9908e-01)\tAcc@1  85.16 ( 82.31)\tAcc@5  98.44 ( 96.82)\n","Epoch: [80][360/391]\tTime  0.168 ( 0.170)\tLoss 7.1934e-01 (6.0488e-01)\tAcc@1  80.47 ( 82.14)\tAcc@5  95.31 ( 96.77)\n","Epoch: [80][390/391]\tTime  0.154 ( 0.170)\tLoss 4.5588e-01 (6.0779e-01)\tAcc@1  87.50 ( 82.03)\tAcc@5 100.00 ( 96.75)\n","==> Train Accuracy: Acc@1 82.034 || Acc@5 96.746\n","==> Test Accuracy:  Acc@1 70.840 || Acc@5 92.090\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 81, lr: 0.020000000000000004 -----\n","Epoch: [81][  0/391]\tTime  0.278 ( 0.278)\tLoss 7.4673e-01 (7.4673e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  96.09 ( 96.09)\n","Epoch: [81][ 30/391]\tTime  0.172 ( 0.172)\tLoss 6.1027e-01 (5.7390e-01)\tAcc@1  83.59 ( 83.14)\tAcc@5  96.09 ( 96.88)\n","Epoch: [81][ 60/391]\tTime  0.170 ( 0.171)\tLoss 5.6538e-01 (5.8320e-01)\tAcc@1  83.59 ( 82.89)\tAcc@5  96.09 ( 96.71)\n","Epoch: [81][ 90/391]\tTime  0.170 ( 0.170)\tLoss 5.5438e-01 (5.9272e-01)\tAcc@1  83.59 ( 82.49)\tAcc@5  96.88 ( 96.72)\n","Epoch: [81][120/391]\tTime  0.168 ( 0.170)\tLoss 6.4014e-01 (5.9431e-01)\tAcc@1  79.69 ( 82.43)\tAcc@5  97.66 ( 96.73)\n","Epoch: [81][150/391]\tTime  0.171 ( 0.170)\tLoss 6.0791e-01 (5.9822e-01)\tAcc@1  82.81 ( 82.32)\tAcc@5  96.09 ( 96.72)\n","Epoch: [81][180/391]\tTime  0.170 ( 0.170)\tLoss 6.3449e-01 (6.0175e-01)\tAcc@1  80.47 ( 82.29)\tAcc@5  95.31 ( 96.60)\n","Epoch: [81][210/391]\tTime  0.170 ( 0.170)\tLoss 6.8848e-01 (6.0167e-01)\tAcc@1  78.91 ( 82.27)\tAcc@5  96.09 ( 96.60)\n","Epoch: [81][240/391]\tTime  0.169 ( 0.170)\tLoss 5.7152e-01 (6.0105e-01)\tAcc@1  82.03 ( 82.32)\tAcc@5  99.22 ( 96.63)\n","Epoch: [81][270/391]\tTime  0.168 ( 0.170)\tLoss 5.8262e-01 (6.0389e-01)\tAcc@1  82.03 ( 82.20)\tAcc@5  95.31 ( 96.59)\n","Epoch: [81][300/391]\tTime  0.171 ( 0.170)\tLoss 7.5499e-01 (6.0635e-01)\tAcc@1  77.34 ( 82.17)\tAcc@5  95.31 ( 96.57)\n","Epoch: [81][330/391]\tTime  0.168 ( 0.170)\tLoss 5.5474e-01 (6.0669e-01)\tAcc@1  83.59 ( 82.18)\tAcc@5  97.66 ( 96.55)\n","Epoch: [81][360/391]\tTime  0.169 ( 0.170)\tLoss 7.3154e-01 (6.0743e-01)\tAcc@1  75.00 ( 82.17)\tAcc@5  95.31 ( 96.58)\n","Epoch: [81][390/391]\tTime  0.153 ( 0.170)\tLoss 8.9163e-01 (6.1305e-01)\tAcc@1  73.75 ( 81.96)\tAcc@5  95.00 ( 96.55)\n","==> Train Accuracy: Acc@1 81.962 || Acc@5 96.554\n","==> Test Accuracy:  Acc@1 70.400 || Acc@5 91.510\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 82, lr: 0.020000000000000004 -----\n","Epoch: [82][  0/391]\tTime  0.289 ( 0.289)\tLoss 6.3419e-01 (6.3419e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.09 ( 96.09)\n","Epoch: [82][ 30/391]\tTime  0.173 ( 0.173)\tLoss 4.9631e-01 (6.0451e-01)\tAcc@1  85.94 ( 82.06)\tAcc@5  99.22 ( 96.52)\n","Epoch: [82][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.4340e-01 (5.8446e-01)\tAcc@1  81.25 ( 82.77)\tAcc@5  98.44 ( 96.66)\n","Epoch: [82][ 90/391]\tTime  0.169 ( 0.171)\tLoss 5.9335e-01 (5.8177e-01)\tAcc@1  87.50 ( 83.06)\tAcc@5  96.88 ( 96.68)\n","Epoch: [82][120/391]\tTime  0.171 ( 0.170)\tLoss 5.0406e-01 (5.8744e-01)\tAcc@1  85.16 ( 82.83)\tAcc@5  97.66 ( 96.66)\n","Epoch: [82][150/391]\tTime  0.168 ( 0.170)\tLoss 4.7863e-01 (5.8178e-01)\tAcc@1  84.38 ( 82.93)\tAcc@5  99.22 ( 96.78)\n","Epoch: [82][180/391]\tTime  0.169 ( 0.170)\tLoss 5.5034e-01 (5.7784e-01)\tAcc@1  83.59 ( 83.05)\tAcc@5  97.66 ( 96.81)\n","Epoch: [82][210/391]\tTime  0.170 ( 0.170)\tLoss 5.7512e-01 (5.8459e-01)\tAcc@1  81.25 ( 82.78)\tAcc@5  96.09 ( 96.76)\n","Epoch: [82][240/391]\tTime  0.168 ( 0.170)\tLoss 7.8104e-01 (5.8847e-01)\tAcc@1  78.91 ( 82.64)\tAcc@5  95.31 ( 96.70)\n","Epoch: [82][270/391]\tTime  0.169 ( 0.170)\tLoss 6.3470e-01 (5.9762e-01)\tAcc@1  80.47 ( 82.37)\tAcc@5  95.31 ( 96.64)\n","Epoch: [82][300/391]\tTime  0.171 ( 0.170)\tLoss 7.6451e-01 (6.0110e-01)\tAcc@1  76.56 ( 82.26)\tAcc@5  96.88 ( 96.63)\n","Epoch: [82][330/391]\tTime  0.169 ( 0.170)\tLoss 5.1220e-01 (6.0170e-01)\tAcc@1  81.25 ( 82.23)\tAcc@5  98.44 ( 96.66)\n","Epoch: [82][360/391]\tTime  0.170 ( 0.170)\tLoss 5.7607e-01 (6.0124e-01)\tAcc@1  82.81 ( 82.21)\tAcc@5  96.88 ( 96.66)\n","Epoch: [82][390/391]\tTime  0.152 ( 0.170)\tLoss 7.1852e-01 (6.0672e-01)\tAcc@1  78.75 ( 82.05)\tAcc@5  95.00 ( 96.61)\n","==> Train Accuracy: Acc@1 82.046 || Acc@5 96.614\n","==> Test Accuracy:  Acc@1 69.700 || Acc@5 91.820\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 83, lr: 0.020000000000000004 -----\n","Epoch: [83][  0/391]\tTime  0.284 ( 0.284)\tLoss 6.0242e-01 (6.0242e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  96.09 ( 96.09)\n","Epoch: [83][ 30/391]\tTime  0.170 ( 0.173)\tLoss 5.8329e-01 (5.3459e-01)\tAcc@1  83.59 ( 83.92)\tAcc@5  95.31 ( 97.18)\n","Epoch: [83][ 60/391]\tTime  0.170 ( 0.171)\tLoss 4.3145e-01 (5.2787e-01)\tAcc@1  89.84 ( 84.38)\tAcc@5  96.88 ( 97.30)\n","Epoch: [83][ 90/391]\tTime  0.171 ( 0.171)\tLoss 6.7891e-01 (5.4743e-01)\tAcc@1  82.03 ( 83.92)\tAcc@5  94.53 ( 97.14)\n","Epoch: [83][120/391]\tTime  0.170 ( 0.170)\tLoss 5.0434e-01 (5.5376e-01)\tAcc@1  82.81 ( 83.67)\tAcc@5  97.66 ( 97.18)\n","Epoch: [83][150/391]\tTime  0.170 ( 0.170)\tLoss 5.5066e-01 (5.5109e-01)\tAcc@1  82.81 ( 83.72)\tAcc@5  96.09 ( 97.19)\n","Epoch: [83][180/391]\tTime  0.170 ( 0.170)\tLoss 4.1308e-01 (5.5511e-01)\tAcc@1  87.50 ( 83.56)\tAcc@5  98.44 ( 97.13)\n","Epoch: [83][210/391]\tTime  0.170 ( 0.170)\tLoss 5.1199e-01 (5.6388e-01)\tAcc@1  85.94 ( 83.35)\tAcc@5  96.09 ( 97.06)\n","Epoch: [83][240/391]\tTime  0.170 ( 0.170)\tLoss 6.1710e-01 (5.6782e-01)\tAcc@1  85.16 ( 83.26)\tAcc@5  96.88 ( 97.03)\n","Epoch: [83][270/391]\tTime  0.170 ( 0.170)\tLoss 6.2697e-01 (5.7586e-01)\tAcc@1  82.03 ( 83.04)\tAcc@5  97.66 ( 96.98)\n","Epoch: [83][300/391]\tTime  0.169 ( 0.170)\tLoss 6.2191e-01 (5.8134e-01)\tAcc@1  79.69 ( 82.89)\tAcc@5  97.66 ( 96.95)\n","Epoch: [83][330/391]\tTime  0.169 ( 0.170)\tLoss 5.8705e-01 (5.8534e-01)\tAcc@1  84.38 ( 82.78)\tAcc@5  96.09 ( 96.90)\n","Epoch: [83][360/391]\tTime  0.169 ( 0.170)\tLoss 6.2138e-01 (5.9116e-01)\tAcc@1  78.12 ( 82.61)\tAcc@5  95.31 ( 96.84)\n","Epoch: [83][390/391]\tTime  0.151 ( 0.169)\tLoss 4.7247e-01 (5.9635e-01)\tAcc@1  88.75 ( 82.44)\tAcc@5  97.50 ( 96.80)\n","==> Train Accuracy: Acc@1 82.436 || Acc@5 96.798\n","==> Test Accuracy:  Acc@1 70.550 || Acc@5 92.130\n","==> 70.45 seconds to train this epoch\n","\n","\n","----- epoch: 84, lr: 0.020000000000000004 -----\n","Epoch: [84][  0/391]\tTime  0.260 ( 0.260)\tLoss 5.5350e-01 (5.5350e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  96.88 ( 96.88)\n","Epoch: [84][ 30/391]\tTime  0.168 ( 0.172)\tLoss 4.5889e-01 (5.5907e-01)\tAcc@1  89.06 ( 84.22)\tAcc@5  97.66 ( 97.30)\n","Epoch: [84][ 60/391]\tTime  0.169 ( 0.170)\tLoss 5.4452e-01 (5.5930e-01)\tAcc@1  85.94 ( 83.59)\tAcc@5  96.09 ( 97.36)\n","Epoch: [84][ 90/391]\tTime  0.171 ( 0.170)\tLoss 5.6105e-01 (5.5726e-01)\tAcc@1  81.25 ( 83.76)\tAcc@5  98.44 ( 97.30)\n","Epoch: [84][120/391]\tTime  0.169 ( 0.170)\tLoss 5.3868e-01 (5.5972e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  97.66 ( 97.20)\n","Epoch: [84][150/391]\tTime  0.169 ( 0.170)\tLoss 5.6157e-01 (5.6395e-01)\tAcc@1  82.81 ( 83.44)\tAcc@5  97.66 ( 97.21)\n","Epoch: [84][180/391]\tTime  0.169 ( 0.170)\tLoss 5.2484e-01 (5.6975e-01)\tAcc@1  82.81 ( 83.28)\tAcc@5  98.44 ( 97.14)\n","Epoch: [84][210/391]\tTime  0.169 ( 0.169)\tLoss 4.6204e-01 (5.7746e-01)\tAcc@1  87.50 ( 83.14)\tAcc@5  97.66 ( 97.07)\n","Epoch: [84][240/391]\tTime  0.168 ( 0.169)\tLoss 6.0592e-01 (5.8064e-01)\tAcc@1  81.25 ( 83.01)\tAcc@5  96.09 ( 97.05)\n","Epoch: [84][270/391]\tTime  0.168 ( 0.169)\tLoss 4.9072e-01 (5.8262e-01)\tAcc@1  88.28 ( 82.90)\tAcc@5  97.66 ( 97.02)\n","Epoch: [84][300/391]\tTime  0.169 ( 0.169)\tLoss 6.3905e-01 (5.8436e-01)\tAcc@1  82.81 ( 82.84)\tAcc@5  97.66 ( 97.02)\n","Epoch: [84][330/391]\tTime  0.168 ( 0.169)\tLoss 6.8063e-01 (5.8874e-01)\tAcc@1  81.25 ( 82.71)\tAcc@5  94.53 ( 96.98)\n","Epoch: [84][360/391]\tTime  0.170 ( 0.169)\tLoss 6.9509e-01 (5.9188e-01)\tAcc@1  81.25 ( 82.63)\tAcc@5  94.53 ( 96.94)\n","Epoch: [84][390/391]\tTime  0.152 ( 0.169)\tLoss 7.3515e-01 (5.9636e-01)\tAcc@1  80.00 ( 82.48)\tAcc@5  95.00 ( 96.92)\n","==> Train Accuracy: Acc@1 82.484 || Acc@5 96.922\n","==> Test Accuracy:  Acc@1 71.090 || Acc@5 92.280\n","==> 70.38 seconds to train this epoch\n","\n","\n","----- epoch: 85, lr: 0.020000000000000004 -----\n","Epoch: [85][  0/391]\tTime  0.324 ( 0.324)\tLoss 5.1976e-01 (5.1976e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n","Epoch: [85][ 30/391]\tTime  0.169 ( 0.173)\tLoss 5.3444e-01 (5.5013e-01)\tAcc@1  81.25 ( 84.55)\tAcc@5  96.88 ( 96.85)\n","Epoch: [85][ 60/391]\tTime  0.170 ( 0.171)\tLoss 6.2855e-01 (5.5219e-01)\tAcc@1  81.25 ( 83.99)\tAcc@5  96.88 ( 96.91)\n","Epoch: [85][ 90/391]\tTime  0.169 ( 0.170)\tLoss 5.5743e-01 (5.5631e-01)\tAcc@1  84.38 ( 83.89)\tAcc@5  96.09 ( 96.88)\n","Epoch: [85][120/391]\tTime  0.169 ( 0.170)\tLoss 7.1721e-01 (5.5781e-01)\tAcc@1  78.12 ( 83.77)\tAcc@5  99.22 ( 96.98)\n","Epoch: [85][150/391]\tTime  0.168 ( 0.170)\tLoss 7.3846e-01 (5.7041e-01)\tAcc@1  80.47 ( 83.45)\tAcc@5  95.31 ( 96.87)\n","Epoch: [85][180/391]\tTime  0.168 ( 0.170)\tLoss 6.1669e-01 (5.7974e-01)\tAcc@1  80.47 ( 83.27)\tAcc@5  95.31 ( 96.73)\n","Epoch: [85][210/391]\tTime  0.170 ( 0.170)\tLoss 5.3532e-01 (5.8077e-01)\tAcc@1  82.81 ( 83.21)\tAcc@5  96.88 ( 96.73)\n","Epoch: [85][240/391]\tTime  0.168 ( 0.169)\tLoss 5.2261e-01 (5.8515e-01)\tAcc@1  82.81 ( 83.00)\tAcc@5  97.66 ( 96.72)\n","Epoch: [85][270/391]\tTime  0.170 ( 0.169)\tLoss 4.3473e-01 (5.8566e-01)\tAcc@1  89.06 ( 82.99)\tAcc@5  97.66 ( 96.71)\n","Epoch: [85][300/391]\tTime  0.168 ( 0.169)\tLoss 7.7157e-01 (5.8775e-01)\tAcc@1  78.91 ( 82.86)\tAcc@5  93.75 ( 96.68)\n","Epoch: [85][330/391]\tTime  0.171 ( 0.169)\tLoss 6.9518e-01 (5.8582e-01)\tAcc@1  82.03 ( 82.93)\tAcc@5  96.88 ( 96.74)\n","Epoch: [85][360/391]\tTime  0.169 ( 0.169)\tLoss 5.4766e-01 (5.8552e-01)\tAcc@1  85.94 ( 82.94)\tAcc@5  97.66 ( 96.75)\n","Epoch: [85][390/391]\tTime  0.151 ( 0.169)\tLoss 6.5441e-01 (5.9131e-01)\tAcc@1  81.25 ( 82.74)\tAcc@5  96.25 ( 96.68)\n","==> Train Accuracy: Acc@1 82.742 || Acc@5 96.684\n","==> Test Accuracy:  Acc@1 71.130 || Acc@5 91.580\n","==> 70.37 seconds to train this epoch\n","\n","\n","----- epoch: 86, lr: 0.020000000000000004 -----\n","Epoch: [86][  0/391]\tTime  0.287 ( 0.287)\tLoss 6.3050e-01 (6.3050e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  95.31 ( 95.31)\n","Epoch: [86][ 30/391]\tTime  0.169 ( 0.173)\tLoss 6.3689e-01 (5.8594e-01)\tAcc@1  81.25 ( 82.61)\tAcc@5  96.88 ( 96.80)\n","Epoch: [86][ 60/391]\tTime  0.170 ( 0.171)\tLoss 5.1594e-01 (5.6188e-01)\tAcc@1  83.59 ( 83.52)\tAcc@5  97.66 ( 96.99)\n","Epoch: [86][ 90/391]\tTime  0.169 ( 0.170)\tLoss 4.4412e-01 (5.5509e-01)\tAcc@1  88.28 ( 83.55)\tAcc@5  96.88 ( 97.10)\n","Epoch: [86][120/391]\tTime  0.170 ( 0.170)\tLoss 4.4242e-01 (5.6352e-01)\tAcc@1  85.94 ( 83.34)\tAcc@5  96.88 ( 97.02)\n","Epoch: [86][150/391]\tTime  0.169 ( 0.170)\tLoss 5.2962e-01 (5.6503e-01)\tAcc@1  82.81 ( 83.44)\tAcc@5 100.00 ( 97.08)\n","Epoch: [86][180/391]\tTime  0.171 ( 0.170)\tLoss 4.6505e-01 (5.7043e-01)\tAcc@1  86.72 ( 83.15)\tAcc@5  98.44 ( 97.06)\n","Epoch: [86][210/391]\tTime  0.168 ( 0.170)\tLoss 5.6459e-01 (5.7633e-01)\tAcc@1  84.38 ( 83.12)\tAcc@5  97.66 ( 96.92)\n","Epoch: [86][240/391]\tTime  0.169 ( 0.170)\tLoss 4.6035e-01 (5.7682e-01)\tAcc@1  87.50 ( 83.10)\tAcc@5  99.22 ( 96.97)\n","Epoch: [86][270/391]\tTime  0.171 ( 0.170)\tLoss 7.1394e-01 (5.7957e-01)\tAcc@1  79.69 ( 82.96)\tAcc@5  96.09 ( 96.96)\n","Epoch: [86][300/391]\tTime  0.168 ( 0.170)\tLoss 6.1854e-01 (5.8022e-01)\tAcc@1  82.81 ( 82.92)\tAcc@5  95.31 ( 96.96)\n","Epoch: [86][330/391]\tTime  0.168 ( 0.169)\tLoss 4.5847e-01 (5.8485e-01)\tAcc@1  87.50 ( 82.80)\tAcc@5  98.44 ( 96.92)\n","Epoch: [86][360/391]\tTime  0.168 ( 0.169)\tLoss 6.4572e-01 (5.8711e-01)\tAcc@1  78.91 ( 82.70)\tAcc@5  96.88 ( 96.91)\n","Epoch: [86][390/391]\tTime  0.152 ( 0.169)\tLoss 6.8537e-01 (5.9024e-01)\tAcc@1  80.00 ( 82.59)\tAcc@5  96.25 ( 96.88)\n","==> Train Accuracy: Acc@1 82.590 || Acc@5 96.878\n","==> Test Accuracy:  Acc@1 70.650 || Acc@5 92.180\n","==> 70.42 seconds to train this epoch\n","\n","\n","----- epoch: 87, lr: 0.020000000000000004 -----\n","Epoch: [87][  0/391]\tTime  0.275 ( 0.275)\tLoss 5.3871e-01 (5.3871e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  96.88 ( 96.88)\n","Epoch: [87][ 30/391]\tTime  0.171 ( 0.172)\tLoss 5.2477e-01 (5.5966e-01)\tAcc@1  84.38 ( 83.97)\tAcc@5  98.44 ( 97.00)\n","Epoch: [87][ 60/391]\tTime  0.168 ( 0.171)\tLoss 4.0212e-01 (5.4175e-01)\tAcc@1  88.28 ( 84.31)\tAcc@5  98.44 ( 97.07)\n","Epoch: [87][ 90/391]\tTime  0.169 ( 0.170)\tLoss 5.5672e-01 (5.4525e-01)\tAcc@1  82.03 ( 84.16)\tAcc@5  97.66 ( 97.07)\n","Epoch: [87][120/391]\tTime  0.170 ( 0.170)\tLoss 5.7526e-01 (5.4916e-01)\tAcc@1  81.25 ( 83.99)\tAcc@5  97.66 ( 96.98)\n","Epoch: [87][150/391]\tTime  0.171 ( 0.170)\tLoss 5.8117e-01 (5.5190e-01)\tAcc@1  85.16 ( 83.90)\tAcc@5  96.88 ( 96.99)\n","Epoch: [87][180/391]\tTime  0.168 ( 0.169)\tLoss 5.7595e-01 (5.5877e-01)\tAcc@1  82.81 ( 83.62)\tAcc@5  96.88 ( 96.95)\n","Epoch: [87][210/391]\tTime  0.168 ( 0.169)\tLoss 6.5582e-01 (5.6119e-01)\tAcc@1  78.91 ( 83.58)\tAcc@5  97.66 ( 96.88)\n","Epoch: [87][240/391]\tTime  0.169 ( 0.169)\tLoss 5.0189e-01 (5.6743e-01)\tAcc@1  84.38 ( 83.34)\tAcc@5  96.88 ( 96.82)\n","Epoch: [87][270/391]\tTime  0.168 ( 0.169)\tLoss 7.9080e-01 (5.7062e-01)\tAcc@1  76.56 ( 83.22)\tAcc@5  92.19 ( 96.84)\n","Epoch: [87][300/391]\tTime  0.171 ( 0.169)\tLoss 7.6376e-01 (5.7630e-01)\tAcc@1  78.12 ( 83.00)\tAcc@5  93.75 ( 96.85)\n","Epoch: [87][330/391]\tTime  0.169 ( 0.169)\tLoss 6.0610e-01 (5.7989e-01)\tAcc@1  79.69 ( 82.86)\tAcc@5  96.09 ( 96.83)\n","Epoch: [87][360/391]\tTime  0.168 ( 0.169)\tLoss 4.6057e-01 (5.8197e-01)\tAcc@1  84.38 ( 82.86)\tAcc@5  97.66 ( 96.84)\n","Epoch: [87][390/391]\tTime  0.151 ( 0.169)\tLoss 7.9118e-01 (5.8474e-01)\tAcc@1  77.50 ( 82.71)\tAcc@5  97.50 ( 96.82)\n","==> Train Accuracy: Acc@1 82.714 || Acc@5 96.820\n","==> Test Accuracy:  Acc@1 69.550 || Acc@5 91.430\n","==> 70.33 seconds to train this epoch\n","\n","\n","----- epoch: 88, lr: 0.020000000000000004 -----\n","Epoch: [88][  0/391]\tTime  0.289 ( 0.289)\tLoss 6.3530e-01 (6.3530e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  94.53 ( 94.53)\n","Epoch: [88][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.8663e-01 (5.4109e-01)\tAcc@1  85.16 ( 84.30)\tAcc@5  95.31 ( 96.75)\n","Epoch: [88][ 60/391]\tTime  0.170 ( 0.171)\tLoss 5.6581e-01 (5.4583e-01)\tAcc@1  80.47 ( 83.99)\tAcc@5  96.88 ( 96.99)\n","Epoch: [88][ 90/391]\tTime  0.171 ( 0.170)\tLoss 4.6456e-01 (5.5363e-01)\tAcc@1  83.59 ( 83.74)\tAcc@5  98.44 ( 96.98)\n","Epoch: [88][120/391]\tTime  0.169 ( 0.170)\tLoss 7.0990e-01 (5.6129e-01)\tAcc@1  78.91 ( 83.50)\tAcc@5  96.09 ( 96.90)\n","Epoch: [88][150/391]\tTime  0.170 ( 0.170)\tLoss 5.7432e-01 (5.5086e-01)\tAcc@1  82.03 ( 83.87)\tAcc@5  96.88 ( 97.02)\n","Epoch: [88][180/391]\tTime  0.169 ( 0.170)\tLoss 6.9039e-01 (5.5408e-01)\tAcc@1  78.91 ( 83.79)\tAcc@5  96.09 ( 97.01)\n","Epoch: [88][210/391]\tTime  0.170 ( 0.170)\tLoss 5.3773e-01 (5.5893e-01)\tAcc@1  88.28 ( 83.66)\tAcc@5  95.31 ( 96.92)\n","Epoch: [88][240/391]\tTime  0.169 ( 0.169)\tLoss 8.0211e-01 (5.6726e-01)\tAcc@1  80.47 ( 83.46)\tAcc@5  96.09 ( 96.88)\n","Epoch: [88][270/391]\tTime  0.170 ( 0.169)\tLoss 5.3695e-01 (5.7280e-01)\tAcc@1  78.91 ( 83.27)\tAcc@5  96.88 ( 96.84)\n","Epoch: [88][300/391]\tTime  0.169 ( 0.169)\tLoss 5.2852e-01 (5.7527e-01)\tAcc@1  85.94 ( 83.19)\tAcc@5  95.31 ( 96.81)\n","Epoch: [88][330/391]\tTime  0.169 ( 0.169)\tLoss 5.8472e-01 (5.7733e-01)\tAcc@1  82.03 ( 83.08)\tAcc@5  97.66 ( 96.80)\n","Epoch: [88][360/391]\tTime  0.170 ( 0.169)\tLoss 6.8993e-01 (5.8032e-01)\tAcc@1  77.34 ( 82.92)\tAcc@5  95.31 ( 96.79)\n","Epoch: [88][390/391]\tTime  0.153 ( 0.169)\tLoss 6.5014e-01 (5.8373e-01)\tAcc@1  77.50 ( 82.80)\tAcc@5  96.25 ( 96.76)\n","==> Train Accuracy: Acc@1 82.804 || Acc@5 96.764\n","==> Test Accuracy:  Acc@1 70.180 || Acc@5 91.540\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 89, lr: 0.020000000000000004 -----\n","Epoch: [89][  0/391]\tTime  0.275 ( 0.275)\tLoss 5.7063e-01 (5.7063e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  97.66 ( 97.66)\n","Epoch: [89][ 30/391]\tTime  0.169 ( 0.172)\tLoss 7.3513e-01 (5.8483e-01)\tAcc@1  80.47 ( 82.79)\tAcc@5  95.31 ( 97.10)\n","Epoch: [89][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.6672e-01 (5.6706e-01)\tAcc@1  85.94 ( 83.07)\tAcc@5  98.44 ( 97.05)\n","Epoch: [89][ 90/391]\tTime  0.169 ( 0.170)\tLoss 6.6885e-01 (5.7215e-01)\tAcc@1  79.69 ( 83.00)\tAcc@5  96.09 ( 97.11)\n","Epoch: [89][120/391]\tTime  0.169 ( 0.170)\tLoss 4.1324e-01 (5.7403e-01)\tAcc@1  90.62 ( 83.12)\tAcc@5  98.44 ( 97.06)\n","Epoch: [89][150/391]\tTime  0.169 ( 0.170)\tLoss 7.0614e-01 (5.7827e-01)\tAcc@1  76.56 ( 82.96)\tAcc@5  96.88 ( 97.03)\n","Epoch: [89][180/391]\tTime  0.168 ( 0.170)\tLoss 5.5175e-01 (5.7834e-01)\tAcc@1  79.69 ( 82.92)\tAcc@5  96.88 ( 97.01)\n","Epoch: [89][210/391]\tTime  0.168 ( 0.170)\tLoss 6.2813e-01 (5.7399e-01)\tAcc@1  81.25 ( 83.06)\tAcc@5  97.66 ( 97.03)\n","Epoch: [89][240/391]\tTime  0.169 ( 0.170)\tLoss 5.6062e-01 (5.7279e-01)\tAcc@1  86.72 ( 83.12)\tAcc@5  97.66 ( 97.03)\n","Epoch: [89][270/391]\tTime  0.170 ( 0.170)\tLoss 5.0029e-01 (5.7397e-01)\tAcc@1  86.72 ( 83.09)\tAcc@5  96.88 ( 97.04)\n","Epoch: [89][300/391]\tTime  0.170 ( 0.169)\tLoss 5.0949e-01 (5.7601e-01)\tAcc@1  85.94 ( 82.99)\tAcc@5  96.88 ( 96.99)\n","Epoch: [89][330/391]\tTime  0.170 ( 0.169)\tLoss 6.1759e-01 (5.7593e-01)\tAcc@1  82.81 ( 82.92)\tAcc@5  96.09 ( 97.00)\n","Epoch: [89][360/391]\tTime  0.169 ( 0.169)\tLoss 7.1832e-01 (5.7876e-01)\tAcc@1  79.69 ( 82.84)\tAcc@5  95.31 ( 96.99)\n","Epoch: [89][390/391]\tTime  0.153 ( 0.169)\tLoss 4.4629e-01 (5.8385e-01)\tAcc@1  85.00 ( 82.71)\tAcc@5  97.50 ( 96.93)\n","==> Train Accuracy: Acc@1 82.714 || Acc@5 96.930\n","==> Test Accuracy:  Acc@1 71.180 || Acc@5 92.190\n","==> 70.43 seconds to train this epoch\n","\n","\n","----- epoch: 90, lr: 0.004000000000000001 -----\n","Epoch: [90][  0/391]\tTime  0.286 ( 0.286)\tLoss 3.7116e-01 (3.7116e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n","Epoch: [90][ 30/391]\tTime  0.172 ( 0.173)\tLoss 6.1331e-01 (5.0771e-01)\tAcc@1  81.25 ( 84.98)\tAcc@5  96.09 ( 97.28)\n","Epoch: [90][ 60/391]\tTime  0.169 ( 0.171)\tLoss 3.1309e-01 (4.6715e-01)\tAcc@1  88.28 ( 86.55)\tAcc@5 100.00 ( 97.53)\n","Epoch: [90][ 90/391]\tTime  0.170 ( 0.170)\tLoss 3.1442e-01 (4.4577e-01)\tAcc@1  90.62 ( 87.11)\tAcc@5  99.22 ( 97.73)\n","Epoch: [90][120/391]\tTime  0.170 ( 0.170)\tLoss 3.2567e-01 (4.2794e-01)\tAcc@1  92.97 ( 87.64)\tAcc@5  98.44 ( 97.91)\n","Epoch: [90][150/391]\tTime  0.170 ( 0.170)\tLoss 3.4077e-01 (4.1548e-01)\tAcc@1  90.62 ( 88.06)\tAcc@5  97.66 ( 97.90)\n","Epoch: [90][180/391]\tTime  0.169 ( 0.170)\tLoss 3.4031e-01 (4.0794e-01)\tAcc@1  89.06 ( 88.18)\tAcc@5  99.22 ( 97.97)\n","Epoch: [90][210/391]\tTime  0.168 ( 0.170)\tLoss 2.7541e-01 (4.0358e-01)\tAcc@1  92.97 ( 88.34)\tAcc@5  98.44 ( 97.95)\n","Epoch: [90][240/391]\tTime  0.168 ( 0.170)\tLoss 2.8068e-01 (3.9696e-01)\tAcc@1  92.19 ( 88.53)\tAcc@5 100.00 ( 97.99)\n","Epoch: [90][270/391]\tTime  0.169 ( 0.170)\tLoss 4.0011e-01 (3.9374e-01)\tAcc@1  85.94 ( 88.62)\tAcc@5  98.44 ( 98.01)\n","Epoch: [90][300/391]\tTime  0.171 ( 0.170)\tLoss 2.7470e-01 (3.8766e-01)\tAcc@1  92.19 ( 88.84)\tAcc@5  99.22 ( 98.05)\n","Epoch: [90][330/391]\tTime  0.169 ( 0.170)\tLoss 3.6666e-01 (3.8231e-01)\tAcc@1  88.28 ( 89.01)\tAcc@5  99.22 ( 98.12)\n","Epoch: [90][360/391]\tTime  0.169 ( 0.170)\tLoss 3.6539e-01 (3.7946e-01)\tAcc@1  87.50 ( 89.10)\tAcc@5  97.66 ( 98.14)\n","Epoch: [90][390/391]\tTime  0.152 ( 0.170)\tLoss 4.0267e-01 (3.7448e-01)\tAcc@1  87.50 ( 89.28)\tAcc@5  98.75 ( 98.19)\n","==> Train Accuracy: Acc@1 89.276 || Acc@5 98.186\n","==> Test Accuracy:  Acc@1 77.010 || Acc@5 94.400\n","==> 70.49 seconds to train this epoch\n","\n","\n","----- epoch: 91, lr: 0.004000000000000001 -----\n","Epoch: [91][  0/391]\tTime  0.298 ( 0.298)\tLoss 2.6761e-01 (2.6761e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [91][ 30/391]\tTime  0.173 ( 0.173)\tLoss 3.2618e-01 (3.0331e-01)\tAcc@1  90.62 ( 91.83)\tAcc@5  97.66 ( 98.77)\n","Epoch: [91][ 60/391]\tTime  0.169 ( 0.171)\tLoss 2.5608e-01 (2.9875e-01)\tAcc@1  95.31 ( 92.05)\tAcc@5  99.22 ( 98.69)\n","Epoch: [91][ 90/391]\tTime  0.170 ( 0.170)\tLoss 2.8820e-01 (2.9772e-01)\tAcc@1  91.41 ( 92.13)\tAcc@5  98.44 ( 98.69)\n","Epoch: [91][120/391]\tTime  0.172 ( 0.170)\tLoss 4.7715e-01 (2.9692e-01)\tAcc@1  86.72 ( 92.09)\tAcc@5  96.09 ( 98.65)\n","Epoch: [91][150/391]\tTime  0.170 ( 0.170)\tLoss 2.7626e-01 (2.9630e-01)\tAcc@1  92.19 ( 92.08)\tAcc@5  97.66 ( 98.65)\n","Epoch: [91][180/391]\tTime  0.170 ( 0.170)\tLoss 2.9394e-01 (2.9562e-01)\tAcc@1  91.41 ( 91.99)\tAcc@5  98.44 ( 98.69)\n","Epoch: [91][210/391]\tTime  0.169 ( 0.170)\tLoss 2.3353e-01 (2.9472e-01)\tAcc@1  93.75 ( 92.04)\tAcc@5  98.44 ( 98.69)\n","Epoch: [91][240/391]\tTime  0.170 ( 0.170)\tLoss 3.5853e-01 (2.9269e-01)\tAcc@1  86.72 ( 92.00)\tAcc@5  97.66 ( 98.70)\n","Epoch: [91][270/391]\tTime  0.170 ( 0.170)\tLoss 2.6542e-01 (2.9297e-01)\tAcc@1  92.97 ( 91.96)\tAcc@5  98.44 ( 98.71)\n","Epoch: [91][300/391]\tTime  0.170 ( 0.170)\tLoss 3.9884e-01 (2.9485e-01)\tAcc@1  89.84 ( 91.91)\tAcc@5  96.88 ( 98.65)\n","Epoch: [91][330/391]\tTime  0.172 ( 0.170)\tLoss 4.2522e-01 (2.9378e-01)\tAcc@1  87.50 ( 91.90)\tAcc@5  97.66 ( 98.68)\n","Epoch: [91][360/391]\tTime  0.171 ( 0.170)\tLoss 1.8629e-01 (2.9453e-01)\tAcc@1  95.31 ( 91.84)\tAcc@5 100.00 ( 98.68)\n","Epoch: [91][390/391]\tTime  0.153 ( 0.170)\tLoss 2.4442e-01 (2.9437e-01)\tAcc@1  92.50 ( 91.85)\tAcc@5 100.00 ( 98.67)\n","==> Train Accuracy: Acc@1 91.852 || Acc@5 98.672\n","==> Test Accuracy:  Acc@1 77.140 || Acc@5 94.550\n","==> 70.49 seconds to train this epoch\n","\n","\n","----- epoch: 92, lr: 0.004000000000000001 -----\n","Epoch: [92][  0/391]\tTime  0.299 ( 0.299)\tLoss 2.3537e-01 (2.3537e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  99.22 ( 99.22)\n","Epoch: [92][ 30/391]\tTime  0.171 ( 0.173)\tLoss 3.3185e-01 (2.8063e-01)\tAcc@1  89.06 ( 92.29)\tAcc@5  99.22 ( 98.61)\n","Epoch: [92][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.7209e-01 (2.8289e-01)\tAcc@1  93.75 ( 92.23)\tAcc@5  97.66 ( 98.63)\n","Epoch: [92][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.3528e-01 (2.7670e-01)\tAcc@1  92.97 ( 92.35)\tAcc@5 100.00 ( 98.74)\n","Epoch: [92][120/391]\tTime  0.169 ( 0.170)\tLoss 2.4603e-01 (2.7712e-01)\tAcc@1  94.53 ( 92.39)\tAcc@5  96.88 ( 98.68)\n","Epoch: [92][150/391]\tTime  0.169 ( 0.170)\tLoss 4.0397e-01 (2.8071e-01)\tAcc@1  90.62 ( 92.24)\tAcc@5  96.88 ( 98.64)\n","Epoch: [92][180/391]\tTime  0.168 ( 0.170)\tLoss 4.2284e-01 (2.8041e-01)\tAcc@1  89.06 ( 92.26)\tAcc@5  96.88 ( 98.68)\n","Epoch: [92][210/391]\tTime  0.168 ( 0.170)\tLoss 1.9564e-01 (2.7768e-01)\tAcc@1  93.75 ( 92.30)\tAcc@5 100.00 ( 98.71)\n","Epoch: [92][240/391]\tTime  0.169 ( 0.170)\tLoss 1.8596e-01 (2.7617e-01)\tAcc@1  94.53 ( 92.31)\tAcc@5  99.22 ( 98.73)\n","Epoch: [92][270/391]\tTime  0.170 ( 0.169)\tLoss 3.4614e-01 (2.7612e-01)\tAcc@1  88.28 ( 92.31)\tAcc@5 100.00 ( 98.70)\n","Epoch: [92][300/391]\tTime  0.169 ( 0.169)\tLoss 2.6444e-01 (2.7424e-01)\tAcc@1  91.41 ( 92.40)\tAcc@5  99.22 ( 98.72)\n","Epoch: [92][330/391]\tTime  0.170 ( 0.169)\tLoss 4.3223e-01 (2.7452e-01)\tAcc@1  86.72 ( 92.42)\tAcc@5  97.66 ( 98.74)\n","Epoch: [92][360/391]\tTime  0.170 ( 0.169)\tLoss 3.4968e-01 (2.7547e-01)\tAcc@1  92.19 ( 92.41)\tAcc@5  97.66 ( 98.73)\n","Epoch: [92][390/391]\tTime  0.153 ( 0.169)\tLoss 3.1291e-01 (2.7392e-01)\tAcc@1  95.00 ( 92.46)\tAcc@5  98.75 ( 98.74)\n","==> Train Accuracy: Acc@1 92.462 || Acc@5 98.738\n","==> Test Accuracy:  Acc@1 77.250 || Acc@5 94.510\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 93, lr: 0.004000000000000001 -----\n","Epoch: [93][  0/391]\tTime  0.281 ( 0.281)\tLoss 3.6343e-01 (3.6343e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  97.66 ( 97.66)\n","Epoch: [93][ 30/391]\tTime  0.171 ( 0.172)\tLoss 2.5173e-01 (2.7387e-01)\tAcc@1  92.19 ( 92.09)\tAcc@5  99.22 ( 98.61)\n","Epoch: [93][ 60/391]\tTime  0.169 ( 0.171)\tLoss 2.9175e-01 (2.5780e-01)\tAcc@1  89.84 ( 92.71)\tAcc@5  98.44 ( 98.76)\n","Epoch: [93][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.9650e-01 (2.5659e-01)\tAcc@1  91.41 ( 92.77)\tAcc@5  98.44 ( 98.83)\n","Epoch: [93][120/391]\tTime  0.169 ( 0.170)\tLoss 2.5742e-01 (2.5822e-01)\tAcc@1  91.41 ( 92.72)\tAcc@5  98.44 ( 98.85)\n","Epoch: [93][150/391]\tTime  0.168 ( 0.170)\tLoss 1.7362e-01 (2.5665e-01)\tAcc@1  96.09 ( 92.80)\tAcc@5 100.00 ( 98.88)\n","Epoch: [93][180/391]\tTime  0.170 ( 0.169)\tLoss 1.8725e-01 (2.5676e-01)\tAcc@1  93.75 ( 92.85)\tAcc@5 100.00 ( 98.86)\n","Epoch: [93][210/391]\tTime  0.169 ( 0.169)\tLoss 2.8047e-01 (2.5718e-01)\tAcc@1  89.84 ( 92.79)\tAcc@5  99.22 ( 98.87)\n","Epoch: [93][240/391]\tTime  0.170 ( 0.169)\tLoss 2.5815e-01 (2.5787e-01)\tAcc@1  94.53 ( 92.83)\tAcc@5  99.22 ( 98.87)\n","Epoch: [93][270/391]\tTime  0.170 ( 0.169)\tLoss 2.1273e-01 (2.5904e-01)\tAcc@1  92.97 ( 92.77)\tAcc@5  98.44 ( 98.84)\n","Epoch: [93][300/391]\tTime  0.170 ( 0.169)\tLoss 3.2712e-01 (2.6014e-01)\tAcc@1  92.19 ( 92.70)\tAcc@5  96.88 ( 98.83)\n","Epoch: [93][330/391]\tTime  0.168 ( 0.169)\tLoss 3.0930e-01 (2.6065e-01)\tAcc@1  91.41 ( 92.72)\tAcc@5  99.22 ( 98.82)\n","Epoch: [93][360/391]\tTime  0.169 ( 0.169)\tLoss 2.5620e-01 (2.5945e-01)\tAcc@1  92.19 ( 92.77)\tAcc@5 100.00 ( 98.84)\n","Epoch: [93][390/391]\tTime  0.152 ( 0.169)\tLoss 1.8202e-01 (2.5954e-01)\tAcc@1  93.75 ( 92.79)\tAcc@5 100.00 ( 98.83)\n","==> Train Accuracy: Acc@1 92.786 || Acc@5 98.834\n","==> Test Accuracy:  Acc@1 77.350 || Acc@5 94.690\n","==> 70.37 seconds to train this epoch\n","\n","\n","----- epoch: 94, lr: 0.004000000000000001 -----\n","Epoch: [94][  0/391]\tTime  0.282 ( 0.282)\tLoss 2.7716e-01 (2.7716e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  99.22 ( 99.22)\n","Epoch: [94][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.8452e-01 (2.3253e-01)\tAcc@1  95.31 ( 93.57)\tAcc@5 100.00 ( 98.99)\n","Epoch: [94][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.9420e-01 (2.3257e-01)\tAcc@1  95.31 ( 93.62)\tAcc@5 100.00 ( 99.09)\n","Epoch: [94][ 90/391]\tTime  0.169 ( 0.170)\tLoss 3.3018e-01 (2.3312e-01)\tAcc@1  89.84 ( 93.60)\tAcc@5  97.66 ( 99.14)\n","Epoch: [94][120/391]\tTime  0.171 ( 0.170)\tLoss 2.8690e-01 (2.3838e-01)\tAcc@1  91.41 ( 93.41)\tAcc@5  97.66 ( 99.01)\n","Epoch: [94][150/391]\tTime  0.168 ( 0.170)\tLoss 2.4971e-01 (2.3770e-01)\tAcc@1  92.97 ( 93.48)\tAcc@5  98.44 ( 99.00)\n","Epoch: [94][180/391]\tTime  0.170 ( 0.170)\tLoss 1.7535e-01 (2.3660e-01)\tAcc@1  92.97 ( 93.51)\tAcc@5 100.00 ( 99.00)\n","Epoch: [94][210/391]\tTime  0.170 ( 0.170)\tLoss 2.6009e-01 (2.4172e-01)\tAcc@1  92.19 ( 93.32)\tAcc@5  99.22 ( 98.97)\n","Epoch: [94][240/391]\tTime  0.170 ( 0.170)\tLoss 2.3816e-01 (2.4185e-01)\tAcc@1  92.19 ( 93.34)\tAcc@5  98.44 ( 98.94)\n","Epoch: [94][270/391]\tTime  0.168 ( 0.170)\tLoss 2.5587e-01 (2.4413e-01)\tAcc@1  92.19 ( 93.29)\tAcc@5  99.22 ( 98.94)\n","Epoch: [94][300/391]\tTime  0.170 ( 0.170)\tLoss 2.0316e-01 (2.4212e-01)\tAcc@1  93.75 ( 93.36)\tAcc@5  98.44 ( 98.95)\n","Epoch: [94][330/391]\tTime  0.170 ( 0.170)\tLoss 1.5468e-01 (2.4203e-01)\tAcc@1  96.09 ( 93.37)\tAcc@5  99.22 ( 98.93)\n","Epoch: [94][360/391]\tTime  0.169 ( 0.170)\tLoss 1.8326e-01 (2.4158e-01)\tAcc@1  94.53 ( 93.38)\tAcc@5  99.22 ( 98.94)\n","Epoch: [94][390/391]\tTime  0.151 ( 0.170)\tLoss 4.3094e-01 (2.4205e-01)\tAcc@1  92.50 ( 93.35)\tAcc@5  96.25 ( 98.95)\n","==> Train Accuracy: Acc@1 93.346 || Acc@5 98.954\n","==> Test Accuracy:  Acc@1 77.270 || Acc@5 94.530\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 95, lr: 0.004000000000000001 -----\n","Epoch: [95][  0/391]\tTime  0.294 ( 0.294)\tLoss 2.0476e-01 (2.0476e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [95][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.5307e-01 (2.1958e-01)\tAcc@1  93.75 ( 93.62)\tAcc@5  98.44 ( 99.09)\n","Epoch: [95][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.7904e-01 (2.2788e-01)\tAcc@1  96.88 ( 93.63)\tAcc@5  99.22 ( 99.09)\n","Epoch: [95][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.4988e-01 (2.3761e-01)\tAcc@1  92.19 ( 93.42)\tAcc@5  99.22 ( 98.96)\n","Epoch: [95][120/391]\tTime  0.169 ( 0.170)\tLoss 1.3183e-01 (2.3559e-01)\tAcc@1  96.09 ( 93.56)\tAcc@5 100.00 ( 98.98)\n","Epoch: [95][150/391]\tTime  0.169 ( 0.170)\tLoss 2.2653e-01 (2.3759e-01)\tAcc@1  93.75 ( 93.49)\tAcc@5  98.44 ( 98.94)\n","Epoch: [95][180/391]\tTime  0.169 ( 0.170)\tLoss 2.3416e-01 (2.3684e-01)\tAcc@1  94.53 ( 93.54)\tAcc@5  99.22 ( 98.93)\n","Epoch: [95][210/391]\tTime  0.171 ( 0.170)\tLoss 2.6710e-01 (2.3791e-01)\tAcc@1  92.97 ( 93.56)\tAcc@5  99.22 ( 98.91)\n","Epoch: [95][240/391]\tTime  0.171 ( 0.170)\tLoss 2.0663e-01 (2.3682e-01)\tAcc@1  95.31 ( 93.63)\tAcc@5  99.22 ( 98.92)\n","Epoch: [95][270/391]\tTime  0.170 ( 0.170)\tLoss 1.7754e-01 (2.3600e-01)\tAcc@1  94.53 ( 93.63)\tAcc@5 100.00 ( 98.94)\n","Epoch: [95][300/391]\tTime  0.169 ( 0.170)\tLoss 2.1617e-01 (2.3588e-01)\tAcc@1  93.75 ( 93.63)\tAcc@5  99.22 ( 98.96)\n","Epoch: [95][330/391]\tTime  0.168 ( 0.170)\tLoss 2.7630e-01 (2.3633e-01)\tAcc@1  91.41 ( 93.60)\tAcc@5  98.44 ( 98.96)\n","Epoch: [95][360/391]\tTime  0.171 ( 0.170)\tLoss 2.6031e-01 (2.3611e-01)\tAcc@1  92.19 ( 93.59)\tAcc@5  99.22 ( 98.95)\n","Epoch: [95][390/391]\tTime  0.151 ( 0.170)\tLoss 2.7144e-01 (2.3611e-01)\tAcc@1  91.25 ( 93.61)\tAcc@5  96.25 ( 98.94)\n","==> Train Accuracy: Acc@1 93.606 || Acc@5 98.944\n","==> Test Accuracy:  Acc@1 77.600 || Acc@5 94.680\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 96, lr: 0.004000000000000001 -----\n","Epoch: [96][  0/391]\tTime  0.280 ( 0.280)\tLoss 2.8853e-01 (2.8853e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  96.88 ( 96.88)\n","Epoch: [96][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.1170e-01 (2.3093e-01)\tAcc@1  92.19 ( 93.65)\tAcc@5  99.22 ( 98.97)\n","Epoch: [96][ 60/391]\tTime  0.170 ( 0.171)\tLoss 3.3829e-01 (2.2805e-01)\tAcc@1  89.06 ( 93.72)\tAcc@5  98.44 ( 98.96)\n","Epoch: [96][ 90/391]\tTime  0.168 ( 0.170)\tLoss 2.0715e-01 (2.2604e-01)\tAcc@1  96.88 ( 93.87)\tAcc@5  99.22 ( 98.98)\n","Epoch: [96][120/391]\tTime  0.168 ( 0.170)\tLoss 2.4739e-01 (2.2967e-01)\tAcc@1  92.19 ( 93.74)\tAcc@5  99.22 ( 98.99)\n","Epoch: [96][150/391]\tTime  0.171 ( 0.170)\tLoss 1.7228e-01 (2.3150e-01)\tAcc@1  95.31 ( 93.64)\tAcc@5  98.44 ( 99.00)\n","Epoch: [96][180/391]\tTime  0.168 ( 0.170)\tLoss 2.4292e-01 (2.2967e-01)\tAcc@1  89.84 ( 93.69)\tAcc@5  99.22 ( 99.02)\n","Epoch: [96][210/391]\tTime  0.171 ( 0.170)\tLoss 2.5311e-01 (2.3098e-01)\tAcc@1  94.53 ( 93.65)\tAcc@5  98.44 ( 98.98)\n","Epoch: [96][240/391]\tTime  0.168 ( 0.170)\tLoss 3.5701e-01 (2.2917e-01)\tAcc@1  91.41 ( 93.69)\tAcc@5  98.44 ( 98.99)\n","Epoch: [96][270/391]\tTime  0.170 ( 0.170)\tLoss 2.0412e-01 (2.2961e-01)\tAcc@1  92.97 ( 93.67)\tAcc@5  99.22 ( 98.99)\n","Epoch: [96][300/391]\tTime  0.169 ( 0.170)\tLoss 3.3242e-01 (2.2999e-01)\tAcc@1  87.50 ( 93.66)\tAcc@5  98.44 ( 98.99)\n","Epoch: [96][330/391]\tTime  0.168 ( 0.170)\tLoss 1.5075e-01 (2.2922e-01)\tAcc@1  96.88 ( 93.69)\tAcc@5 100.00 ( 99.00)\n","Epoch: [96][360/391]\tTime  0.170 ( 0.170)\tLoss 3.4202e-01 (2.3097e-01)\tAcc@1  92.97 ( 93.64)\tAcc@5  98.44 ( 99.00)\n","Epoch: [96][390/391]\tTime  0.153 ( 0.170)\tLoss 3.7826e-01 (2.3108e-01)\tAcc@1  91.25 ( 93.64)\tAcc@5  97.50 ( 98.98)\n","==> Train Accuracy: Acc@1 93.640 || Acc@5 98.980\n","==> Test Accuracy:  Acc@1 77.660 || Acc@5 94.490\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 97, lr: 0.004000000000000001 -----\n","Epoch: [97][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.8156e-01 (1.8156e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n","Epoch: [97][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.2211e-01 (2.1520e-01)\tAcc@1  96.88 ( 93.95)\tAcc@5 100.00 ( 99.12)\n","Epoch: [97][ 60/391]\tTime  0.169 ( 0.171)\tLoss 2.2688e-01 (2.1448e-01)\tAcc@1  94.53 ( 94.21)\tAcc@5  99.22 ( 99.10)\n","Epoch: [97][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.3974e-01 (2.1241e-01)\tAcc@1  91.41 ( 94.18)\tAcc@5 100.00 ( 99.12)\n","Epoch: [97][120/391]\tTime  0.168 ( 0.170)\tLoss 2.2743e-01 (2.0998e-01)\tAcc@1  94.53 ( 94.21)\tAcc@5  97.66 ( 99.20)\n","Epoch: [97][150/391]\tTime  0.168 ( 0.170)\tLoss 2.9913e-01 (2.1094e-01)\tAcc@1  92.19 ( 94.21)\tAcc@5  99.22 ( 99.20)\n","Epoch: [97][180/391]\tTime  0.169 ( 0.170)\tLoss 1.9636e-01 (2.1193e-01)\tAcc@1  92.97 ( 94.16)\tAcc@5 100.00 ( 99.20)\n","Epoch: [97][210/391]\tTime  0.170 ( 0.170)\tLoss 1.7801e-01 (2.1229e-01)\tAcc@1  96.09 ( 94.16)\tAcc@5  99.22 ( 99.18)\n","Epoch: [97][240/391]\tTime  0.169 ( 0.170)\tLoss 2.1748e-01 (2.1519e-01)\tAcc@1  92.97 ( 94.07)\tAcc@5  99.22 ( 99.17)\n","Epoch: [97][270/391]\tTime  0.169 ( 0.170)\tLoss 3.0462e-01 (2.1685e-01)\tAcc@1  89.84 ( 94.03)\tAcc@5  97.66 ( 99.14)\n","Epoch: [97][300/391]\tTime  0.170 ( 0.170)\tLoss 1.8178e-01 (2.1676e-01)\tAcc@1  95.31 ( 94.03)\tAcc@5  98.44 ( 99.13)\n","Epoch: [97][330/391]\tTime  0.169 ( 0.170)\tLoss 1.8013e-01 (2.1714e-01)\tAcc@1  96.09 ( 94.00)\tAcc@5  99.22 ( 99.12)\n","Epoch: [97][360/391]\tTime  0.170 ( 0.169)\tLoss 2.1762e-01 (2.1785e-01)\tAcc@1  96.09 ( 93.99)\tAcc@5  97.66 ( 99.10)\n","Epoch: [97][390/391]\tTime  0.151 ( 0.169)\tLoss 2.6094e-01 (2.1850e-01)\tAcc@1  92.50 ( 93.94)\tAcc@5  98.75 ( 99.08)\n","==> Train Accuracy: Acc@1 93.940 || Acc@5 99.080\n","==> Test Accuracy:  Acc@1 77.610 || Acc@5 94.470\n","==> 70.43 seconds to train this epoch\n","\n","\n","----- epoch: 98, lr: 0.004000000000000001 -----\n","Epoch: [98][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.9032e-01 (1.9032e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  98.44 ( 98.44)\n","Epoch: [98][ 30/391]\tTime  0.170 ( 0.172)\tLoss 2.4086e-01 (2.0011e-01)\tAcc@1  92.97 ( 94.56)\tAcc@5  97.66 ( 99.04)\n","Epoch: [98][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.5662e-01 (2.0612e-01)\tAcc@1  93.75 ( 94.57)\tAcc@5  98.44 ( 98.99)\n","Epoch: [98][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.3319e-01 (2.0965e-01)\tAcc@1  96.09 ( 94.44)\tAcc@5  99.22 ( 99.03)\n","Epoch: [98][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4162e-01 (2.1193e-01)\tAcc@1  97.66 ( 94.30)\tAcc@5  99.22 ( 99.04)\n","Epoch: [98][150/391]\tTime  0.168 ( 0.169)\tLoss 2.1223e-01 (2.1288e-01)\tAcc@1  93.75 ( 94.19)\tAcc@5  98.44 ( 99.07)\n","Epoch: [98][180/391]\tTime  0.170 ( 0.169)\tLoss 2.6573e-01 (2.1388e-01)\tAcc@1  92.19 ( 94.15)\tAcc@5  99.22 ( 99.04)\n","Epoch: [98][210/391]\tTime  0.170 ( 0.169)\tLoss 1.6281e-01 (2.1604e-01)\tAcc@1  97.66 ( 94.07)\tAcc@5 100.00 ( 99.04)\n","Epoch: [98][240/391]\tTime  0.168 ( 0.169)\tLoss 2.5709e-01 (2.1728e-01)\tAcc@1  92.19 ( 94.06)\tAcc@5  98.44 ( 99.04)\n","Epoch: [98][270/391]\tTime  0.170 ( 0.169)\tLoss 1.6666e-01 (2.1828e-01)\tAcc@1  94.53 ( 94.02)\tAcc@5 100.00 ( 99.05)\n","Epoch: [98][300/391]\tTime  0.169 ( 0.169)\tLoss 2.8625e-01 (2.1918e-01)\tAcc@1  92.19 ( 94.01)\tAcc@5  97.66 ( 99.05)\n","Epoch: [98][330/391]\tTime  0.169 ( 0.169)\tLoss 2.0133e-01 (2.1921e-01)\tAcc@1  96.09 ( 94.00)\tAcc@5 100.00 ( 99.06)\n","Epoch: [98][360/391]\tTime  0.168 ( 0.169)\tLoss 2.9306e-01 (2.2102e-01)\tAcc@1  89.84 ( 93.92)\tAcc@5  98.44 ( 99.03)\n","Epoch: [98][390/391]\tTime  0.151 ( 0.169)\tLoss 1.9054e-01 (2.2071e-01)\tAcc@1  95.00 ( 93.94)\tAcc@5 100.00 ( 99.03)\n","==> Train Accuracy: Acc@1 93.942 || Acc@5 99.032\n","==> Test Accuracy:  Acc@1 77.590 || Acc@5 94.540\n","==> 70.30 seconds to train this epoch\n","\n","\n","----- epoch: 99, lr: 0.004000000000000001 -----\n","Epoch: [99][  0/391]\tTime  0.289 ( 0.289)\tLoss 2.3493e-01 (2.3493e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n","Epoch: [99][ 30/391]\tTime  0.170 ( 0.172)\tLoss 3.1342e-01 (2.0757e-01)\tAcc@1  92.97 ( 94.03)\tAcc@5  99.22 ( 99.40)\n","Epoch: [99][ 60/391]\tTime  0.171 ( 0.171)\tLoss 2.2138e-01 (2.0765e-01)\tAcc@1  94.53 ( 94.28)\tAcc@5  99.22 ( 99.23)\n","Epoch: [99][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.7820e-01 (2.0752e-01)\tAcc@1  94.53 ( 94.30)\tAcc@5  99.22 ( 99.20)\n","Epoch: [99][120/391]\tTime  0.168 ( 0.170)\tLoss 1.9863e-01 (2.0679e-01)\tAcc@1  94.53 ( 94.40)\tAcc@5  99.22 ( 99.24)\n","Epoch: [99][150/391]\tTime  0.170 ( 0.170)\tLoss 3.3223e-01 (2.0988e-01)\tAcc@1  90.62 ( 94.30)\tAcc@5  96.88 ( 99.16)\n","Epoch: [99][180/391]\tTime  0.172 ( 0.170)\tLoss 2.5806e-01 (2.1213e-01)\tAcc@1  92.19 ( 94.23)\tAcc@5  98.44 ( 99.07)\n","Epoch: [99][210/391]\tTime  0.169 ( 0.170)\tLoss 2.4294e-01 (2.1374e-01)\tAcc@1  91.41 ( 94.16)\tAcc@5  99.22 ( 99.06)\n","Epoch: [99][240/391]\tTime  0.170 ( 0.169)\tLoss 1.7638e-01 (2.1312e-01)\tAcc@1  95.31 ( 94.20)\tAcc@5 100.00 ( 99.07)\n","Epoch: [99][270/391]\tTime  0.170 ( 0.169)\tLoss 1.7674e-01 (2.1417e-01)\tAcc@1  93.75 ( 94.17)\tAcc@5 100.00 ( 99.06)\n","Epoch: [99][300/391]\tTime  0.169 ( 0.169)\tLoss 2.9030e-01 (2.1497e-01)\tAcc@1  90.62 ( 94.11)\tAcc@5  97.66 ( 99.06)\n","Epoch: [99][330/391]\tTime  0.170 ( 0.169)\tLoss 1.7914e-01 (2.1517e-01)\tAcc@1  95.31 ( 94.13)\tAcc@5 100.00 ( 99.07)\n","Epoch: [99][360/391]\tTime  0.173 ( 0.169)\tLoss 2.9337e-01 (2.1416e-01)\tAcc@1  91.41 ( 94.19)\tAcc@5  97.66 ( 99.07)\n","Epoch: [99][390/391]\tTime  0.151 ( 0.169)\tLoss 8.7549e-02 (2.1330e-01)\tAcc@1  97.50 ( 94.21)\tAcc@5 100.00 ( 99.06)\n","==> Train Accuracy: Acc@1 94.214 || Acc@5 99.062\n","==> Test Accuracy:  Acc@1 77.730 || Acc@5 94.720\n","==> 70.38 seconds to train this epoch\n","\n","\n","----- epoch: 100, lr: 0.004000000000000001 -----\n","Epoch: [100][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.4672e-01 (1.4672e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n","Epoch: [100][ 30/391]\tTime  0.170 ( 0.172)\tLoss 2.9615e-01 (2.0063e-01)\tAcc@1  91.41 ( 94.46)\tAcc@5  98.44 ( 99.24)\n","Epoch: [100][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.5441e-01 (2.0558e-01)\tAcc@1  96.88 ( 94.43)\tAcc@5 100.00 ( 99.05)\n","Epoch: [100][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.9017e-01 (1.9923e-01)\tAcc@1  93.75 ( 94.51)\tAcc@5 100.00 ( 99.15)\n","Epoch: [100][120/391]\tTime  0.170 ( 0.170)\tLoss 2.8107e-01 (2.0666e-01)\tAcc@1  89.84 ( 94.32)\tAcc@5  99.22 ( 99.09)\n","Epoch: [100][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5824e-01 (2.0526e-01)\tAcc@1  96.09 ( 94.37)\tAcc@5  99.22 ( 99.13)\n","Epoch: [100][180/391]\tTime  0.169 ( 0.170)\tLoss 2.4501e-01 (2.0706e-01)\tAcc@1  93.75 ( 94.37)\tAcc@5  97.66 ( 99.11)\n","Epoch: [100][210/391]\tTime  0.170 ( 0.170)\tLoss 2.6977e-01 (2.0698e-01)\tAcc@1  91.41 ( 94.37)\tAcc@5  98.44 ( 99.09)\n","Epoch: [100][240/391]\tTime  0.168 ( 0.170)\tLoss 1.9142e-01 (2.0649e-01)\tAcc@1  93.75 ( 94.39)\tAcc@5  99.22 ( 99.13)\n","Epoch: [100][270/391]\tTime  0.168 ( 0.170)\tLoss 2.1819e-01 (2.0678e-01)\tAcc@1  93.75 ( 94.33)\tAcc@5  99.22 ( 99.13)\n","Epoch: [100][300/391]\tTime  0.170 ( 0.169)\tLoss 2.6197e-01 (2.0931e-01)\tAcc@1  92.19 ( 94.27)\tAcc@5  97.66 ( 99.11)\n","Epoch: [100][330/391]\tTime  0.169 ( 0.169)\tLoss 1.5643e-01 (2.0842e-01)\tAcc@1  96.09 ( 94.31)\tAcc@5  99.22 ( 99.13)\n","Epoch: [100][360/391]\tTime  0.169 ( 0.169)\tLoss 6.0854e-02 (2.0858e-01)\tAcc@1  99.22 ( 94.33)\tAcc@5 100.00 ( 99.11)\n","Epoch: [100][390/391]\tTime  0.153 ( 0.169)\tLoss 1.5976e-01 (2.0854e-01)\tAcc@1  96.25 ( 94.31)\tAcc@5 100.00 ( 99.12)\n","==> Train Accuracy: Acc@1 94.312 || Acc@5 99.122\n","==> Test Accuracy:  Acc@1 77.630 || Acc@5 94.710\n","==> 70.41 seconds to train this epoch\n","\n","\n","----- epoch: 101, lr: 0.004000000000000001 -----\n","Epoch: [101][  0/391]\tTime  0.293 ( 0.293)\tLoss 2.2814e-01 (2.2814e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  97.66 ( 97.66)\n","Epoch: [101][ 30/391]\tTime  0.171 ( 0.172)\tLoss 2.4232e-01 (2.1603e-01)\tAcc@1  95.31 ( 94.15)\tAcc@5  98.44 ( 98.84)\n","Epoch: [101][ 60/391]\tTime  0.168 ( 0.171)\tLoss 2.7354e-01 (2.0499e-01)\tAcc@1  92.97 ( 94.47)\tAcc@5  99.22 ( 99.08)\n","Epoch: [101][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.4573e-01 (2.0826e-01)\tAcc@1  96.09 ( 94.25)\tAcc@5 100.00 ( 99.10)\n","Epoch: [101][120/391]\tTime  0.171 ( 0.170)\tLoss 1.5281e-01 (2.0317e-01)\tAcc@1  95.31 ( 94.44)\tAcc@5 100.00 ( 99.13)\n","Epoch: [101][150/391]\tTime  0.168 ( 0.170)\tLoss 2.5100e-01 (2.0267e-01)\tAcc@1  92.19 ( 94.51)\tAcc@5  99.22 ( 99.12)\n","Epoch: [101][180/391]\tTime  0.168 ( 0.170)\tLoss 2.3699e-01 (2.0262e-01)\tAcc@1  94.53 ( 94.55)\tAcc@5 100.00 ( 99.13)\n","Epoch: [101][210/391]\tTime  0.168 ( 0.169)\tLoss 1.5758e-01 (2.0277e-01)\tAcc@1  94.53 ( 94.57)\tAcc@5  99.22 ( 99.14)\n","Epoch: [101][240/391]\tTime  0.171 ( 0.169)\tLoss 2.5620e-01 (2.0218e-01)\tAcc@1  91.41 ( 94.59)\tAcc@5  98.44 ( 99.13)\n","Epoch: [101][270/391]\tTime  0.171 ( 0.169)\tLoss 1.9755e-01 (2.0293e-01)\tAcc@1  93.75 ( 94.57)\tAcc@5 100.00 ( 99.13)\n","Epoch: [101][300/391]\tTime  0.168 ( 0.169)\tLoss 1.7110e-01 (2.0252e-01)\tAcc@1  96.09 ( 94.55)\tAcc@5  99.22 ( 99.14)\n","Epoch: [101][330/391]\tTime  0.168 ( 0.169)\tLoss 9.7390e-02 (2.0227e-01)\tAcc@1  98.44 ( 94.58)\tAcc@5 100.00 ( 99.14)\n","Epoch: [101][360/391]\tTime  0.169 ( 0.169)\tLoss 1.1513e-01 (2.0185e-01)\tAcc@1  99.22 ( 94.60)\tAcc@5 100.00 ( 99.11)\n","Epoch: [101][390/391]\tTime  0.151 ( 0.169)\tLoss 1.7861e-01 (2.0133e-01)\tAcc@1  96.25 ( 94.62)\tAcc@5 100.00 ( 99.12)\n","==> Train Accuracy: Acc@1 94.618 || Acc@5 99.118\n","==> Test Accuracy:  Acc@1 77.960 || Acc@5 94.710\n","==> 70.39 seconds to train this epoch\n","\n","\n","----- epoch: 102, lr: 0.004000000000000001 -----\n","Epoch: [102][  0/391]\tTime  0.299 ( 0.299)\tLoss 1.9456e-01 (1.9456e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n","Epoch: [102][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.4372e-01 (1.8939e-01)\tAcc@1  96.09 ( 95.04)\tAcc@5 100.00 ( 99.29)\n","Epoch: [102][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.0641e-01 (1.8911e-01)\tAcc@1  96.88 ( 94.99)\tAcc@5 100.00 ( 99.24)\n","Epoch: [102][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.0678e-01 (1.9626e-01)\tAcc@1  95.31 ( 94.77)\tAcc@5  98.44 ( 99.16)\n","Epoch: [102][120/391]\tTime  0.169 ( 0.170)\tLoss 2.2371e-01 (1.9721e-01)\tAcc@1  94.53 ( 94.76)\tAcc@5 100.00 ( 99.13)\n","Epoch: [102][150/391]\tTime  0.169 ( 0.170)\tLoss 1.7078e-01 (2.0149e-01)\tAcc@1  95.31 ( 94.59)\tAcc@5  99.22 ( 99.09)\n","Epoch: [102][180/391]\tTime  0.169 ( 0.170)\tLoss 1.8690e-01 (2.0082e-01)\tAcc@1  94.53 ( 94.60)\tAcc@5  98.44 ( 99.11)\n","Epoch: [102][210/391]\tTime  0.169 ( 0.170)\tLoss 1.2011e-01 (1.9984e-01)\tAcc@1  96.09 ( 94.63)\tAcc@5 100.00 ( 99.14)\n","Epoch: [102][240/391]\tTime  0.168 ( 0.170)\tLoss 1.7373e-01 (2.0027e-01)\tAcc@1  93.75 ( 94.61)\tAcc@5  99.22 ( 99.12)\n","Epoch: [102][270/391]\tTime  0.170 ( 0.170)\tLoss 2.7066e-01 (2.0046e-01)\tAcc@1  92.97 ( 94.61)\tAcc@5  98.44 ( 99.11)\n","Epoch: [102][300/391]\tTime  0.168 ( 0.169)\tLoss 2.1847e-01 (2.0042e-01)\tAcc@1  93.75 ( 94.57)\tAcc@5 100.00 ( 99.14)\n","Epoch: [102][330/391]\tTime  0.169 ( 0.169)\tLoss 2.0748e-01 (1.9995e-01)\tAcc@1  94.53 ( 94.61)\tAcc@5 100.00 ( 99.14)\n","Epoch: [102][360/391]\tTime  0.170 ( 0.169)\tLoss 1.9557e-01 (1.9984e-01)\tAcc@1  95.31 ( 94.62)\tAcc@5  99.22 ( 99.15)\n","Epoch: [102][390/391]\tTime  0.152 ( 0.169)\tLoss 3.3080e-01 (1.9977e-01)\tAcc@1  87.50 ( 94.61)\tAcc@5 100.00 ( 99.15)\n","==> Train Accuracy: Acc@1 94.610 || Acc@5 99.148\n","==> Test Accuracy:  Acc@1 77.740 || Acc@5 94.550\n","==> 70.43 seconds to train this epoch\n","\n","\n","----- epoch: 103, lr: 0.004000000000000001 -----\n","Epoch: [103][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.2753e-01 (1.2753e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [103][ 30/391]\tTime  0.169 ( 0.173)\tLoss 5.9475e-02 (1.5623e-01)\tAcc@1  99.22 ( 96.07)\tAcc@5 100.00 ( 99.45)\n","Epoch: [103][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.7032e-01 (1.9031e-01)\tAcc@1  94.53 ( 95.01)\tAcc@5 100.00 ( 99.14)\n","Epoch: [103][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.7275e-01 (1.8976e-01)\tAcc@1  96.09 ( 94.92)\tAcc@5  99.22 ( 99.19)\n","Epoch: [103][120/391]\tTime  0.168 ( 0.170)\tLoss 3.0501e-01 (1.9169e-01)\tAcc@1  92.97 ( 94.82)\tAcc@5  97.66 ( 99.17)\n","Epoch: [103][150/391]\tTime  0.169 ( 0.170)\tLoss 1.7230e-01 (1.9134e-01)\tAcc@1  92.97 ( 94.82)\tAcc@5 100.00 ( 99.21)\n","Epoch: [103][180/391]\tTime  0.171 ( 0.170)\tLoss 3.3383e-01 (1.9250e-01)\tAcc@1  89.84 ( 94.79)\tAcc@5  98.44 ( 99.18)\n","Epoch: [103][210/391]\tTime  0.170 ( 0.170)\tLoss 1.5873e-01 (1.9490e-01)\tAcc@1  95.31 ( 94.65)\tAcc@5  99.22 ( 99.16)\n","Epoch: [103][240/391]\tTime  0.170 ( 0.170)\tLoss 1.5984e-01 (1.9527e-01)\tAcc@1  96.09 ( 94.68)\tAcc@5 100.00 ( 99.15)\n","Epoch: [103][270/391]\tTime  0.169 ( 0.170)\tLoss 1.3310e-01 (1.9670e-01)\tAcc@1  96.88 ( 94.65)\tAcc@5 100.00 ( 99.13)\n","Epoch: [103][300/391]\tTime  0.169 ( 0.170)\tLoss 1.7519e-01 (1.9623e-01)\tAcc@1  96.88 ( 94.65)\tAcc@5  99.22 ( 99.16)\n","Epoch: [103][330/391]\tTime  0.170 ( 0.170)\tLoss 2.9485e-01 (1.9768e-01)\tAcc@1  91.41 ( 94.62)\tAcc@5  98.44 ( 99.15)\n","Epoch: [103][360/391]\tTime  0.168 ( 0.170)\tLoss 2.5074e-01 (1.9852e-01)\tAcc@1  93.75 ( 94.62)\tAcc@5  98.44 ( 99.15)\n","Epoch: [103][390/391]\tTime  0.153 ( 0.169)\tLoss 3.1821e-01 (1.9932e-01)\tAcc@1  90.00 ( 94.59)\tAcc@5  98.75 ( 99.15)\n","==> Train Accuracy: Acc@1 94.586 || Acc@5 99.150\n","==> Test Accuracy:  Acc@1 77.490 || Acc@5 94.460\n","==> 70.46 seconds to train this epoch\n","\n","\n","----- epoch: 104, lr: 0.004000000000000001 -----\n","Epoch: [104][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.3607e-01 (1.3607e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [104][ 30/391]\tTime  0.170 ( 0.172)\tLoss 1.5074e-01 (2.0271e-01)\tAcc@1  96.88 ( 94.53)\tAcc@5 100.00 ( 99.19)\n","Epoch: [104][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.5013e-01 (1.9218e-01)\tAcc@1  97.66 ( 94.75)\tAcc@5 100.00 ( 99.32)\n","Epoch: [104][ 90/391]\tTime  0.171 ( 0.170)\tLoss 2.6861e-01 (1.9677e-01)\tAcc@1  95.31 ( 94.73)\tAcc@5  97.66 ( 99.18)\n","Epoch: [104][120/391]\tTime  0.169 ( 0.170)\tLoss 1.7338e-01 (1.9400e-01)\tAcc@1  94.53 ( 94.79)\tAcc@5 100.00 ( 99.17)\n","Epoch: [104][150/391]\tTime  0.169 ( 0.170)\tLoss 1.3728e-01 (1.9816e-01)\tAcc@1  96.09 ( 94.58)\tAcc@5 100.00 ( 99.17)\n","Epoch: [104][180/391]\tTime  0.170 ( 0.170)\tLoss 2.1792e-01 (1.9736e-01)\tAcc@1  93.75 ( 94.63)\tAcc@5  98.44 ( 99.20)\n","Epoch: [104][210/391]\tTime  0.170 ( 0.170)\tLoss 1.6650e-01 (1.9708e-01)\tAcc@1  94.53 ( 94.61)\tAcc@5 100.00 ( 99.19)\n","Epoch: [104][240/391]\tTime  0.169 ( 0.170)\tLoss 1.2464e-01 (1.9719e-01)\tAcc@1  97.66 ( 94.61)\tAcc@5 100.00 ( 99.18)\n","Epoch: [104][270/391]\tTime  0.168 ( 0.170)\tLoss 1.1878e-01 (1.9602e-01)\tAcc@1  96.88 ( 94.65)\tAcc@5  99.22 ( 99.17)\n","Epoch: [104][300/391]\tTime  0.171 ( 0.170)\tLoss 1.9864e-01 (1.9646e-01)\tAcc@1  93.75 ( 94.64)\tAcc@5 100.00 ( 99.17)\n","Epoch: [104][330/391]\tTime  0.168 ( 0.170)\tLoss 9.5980e-02 (1.9548e-01)\tAcc@1  96.88 ( 94.69)\tAcc@5 100.00 ( 99.16)\n","Epoch: [104][360/391]\tTime  0.168 ( 0.170)\tLoss 3.0610e-01 (1.9512e-01)\tAcc@1  89.84 ( 94.68)\tAcc@5  99.22 ( 99.16)\n","Epoch: [104][390/391]\tTime  0.152 ( 0.169)\tLoss 1.5560e-01 (1.9573e-01)\tAcc@1  95.00 ( 94.68)\tAcc@5 100.00 ( 99.16)\n","==> Train Accuracy: Acc@1 94.684 || Acc@5 99.164\n","==> Test Accuracy:  Acc@1 77.310 || Acc@5 94.360\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 105, lr: 0.004000000000000001 -----\n","Epoch: [105][  0/391]\tTime  0.305 ( 0.305)\tLoss 1.9932e-01 (1.9932e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n","Epoch: [105][ 30/391]\tTime  0.166 ( 0.173)\tLoss 3.8410e-01 (2.0339e-01)\tAcc@1  92.19 ( 94.78)\tAcc@5  95.31 ( 98.97)\n","Epoch: [105][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.6249e-01 (2.0374e-01)\tAcc@1  96.09 ( 94.70)\tAcc@5  99.22 ( 98.98)\n","Epoch: [105][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.7865e-01 (1.9805e-01)\tAcc@1  95.31 ( 94.75)\tAcc@5  99.22 ( 99.05)\n","Epoch: [105][120/391]\tTime  0.167 ( 0.170)\tLoss 2.2111e-01 (1.9579e-01)\tAcc@1  92.19 ( 94.92)\tAcc@5  99.22 ( 99.07)\n","Epoch: [105][150/391]\tTime  0.168 ( 0.170)\tLoss 2.8151e-01 (1.9383e-01)\tAcc@1  92.19 ( 94.92)\tAcc@5  98.44 ( 99.12)\n","Epoch: [105][180/391]\tTime  0.168 ( 0.170)\tLoss 2.1988e-01 (1.9339e-01)\tAcc@1  94.53 ( 94.92)\tAcc@5  98.44 ( 99.15)\n","Epoch: [105][210/391]\tTime  0.171 ( 0.170)\tLoss 1.7510e-01 (1.9553e-01)\tAcc@1  93.75 ( 94.83)\tAcc@5  99.22 ( 99.16)\n","Epoch: [105][240/391]\tTime  0.168 ( 0.170)\tLoss 1.6243e-01 (1.9412e-01)\tAcc@1  95.31 ( 94.86)\tAcc@5  98.44 ( 99.16)\n","Epoch: [105][270/391]\tTime  0.169 ( 0.170)\tLoss 1.1453e-01 (1.9551e-01)\tAcc@1  95.31 ( 94.77)\tAcc@5 100.00 ( 99.16)\n","Epoch: [105][300/391]\tTime  0.169 ( 0.170)\tLoss 2.1597e-01 (1.9680e-01)\tAcc@1  94.53 ( 94.72)\tAcc@5  99.22 ( 99.17)\n","Epoch: [105][330/391]\tTime  0.169 ( 0.170)\tLoss 9.6617e-02 (1.9689e-01)\tAcc@1  96.88 ( 94.67)\tAcc@5 100.00 ( 99.18)\n","Epoch: [105][360/391]\tTime  0.168 ( 0.170)\tLoss 2.2188e-01 (1.9666e-01)\tAcc@1  93.75 ( 94.67)\tAcc@5  99.22 ( 99.21)\n","Epoch: [105][390/391]\tTime  0.151 ( 0.170)\tLoss 7.0142e-02 (1.9653e-01)\tAcc@1  98.75 ( 94.66)\tAcc@5 100.00 ( 99.22)\n","==> Train Accuracy: Acc@1 94.658 || Acc@5 99.218\n","==> Test Accuracy:  Acc@1 77.330 || Acc@5 94.450\n","==> 70.51 seconds to train this epoch\n","\n","\n","----- epoch: 106, lr: 0.004000000000000001 -----\n","Epoch: [106][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.1682e-01 (1.1682e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [106][ 30/391]\tTime  0.171 ( 0.173)\tLoss 3.7474e-01 (1.7405e-01)\tAcc@1  90.62 ( 95.54)\tAcc@5  96.09 ( 99.22)\n","Epoch: [106][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.0094e-01 (1.7783e-01)\tAcc@1  98.44 ( 95.25)\tAcc@5 100.00 ( 99.19)\n","Epoch: [106][ 90/391]\tTime  0.170 ( 0.170)\tLoss 2.1869e-01 (1.8745e-01)\tAcc@1  95.31 ( 94.93)\tAcc@5  99.22 ( 99.17)\n","Epoch: [106][120/391]\tTime  0.169 ( 0.170)\tLoss 2.5192e-01 (1.8729e-01)\tAcc@1  89.84 ( 94.93)\tAcc@5  99.22 ( 99.17)\n","Epoch: [106][150/391]\tTime  0.170 ( 0.170)\tLoss 1.6583e-01 (1.8639e-01)\tAcc@1  96.88 ( 94.96)\tAcc@5  99.22 ( 99.19)\n","Epoch: [106][180/391]\tTime  0.170 ( 0.170)\tLoss 2.5366e-01 (1.8702e-01)\tAcc@1  91.41 ( 94.93)\tAcc@5  98.44 ( 99.18)\n","Epoch: [106][210/391]\tTime  0.170 ( 0.170)\tLoss 2.1746e-01 (1.8550e-01)\tAcc@1  92.97 ( 94.93)\tAcc@5  99.22 ( 99.21)\n","Epoch: [106][240/391]\tTime  0.169 ( 0.170)\tLoss 9.8592e-02 (1.8525e-01)\tAcc@1  97.66 ( 94.96)\tAcc@5 100.00 ( 99.21)\n","Epoch: [106][270/391]\tTime  0.170 ( 0.170)\tLoss 1.8127e-01 (1.8587e-01)\tAcc@1  93.75 ( 94.96)\tAcc@5 100.00 ( 99.20)\n","Epoch: [106][300/391]\tTime  0.169 ( 0.170)\tLoss 1.9110e-01 (1.8684e-01)\tAcc@1  92.97 ( 94.94)\tAcc@5  99.22 ( 99.18)\n","Epoch: [106][330/391]\tTime  0.169 ( 0.170)\tLoss 3.0224e-01 (1.8694e-01)\tAcc@1  92.97 ( 94.94)\tAcc@5  98.44 ( 99.17)\n","Epoch: [106][360/391]\tTime  0.170 ( 0.170)\tLoss 1.7435e-01 (1.8706e-01)\tAcc@1  95.31 ( 94.92)\tAcc@5  97.66 ( 99.18)\n","Epoch: [106][390/391]\tTime  0.153 ( 0.169)\tLoss 2.2420e-01 (1.8727e-01)\tAcc@1  96.25 ( 94.91)\tAcc@5 100.00 ( 99.19)\n","==> Train Accuracy: Acc@1 94.914 || Acc@5 99.186\n","==> Test Accuracy:  Acc@1 77.550 || Acc@5 94.240\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 107, lr: 0.004000000000000001 -----\n","Epoch: [107][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.1420e-01 (1.1420e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [107][ 30/391]\tTime  0.171 ( 0.172)\tLoss 1.8893e-01 (1.7962e-01)\tAcc@1  96.09 ( 95.26)\tAcc@5 100.00 ( 99.19)\n","Epoch: [107][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.3982e-01 (1.6926e-01)\tAcc@1  94.53 ( 95.44)\tAcc@5  98.44 ( 99.31)\n","Epoch: [107][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.6763e-01 (1.7281e-01)\tAcc@1  96.09 ( 95.30)\tAcc@5  99.22 ( 99.30)\n","Epoch: [107][120/391]\tTime  0.171 ( 0.170)\tLoss 1.3562e-01 (1.7717e-01)\tAcc@1  95.31 ( 95.24)\tAcc@5 100.00 ( 99.24)\n","Epoch: [107][150/391]\tTime  0.168 ( 0.170)\tLoss 1.8358e-01 (1.8109e-01)\tAcc@1  94.53 ( 95.04)\tAcc@5  99.22 ( 99.23)\n","Epoch: [107][180/391]\tTime  0.170 ( 0.170)\tLoss 2.2509e-01 (1.8399e-01)\tAcc@1  92.97 ( 94.98)\tAcc@5 100.00 ( 99.22)\n","Epoch: [107][210/391]\tTime  0.171 ( 0.170)\tLoss 1.2371e-01 (1.8321e-01)\tAcc@1  96.88 ( 95.05)\tAcc@5  99.22 ( 99.23)\n","Epoch: [107][240/391]\tTime  0.170 ( 0.170)\tLoss 1.1931e-01 (1.8624e-01)\tAcc@1  95.31 ( 94.99)\tAcc@5  99.22 ( 99.19)\n","Epoch: [107][270/391]\tTime  0.169 ( 0.170)\tLoss 1.5125e-01 (1.8728e-01)\tAcc@1  94.53 ( 94.96)\tAcc@5 100.00 ( 99.20)\n","Epoch: [107][300/391]\tTime  0.169 ( 0.170)\tLoss 1.7583e-01 (1.8874e-01)\tAcc@1  93.75 ( 94.88)\tAcc@5 100.00 ( 99.23)\n","Epoch: [107][330/391]\tTime  0.168 ( 0.170)\tLoss 2.0899e-01 (1.9125e-01)\tAcc@1  92.97 ( 94.77)\tAcc@5  99.22 ( 99.21)\n","Epoch: [107][360/391]\tTime  0.170 ( 0.170)\tLoss 1.9429e-01 (1.9165e-01)\tAcc@1  94.53 ( 94.76)\tAcc@5  99.22 ( 99.19)\n","Epoch: [107][390/391]\tTime  0.152 ( 0.169)\tLoss 2.1982e-01 (1.9282e-01)\tAcc@1  96.25 ( 94.73)\tAcc@5  98.75 ( 99.18)\n","==> Train Accuracy: Acc@1 94.728 || Acc@5 99.180\n","==> Test Accuracy:  Acc@1 78.250 || Acc@5 94.670\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 108, lr: 0.004000000000000001 -----\n","Epoch: [108][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.7184e-01 (1.7184e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [108][ 30/391]\tTime  0.170 ( 0.172)\tLoss 1.7966e-01 (1.8397e-01)\tAcc@1  94.53 ( 95.16)\tAcc@5  99.22 ( 99.40)\n","Epoch: [108][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.7486e-01 (1.8320e-01)\tAcc@1  96.09 ( 95.15)\tAcc@5 100.00 ( 99.40)\n","Epoch: [108][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.2674e-01 (1.8099e-01)\tAcc@1  95.31 ( 95.19)\tAcc@5 100.00 ( 99.44)\n","Epoch: [108][120/391]\tTime  0.168 ( 0.170)\tLoss 2.4879e-01 (1.8310e-01)\tAcc@1  95.31 ( 95.09)\tAcc@5  98.44 ( 99.33)\n","Epoch: [108][150/391]\tTime  0.170 ( 0.170)\tLoss 9.5746e-02 (1.8204e-01)\tAcc@1  97.66 ( 95.12)\tAcc@5  99.22 ( 99.33)\n","Epoch: [108][180/391]\tTime  0.169 ( 0.170)\tLoss 1.7487e-01 (1.8206e-01)\tAcc@1  96.88 ( 95.10)\tAcc@5  99.22 ( 99.34)\n","Epoch: [108][210/391]\tTime  0.170 ( 0.170)\tLoss 2.0374e-01 (1.8220e-01)\tAcc@1  95.31 ( 95.09)\tAcc@5  97.66 ( 99.30)\n","Epoch: [108][240/391]\tTime  0.168 ( 0.170)\tLoss 1.8849e-01 (1.8236e-01)\tAcc@1  93.75 ( 95.08)\tAcc@5  99.22 ( 99.30)\n","Epoch: [108][270/391]\tTime  0.169 ( 0.170)\tLoss 1.2945e-01 (1.8662e-01)\tAcc@1  95.31 ( 94.94)\tAcc@5  99.22 ( 99.25)\n","Epoch: [108][300/391]\tTime  0.171 ( 0.170)\tLoss 1.0249e-01 (1.8754e-01)\tAcc@1  96.88 ( 94.88)\tAcc@5 100.00 ( 99.25)\n","Epoch: [108][330/391]\tTime  0.170 ( 0.170)\tLoss 1.8307e-01 (1.8823e-01)\tAcc@1  95.31 ( 94.88)\tAcc@5  99.22 ( 99.23)\n","Epoch: [108][360/391]\tTime  0.171 ( 0.170)\tLoss 2.3296e-01 (1.9052e-01)\tAcc@1  93.75 ( 94.81)\tAcc@5 100.00 ( 99.23)\n","Epoch: [108][390/391]\tTime  0.154 ( 0.170)\tLoss 3.3992e-01 (1.9105e-01)\tAcc@1  90.00 ( 94.78)\tAcc@5  98.75 ( 99.22)\n","==> Train Accuracy: Acc@1 94.780 || Acc@5 99.224\n","==> Test Accuracy:  Acc@1 77.620 || Acc@5 94.400\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 109, lr: 0.004000000000000001 -----\n","Epoch: [109][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.1493e-01 (1.1493e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [109][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.5117e-01 (1.5932e-01)\tAcc@1  96.88 ( 95.64)\tAcc@5 100.00 ( 99.50)\n","Epoch: [109][ 60/391]\tTime  0.168 ( 0.171)\tLoss 2.7192e-01 (1.7496e-01)\tAcc@1  91.41 ( 95.35)\tAcc@5  98.44 ( 99.31)\n","Epoch: [109][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.1342e-01 (1.8166e-01)\tAcc@1  93.75 ( 95.10)\tAcc@5  98.44 ( 99.23)\n","Epoch: [109][120/391]\tTime  0.169 ( 0.170)\tLoss 2.1896e-01 (1.7973e-01)\tAcc@1  92.97 ( 95.16)\tAcc@5 100.00 ( 99.26)\n","Epoch: [109][150/391]\tTime  0.170 ( 0.170)\tLoss 1.8587e-01 (1.8377e-01)\tAcc@1  97.66 ( 95.00)\tAcc@5 100.00 ( 99.24)\n","Epoch: [109][180/391]\tTime  0.169 ( 0.170)\tLoss 1.3263e-01 (1.8529e-01)\tAcc@1  96.88 ( 94.91)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][210/391]\tTime  0.171 ( 0.170)\tLoss 1.8139e-01 (1.8542e-01)\tAcc@1  96.09 ( 94.92)\tAcc@5  99.22 ( 99.23)\n","Epoch: [109][240/391]\tTime  0.170 ( 0.170)\tLoss 1.6269e-01 (1.8466e-01)\tAcc@1  96.09 ( 94.98)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][270/391]\tTime  0.168 ( 0.170)\tLoss 1.8248e-01 (1.8594e-01)\tAcc@1  96.09 ( 94.96)\tAcc@5 100.00 ( 99.22)\n","Epoch: [109][300/391]\tTime  0.171 ( 0.170)\tLoss 2.8161e-01 (1.8591e-01)\tAcc@1  92.19 ( 94.95)\tAcc@5  99.22 ( 99.23)\n","Epoch: [109][330/391]\tTime  0.169 ( 0.170)\tLoss 1.4945e-01 (1.8699e-01)\tAcc@1  95.31 ( 94.91)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][360/391]\tTime  0.170 ( 0.170)\tLoss 1.0161e-01 (1.8645e-01)\tAcc@1  98.44 ( 94.94)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][390/391]\tTime  0.152 ( 0.170)\tLoss 2.9592e-01 (1.8616e-01)\tAcc@1  90.00 ( 94.96)\tAcc@5  97.50 ( 99.23)\n","==> Train Accuracy: Acc@1 94.960 || Acc@5 99.234\n","==> Test Accuracy:  Acc@1 77.970 || Acc@5 94.580\n","==> 70.51 seconds to train this epoch\n","\n","\n","----- epoch: 110, lr: 0.004000000000000001 -----\n","Epoch: [110][  0/391]\tTime  0.294 ( 0.294)\tLoss 2.2019e-01 (2.2019e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [110][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.4983e-01 (1.6662e-01)\tAcc@1  95.31 ( 95.39)\tAcc@5  99.22 ( 99.45)\n","Epoch: [110][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.7499e-01 (1.7949e-01)\tAcc@1  96.88 ( 94.98)\tAcc@5  98.44 ( 99.32)\n","Epoch: [110][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.7373e-01 (1.7817e-01)\tAcc@1  95.31 ( 95.08)\tAcc@5  98.44 ( 99.29)\n","Epoch: [110][120/391]\tTime  0.171 ( 0.170)\tLoss 2.0526e-01 (1.7849e-01)\tAcc@1  96.09 ( 95.20)\tAcc@5  98.44 ( 99.25)\n","Epoch: [110][150/391]\tTime  0.170 ( 0.170)\tLoss 1.7945e-01 (1.7886e-01)\tAcc@1  95.31 ( 95.20)\tAcc@5  99.22 ( 99.26)\n","Epoch: [110][180/391]\tTime  0.169 ( 0.170)\tLoss 2.0315e-01 (1.7804e-01)\tAcc@1  94.53 ( 95.17)\tAcc@5  99.22 ( 99.29)\n","Epoch: [110][210/391]\tTime  0.171 ( 0.170)\tLoss 1.8162e-01 (1.8033e-01)\tAcc@1  95.31 ( 95.10)\tAcc@5  99.22 ( 99.29)\n","Epoch: [110][240/391]\tTime  0.168 ( 0.170)\tLoss 2.0232e-01 (1.8302e-01)\tAcc@1  93.75 ( 95.04)\tAcc@5 100.00 ( 99.26)\n","Epoch: [110][270/391]\tTime  0.169 ( 0.170)\tLoss 1.3978e-01 (1.8575e-01)\tAcc@1  96.88 ( 94.91)\tAcc@5 100.00 ( 99.26)\n","Epoch: [110][300/391]\tTime  0.168 ( 0.170)\tLoss 8.2739e-02 (1.8542e-01)\tAcc@1  99.22 ( 94.94)\tAcc@5 100.00 ( 99.26)\n","Epoch: [110][330/391]\tTime  0.170 ( 0.170)\tLoss 1.1370e-01 (1.8638e-01)\tAcc@1  98.44 ( 94.92)\tAcc@5 100.00 ( 99.26)\n","Epoch: [110][360/391]\tTime  0.170 ( 0.170)\tLoss 1.9587e-01 (1.8693e-01)\tAcc@1  95.31 ( 94.91)\tAcc@5  98.44 ( 99.26)\n","Epoch: [110][390/391]\tTime  0.153 ( 0.170)\tLoss 2.2930e-01 (1.8778e-01)\tAcc@1  96.25 ( 94.89)\tAcc@5  98.75 ( 99.24)\n","==> Train Accuracy: Acc@1 94.886 || Acc@5 99.242\n","==> Test Accuracy:  Acc@1 77.660 || Acc@5 94.430\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 111, lr: 0.004000000000000001 -----\n","Epoch: [111][  0/391]\tTime  0.280 ( 0.280)\tLoss 2.5340e-01 (2.5340e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  99.22 ( 99.22)\n","Epoch: [111][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.2911e-01 (1.9521e-01)\tAcc@1  93.75 ( 94.56)\tAcc@5  98.44 ( 99.17)\n","Epoch: [111][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.8396e-01 (1.8480e-01)\tAcc@1  96.09 ( 94.86)\tAcc@5  99.22 ( 99.22)\n","Epoch: [111][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.1078e-01 (1.8635e-01)\tAcc@1  92.97 ( 94.81)\tAcc@5  99.22 ( 99.24)\n","Epoch: [111][120/391]\tTime  0.170 ( 0.170)\tLoss 1.9798e-01 (1.8219e-01)\tAcc@1  95.31 ( 94.92)\tAcc@5  98.44 ( 99.27)\n","Epoch: [111][150/391]\tTime  0.168 ( 0.170)\tLoss 1.6757e-01 (1.7704e-01)\tAcc@1  96.09 ( 95.14)\tAcc@5  99.22 ( 99.29)\n","Epoch: [111][180/391]\tTime  0.169 ( 0.170)\tLoss 1.8040e-01 (1.7935e-01)\tAcc@1  93.75 ( 95.06)\tAcc@5 100.00 ( 99.27)\n","Epoch: [111][210/391]\tTime  0.168 ( 0.170)\tLoss 1.4664e-01 (1.8113e-01)\tAcc@1  95.31 ( 94.99)\tAcc@5 100.00 ( 99.30)\n","Epoch: [111][240/391]\tTime  0.169 ( 0.170)\tLoss 2.0587e-01 (1.8364e-01)\tAcc@1  95.31 ( 94.94)\tAcc@5  97.66 ( 99.27)\n","Epoch: [111][270/391]\tTime  0.168 ( 0.170)\tLoss 7.2225e-02 (1.8232e-01)\tAcc@1  99.22 ( 94.96)\tAcc@5 100.00 ( 99.28)\n","Epoch: [111][300/391]\tTime  0.167 ( 0.170)\tLoss 2.3782e-01 (1.8251e-01)\tAcc@1  93.75 ( 94.96)\tAcc@5  96.88 ( 99.26)\n","Epoch: [111][330/391]\tTime  0.169 ( 0.170)\tLoss 1.3113e-01 (1.8433e-01)\tAcc@1  94.53 ( 94.93)\tAcc@5 100.00 ( 99.25)\n","Epoch: [111][360/391]\tTime  0.169 ( 0.170)\tLoss 1.8966e-01 (1.8492e-01)\tAcc@1  94.53 ( 94.93)\tAcc@5  98.44 ( 99.25)\n","Epoch: [111][390/391]\tTime  0.153 ( 0.169)\tLoss 2.3656e-01 (1.8483e-01)\tAcc@1  93.75 ( 94.91)\tAcc@5 100.00 ( 99.26)\n","==> Train Accuracy: Acc@1 94.906 || Acc@5 99.264\n","==> Test Accuracy:  Acc@1 77.750 || Acc@5 94.320\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 112, lr: 0.004000000000000001 -----\n","Epoch: [112][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.0972e-01 (2.0972e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n","Epoch: [112][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.7609e-01 (1.6883e-01)\tAcc@1  96.09 ( 95.82)\tAcc@5  99.22 ( 99.29)\n","Epoch: [112][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.1485e-01 (1.7533e-01)\tAcc@1  93.75 ( 95.45)\tAcc@5  98.44 ( 99.24)\n","Epoch: [112][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.4036e-01 (1.8248e-01)\tAcc@1  96.88 ( 95.18)\tAcc@5  99.22 ( 99.20)\n","Epoch: [112][120/391]\tTime  0.171 ( 0.170)\tLoss 1.8978e-01 (1.8122e-01)\tAcc@1  94.53 ( 95.18)\tAcc@5  99.22 ( 99.21)\n","Epoch: [112][150/391]\tTime  0.169 ( 0.170)\tLoss 2.3639e-01 (1.8221e-01)\tAcc@1  92.19 ( 95.12)\tAcc@5 100.00 ( 99.19)\n","Epoch: [112][180/391]\tTime  0.171 ( 0.170)\tLoss 1.4267e-01 (1.8327e-01)\tAcc@1  95.31 ( 95.04)\tAcc@5  99.22 ( 99.22)\n","Epoch: [112][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3993e-01 (1.8376e-01)\tAcc@1  94.53 ( 95.02)\tAcc@5 100.00 ( 99.23)\n","Epoch: [112][240/391]\tTime  0.168 ( 0.170)\tLoss 1.9304e-01 (1.8465e-01)\tAcc@1  95.31 ( 94.99)\tAcc@5 100.00 ( 99.24)\n","Epoch: [112][270/391]\tTime  0.170 ( 0.170)\tLoss 1.9669e-01 (1.8454e-01)\tAcc@1  94.53 ( 95.00)\tAcc@5  98.44 ( 99.25)\n","Epoch: [112][300/391]\tTime  0.169 ( 0.170)\tLoss 1.9674e-01 (1.8423e-01)\tAcc@1  92.97 ( 95.01)\tAcc@5 100.00 ( 99.26)\n","Epoch: [112][330/391]\tTime  0.169 ( 0.169)\tLoss 1.2078e-01 (1.8362e-01)\tAcc@1  96.88 ( 95.03)\tAcc@5 100.00 ( 99.27)\n","Epoch: [112][360/391]\tTime  0.169 ( 0.169)\tLoss 2.4988e-01 (1.8337e-01)\tAcc@1  93.75 ( 95.04)\tAcc@5  98.44 ( 99.27)\n","Epoch: [112][390/391]\tTime  0.153 ( 0.169)\tLoss 2.8670e-01 (1.8457e-01)\tAcc@1  92.50 ( 95.02)\tAcc@5  98.75 ( 99.25)\n","==> Train Accuracy: Acc@1 95.016 || Acc@5 99.246\n","==> Test Accuracy:  Acc@1 77.470 || Acc@5 94.370\n","==> 70.43 seconds to train this epoch\n","\n","\n","----- epoch: 113, lr: 0.004000000000000001 -----\n","Epoch: [113][  0/391]\tTime  0.292 ( 0.292)\tLoss 9.4419e-02 (9.4419e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [113][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.5562e-01 (1.6819e-01)\tAcc@1  94.53 ( 95.39)\tAcc@5 100.00 ( 99.34)\n","Epoch: [113][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.8656e-01 (1.6506e-01)\tAcc@1  96.88 ( 95.57)\tAcc@5  99.22 ( 99.37)\n","Epoch: [113][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.7130e-01 (1.7026e-01)\tAcc@1  94.53 ( 95.42)\tAcc@5  99.22 ( 99.30)\n","Epoch: [113][120/391]\tTime  0.169 ( 0.170)\tLoss 2.5680e-01 (1.7195e-01)\tAcc@1  92.19 ( 95.41)\tAcc@5  98.44 ( 99.25)\n","Epoch: [113][150/391]\tTime  0.170 ( 0.170)\tLoss 2.1095e-01 (1.7203e-01)\tAcc@1  95.31 ( 95.36)\tAcc@5  98.44 ( 99.27)\n","Epoch: [113][180/391]\tTime  0.169 ( 0.170)\tLoss 1.8690e-01 (1.7368e-01)\tAcc@1  92.97 ( 95.30)\tAcc@5 100.00 ( 99.27)\n","Epoch: [113][210/391]\tTime  0.168 ( 0.170)\tLoss 1.7679e-01 (1.7514e-01)\tAcc@1  94.53 ( 95.25)\tAcc@5  98.44 ( 99.28)\n","Epoch: [113][240/391]\tTime  0.170 ( 0.170)\tLoss 2.1492e-01 (1.7428e-01)\tAcc@1  96.09 ( 95.26)\tAcc@5  97.66 ( 99.29)\n","Epoch: [113][270/391]\tTime  0.170 ( 0.170)\tLoss 2.3557e-01 (1.7517e-01)\tAcc@1  96.09 ( 95.25)\tAcc@5  98.44 ( 99.26)\n","Epoch: [113][300/391]\tTime  0.171 ( 0.170)\tLoss 1.4170e-01 (1.7685e-01)\tAcc@1  96.88 ( 95.23)\tAcc@5 100.00 ( 99.23)\n","Epoch: [113][330/391]\tTime  0.168 ( 0.170)\tLoss 2.1205e-01 (1.7700e-01)\tAcc@1  95.31 ( 95.25)\tAcc@5  99.22 ( 99.24)\n","Epoch: [113][360/391]\tTime  0.169 ( 0.169)\tLoss 1.5312e-01 (1.7785e-01)\tAcc@1  96.88 ( 95.24)\tAcc@5 100.00 ( 99.24)\n","Epoch: [113][390/391]\tTime  0.152 ( 0.169)\tLoss 1.4835e-01 (1.7741e-01)\tAcc@1  96.25 ( 95.25)\tAcc@5 100.00 ( 99.24)\n","==> Train Accuracy: Acc@1 95.254 || Acc@5 99.244\n","==> Test Accuracy:  Acc@1 77.500 || Acc@5 94.140\n","==> 70.45 seconds to train this epoch\n","\n","\n","----- epoch: 114, lr: 0.004000000000000001 -----\n","Epoch: [114][  0/391]\tTime  0.266 ( 0.266)\tLoss 2.2838e-01 (2.2838e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  98.44 ( 98.44)\n","Epoch: [114][ 30/391]\tTime  0.171 ( 0.172)\tLoss 1.7156e-01 (1.6872e-01)\tAcc@1  93.75 ( 95.61)\tAcc@5  99.22 ( 99.19)\n","Epoch: [114][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.2365e-01 (1.6703e-01)\tAcc@1  96.88 ( 95.67)\tAcc@5  99.22 ( 99.32)\n","Epoch: [114][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.7206e-01 (1.6219e-01)\tAcc@1  96.09 ( 95.70)\tAcc@5  99.22 ( 99.39)\n","Epoch: [114][120/391]\tTime  0.169 ( 0.170)\tLoss 1.1828e-01 (1.6353e-01)\tAcc@1  96.09 ( 95.64)\tAcc@5 100.00 ( 99.39)\n","Epoch: [114][150/391]\tTime  0.168 ( 0.170)\tLoss 1.4219e-01 (1.7116e-01)\tAcc@1  96.09 ( 95.43)\tAcc@5 100.00 ( 99.35)\n","Epoch: [114][180/391]\tTime  0.168 ( 0.170)\tLoss 2.1854e-01 (1.6953e-01)\tAcc@1  92.19 ( 95.39)\tAcc@5  98.44 ( 99.38)\n","Epoch: [114][210/391]\tTime  0.169 ( 0.170)\tLoss 1.5593e-01 (1.7303e-01)\tAcc@1  96.88 ( 95.25)\tAcc@5 100.00 ( 99.34)\n","Epoch: [114][240/391]\tTime  0.168 ( 0.170)\tLoss 1.8004e-01 (1.7428e-01)\tAcc@1  95.31 ( 95.25)\tAcc@5 100.00 ( 99.32)\n","Epoch: [114][270/391]\tTime  0.170 ( 0.170)\tLoss 2.2241e-01 (1.7309e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  97.66 ( 99.33)\n","Epoch: [114][300/391]\tTime  0.170 ( 0.170)\tLoss 1.0772e-01 (1.7288e-01)\tAcc@1  95.31 ( 95.32)\tAcc@5  99.22 ( 99.32)\n","Epoch: [114][330/391]\tTime  0.169 ( 0.170)\tLoss 1.4544e-01 (1.7486e-01)\tAcc@1  96.88 ( 95.29)\tAcc@5  98.44 ( 99.30)\n","Epoch: [114][360/391]\tTime  0.169 ( 0.170)\tLoss 1.5200e-01 (1.7586e-01)\tAcc@1  94.53 ( 95.27)\tAcc@5 100.00 ( 99.30)\n","Epoch: [114][390/391]\tTime  0.152 ( 0.169)\tLoss 1.3701e-01 (1.7597e-01)\tAcc@1  97.50 ( 95.29)\tAcc@5  98.75 ( 99.30)\n","==> Train Accuracy: Acc@1 95.288 || Acc@5 99.296\n","==> Test Accuracy:  Acc@1 77.430 || Acc@5 94.190\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 115, lr: 0.004000000000000001 -----\n","Epoch: [115][  0/391]\tTime  0.288 ( 0.288)\tLoss 2.1032e-01 (2.1032e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  99.22 ( 99.22)\n","Epoch: [115][ 30/391]\tTime  0.168 ( 0.172)\tLoss 2.5900e-01 (1.6134e-01)\tAcc@1  92.19 ( 95.59)\tAcc@5  97.66 ( 99.27)\n","Epoch: [115][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.6528e-01 (1.6556e-01)\tAcc@1  96.88 ( 95.56)\tAcc@5  99.22 ( 99.27)\n","Epoch: [115][ 90/391]\tTime  0.169 ( 0.170)\tLoss 2.0937e-01 (1.6721e-01)\tAcc@1  93.75 ( 95.54)\tAcc@5  98.44 ( 99.29)\n","Epoch: [115][120/391]\tTime  0.170 ( 0.170)\tLoss 1.8928e-01 (1.6917e-01)\tAcc@1  92.97 ( 95.47)\tAcc@5  99.22 ( 99.32)\n","Epoch: [115][150/391]\tTime  0.169 ( 0.170)\tLoss 1.0147e-01 (1.6986e-01)\tAcc@1  96.88 ( 95.46)\tAcc@5  99.22 ( 99.30)\n","Epoch: [115][180/391]\tTime  0.169 ( 0.170)\tLoss 1.9278e-01 (1.7324e-01)\tAcc@1  96.09 ( 95.39)\tAcc@5  99.22 ( 99.25)\n","Epoch: [115][210/391]\tTime  0.172 ( 0.170)\tLoss 1.7711e-01 (1.7533e-01)\tAcc@1  95.31 ( 95.29)\tAcc@5  99.22 ( 99.26)\n","Epoch: [115][240/391]\tTime  0.168 ( 0.170)\tLoss 4.1842e-01 (1.7567e-01)\tAcc@1  88.28 ( 95.25)\tAcc@5  96.88 ( 99.28)\n","Epoch: [115][270/391]\tTime  0.170 ( 0.170)\tLoss 1.4786e-01 (1.7682e-01)\tAcc@1  96.09 ( 95.23)\tAcc@5 100.00 ( 99.27)\n","Epoch: [115][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4204e-01 (1.7515e-01)\tAcc@1  95.31 ( 95.29)\tAcc@5 100.00 ( 99.27)\n","Epoch: [115][330/391]\tTime  0.170 ( 0.170)\tLoss 1.9241e-01 (1.7551e-01)\tAcc@1  94.53 ( 95.27)\tAcc@5  98.44 ( 99.25)\n","Epoch: [115][360/391]\tTime  0.169 ( 0.170)\tLoss 2.0245e-01 (1.7736e-01)\tAcc@1  95.31 ( 95.25)\tAcc@5  98.44 ( 99.23)\n","Epoch: [115][390/391]\tTime  0.150 ( 0.169)\tLoss 1.2495e-01 (1.7718e-01)\tAcc@1  95.00 ( 95.25)\tAcc@5 100.00 ( 99.23)\n","==> Train Accuracy: Acc@1 95.252 || Acc@5 99.230\n","==> Test Accuracy:  Acc@1 77.730 || Acc@5 94.130\n","==> 70.46 seconds to train this epoch\n","\n","\n","----- epoch: 116, lr: 0.004000000000000001 -----\n","Epoch: [116][  0/391]\tTime  0.308 ( 0.308)\tLoss 1.9914e-01 (1.9914e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  98.44 ( 98.44)\n","Epoch: [116][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3353e-01 (1.5698e-01)\tAcc@1  96.88 ( 95.92)\tAcc@5 100.00 ( 99.32)\n","Epoch: [116][ 60/391]\tTime  0.169 ( 0.171)\tLoss 2.1264e-01 (1.6302e-01)\tAcc@1  94.53 ( 95.65)\tAcc@5  98.44 ( 99.30)\n","Epoch: [116][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.9641e-01 (1.6992e-01)\tAcc@1  94.53 ( 95.51)\tAcc@5  97.66 ( 99.21)\n","Epoch: [116][120/391]\tTime  0.170 ( 0.170)\tLoss 1.3523e-01 (1.6859e-01)\tAcc@1  96.88 ( 95.49)\tAcc@5 100.00 ( 99.26)\n","Epoch: [116][150/391]\tTime  0.170 ( 0.170)\tLoss 1.2915e-01 (1.6892e-01)\tAcc@1  96.09 ( 95.45)\tAcc@5  99.22 ( 99.28)\n","Epoch: [116][180/391]\tTime  0.171 ( 0.170)\tLoss 2.0868e-01 (1.7378e-01)\tAcc@1  95.31 ( 95.28)\tAcc@5  99.22 ( 99.25)\n","Epoch: [116][210/391]\tTime  0.169 ( 0.170)\tLoss 1.8669e-01 (1.7382e-01)\tAcc@1  96.09 ( 95.29)\tAcc@5 100.00 ( 99.25)\n","Epoch: [116][240/391]\tTime  0.168 ( 0.170)\tLoss 1.4066e-01 (1.7290e-01)\tAcc@1  96.88 ( 95.34)\tAcc@5  99.22 ( 99.25)\n","Epoch: [116][270/391]\tTime  0.169 ( 0.170)\tLoss 2.3611e-01 (1.7406e-01)\tAcc@1  93.75 ( 95.28)\tAcc@5  98.44 ( 99.25)\n","Epoch: [116][300/391]\tTime  0.169 ( 0.170)\tLoss 2.7246e-01 (1.7583e-01)\tAcc@1  93.75 ( 95.21)\tAcc@5  99.22 ( 99.24)\n","Epoch: [116][330/391]\tTime  0.168 ( 0.170)\tLoss 1.5116e-01 (1.7457e-01)\tAcc@1  95.31 ( 95.23)\tAcc@5  99.22 ( 99.25)\n","Epoch: [116][360/391]\tTime  0.168 ( 0.170)\tLoss 2.1499e-01 (1.7553e-01)\tAcc@1  93.75 ( 95.21)\tAcc@5 100.00 ( 99.25)\n","Epoch: [116][390/391]\tTime  0.152 ( 0.169)\tLoss 1.3639e-01 (1.7676e-01)\tAcc@1  96.25 ( 95.18)\tAcc@5 100.00 ( 99.25)\n","==> Train Accuracy: Acc@1 95.184 || Acc@5 99.250\n","==> Test Accuracy:  Acc@1 77.340 || Acc@5 94.050\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 117, lr: 0.004000000000000001 -----\n","Epoch: [117][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.1851e-01 (1.1851e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [117][ 30/391]\tTime  0.170 ( 0.172)\tLoss 1.7476e-01 (1.8398e-01)\tAcc@1  96.09 ( 95.01)\tAcc@5  99.22 ( 99.19)\n","Epoch: [117][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.2291e-01 (1.7432e-01)\tAcc@1  96.88 ( 95.36)\tAcc@5 100.00 ( 99.24)\n","Epoch: [117][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.3927e-01 (1.7047e-01)\tAcc@1  96.09 ( 95.48)\tAcc@5 100.00 ( 99.29)\n","Epoch: [117][120/391]\tTime  0.170 ( 0.170)\tLoss 2.1718e-01 (1.7175e-01)\tAcc@1  96.09 ( 95.43)\tAcc@5  97.66 ( 99.24)\n","Epoch: [117][150/391]\tTime  0.170 ( 0.170)\tLoss 1.2774e-01 (1.7256e-01)\tAcc@1  96.88 ( 95.39)\tAcc@5 100.00 ( 99.27)\n","Epoch: [117][180/391]\tTime  0.170 ( 0.170)\tLoss 2.2228e-01 (1.7552e-01)\tAcc@1  93.75 ( 95.28)\tAcc@5  98.44 ( 99.23)\n","Epoch: [117][210/391]\tTime  0.170 ( 0.170)\tLoss 2.2628e-01 (1.7737e-01)\tAcc@1  92.97 ( 95.25)\tAcc@5 100.00 ( 99.21)\n","Epoch: [117][240/391]\tTime  0.170 ( 0.170)\tLoss 2.6156e-01 (1.7695e-01)\tAcc@1  92.19 ( 95.24)\tAcc@5  99.22 ( 99.23)\n","Epoch: [117][270/391]\tTime  0.170 ( 0.170)\tLoss 2.9696e-01 (1.7711e-01)\tAcc@1  90.62 ( 95.22)\tAcc@5  99.22 ( 99.24)\n","Epoch: [117][300/391]\tTime  0.170 ( 0.170)\tLoss 1.6107e-01 (1.7665e-01)\tAcc@1  96.09 ( 95.24)\tAcc@5  99.22 ( 99.23)\n","Epoch: [117][330/391]\tTime  0.169 ( 0.170)\tLoss 1.2536e-01 (1.7911e-01)\tAcc@1  97.66 ( 95.15)\tAcc@5  99.22 ( 99.23)\n","Epoch: [117][360/391]\tTime  0.169 ( 0.169)\tLoss 1.7781e-01 (1.7850e-01)\tAcc@1  94.53 ( 95.17)\tAcc@5  99.22 ( 99.24)\n","Epoch: [117][390/391]\tTime  0.151 ( 0.169)\tLoss 3.1041e-01 (1.7917e-01)\tAcc@1  90.00 ( 95.15)\tAcc@5  96.25 ( 99.23)\n","==> Train Accuracy: Acc@1 95.152 || Acc@5 99.232\n","==> Test Accuracy:  Acc@1 77.370 || Acc@5 94.210\n","==> 70.44 seconds to train this epoch\n","\n","\n","----- epoch: 118, lr: 0.004000000000000001 -----\n","Epoch: [118][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.3137e-01 (1.3137e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [118][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.2254e-01 (1.7263e-01)\tAcc@1  96.88 ( 95.19)\tAcc@5  99.22 ( 99.34)\n","Epoch: [118][ 60/391]\tTime  0.170 ( 0.171)\tLoss 9.3669e-02 (1.7414e-01)\tAcc@1  96.88 ( 95.33)\tAcc@5 100.00 ( 99.37)\n","Epoch: [118][ 90/391]\tTime  0.170 ( 0.170)\tLoss 9.2883e-02 (1.7663e-01)\tAcc@1  96.88 ( 95.24)\tAcc@5 100.00 ( 99.29)\n","Epoch: [118][120/391]\tTime  0.168 ( 0.170)\tLoss 2.1669e-01 (1.7924e-01)\tAcc@1  96.88 ( 95.24)\tAcc@5 100.00 ( 99.26)\n","Epoch: [118][150/391]\tTime  0.168 ( 0.170)\tLoss 1.4885e-01 (1.7558e-01)\tAcc@1  97.66 ( 95.42)\tAcc@5 100.00 ( 99.27)\n","Epoch: [118][180/391]\tTime  0.168 ( 0.170)\tLoss 1.7006e-01 (1.7556e-01)\tAcc@1  96.09 ( 95.41)\tAcc@5  99.22 ( 99.29)\n","Epoch: [118][210/391]\tTime  0.170 ( 0.170)\tLoss 2.1916e-01 (1.7516e-01)\tAcc@1  93.75 ( 95.43)\tAcc@5  99.22 ( 99.30)\n","Epoch: [118][240/391]\tTime  0.169 ( 0.169)\tLoss 2.2333e-01 (1.7592e-01)\tAcc@1  93.75 ( 95.42)\tAcc@5 100.00 ( 99.30)\n","Epoch: [118][270/391]\tTime  0.168 ( 0.169)\tLoss 1.7235e-01 (1.7509e-01)\tAcc@1  96.09 ( 95.41)\tAcc@5  99.22 ( 99.32)\n","Epoch: [118][300/391]\tTime  0.170 ( 0.169)\tLoss 1.9274e-01 (1.7468e-01)\tAcc@1  92.97 ( 95.37)\tAcc@5  99.22 ( 99.32)\n","Epoch: [118][330/391]\tTime  0.171 ( 0.169)\tLoss 1.5628e-01 (1.7542e-01)\tAcc@1  95.31 ( 95.33)\tAcc@5 100.00 ( 99.32)\n","Epoch: [118][360/391]\tTime  0.170 ( 0.169)\tLoss 1.7827e-01 (1.7484e-01)\tAcc@1  95.31 ( 95.30)\tAcc@5  99.22 ( 99.33)\n","Epoch: [118][390/391]\tTime  0.155 ( 0.169)\tLoss 2.3057e-01 (1.7463e-01)\tAcc@1  93.75 ( 95.31)\tAcc@5  97.50 ( 99.32)\n","==> Train Accuracy: Acc@1 95.308 || Acc@5 99.324\n","==> Test Accuracy:  Acc@1 77.530 || Acc@5 94.220\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 119, lr: 0.004000000000000001 -----\n","Epoch: [119][  0/391]\tTime  0.289 ( 0.289)\tLoss 2.6023e-01 (2.6023e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n","Epoch: [119][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.2320e-01 (1.7372e-01)\tAcc@1  94.53 ( 95.46)\tAcc@5  98.44 ( 99.17)\n","Epoch: [119][ 60/391]\tTime  0.171 ( 0.171)\tLoss 2.0153e-01 (1.7368e-01)\tAcc@1  94.53 ( 95.15)\tAcc@5  98.44 ( 99.21)\n","Epoch: [119][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.6692e-01 (1.7878e-01)\tAcc@1  94.53 ( 95.06)\tAcc@5 100.00 ( 99.18)\n","Epoch: [119][120/391]\tTime  0.169 ( 0.170)\tLoss 1.8787e-01 (1.7671e-01)\tAcc@1  94.53 ( 95.18)\tAcc@5  98.44 ( 99.24)\n","Epoch: [119][150/391]\tTime  0.172 ( 0.170)\tLoss 1.2097e-01 (1.7627e-01)\tAcc@1  96.09 ( 95.21)\tAcc@5 100.00 ( 99.24)\n","Epoch: [119][180/391]\tTime  0.170 ( 0.170)\tLoss 1.7667e-01 (1.7445e-01)\tAcc@1  93.75 ( 95.32)\tAcc@5 100.00 ( 99.25)\n","Epoch: [119][210/391]\tTime  0.169 ( 0.170)\tLoss 1.4190e-01 (1.7394e-01)\tAcc@1  95.31 ( 95.35)\tAcc@5  99.22 ( 99.26)\n","Epoch: [119][240/391]\tTime  0.168 ( 0.170)\tLoss 1.7541e-01 (1.7403e-01)\tAcc@1  94.53 ( 95.35)\tAcc@5 100.00 ( 99.25)\n","Epoch: [119][270/391]\tTime  0.169 ( 0.170)\tLoss 2.1014e-01 (1.7382e-01)\tAcc@1  93.75 ( 95.34)\tAcc@5  99.22 ( 99.27)\n","Epoch: [119][300/391]\tTime  0.171 ( 0.170)\tLoss 1.6076e-01 (1.7373e-01)\tAcc@1  95.31 ( 95.35)\tAcc@5 100.00 ( 99.27)\n","Epoch: [119][330/391]\tTime  0.167 ( 0.170)\tLoss 2.2002e-01 (1.7389e-01)\tAcc@1  93.75 ( 95.35)\tAcc@5  98.44 ( 99.27)\n","Epoch: [119][360/391]\tTime  0.170 ( 0.170)\tLoss 1.6725e-01 (1.7394e-01)\tAcc@1  93.75 ( 95.34)\tAcc@5 100.00 ( 99.26)\n","Epoch: [119][390/391]\tTime  0.153 ( 0.170)\tLoss 2.6811e-01 (1.7445e-01)\tAcc@1  92.50 ( 95.35)\tAcc@5 100.00 ( 99.25)\n","==> Train Accuracy: Acc@1 95.350 || Acc@5 99.250\n","==> Test Accuracy:  Acc@1 77.590 || Acc@5 94.290\n","==> 70.52 seconds to train this epoch\n","\n","\n","----- epoch: 120, lr: 0.0008000000000000003 -----\n","Epoch: [120][  0/391]\tTime  0.292 ( 0.292)\tLoss 8.0647e-02 (8.0647e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [120][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.3921e-01 (1.6363e-01)\tAcc@1  96.88 ( 95.74)\tAcc@5 100.00 ( 99.42)\n","Epoch: [120][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.5022e-01 (1.5379e-01)\tAcc@1  96.88 ( 96.04)\tAcc@5 100.00 ( 99.47)\n","Epoch: [120][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.1603e-01 (1.5423e-01)\tAcc@1  96.88 ( 95.78)\tAcc@5 100.00 ( 99.40)\n","Epoch: [120][120/391]\tTime  0.167 ( 0.170)\tLoss 2.2963e-01 (1.5165e-01)\tAcc@1  93.75 ( 95.93)\tAcc@5  98.44 ( 99.38)\n","Epoch: [120][150/391]\tTime  0.169 ( 0.170)\tLoss 1.5631e-01 (1.5267e-01)\tAcc@1  94.53 ( 95.90)\tAcc@5 100.00 ( 99.36)\n","Epoch: [120][180/391]\tTime  0.169 ( 0.170)\tLoss 1.2831e-01 (1.5305e-01)\tAcc@1  96.88 ( 95.86)\tAcc@5  99.22 ( 99.39)\n","Epoch: [120][210/391]\tTime  0.169 ( 0.169)\tLoss 1.2157e-01 (1.5184e-01)\tAcc@1  96.88 ( 95.89)\tAcc@5 100.00 ( 99.41)\n","Epoch: [120][240/391]\tTime  0.168 ( 0.169)\tLoss 2.7862e-01 (1.4967e-01)\tAcc@1  92.97 ( 95.98)\tAcc@5  98.44 ( 99.42)\n","Epoch: [120][270/391]\tTime  0.168 ( 0.169)\tLoss 1.2995e-01 (1.4883e-01)\tAcc@1  96.09 ( 95.98)\tAcc@5 100.00 ( 99.43)\n","Epoch: [120][300/391]\tTime  0.168 ( 0.169)\tLoss 1.7458e-01 (1.4750e-01)\tAcc@1  94.53 ( 96.03)\tAcc@5  98.44 ( 99.44)\n","Epoch: [120][330/391]\tTime  0.170 ( 0.169)\tLoss 9.0289e-02 (1.4642e-01)\tAcc@1  96.09 ( 96.03)\tAcc@5 100.00 ( 99.45)\n","Epoch: [120][360/391]\tTime  0.169 ( 0.169)\tLoss 5.4949e-02 (1.4549e-01)\tAcc@1  99.22 ( 96.07)\tAcc@5 100.00 ( 99.46)\n","Epoch: [120][390/391]\tTime  0.152 ( 0.169)\tLoss 1.3716e-01 (1.4344e-01)\tAcc@1  97.50 ( 96.15)\tAcc@5 100.00 ( 99.47)\n","==> Train Accuracy: Acc@1 96.150 || Acc@5 99.472\n","==> Test Accuracy:  Acc@1 78.290 || Acc@5 94.660\n","==> 70.32 seconds to train this epoch\n","\n","\n","----- epoch: 121, lr: 0.0008000000000000003 -----\n","Epoch: [121][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.3546e-01 (1.3546e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [121][ 30/391]\tTime  0.167 ( 0.172)\tLoss 1.3357e-01 (1.3694e-01)\tAcc@1  95.31 ( 96.30)\tAcc@5  99.22 ( 99.42)\n","Epoch: [121][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.6125e-02 (1.3957e-01)\tAcc@1 100.00 ( 96.20)\tAcc@5 100.00 ( 99.51)\n","Epoch: [121][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.7624e-01 (1.3502e-01)\tAcc@1  95.31 ( 96.31)\tAcc@5  99.22 ( 99.54)\n","Epoch: [121][120/391]\tTime  0.170 ( 0.170)\tLoss 1.8243e-01 (1.3444e-01)\tAcc@1  94.53 ( 96.36)\tAcc@5  99.22 ( 99.56)\n","Epoch: [121][150/391]\tTime  0.168 ( 0.170)\tLoss 2.0048e-01 (1.3448e-01)\tAcc@1  94.53 ( 96.38)\tAcc@5  99.22 ( 99.55)\n","Epoch: [121][180/391]\tTime  0.169 ( 0.169)\tLoss 1.2692e-01 (1.3587e-01)\tAcc@1  95.31 ( 96.33)\tAcc@5 100.00 ( 99.54)\n","Epoch: [121][210/391]\tTime  0.169 ( 0.169)\tLoss 1.1863e-01 (1.3557e-01)\tAcc@1  97.66 ( 96.33)\tAcc@5 100.00 ( 99.54)\n","Epoch: [121][240/391]\tTime  0.170 ( 0.169)\tLoss 1.7715e-01 (1.3459e-01)\tAcc@1  96.09 ( 96.35)\tAcc@5 100.00 ( 99.54)\n","Epoch: [121][270/391]\tTime  0.170 ( 0.169)\tLoss 1.4868e-01 (1.3428e-01)\tAcc@1  95.31 ( 96.34)\tAcc@5  99.22 ( 99.54)\n","Epoch: [121][300/391]\tTime  0.169 ( 0.169)\tLoss 2.1648e-01 (1.3565e-01)\tAcc@1  94.53 ( 96.32)\tAcc@5  97.66 ( 99.52)\n","Epoch: [121][330/391]\tTime  0.170 ( 0.169)\tLoss 1.7573e-01 (1.3453e-01)\tAcc@1  95.31 ( 96.35)\tAcc@5 100.00 ( 99.53)\n","Epoch: [121][360/391]\tTime  0.168 ( 0.169)\tLoss 1.7559e-01 (1.3489e-01)\tAcc@1  96.88 ( 96.35)\tAcc@5  98.44 ( 99.52)\n","Epoch: [121][390/391]\tTime  0.152 ( 0.169)\tLoss 1.4851e-01 (1.3598e-01)\tAcc@1  95.00 ( 96.32)\tAcc@5 100.00 ( 99.51)\n","==> Train Accuracy: Acc@1 96.320 || Acc@5 99.514\n","==> Test Accuracy:  Acc@1 78.510 || Acc@5 94.700\n","==> 70.40 seconds to train this epoch\n","\n","\n","----- epoch: 122, lr: 0.0008000000000000003 -----\n","Epoch: [122][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.5587e-01 (1.5587e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n","Epoch: [122][ 30/391]\tTime  0.172 ( 0.172)\tLoss 1.2659e-01 (1.2629e-01)\tAcc@1  96.88 ( 96.72)\tAcc@5 100.00 ( 99.62)\n","Epoch: [122][ 60/391]\tTime  0.172 ( 0.171)\tLoss 1.0439e-01 (1.2954e-01)\tAcc@1  97.66 ( 96.64)\tAcc@5 100.00 ( 99.56)\n","Epoch: [122][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.4292e-01 (1.3021e-01)\tAcc@1  95.31 ( 96.57)\tAcc@5  99.22 ( 99.56)\n","Epoch: [122][120/391]\tTime  0.167 ( 0.170)\tLoss 1.1773e-01 (1.3449e-01)\tAcc@1  97.66 ( 96.47)\tAcc@5 100.00 ( 99.51)\n","Epoch: [122][150/391]\tTime  0.170 ( 0.170)\tLoss 1.1940e-01 (1.3622e-01)\tAcc@1  96.88 ( 96.45)\tAcc@5  99.22 ( 99.47)\n","Epoch: [122][180/391]\tTime  0.172 ( 0.170)\tLoss 9.9993e-02 (1.3622e-01)\tAcc@1  97.66 ( 96.44)\tAcc@5 100.00 ( 99.46)\n","Epoch: [122][210/391]\tTime  0.169 ( 0.170)\tLoss 9.3582e-02 (1.3555e-01)\tAcc@1  98.44 ( 96.43)\tAcc@5 100.00 ( 99.49)\n","Epoch: [122][240/391]\tTime  0.168 ( 0.170)\tLoss 1.6122e-01 (1.3551e-01)\tAcc@1  94.53 ( 96.47)\tAcc@5  99.22 ( 99.46)\n","Epoch: [122][270/391]\tTime  0.169 ( 0.170)\tLoss 1.9764e-01 (1.3414e-01)\tAcc@1  94.53 ( 96.51)\tAcc@5 100.00 ( 99.46)\n","Epoch: [122][300/391]\tTime  0.170 ( 0.170)\tLoss 6.8256e-02 (1.3384e-01)\tAcc@1  99.22 ( 96.49)\tAcc@5 100.00 ( 99.47)\n","Epoch: [122][330/391]\tTime  0.170 ( 0.170)\tLoss 1.4442e-01 (1.3234e-01)\tAcc@1  96.88 ( 96.54)\tAcc@5  99.22 ( 99.48)\n","Epoch: [122][360/391]\tTime  0.169 ( 0.170)\tLoss 1.2930e-01 (1.3144e-01)\tAcc@1  96.88 ( 96.57)\tAcc@5 100.00 ( 99.48)\n","Epoch: [122][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3310e-01 (1.3211e-01)\tAcc@1  97.50 ( 96.54)\tAcc@5 100.00 ( 99.48)\n","==> Train Accuracy: Acc@1 96.540 || Acc@5 99.484\n","==> Test Accuracy:  Acc@1 78.560 || Acc@5 94.520\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 123, lr: 0.0008000000000000003 -----\n","Epoch: [123][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.5651e-01 (1.5651e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [123][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.3700e-01 (1.1811e-01)\tAcc@1  96.09 ( 96.75)\tAcc@5 100.00 ( 99.72)\n","Epoch: [123][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.5621e-01 (1.2133e-01)\tAcc@1  94.53 ( 96.75)\tAcc@5 100.00 ( 99.68)\n","Epoch: [123][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.5760e-01 (1.2593e-01)\tAcc@1  96.88 ( 96.72)\tAcc@5 100.00 ( 99.55)\n","Epoch: [123][120/391]\tTime  0.169 ( 0.170)\tLoss 8.8141e-02 (1.2885e-01)\tAcc@1  97.66 ( 96.66)\tAcc@5  99.22 ( 99.48)\n","Epoch: [123][150/391]\tTime  0.170 ( 0.170)\tLoss 6.8478e-02 (1.2733e-01)\tAcc@1  97.66 ( 96.66)\tAcc@5 100.00 ( 99.51)\n","Epoch: [123][180/391]\tTime  0.168 ( 0.170)\tLoss 1.2555e-01 (1.2605e-01)\tAcc@1  96.88 ( 96.68)\tAcc@5  99.22 ( 99.55)\n","Epoch: [123][210/391]\tTime  0.168 ( 0.170)\tLoss 9.5758e-02 (1.2671e-01)\tAcc@1  97.66 ( 96.65)\tAcc@5 100.00 ( 99.53)\n","Epoch: [123][240/391]\tTime  0.172 ( 0.170)\tLoss 1.7748e-01 (1.2633e-01)\tAcc@1  94.53 ( 96.65)\tAcc@5 100.00 ( 99.52)\n","Epoch: [123][270/391]\tTime  0.168 ( 0.170)\tLoss 1.7918e-01 (1.2728e-01)\tAcc@1  96.09 ( 96.63)\tAcc@5  99.22 ( 99.52)\n","Epoch: [123][300/391]\tTime  0.167 ( 0.170)\tLoss 1.9269e-01 (1.2794e-01)\tAcc@1  94.53 ( 96.60)\tAcc@5  99.22 ( 99.51)\n","Epoch: [123][330/391]\tTime  0.169 ( 0.170)\tLoss 2.4979e-02 (1.2741e-01)\tAcc@1  99.22 ( 96.60)\tAcc@5 100.00 ( 99.52)\n","Epoch: [123][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3511e-01 (1.2822e-01)\tAcc@1  96.88 ( 96.59)\tAcc@5 100.00 ( 99.52)\n","Epoch: [123][390/391]\tTime  0.153 ( 0.170)\tLoss 8.4031e-02 (1.2738e-01)\tAcc@1  97.50 ( 96.61)\tAcc@5 100.00 ( 99.53)\n","==> Train Accuracy: Acc@1 96.614 || Acc@5 99.530\n","==> Test Accuracy:  Acc@1 78.530 || Acc@5 94.670\n","==> 70.53 seconds to train this epoch\n","\n","\n","----- epoch: 124, lr: 0.0008000000000000003 -----\n","Epoch: [124][  0/391]\tTime  0.283 ( 0.283)\tLoss 7.7580e-02 (7.7580e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [124][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.1962e-01 (1.2091e-01)\tAcc@1  98.44 ( 97.13)\tAcc@5  98.44 ( 99.40)\n","Epoch: [124][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.4873e-01 (1.1560e-01)\tAcc@1  94.53 ( 97.09)\tAcc@5 100.00 ( 99.56)\n","Epoch: [124][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.3142e-01 (1.1851e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.56)\n","Epoch: [124][120/391]\tTime  0.167 ( 0.170)\tLoss 1.3730e-01 (1.2275e-01)\tAcc@1  96.88 ( 96.78)\tAcc@5  99.22 ( 99.50)\n","Epoch: [124][150/391]\tTime  0.170 ( 0.170)\tLoss 1.6836e-01 (1.2404e-01)\tAcc@1  95.31 ( 96.75)\tAcc@5  99.22 ( 99.48)\n","Epoch: [124][180/391]\tTime  0.170 ( 0.170)\tLoss 1.8774e-01 (1.2378e-01)\tAcc@1  94.53 ( 96.73)\tAcc@5  99.22 ( 99.49)\n","Epoch: [124][210/391]\tTime  0.168 ( 0.170)\tLoss 2.0878e-01 (1.2595e-01)\tAcc@1  94.53 ( 96.69)\tAcc@5  97.66 ( 99.48)\n","Epoch: [124][240/391]\tTime  0.170 ( 0.170)\tLoss 1.2351e-01 (1.2436e-01)\tAcc@1  95.31 ( 96.71)\tAcc@5 100.00 ( 99.50)\n","Epoch: [124][270/391]\tTime  0.169 ( 0.170)\tLoss 1.3769e-01 (1.2583e-01)\tAcc@1  97.66 ( 96.66)\tAcc@5  99.22 ( 99.51)\n","Epoch: [124][300/391]\tTime  0.170 ( 0.170)\tLoss 1.6310e-01 (1.2385e-01)\tAcc@1  96.88 ( 96.72)\tAcc@5  99.22 ( 99.53)\n","Epoch: [124][330/391]\tTime  0.169 ( 0.170)\tLoss 8.2833e-02 (1.2402e-01)\tAcc@1  97.66 ( 96.70)\tAcc@5 100.00 ( 99.53)\n","Epoch: [124][360/391]\tTime  0.170 ( 0.170)\tLoss 8.8070e-02 (1.2480e-01)\tAcc@1  97.66 ( 96.68)\tAcc@5 100.00 ( 99.53)\n","Epoch: [124][390/391]\tTime  0.153 ( 0.170)\tLoss 9.3388e-02 (1.2437e-01)\tAcc@1  98.75 ( 96.69)\tAcc@5 100.00 ( 99.54)\n","==> Train Accuracy: Acc@1 96.692 || Acc@5 99.538\n","==> Test Accuracy:  Acc@1 78.610 || Acc@5 94.600\n","==> 70.52 seconds to train this epoch\n","\n","\n","----- epoch: 125, lr: 0.0008000000000000003 -----\n","Epoch: [125][  0/391]\tTime  0.294 ( 0.294)\tLoss 9.8157e-02 (9.8157e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [125][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.6428e-01 (1.2781e-01)\tAcc@1  94.53 ( 96.24)\tAcc@5  99.22 ( 99.55)\n","Epoch: [125][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.9870e-02 (1.1732e-01)\tAcc@1  97.66 ( 96.70)\tAcc@5 100.00 ( 99.67)\n","Epoch: [125][ 90/391]\tTime  0.167 ( 0.170)\tLoss 6.6372e-02 (1.1754e-01)\tAcc@1  98.44 ( 96.81)\tAcc@5 100.00 ( 99.66)\n","Epoch: [125][120/391]\tTime  0.168 ( 0.170)\tLoss 1.2889e-01 (1.1588e-01)\tAcc@1  96.88 ( 96.91)\tAcc@5 100.00 ( 99.66)\n","Epoch: [125][150/391]\tTime  0.170 ( 0.170)\tLoss 7.8831e-02 (1.1905e-01)\tAcc@1  99.22 ( 96.83)\tAcc@5 100.00 ( 99.59)\n","Epoch: [125][180/391]\tTime  0.169 ( 0.170)\tLoss 5.8791e-02 (1.2097e-01)\tAcc@1  97.66 ( 96.81)\tAcc@5 100.00 ( 99.57)\n","Epoch: [125][210/391]\tTime  0.170 ( 0.170)\tLoss 8.8513e-02 (1.1914e-01)\tAcc@1  97.66 ( 96.85)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][240/391]\tTime  0.170 ( 0.170)\tLoss 8.5048e-02 (1.1911e-01)\tAcc@1  98.44 ( 96.81)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][270/391]\tTime  0.170 ( 0.170)\tLoss 1.0085e-01 (1.1903e-01)\tAcc@1  96.88 ( 96.81)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][300/391]\tTime  0.170 ( 0.170)\tLoss 8.3473e-02 (1.1877e-01)\tAcc@1  96.88 ( 96.82)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][330/391]\tTime  0.168 ( 0.170)\tLoss 1.0476e-01 (1.1922e-01)\tAcc@1  97.66 ( 96.81)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][360/391]\tTime  0.170 ( 0.170)\tLoss 7.4009e-02 (1.1936e-01)\tAcc@1  97.66 ( 96.82)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][390/391]\tTime  0.153 ( 0.169)\tLoss 1.7038e-01 (1.2007e-01)\tAcc@1  95.00 ( 96.78)\tAcc@5  98.75 ( 99.59)\n","==> Train Accuracy: Acc@1 96.784 || Acc@5 99.594\n","==> Test Accuracy:  Acc@1 78.380 || Acc@5 94.600\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 126, lr: 0.0008000000000000003 -----\n","Epoch: [126][  0/391]\tTime  0.289 ( 0.289)\tLoss 1.5435e-01 (1.5435e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n","Epoch: [126][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.3281e-01 (1.1817e-01)\tAcc@1  94.53 ( 96.80)\tAcc@5  99.22 ( 99.57)\n","Epoch: [126][ 60/391]\tTime  0.170 ( 0.171)\tLoss 7.4598e-02 (1.1051e-01)\tAcc@1  96.88 ( 97.04)\tAcc@5  99.22 ( 99.58)\n","Epoch: [126][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.3123e-01 (1.1324e-01)\tAcc@1  95.31 ( 97.00)\tAcc@5 100.00 ( 99.54)\n","Epoch: [126][120/391]\tTime  0.170 ( 0.170)\tLoss 9.7567e-02 (1.1486e-01)\tAcc@1  97.66 ( 96.97)\tAcc@5  99.22 ( 99.55)\n","Epoch: [126][150/391]\tTime  0.169 ( 0.170)\tLoss 8.2523e-02 (1.1583e-01)\tAcc@1  98.44 ( 96.98)\tAcc@5 100.00 ( 99.59)\n","Epoch: [126][180/391]\tTime  0.169 ( 0.170)\tLoss 1.2561e-01 (1.1983e-01)\tAcc@1  96.09 ( 96.88)\tAcc@5  99.22 ( 99.54)\n","Epoch: [126][210/391]\tTime  0.169 ( 0.170)\tLoss 1.2388e-01 (1.1863e-01)\tAcc@1  96.88 ( 96.92)\tAcc@5  99.22 ( 99.54)\n","Epoch: [126][240/391]\tTime  0.169 ( 0.170)\tLoss 1.0817e-01 (1.1817e-01)\tAcc@1  96.88 ( 96.98)\tAcc@5 100.00 ( 99.56)\n","Epoch: [126][270/391]\tTime  0.170 ( 0.170)\tLoss 1.1862e-01 (1.1913e-01)\tAcc@1  96.09 ( 96.95)\tAcc@5 100.00 ( 99.56)\n","Epoch: [126][300/391]\tTime  0.169 ( 0.170)\tLoss 1.6180e-01 (1.1983e-01)\tAcc@1  95.31 ( 96.95)\tAcc@5  99.22 ( 99.56)\n","Epoch: [126][330/391]\tTime  0.171 ( 0.170)\tLoss 1.2770e-01 (1.2022e-01)\tAcc@1  98.44 ( 96.95)\tAcc@5  99.22 ( 99.56)\n","Epoch: [126][360/391]\tTime  0.169 ( 0.169)\tLoss 1.3411e-01 (1.2030e-01)\tAcc@1  96.88 ( 96.93)\tAcc@5  99.22 ( 99.55)\n","Epoch: [126][390/391]\tTime  0.151 ( 0.169)\tLoss 1.1436e-01 (1.2076e-01)\tAcc@1  97.50 ( 96.92)\tAcc@5 100.00 ( 99.54)\n","==> Train Accuracy: Acc@1 96.916 || Acc@5 99.536\n","==> Test Accuracy:  Acc@1 78.510 || Acc@5 94.530\n","==> 70.46 seconds to train this epoch\n","\n","\n","----- epoch: 127, lr: 0.0008000000000000003 -----\n","Epoch: [127][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.1981e-01 (1.1981e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [127][ 30/391]\tTime  0.169 ( 0.173)\tLoss 2.1370e-01 (1.1516e-01)\tAcc@1  95.31 ( 96.85)\tAcc@5  98.44 ( 99.57)\n","Epoch: [127][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.0460e-01 (1.2163e-01)\tAcc@1  96.88 ( 96.70)\tAcc@5  99.22 ( 99.58)\n","Epoch: [127][ 90/391]\tTime  0.168 ( 0.170)\tLoss 1.1674e-01 (1.2450e-01)\tAcc@1  95.31 ( 96.61)\tAcc@5 100.00 ( 99.55)\n","Epoch: [127][120/391]\tTime  0.168 ( 0.170)\tLoss 1.1186e-01 (1.2595e-01)\tAcc@1  97.66 ( 96.65)\tAcc@5 100.00 ( 99.54)\n","Epoch: [127][150/391]\tTime  0.169 ( 0.170)\tLoss 1.0963e-01 (1.2440e-01)\tAcc@1  97.66 ( 96.70)\tAcc@5  99.22 ( 99.52)\n","Epoch: [127][180/391]\tTime  0.169 ( 0.170)\tLoss 9.9651e-02 (1.2448e-01)\tAcc@1  98.44 ( 96.76)\tAcc@5 100.00 ( 99.53)\n","Epoch: [127][210/391]\tTime  0.169 ( 0.170)\tLoss 1.6716e-01 (1.2474e-01)\tAcc@1  94.53 ( 96.75)\tAcc@5  99.22 ( 99.51)\n","Epoch: [127][240/391]\tTime  0.169 ( 0.170)\tLoss 1.0642e-01 (1.2234e-01)\tAcc@1  96.09 ( 96.81)\tAcc@5  99.22 ( 99.54)\n","Epoch: [127][270/391]\tTime  0.168 ( 0.170)\tLoss 1.7256e-01 (1.2179e-01)\tAcc@1  95.31 ( 96.85)\tAcc@5  99.22 ( 99.53)\n","Epoch: [127][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5443e-01 (1.2228e-01)\tAcc@1  94.53 ( 96.83)\tAcc@5 100.00 ( 99.53)\n","Epoch: [127][330/391]\tTime  0.170 ( 0.169)\tLoss 1.1371e-01 (1.2214e-01)\tAcc@1  96.88 ( 96.83)\tAcc@5 100.00 ( 99.54)\n","Epoch: [127][360/391]\tTime  0.169 ( 0.169)\tLoss 9.7949e-02 (1.2156e-01)\tAcc@1  97.66 ( 96.85)\tAcc@5 100.00 ( 99.55)\n","Epoch: [127][390/391]\tTime  0.152 ( 0.169)\tLoss 1.4190e-01 (1.2205e-01)\tAcc@1  96.25 ( 96.82)\tAcc@5  98.75 ( 99.53)\n","==> Train Accuracy: Acc@1 96.824 || Acc@5 99.534\n","==> Test Accuracy:  Acc@1 78.420 || Acc@5 94.580\n","==> 70.45 seconds to train this epoch\n","\n","\n","----- epoch: 128, lr: 0.0008000000000000003 -----\n","Epoch: [128][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.5807e-01 (1.5807e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [128][ 30/391]\tTime  0.172 ( 0.172)\tLoss 4.2974e-02 (1.1428e-01)\tAcc@1  99.22 ( 97.18)\tAcc@5 100.00 ( 99.57)\n","Epoch: [128][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.1513e-01 (1.2170e-01)\tAcc@1  96.09 ( 96.85)\tAcc@5 100.00 ( 99.56)\n","Epoch: [128][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.2062e-01 (1.2190e-01)\tAcc@1  97.66 ( 96.79)\tAcc@5 100.00 ( 99.59)\n","Epoch: [128][120/391]\tTime  0.170 ( 0.170)\tLoss 1.8451e-01 (1.2259e-01)\tAcc@1  95.31 ( 96.76)\tAcc@5  98.44 ( 99.57)\n","Epoch: [128][150/391]\tTime  0.171 ( 0.170)\tLoss 1.1812e-01 (1.2169e-01)\tAcc@1  96.88 ( 96.75)\tAcc@5 100.00 ( 99.55)\n","Epoch: [128][180/391]\tTime  0.169 ( 0.170)\tLoss 1.3319e-01 (1.2009e-01)\tAcc@1  96.88 ( 96.82)\tAcc@5  99.22 ( 99.57)\n","Epoch: [128][210/391]\tTime  0.171 ( 0.170)\tLoss 9.5916e-02 (1.1751e-01)\tAcc@1  96.88 ( 96.90)\tAcc@5 100.00 ( 99.59)\n","Epoch: [128][240/391]\tTime  0.169 ( 0.170)\tLoss 1.3606e-01 (1.1652e-01)\tAcc@1  95.31 ( 96.92)\tAcc@5 100.00 ( 99.60)\n","Epoch: [128][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4634e-01 (1.1640e-01)\tAcc@1  96.88 ( 96.94)\tAcc@5  98.44 ( 99.61)\n","Epoch: [128][300/391]\tTime  0.169 ( 0.170)\tLoss 7.7626e-02 (1.1610e-01)\tAcc@1  96.88 ( 96.97)\tAcc@5 100.00 ( 99.60)\n","Epoch: [128][330/391]\tTime  0.169 ( 0.170)\tLoss 1.7859e-01 (1.1582e-01)\tAcc@1  96.09 ( 96.96)\tAcc@5  99.22 ( 99.59)\n","Epoch: [128][360/391]\tTime  0.170 ( 0.169)\tLoss 1.4942e-01 (1.1610e-01)\tAcc@1  96.88 ( 96.95)\tAcc@5  99.22 ( 99.58)\n","Epoch: [128][390/391]\tTime  0.153 ( 0.169)\tLoss 6.1611e-02 (1.1571e-01)\tAcc@1 100.00 ( 96.98)\tAcc@5 100.00 ( 99.58)\n","==> Train Accuracy: Acc@1 96.982 || Acc@5 99.576\n","==> Test Accuracy:  Acc@1 78.600 || Acc@5 94.650\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 129, lr: 0.0008000000000000003 -----\n","Epoch: [129][  0/391]\tTime  0.298 ( 0.298)\tLoss 1.4618e-01 (1.4618e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n","Epoch: [129][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.1931e-01 (1.1675e-01)\tAcc@1  96.88 ( 96.98)\tAcc@5  99.22 ( 99.40)\n","Epoch: [129][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.1716e-01 (1.2780e-01)\tAcc@1  96.09 ( 96.63)\tAcc@5 100.00 ( 99.36)\n","Epoch: [129][ 90/391]\tTime  0.170 ( 0.171)\tLoss 8.6262e-02 (1.2689e-01)\tAcc@1  98.44 ( 96.71)\tAcc@5 100.00 ( 99.39)\n","Epoch: [129][120/391]\tTime  0.168 ( 0.170)\tLoss 7.7240e-02 (1.2217e-01)\tAcc@1  96.88 ( 96.84)\tAcc@5 100.00 ( 99.49)\n","Epoch: [129][150/391]\tTime  0.169 ( 0.170)\tLoss 1.3354e-01 (1.2139e-01)\tAcc@1  95.31 ( 96.84)\tAcc@5 100.00 ( 99.50)\n","Epoch: [129][180/391]\tTime  0.170 ( 0.170)\tLoss 1.0715e-01 (1.2166e-01)\tAcc@1  96.88 ( 96.85)\tAcc@5 100.00 ( 99.51)\n","Epoch: [129][210/391]\tTime  0.170 ( 0.170)\tLoss 7.2162e-02 (1.2005e-01)\tAcc@1  96.88 ( 96.89)\tAcc@5 100.00 ( 99.52)\n","Epoch: [129][240/391]\tTime  0.169 ( 0.170)\tLoss 6.1102e-02 (1.1728e-01)\tAcc@1  98.44 ( 96.97)\tAcc@5 100.00 ( 99.55)\n","Epoch: [129][270/391]\tTime  0.168 ( 0.170)\tLoss 7.3703e-02 (1.1783e-01)\tAcc@1  98.44 ( 96.94)\tAcc@5 100.00 ( 99.56)\n","Epoch: [129][300/391]\tTime  0.170 ( 0.170)\tLoss 8.2481e-02 (1.1626e-01)\tAcc@1  99.22 ( 96.99)\tAcc@5 100.00 ( 99.57)\n","Epoch: [129][330/391]\tTime  0.171 ( 0.170)\tLoss 2.5621e-01 (1.1638e-01)\tAcc@1  93.75 ( 96.99)\tAcc@5  98.44 ( 99.58)\n","Epoch: [129][360/391]\tTime  0.168 ( 0.170)\tLoss 6.8211e-02 (1.1538e-01)\tAcc@1  98.44 ( 97.03)\tAcc@5 100.00 ( 99.59)\n","Epoch: [129][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3156e-01 (1.1494e-01)\tAcc@1  97.50 ( 97.05)\tAcc@5  98.75 ( 99.59)\n","==> Train Accuracy: Acc@1 97.048 || Acc@5 99.590\n","==> Test Accuracy:  Acc@1 78.530 || Acc@5 94.560\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 130, lr: 0.0008000000000000003 -----\n","Epoch: [130][  0/391]\tTime  0.287 ( 0.287)\tLoss 2.8153e-02 (2.8153e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [130][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4309e-01 (1.0571e-01)\tAcc@1  94.53 ( 97.05)\tAcc@5 100.00 ( 99.70)\n","Epoch: [130][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.5496e-01 (1.1191e-01)\tAcc@1  94.53 ( 96.84)\tAcc@5  99.22 ( 99.62)\n","Epoch: [130][ 90/391]\tTime  0.169 ( 0.170)\tLoss 4.2524e-02 (1.1272e-01)\tAcc@1  98.44 ( 96.88)\tAcc@5 100.00 ( 99.60)\n","Epoch: [130][120/391]\tTime  0.170 ( 0.170)\tLoss 1.1853e-01 (1.1261e-01)\tAcc@1  96.88 ( 96.92)\tAcc@5 100.00 ( 99.59)\n","Epoch: [130][150/391]\tTime  0.169 ( 0.170)\tLoss 7.3042e-02 (1.1523e-01)\tAcc@1  98.44 ( 96.83)\tAcc@5 100.00 ( 99.57)\n","Epoch: [130][180/391]\tTime  0.169 ( 0.170)\tLoss 8.3649e-02 (1.1589e-01)\tAcc@1  97.66 ( 96.78)\tAcc@5 100.00 ( 99.56)\n","Epoch: [130][210/391]\tTime  0.169 ( 0.170)\tLoss 1.6077e-01 (1.1629e-01)\tAcc@1  95.31 ( 96.80)\tAcc@5 100.00 ( 99.57)\n","Epoch: [130][240/391]\tTime  0.169 ( 0.170)\tLoss 8.9306e-02 (1.1632e-01)\tAcc@1  96.88 ( 96.81)\tAcc@5  99.22 ( 99.58)\n","Epoch: [130][270/391]\tTime  0.171 ( 0.170)\tLoss 1.0796e-01 (1.1630e-01)\tAcc@1  96.88 ( 96.83)\tAcc@5 100.00 ( 99.58)\n","Epoch: [130][300/391]\tTime  0.171 ( 0.170)\tLoss 8.9508e-02 (1.1672e-01)\tAcc@1  97.66 ( 96.82)\tAcc@5 100.00 ( 99.58)\n","Epoch: [130][330/391]\tTime  0.169 ( 0.170)\tLoss 1.0402e-01 (1.1635e-01)\tAcc@1  96.09 ( 96.83)\tAcc@5  99.22 ( 99.58)\n","Epoch: [130][360/391]\tTime  0.169 ( 0.170)\tLoss 5.4989e-02 (1.1551e-01)\tAcc@1  98.44 ( 96.86)\tAcc@5 100.00 ( 99.59)\n","Epoch: [130][390/391]\tTime  0.153 ( 0.169)\tLoss 2.3336e-01 (1.1545e-01)\tAcc@1  93.75 ( 96.87)\tAcc@5  97.50 ( 99.59)\n","==> Train Accuracy: Acc@1 96.868 || Acc@5 99.586\n","==> Test Accuracy:  Acc@1 78.790 || Acc@5 94.480\n","==> 70.49 seconds to train this epoch\n","\n","\n","----- epoch: 131, lr: 0.0008000000000000003 -----\n","Epoch: [131][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.5413e-01 (1.5413e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [131][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.0559e-01 (1.0924e-01)\tAcc@1  96.88 ( 97.03)\tAcc@5 100.00 ( 99.67)\n","Epoch: [131][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.4109e-01 (1.0761e-01)\tAcc@1  94.53 ( 97.13)\tAcc@5  98.44 ( 99.69)\n","Epoch: [131][ 90/391]\tTime  0.172 ( 0.170)\tLoss 7.2738e-02 (1.1169e-01)\tAcc@1  98.44 ( 97.02)\tAcc@5 100.00 ( 99.68)\n","Epoch: [131][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4009e-01 (1.1517e-01)\tAcc@1  96.88 ( 96.95)\tAcc@5  99.22 ( 99.64)\n","Epoch: [131][150/391]\tTime  0.171 ( 0.170)\tLoss 9.9716e-02 (1.1381e-01)\tAcc@1  98.44 ( 96.95)\tAcc@5 100.00 ( 99.65)\n","Epoch: [131][180/391]\tTime  0.169 ( 0.170)\tLoss 5.1593e-02 (1.1293e-01)\tAcc@1  99.22 ( 97.03)\tAcc@5  99.22 ( 99.64)\n","Epoch: [131][210/391]\tTime  0.170 ( 0.170)\tLoss 9.3387e-02 (1.1461e-01)\tAcc@1  98.44 ( 96.99)\tAcc@5 100.00 ( 99.61)\n","Epoch: [131][240/391]\tTime  0.168 ( 0.170)\tLoss 1.7936e-01 (1.1723e-01)\tAcc@1  94.53 ( 96.93)\tAcc@5 100.00 ( 99.58)\n","Epoch: [131][270/391]\tTime  0.168 ( 0.170)\tLoss 8.6832e-02 (1.1748e-01)\tAcc@1  98.44 ( 96.91)\tAcc@5 100.00 ( 99.57)\n","Epoch: [131][300/391]\tTime  0.169 ( 0.170)\tLoss 1.6235e-01 (1.1823e-01)\tAcc@1  95.31 ( 96.88)\tAcc@5  99.22 ( 99.56)\n","Epoch: [131][330/391]\tTime  0.169 ( 0.170)\tLoss 1.1145e-01 (1.1698e-01)\tAcc@1  96.88 ( 96.90)\tAcc@5 100.00 ( 99.58)\n","Epoch: [131][360/391]\tTime  0.170 ( 0.170)\tLoss 1.2379e-01 (1.1823e-01)\tAcc@1  96.09 ( 96.87)\tAcc@5 100.00 ( 99.56)\n","Epoch: [131][390/391]\tTime  0.152 ( 0.169)\tLoss 8.5613e-02 (1.1836e-01)\tAcc@1 100.00 ( 96.85)\tAcc@5 100.00 ( 99.56)\n","==> Train Accuracy: Acc@1 96.854 || Acc@5 99.560\n","==> Test Accuracy:  Acc@1 78.630 || Acc@5 94.530\n","==> 70.51 seconds to train this epoch\n","\n","\n","----- epoch: 132, lr: 0.0008000000000000003 -----\n","Epoch: [132][  0/391]\tTime  0.296 ( 0.296)\tLoss 9.9344e-02 (9.9344e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [132][ 30/391]\tTime  0.168 ( 0.173)\tLoss 1.9666e-01 (1.0617e-01)\tAcc@1  93.75 ( 97.10)\tAcc@5  98.44 ( 99.67)\n","Epoch: [132][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.2611e-01 (1.0632e-01)\tAcc@1  96.88 ( 97.20)\tAcc@5  99.22 ( 99.72)\n","Epoch: [132][ 90/391]\tTime  0.169 ( 0.171)\tLoss 8.1918e-02 (1.1070e-01)\tAcc@1  97.66 ( 97.06)\tAcc@5 100.00 ( 99.72)\n","Epoch: [132][120/391]\tTime  0.171 ( 0.170)\tLoss 1.5567e-01 (1.1508e-01)\tAcc@1  96.09 ( 96.91)\tAcc@5  99.22 ( 99.66)\n","Epoch: [132][150/391]\tTime  0.169 ( 0.170)\tLoss 8.0971e-02 (1.1289e-01)\tAcc@1  98.44 ( 96.93)\tAcc@5 100.00 ( 99.66)\n","Epoch: [132][180/391]\tTime  0.168 ( 0.170)\tLoss 3.7337e-02 (1.1304e-01)\tAcc@1 100.00 ( 97.01)\tAcc@5 100.00 ( 99.63)\n","Epoch: [132][210/391]\tTime  0.168 ( 0.170)\tLoss 1.3093e-01 (1.1485e-01)\tAcc@1  96.09 ( 96.96)\tAcc@5  99.22 ( 99.61)\n","Epoch: [132][240/391]\tTime  0.170 ( 0.170)\tLoss 1.3386e-01 (1.1421e-01)\tAcc@1  96.88 ( 97.00)\tAcc@5 100.00 ( 99.60)\n","Epoch: [132][270/391]\tTime  0.170 ( 0.170)\tLoss 7.4200e-02 (1.1318e-01)\tAcc@1  97.66 ( 97.03)\tAcc@5 100.00 ( 99.62)\n","Epoch: [132][300/391]\tTime  0.169 ( 0.170)\tLoss 9.0324e-02 (1.1225e-01)\tAcc@1  98.44 ( 97.06)\tAcc@5  99.22 ( 99.61)\n","Epoch: [132][330/391]\tTime  0.169 ( 0.170)\tLoss 1.4353e-01 (1.1274e-01)\tAcc@1  96.88 ( 97.03)\tAcc@5  98.44 ( 99.61)\n","Epoch: [132][360/391]\tTime  0.169 ( 0.170)\tLoss 1.1232e-01 (1.1360e-01)\tAcc@1  97.66 ( 97.01)\tAcc@5  99.22 ( 99.59)\n","Epoch: [132][390/391]\tTime  0.151 ( 0.170)\tLoss 7.0970e-02 (1.1278e-01)\tAcc@1  98.75 ( 97.02)\tAcc@5 100.00 ( 99.60)\n","==> Train Accuracy: Acc@1 97.024 || Acc@5 99.596\n","==> Test Accuracy:  Acc@1 78.700 || Acc@5 94.650\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 133, lr: 0.0008000000000000003 -----\n","Epoch: [133][  0/391]\tTime  0.304 ( 0.304)\tLoss 1.4279e-01 (1.4279e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [133][ 30/391]\tTime  0.169 ( 0.173)\tLoss 7.4661e-02 (1.1353e-01)\tAcc@1  98.44 ( 96.90)\tAcc@5 100.00 ( 99.57)\n","Epoch: [133][ 60/391]\tTime  0.169 ( 0.171)\tLoss 7.6408e-02 (1.0795e-01)\tAcc@1  98.44 ( 97.18)\tAcc@5 100.00 ( 99.63)\n","Epoch: [133][ 90/391]\tTime  0.170 ( 0.171)\tLoss 9.4678e-02 (1.0583e-01)\tAcc@1  96.88 ( 97.22)\tAcc@5 100.00 ( 99.65)\n","Epoch: [133][120/391]\tTime  0.169 ( 0.170)\tLoss 1.1666e-01 (1.0838e-01)\tAcc@1  97.66 ( 97.11)\tAcc@5 100.00 ( 99.66)\n","Epoch: [133][150/391]\tTime  0.169 ( 0.170)\tLoss 1.4003e-01 (1.1213e-01)\tAcc@1  96.88 ( 97.04)\tAcc@5  98.44 ( 99.58)\n","Epoch: [133][180/391]\tTime  0.169 ( 0.170)\tLoss 9.9129e-02 (1.0967e-01)\tAcc@1  96.88 ( 97.11)\tAcc@5 100.00 ( 99.61)\n","Epoch: [133][210/391]\tTime  0.170 ( 0.170)\tLoss 1.4742e-01 (1.0907e-01)\tAcc@1  96.88 ( 97.13)\tAcc@5  99.22 ( 99.63)\n","Epoch: [133][240/391]\tTime  0.170 ( 0.170)\tLoss 7.6272e-02 (1.1054e-01)\tAcc@1  98.44 ( 97.08)\tAcc@5  99.22 ( 99.63)\n","Epoch: [133][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4455e-01 (1.1073e-01)\tAcc@1  95.31 ( 97.07)\tAcc@5  99.22 ( 99.61)\n","Epoch: [133][300/391]\tTime  0.169 ( 0.170)\tLoss 1.1797e-01 (1.0992e-01)\tAcc@1  96.88 ( 97.11)\tAcc@5 100.00 ( 99.59)\n","Epoch: [133][330/391]\tTime  0.168 ( 0.170)\tLoss 1.2204e-01 (1.1063e-01)\tAcc@1  96.09 ( 97.10)\tAcc@5  99.22 ( 99.59)\n","Epoch: [133][360/391]\tTime  0.170 ( 0.170)\tLoss 1.2121e-01 (1.1055e-01)\tAcc@1  96.88 ( 97.08)\tAcc@5 100.00 ( 99.59)\n","Epoch: [133][390/391]\tTime  0.152 ( 0.170)\tLoss 1.1411e-01 (1.1163e-01)\tAcc@1  96.25 ( 97.06)\tAcc@5 100.00 ( 99.59)\n","==> Train Accuracy: Acc@1 97.060 || Acc@5 99.590\n","==> Test Accuracy:  Acc@1 78.290 || Acc@5 94.670\n","==> 70.52 seconds to train this epoch\n","\n","\n","----- epoch: 134, lr: 0.0008000000000000003 -----\n","Epoch: [134][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.5312e-01 (1.5312e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [134][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.2316e-01 (1.1243e-01)\tAcc@1  96.09 ( 96.98)\tAcc@5 100.00 ( 99.60)\n","Epoch: [134][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.0840e-01 (1.1437e-01)\tAcc@1  96.09 ( 96.86)\tAcc@5  99.22 ( 99.58)\n","Epoch: [134][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.4280e-01 (1.1166e-01)\tAcc@1  96.88 ( 97.00)\tAcc@5  99.22 ( 99.59)\n","Epoch: [134][120/391]\tTime  0.168 ( 0.170)\tLoss 1.1339e-01 (1.1312e-01)\tAcc@1  96.09 ( 96.93)\tAcc@5 100.00 ( 99.57)\n","Epoch: [134][150/391]\tTime  0.170 ( 0.170)\tLoss 1.0829e-01 (1.1401e-01)\tAcc@1  96.09 ( 96.87)\tAcc@5 100.00 ( 99.57)\n","Epoch: [134][180/391]\tTime  0.170 ( 0.170)\tLoss 1.2870e-01 (1.1612e-01)\tAcc@1  96.88 ( 96.85)\tAcc@5 100.00 ( 99.55)\n","Epoch: [134][210/391]\tTime  0.169 ( 0.170)\tLoss 8.6935e-02 (1.1386e-01)\tAcc@1  97.66 ( 96.93)\tAcc@5 100.00 ( 99.57)\n","Epoch: [134][240/391]\tTime  0.169 ( 0.170)\tLoss 9.7316e-02 (1.1249e-01)\tAcc@1  96.09 ( 96.97)\tAcc@5 100.00 ( 99.60)\n","Epoch: [134][270/391]\tTime  0.169 ( 0.170)\tLoss 1.7650e-01 (1.1156e-01)\tAcc@1  96.09 ( 97.00)\tAcc@5  99.22 ( 99.61)\n","Epoch: [134][300/391]\tTime  0.170 ( 0.170)\tLoss 7.4531e-02 (1.1130e-01)\tAcc@1  97.66 ( 97.00)\tAcc@5 100.00 ( 99.62)\n","Epoch: [134][330/391]\tTime  0.170 ( 0.170)\tLoss 9.1522e-02 (1.1219e-01)\tAcc@1  97.66 ( 97.00)\tAcc@5 100.00 ( 99.61)\n","Epoch: [134][360/391]\tTime  0.168 ( 0.170)\tLoss 1.4913e-01 (1.1189e-01)\tAcc@1  95.31 ( 97.00)\tAcc@5  99.22 ( 99.60)\n","Epoch: [134][390/391]\tTime  0.153 ( 0.170)\tLoss 1.9761e-01 (1.1279e-01)\tAcc@1  93.75 ( 96.98)\tAcc@5 100.00 ( 99.60)\n","==> Train Accuracy: Acc@1 96.978 || Acc@5 99.596\n","==> Test Accuracy:  Acc@1 78.650 || Acc@5 94.760\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 135, lr: 0.0008000000000000003 -----\n","Epoch: [135][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.2683e-01 (1.2683e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [135][ 30/391]\tTime  0.170 ( 0.172)\tLoss 2.0333e-01 (9.6595e-02)\tAcc@1  93.75 ( 97.43)\tAcc@5  98.44 ( 99.65)\n","Epoch: [135][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.0424e-01 (9.9824e-02)\tAcc@1  95.31 ( 97.17)\tAcc@5 100.00 ( 99.69)\n","Epoch: [135][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.1104e-01 (1.0289e-01)\tAcc@1  96.88 ( 97.11)\tAcc@5 100.00 ( 99.69)\n","Epoch: [135][120/391]\tTime  0.171 ( 0.170)\tLoss 8.2694e-02 (1.0251e-01)\tAcc@1  96.88 ( 97.14)\tAcc@5 100.00 ( 99.68)\n","Epoch: [135][150/391]\tTime  0.169 ( 0.170)\tLoss 1.0956e-01 (1.0521e-01)\tAcc@1  97.66 ( 97.12)\tAcc@5 100.00 ( 99.63)\n","Epoch: [135][180/391]\tTime  0.171 ( 0.170)\tLoss 1.0679e-01 (1.0664e-01)\tAcc@1  97.66 ( 97.09)\tAcc@5 100.00 ( 99.61)\n","Epoch: [135][210/391]\tTime  0.169 ( 0.170)\tLoss 8.2704e-02 (1.0960e-01)\tAcc@1  97.66 ( 97.03)\tAcc@5 100.00 ( 99.59)\n","Epoch: [135][240/391]\tTime  0.171 ( 0.170)\tLoss 1.1340e-01 (1.0996e-01)\tAcc@1  96.88 ( 97.05)\tAcc@5  99.22 ( 99.59)\n","Epoch: [135][270/391]\tTime  0.170 ( 0.170)\tLoss 9.6198e-02 (1.0954e-01)\tAcc@1  97.66 ( 97.07)\tAcc@5 100.00 ( 99.58)\n","Epoch: [135][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5364e-01 (1.0938e-01)\tAcc@1  96.88 ( 97.09)\tAcc@5  98.44 ( 99.58)\n","Epoch: [135][330/391]\tTime  0.168 ( 0.170)\tLoss 7.1381e-02 (1.0995e-01)\tAcc@1  98.44 ( 97.10)\tAcc@5 100.00 ( 99.57)\n","Epoch: [135][360/391]\tTime  0.170 ( 0.170)\tLoss 1.2117e-01 (1.0927e-01)\tAcc@1  96.88 ( 97.12)\tAcc@5 100.00 ( 99.57)\n","Epoch: [135][390/391]\tTime  0.152 ( 0.169)\tLoss 1.5169e-01 (1.0910e-01)\tAcc@1  96.25 ( 97.11)\tAcc@5 100.00 ( 99.57)\n","==> Train Accuracy: Acc@1 97.110 || Acc@5 99.568\n","==> Test Accuracy:  Acc@1 78.530 || Acc@5 94.630\n","==> 70.48 seconds to train this epoch\n","\n","\n","----- epoch: 136, lr: 0.0008000000000000003 -----\n","Epoch: [136][  0/391]\tTime  0.280 ( 0.280)\tLoss 9.5164e-02 (9.5164e-02)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [136][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.6109e-01 (1.1268e-01)\tAcc@1  96.09 ( 97.00)\tAcc@5  99.22 ( 99.60)\n","Epoch: [136][ 60/391]\tTime  0.171 ( 0.171)\tLoss 6.9055e-02 (1.2421e-01)\tAcc@1  99.22 ( 96.61)\tAcc@5 100.00 ( 99.56)\n","Epoch: [136][ 90/391]\tTime  0.170 ( 0.170)\tLoss 3.6815e-02 (1.1828e-01)\tAcc@1 100.00 ( 96.87)\tAcc@5 100.00 ( 99.55)\n","Epoch: [136][120/391]\tTime  0.168 ( 0.170)\tLoss 6.9098e-02 (1.1632e-01)\tAcc@1  97.66 ( 96.93)\tAcc@5 100.00 ( 99.57)\n","Epoch: [136][150/391]\tTime  0.170 ( 0.170)\tLoss 1.5281e-01 (1.1325e-01)\tAcc@1  97.66 ( 97.08)\tAcc@5  98.44 ( 99.58)\n","Epoch: [136][180/391]\tTime  0.170 ( 0.170)\tLoss 1.0312e-01 (1.1147e-01)\tAcc@1  97.66 ( 97.13)\tAcc@5 100.00 ( 99.59)\n","Epoch: [136][210/391]\tTime  0.169 ( 0.170)\tLoss 1.2160e-01 (1.1075e-01)\tAcc@1  96.09 ( 97.16)\tAcc@5  99.22 ( 99.60)\n","Epoch: [136][240/391]\tTime  0.169 ( 0.170)\tLoss 6.5551e-02 (1.0929e-01)\tAcc@1  97.66 ( 97.20)\tAcc@5 100.00 ( 99.61)\n","Epoch: [136][270/391]\tTime  0.170 ( 0.170)\tLoss 6.3349e-02 (1.1012e-01)\tAcc@1  98.44 ( 97.19)\tAcc@5 100.00 ( 99.61)\n","Epoch: [136][300/391]\tTime  0.171 ( 0.170)\tLoss 2.0656e-01 (1.1018e-01)\tAcc@1  93.75 ( 97.18)\tAcc@5  98.44 ( 99.60)\n","Epoch: [136][330/391]\tTime  0.170 ( 0.170)\tLoss 1.1633e-01 (1.1033e-01)\tAcc@1  96.09 ( 97.15)\tAcc@5 100.00 ( 99.60)\n","Epoch: [136][360/391]\tTime  0.169 ( 0.170)\tLoss 6.9713e-02 (1.1025e-01)\tAcc@1  97.66 ( 97.15)\tAcc@5 100.00 ( 99.60)\n","Epoch: [136][390/391]\tTime  0.152 ( 0.170)\tLoss 1.6950e-01 (1.1005e-01)\tAcc@1  96.25 ( 97.15)\tAcc@5  98.75 ( 99.60)\n","==> Train Accuracy: Acc@1 97.150 || Acc@5 99.602\n","==> Test Accuracy:  Acc@1 78.480 || Acc@5 94.410\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 137, lr: 0.0008000000000000003 -----\n","Epoch: [137][  0/391]\tTime  0.312 ( 0.312)\tLoss 1.0389e-01 (1.0389e-01)\tAcc@1  98.44 ( 98.44)\tAcc@5  99.22 ( 99.22)\n","Epoch: [137][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.0975e-01 (9.9360e-02)\tAcc@1  98.44 ( 97.78)\tAcc@5  99.22 ( 99.65)\n","Epoch: [137][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.5984e-02 (1.1137e-01)\tAcc@1  98.44 ( 97.32)\tAcc@5 100.00 ( 99.55)\n","Epoch: [137][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.2555e-01 (1.0921e-01)\tAcc@1  96.88 ( 97.30)\tAcc@5  99.22 ( 99.54)\n","Epoch: [137][120/391]\tTime  0.169 ( 0.170)\tLoss 1.3092e-01 (1.0770e-01)\tAcc@1  96.88 ( 97.29)\tAcc@5  99.22 ( 99.57)\n","Epoch: [137][150/391]\tTime  0.169 ( 0.170)\tLoss 9.9011e-02 (1.0768e-01)\tAcc@1  98.44 ( 97.29)\tAcc@5  99.22 ( 99.57)\n","Epoch: [137][180/391]\tTime  0.169 ( 0.170)\tLoss 8.3741e-02 (1.0830e-01)\tAcc@1  97.66 ( 97.25)\tAcc@5 100.00 ( 99.58)\n","Epoch: [137][210/391]\tTime  0.170 ( 0.170)\tLoss 3.3659e-02 (1.0770e-01)\tAcc@1  99.22 ( 97.23)\tAcc@5 100.00 ( 99.57)\n","Epoch: [137][240/391]\tTime  0.169 ( 0.170)\tLoss 1.4931e-01 (1.1107e-01)\tAcc@1  96.09 ( 97.14)\tAcc@5  99.22 ( 99.54)\n","Epoch: [137][270/391]\tTime  0.170 ( 0.170)\tLoss 1.0282e-01 (1.1028e-01)\tAcc@1  96.09 ( 97.13)\tAcc@5 100.00 ( 99.57)\n","Epoch: [137][300/391]\tTime  0.170 ( 0.170)\tLoss 1.6624e-01 (1.1039e-01)\tAcc@1  94.53 ( 97.12)\tAcc@5  99.22 ( 99.57)\n","Epoch: [137][330/391]\tTime  0.169 ( 0.170)\tLoss 1.1113e-01 (1.1100e-01)\tAcc@1  96.88 ( 97.12)\tAcc@5  98.44 ( 99.57)\n","Epoch: [137][360/391]\tTime  0.170 ( 0.170)\tLoss 1.6735e-01 (1.1191e-01)\tAcc@1  96.09 ( 97.09)\tAcc@5  99.22 ( 99.55)\n","Epoch: [137][390/391]\tTime  0.151 ( 0.170)\tLoss 1.1996e-01 (1.1130e-01)\tAcc@1  96.25 ( 97.12)\tAcc@5 100.00 ( 99.55)\n","==> Train Accuracy: Acc@1 97.122 || Acc@5 99.546\n","==> Test Accuracy:  Acc@1 78.290 || Acc@5 94.550\n","==> 70.56 seconds to train this epoch\n","\n","\n","----- epoch: 138, lr: 0.0008000000000000003 -----\n","Epoch: [138][  0/391]\tTime  0.282 ( 0.282)\tLoss 9.9981e-02 (9.9981e-02)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [138][ 30/391]\tTime  0.169 ( 0.173)\tLoss 9.3866e-02 (9.6287e-02)\tAcc@1  97.66 ( 97.43)\tAcc@5 100.00 ( 99.77)\n","Epoch: [138][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.0847e-01 (1.0546e-01)\tAcc@1  98.44 ( 97.22)\tAcc@5 100.00 ( 99.65)\n","Epoch: [138][ 90/391]\tTime  0.170 ( 0.170)\tLoss 9.8023e-02 (1.0293e-01)\tAcc@1  99.22 ( 97.37)\tAcc@5  99.22 ( 99.62)\n","Epoch: [138][120/391]\tTime  0.168 ( 0.170)\tLoss 1.3020e-01 (1.0638e-01)\tAcc@1  96.09 ( 97.26)\tAcc@5  99.22 ( 99.58)\n","Epoch: [138][150/391]\tTime  0.169 ( 0.170)\tLoss 1.6307e-01 (1.0776e-01)\tAcc@1  96.09 ( 97.23)\tAcc@5  99.22 ( 99.57)\n","Epoch: [138][180/391]\tTime  0.169 ( 0.170)\tLoss 1.2148e-01 (1.0622e-01)\tAcc@1  94.53 ( 97.29)\tAcc@5 100.00 ( 99.58)\n","Epoch: [138][210/391]\tTime  0.171 ( 0.170)\tLoss 9.9323e-02 (1.0529e-01)\tAcc@1  98.44 ( 97.34)\tAcc@5 100.00 ( 99.61)\n","Epoch: [138][240/391]\tTime  0.170 ( 0.170)\tLoss 1.2523e-01 (1.0594e-01)\tAcc@1  96.88 ( 97.33)\tAcc@5  99.22 ( 99.61)\n","Epoch: [138][270/391]\tTime  0.169 ( 0.170)\tLoss 9.4190e-02 (1.0665e-01)\tAcc@1  96.09 ( 97.28)\tAcc@5 100.00 ( 99.62)\n","Epoch: [138][300/391]\tTime  0.168 ( 0.170)\tLoss 1.3301e-01 (1.0666e-01)\tAcc@1  97.66 ( 97.26)\tAcc@5 100.00 ( 99.63)\n","Epoch: [138][330/391]\tTime  0.171 ( 0.170)\tLoss 1.2651e-01 (1.0639e-01)\tAcc@1  95.31 ( 97.26)\tAcc@5  99.22 ( 99.63)\n","Epoch: [138][360/391]\tTime  0.169 ( 0.170)\tLoss 1.1794e-01 (1.0799e-01)\tAcc@1  96.09 ( 97.21)\tAcc@5 100.00 ( 99.63)\n","Epoch: [138][390/391]\tTime  0.153 ( 0.170)\tLoss 1.1896e-01 (1.0791e-01)\tAcc@1  97.50 ( 97.23)\tAcc@5  98.75 ( 99.63)\n","==> Train Accuracy: Acc@1 97.234 || Acc@5 99.630\n","==> Test Accuracy:  Acc@1 78.530 || Acc@5 94.470\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 139, lr: 0.0008000000000000003 -----\n","Epoch: [139][  0/391]\tTime  0.286 ( 0.286)\tLoss 7.1355e-02 (7.1355e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5  99.22 ( 99.22)\n","Epoch: [139][ 30/391]\tTime  0.170 ( 0.172)\tLoss 6.8887e-02 (1.1078e-01)\tAcc@1  98.44 ( 97.18)\tAcc@5  99.22 ( 99.47)\n","Epoch: [139][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.2661e-01 (1.1054e-01)\tAcc@1  97.66 ( 97.08)\tAcc@5  99.22 ( 99.51)\n","Epoch: [139][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.3367e-01 (1.1140e-01)\tAcc@1  96.09 ( 97.09)\tAcc@5 100.00 ( 99.53)\n","Epoch: [139][120/391]\tTime  0.168 ( 0.170)\tLoss 1.0646e-01 (1.1065e-01)\tAcc@1  97.66 ( 97.09)\tAcc@5 100.00 ( 99.55)\n","Epoch: [139][150/391]\tTime  0.169 ( 0.170)\tLoss 5.2371e-02 (1.0821e-01)\tAcc@1  99.22 ( 97.19)\tAcc@5 100.00 ( 99.59)\n","Epoch: [139][180/391]\tTime  0.169 ( 0.170)\tLoss 9.9222e-02 (1.0799e-01)\tAcc@1  97.66 ( 97.16)\tAcc@5 100.00 ( 99.60)\n","Epoch: [139][210/391]\tTime  0.169 ( 0.170)\tLoss 6.2199e-02 (1.0699e-01)\tAcc@1  98.44 ( 97.19)\tAcc@5 100.00 ( 99.60)\n","Epoch: [139][240/391]\tTime  0.168 ( 0.170)\tLoss 1.2225e-01 (1.0709e-01)\tAcc@1  96.09 ( 97.18)\tAcc@5 100.00 ( 99.61)\n","Epoch: [139][270/391]\tTime  0.170 ( 0.170)\tLoss 4.2914e-02 (1.0803e-01)\tAcc@1 100.00 ( 97.17)\tAcc@5 100.00 ( 99.59)\n","Epoch: [139][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4297e-01 (1.0825e-01)\tAcc@1  96.88 ( 97.19)\tAcc@5  99.22 ( 99.58)\n","Epoch: [139][330/391]\tTime  0.168 ( 0.170)\tLoss 1.0229e-01 (1.0766e-01)\tAcc@1  96.88 ( 97.18)\tAcc@5 100.00 ( 99.59)\n","Epoch: [139][360/391]\tTime  0.169 ( 0.170)\tLoss 1.2412e-01 (1.0805e-01)\tAcc@1  97.66 ( 97.16)\tAcc@5 100.00 ( 99.60)\n","Epoch: [139][390/391]\tTime  0.151 ( 0.169)\tLoss 2.3749e-01 (1.0853e-01)\tAcc@1  92.50 ( 97.14)\tAcc@5 100.00 ( 99.59)\n","==> Train Accuracy: Acc@1 97.144 || Acc@5 99.592\n","==> Test Accuracy:  Acc@1 78.470 || Acc@5 94.560\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 140, lr: 0.0008000000000000003 -----\n","Epoch: [140][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.0864e-01 (1.0864e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [140][ 30/391]\tTime  0.170 ( 0.172)\tLoss 9.4053e-02 (1.0022e-01)\tAcc@1  97.66 ( 97.40)\tAcc@5 100.00 ( 99.50)\n","Epoch: [140][ 60/391]\tTime  0.169 ( 0.171)\tLoss 9.7359e-02 (9.5324e-02)\tAcc@1  97.66 ( 97.41)\tAcc@5 100.00 ( 99.67)\n","Epoch: [140][ 90/391]\tTime  0.170 ( 0.170)\tLoss 7.0864e-02 (9.4892e-02)\tAcc@1  98.44 ( 97.54)\tAcc@5  99.22 ( 99.66)\n","Epoch: [140][120/391]\tTime  0.169 ( 0.170)\tLoss 7.6941e-02 (9.6309e-02)\tAcc@1  98.44 ( 97.51)\tAcc@5  99.22 ( 99.65)\n","Epoch: [140][150/391]\tTime  0.170 ( 0.170)\tLoss 4.2856e-02 (9.8856e-02)\tAcc@1  99.22 ( 97.45)\tAcc@5 100.00 ( 99.64)\n","Epoch: [140][180/391]\tTime  0.170 ( 0.170)\tLoss 1.5985e-01 (9.9844e-02)\tAcc@1  96.09 ( 97.44)\tAcc@5 100.00 ( 99.64)\n","Epoch: [140][210/391]\tTime  0.170 ( 0.170)\tLoss 9.9948e-02 (9.9533e-02)\tAcc@1  96.88 ( 97.44)\tAcc@5  99.22 ( 99.65)\n","Epoch: [140][240/391]\tTime  0.168 ( 0.170)\tLoss 2.6125e-01 (1.0164e-01)\tAcc@1  92.97 ( 97.39)\tAcc@5  97.66 ( 99.63)\n","Epoch: [140][270/391]\tTime  0.170 ( 0.170)\tLoss 1.0679e-01 (1.0276e-01)\tAcc@1  96.09 ( 97.35)\tAcc@5 100.00 ( 99.63)\n","Epoch: [140][300/391]\tTime  0.168 ( 0.170)\tLoss 1.5301e-01 (1.0247e-01)\tAcc@1  96.09 ( 97.36)\tAcc@5  99.22 ( 99.63)\n","Epoch: [140][330/391]\tTime  0.171 ( 0.170)\tLoss 1.0218e-01 (1.0325e-01)\tAcc@1  98.44 ( 97.34)\tAcc@5 100.00 ( 99.63)\n","Epoch: [140][360/391]\tTime  0.168 ( 0.170)\tLoss 1.3065e-01 (1.0386e-01)\tAcc@1  97.66 ( 97.33)\tAcc@5  99.22 ( 99.62)\n","Epoch: [140][390/391]\tTime  0.151 ( 0.169)\tLoss 6.9752e-02 (1.0429e-01)\tAcc@1  98.75 ( 97.32)\tAcc@5 100.00 ( 99.63)\n","==> Train Accuracy: Acc@1 97.318 || Acc@5 99.630\n","==> Test Accuracy:  Acc@1 78.480 || Acc@5 94.550\n","==> 70.46 seconds to train this epoch\n","\n","\n","----- epoch: 141, lr: 0.0008000000000000003 -----\n","Epoch: [141][  0/391]\tTime  0.294 ( 0.294)\tLoss 4.7697e-02 (4.7697e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [141][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.6421e-01 (1.1107e-01)\tAcc@1  95.31 ( 96.98)\tAcc@5 100.00 ( 99.55)\n","Epoch: [141][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.3077e-01 (1.0220e-01)\tAcc@1  96.09 ( 97.26)\tAcc@5 100.00 ( 99.65)\n","Epoch: [141][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.5201e-01 (1.0569e-01)\tAcc@1  96.88 ( 97.14)\tAcc@5  97.66 ( 99.58)\n","Epoch: [141][120/391]\tTime  0.170 ( 0.170)\tLoss 1.2624e-01 (1.0571e-01)\tAcc@1  96.09 ( 97.12)\tAcc@5 100.00 ( 99.61)\n","Epoch: [141][150/391]\tTime  0.168 ( 0.170)\tLoss 8.4807e-02 (1.0864e-01)\tAcc@1  97.66 ( 97.06)\tAcc@5  99.22 ( 99.57)\n","Epoch: [141][180/391]\tTime  0.170 ( 0.170)\tLoss 8.2117e-02 (1.0857e-01)\tAcc@1  97.66 ( 97.10)\tAcc@5  99.22 ( 99.58)\n","Epoch: [141][210/391]\tTime  0.168 ( 0.170)\tLoss 1.0625e-01 (1.0908e-01)\tAcc@1  96.88 ( 97.06)\tAcc@5 100.00 ( 99.60)\n","Epoch: [141][240/391]\tTime  0.170 ( 0.170)\tLoss 1.6459e-01 (1.1029e-01)\tAcc@1  95.31 ( 97.02)\tAcc@5  98.44 ( 99.60)\n","Epoch: [141][270/391]\tTime  0.166 ( 0.170)\tLoss 7.1002e-02 (1.1061e-01)\tAcc@1  98.44 ( 97.01)\tAcc@5 100.00 ( 99.60)\n","Epoch: [141][300/391]\tTime  0.168 ( 0.170)\tLoss 1.4406e-01 (1.1143e-01)\tAcc@1  96.09 ( 97.00)\tAcc@5 100.00 ( 99.58)\n","Epoch: [141][330/391]\tTime  0.169 ( 0.170)\tLoss 1.3933e-01 (1.1109e-01)\tAcc@1  96.09 ( 97.04)\tAcc@5  99.22 ( 99.58)\n","Epoch: [141][360/391]\tTime  0.170 ( 0.170)\tLoss 1.6158e-01 (1.1312e-01)\tAcc@1  96.09 ( 96.99)\tAcc@5  98.44 ( 99.57)\n","Epoch: [141][390/391]\tTime  0.152 ( 0.170)\tLoss 1.3832e-01 (1.1354e-01)\tAcc@1  97.50 ( 96.98)\tAcc@5  98.75 ( 99.57)\n","==> Train Accuracy: Acc@1 96.980 || Acc@5 99.574\n","==> Test Accuracy:  Acc@1 78.400 || Acc@5 94.550\n","==> 70.50 seconds to train this epoch\n","\n","\n","----- epoch: 142, lr: 0.0008000000000000003 -----\n","Epoch: [142][  0/391]\tTime  0.297 ( 0.297)\tLoss 1.4802e-01 (1.4802e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [142][ 30/391]\tTime  0.170 ( 0.173)\tLoss 8.7047e-02 (1.2232e-01)\tAcc@1  97.66 ( 96.77)\tAcc@5 100.00 ( 99.37)\n","Epoch: [142][ 60/391]\tTime  0.167 ( 0.171)\tLoss 7.9907e-02 (1.0870e-01)\tAcc@1  97.66 ( 97.08)\tAcc@5 100.00 ( 99.58)\n","Epoch: [142][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.0087e-01 (1.0658e-01)\tAcc@1  98.44 ( 97.24)\tAcc@5 100.00 ( 99.64)\n","Epoch: [142][120/391]\tTime  0.169 ( 0.170)\tLoss 1.1354e-01 (1.0720e-01)\tAcc@1  96.88 ( 97.18)\tAcc@5 100.00 ( 99.64)\n","Epoch: [142][150/391]\tTime  0.171 ( 0.170)\tLoss 1.9996e-01 (1.0717e-01)\tAcc@1  92.97 ( 97.14)\tAcc@5  98.44 ( 99.66)\n","Epoch: [142][180/391]\tTime  0.168 ( 0.170)\tLoss 1.2483e-01 (1.0461e-01)\tAcc@1  96.09 ( 97.19)\tAcc@5  99.22 ( 99.66)\n","Epoch: [142][210/391]\tTime  0.169 ( 0.170)\tLoss 4.1245e-02 (1.0567e-01)\tAcc@1 100.00 ( 97.18)\tAcc@5 100.00 ( 99.66)\n","Epoch: [142][240/391]\tTime  0.170 ( 0.170)\tLoss 1.3526e-01 (1.0535e-01)\tAcc@1  97.66 ( 97.20)\tAcc@5  99.22 ( 99.65)\n","Epoch: [142][270/391]\tTime  0.169 ( 0.170)\tLoss 1.0665e-01 (1.0553e-01)\tAcc@1  97.66 ( 97.21)\tAcc@5 100.00 ( 99.66)\n","Epoch: [142][300/391]\tTime  0.170 ( 0.170)\tLoss 1.0176e-01 (1.0624e-01)\tAcc@1  97.66 ( 97.18)\tAcc@5 100.00 ( 99.64)\n","Epoch: [142][330/391]\tTime  0.169 ( 0.170)\tLoss 6.7363e-02 (1.0705e-01)\tAcc@1  98.44 ( 97.15)\tAcc@5 100.00 ( 99.63)\n","Epoch: [142][360/391]\tTime  0.169 ( 0.170)\tLoss 1.4619e-01 (1.0658e-01)\tAcc@1  96.09 ( 97.18)\tAcc@5  99.22 ( 99.64)\n","Epoch: [142][390/391]\tTime  0.152 ( 0.170)\tLoss 1.2294e-01 (1.0519e-01)\tAcc@1  97.50 ( 97.22)\tAcc@5  98.75 ( 99.65)\n","==> Train Accuracy: Acc@1 97.224 || Acc@5 99.646\n","==> Test Accuracy:  Acc@1 78.760 || Acc@5 94.490\n","==> 70.47 seconds to train this epoch\n","\n","\n","----- epoch: 143, lr: 0.0008000000000000003 -----\n","Epoch: [143][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.1773e-01 (1.1773e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [143][ 30/391]\tTime  0.170 ( 0.173)\tLoss 8.3838e-02 (1.0632e-01)\tAcc@1  97.66 ( 96.93)\tAcc@5 100.00 ( 99.65)\n","Epoch: [143][ 60/391]\tTime  0.171 ( 0.171)\tLoss 7.2332e-02 (1.0728e-01)\tAcc@1  97.66 ( 97.08)\tAcc@5 100.00 ( 99.55)\n","Epoch: [143][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.2226e-01 (1.0945e-01)\tAcc@1  97.66 ( 97.15)\tAcc@5  99.22 ( 99.54)\n","Epoch: [143][120/391]\tTime  0.168 ( 0.170)\tLoss 1.3582e-01 (1.0585e-01)\tAcc@1  96.09 ( 97.24)\tAcc@5 100.00 ( 99.61)\n","Epoch: [143][150/391]\tTime  0.168 ( 0.170)\tLoss 1.6537e-01 (1.0609e-01)\tAcc@1  93.75 ( 97.20)\tAcc@5  98.44 ( 99.63)\n","Epoch: [143][180/391]\tTime  0.169 ( 0.170)\tLoss 8.4922e-02 (1.0562e-01)\tAcc@1  96.88 ( 97.21)\tAcc@5 100.00 ( 99.64)\n","Epoch: [143][210/391]\tTime  0.169 ( 0.170)\tLoss 1.0073e-01 (1.0529e-01)\tAcc@1  96.88 ( 97.18)\tAcc@5 100.00 ( 99.66)\n","Epoch: [143][240/391]\tTime  0.169 ( 0.170)\tLoss 1.0900e-01 (1.0394e-01)\tAcc@1  97.66 ( 97.25)\tAcc@5 100.00 ( 99.67)\n","Epoch: [143][270/391]\tTime  0.168 ( 0.170)\tLoss 1.1323e-01 (1.0561e-01)\tAcc@1  98.44 ( 97.22)\tAcc@5  98.44 ( 99.65)\n","Epoch: [143][300/391]\tTime  0.168 ( 0.170)\tLoss 7.4723e-02 (1.0518e-01)\tAcc@1  99.22 ( 97.26)\tAcc@5 100.00 ( 99.66)\n","Epoch: [143][330/391]\tTime  0.169 ( 0.170)\tLoss 7.7433e-02 (1.0639e-01)\tAcc@1  98.44 ( 97.20)\tAcc@5 100.00 ( 99.65)\n","Epoch: [143][360/391]\tTime  0.168 ( 0.170)\tLoss 1.2058e-01 (1.0730e-01)\tAcc@1  96.09 ( 97.16)\tAcc@5  98.44 ( 99.64)\n","Epoch: [143][390/391]\tTime  0.153 ( 0.169)\tLoss 1.4050e-01 (1.0639e-01)\tAcc@1  97.50 ( 97.19)\tAcc@5  98.75 ( 99.63)\n","==> Train Accuracy: Acc@1 97.186 || Acc@5 99.628\n","==> Test Accuracy:  Acc@1 78.690 || Acc@5 94.610\n","==> 70.45 seconds to train this epoch\n","\n","\n","----- epoch: 144, lr: 0.0008000000000000003 -----\n","Epoch: [144][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.5459e-01 (1.5459e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [144][ 30/391]\tTime  0.171 ( 0.172)\tLoss 1.1114e-01 (1.0754e-01)\tAcc@1  95.31 ( 97.15)\tAcc@5 100.00 ( 99.57)\n","Epoch: [144][ 60/391]\tTime  0.169 ( 0.171)\tLoss 3.8821e-02 (1.0266e-01)\tAcc@1 100.00 ( 97.30)\tAcc@5 100.00 ( 99.59)\n","Epoch: [144][ 90/391]\tTime  0.169 ( 0.170)\tLoss 1.3352e-01 (1.0210e-01)\tAcc@1  93.75 ( 97.33)\tAcc@5 100.00 ( 99.61)\n","Epoch: [144][120/391]\tTime  0.170 ( 0.170)\tLoss 1.7629e-01 (1.0452e-01)\tAcc@1  96.09 ( 97.25)\tAcc@5  99.22 ( 99.59)\n","Epoch: [144][150/391]\tTime  0.171 ( 0.170)\tLoss 9.1072e-02 (1.0478e-01)\tAcc@1  98.44 ( 97.24)\tAcc@5  99.22 ( 99.60)\n","Epoch: [144][180/391]\tTime  0.170 ( 0.170)\tLoss 5.5595e-02 (1.0401e-01)\tAcc@1  98.44 ( 97.28)\tAcc@5 100.00 ( 99.61)\n","Epoch: [144][210/391]\tTime  0.169 ( 0.170)\tLoss 1.1763e-01 (1.0383e-01)\tAcc@1  97.66 ( 97.28)\tAcc@5 100.00 ( 99.62)\n","Epoch: [144][240/391]\tTime  0.167 ( 0.170)\tLoss 3.0628e-02 (1.0347e-01)\tAcc@1  99.22 ( 97.28)\tAcc@5 100.00 ( 99.65)\n","Epoch: [144][270/391]\tTime  0.169 ( 0.169)\tLoss 1.3773e-01 (1.0266e-01)\tAcc@1  96.09 ( 97.30)\tAcc@5  99.22 ( 99.65)\n","Epoch: [144][300/391]\tTime  0.169 ( 0.169)\tLoss 1.3000e-01 (1.0359e-01)\tAcc@1  96.09 ( 97.26)\tAcc@5  99.22 ( 99.63)\n","Epoch: [144][330/391]\tTime  0.169 ( 0.169)\tLoss 8.4551e-02 (1.0372e-01)\tAcc@1  97.66 ( 97.26)\tAcc@5  99.22 ( 99.62)\n","Epoch: [144][360/391]\tTime  0.170 ( 0.169)\tLoss 1.5856e-01 (1.0433e-01)\tAcc@1  96.09 ( 97.25)\tAcc@5  98.44 ( 99.62)\n","Epoch: [144][390/391]\tTime  0.153 ( 0.169)\tLoss 1.3987e-01 (1.0366e-01)\tAcc@1  96.25 ( 97.29)\tAcc@5 100.00 ( 99.63)\n","==> Train Accuracy: Acc@1 97.292 || Acc@5 99.628\n","==> Test Accuracy:  Acc@1 78.430 || Acc@5 94.700\n","==> 70.42 seconds to train this epoch\n","\n","\n","----- epoch: 145, lr: 0.0008000000000000003 -----\n","Epoch: [145][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.6397e-01 (1.6397e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  97.66 ( 97.66)\n","Epoch: [145][ 30/391]\tTime  0.171 ( 0.172)\tLoss 1.1048e-01 (1.0629e-01)\tAcc@1  96.09 ( 97.28)\tAcc@5 100.00 ( 99.70)\n","Epoch: [145][ 60/391]\tTime  0.170 ( 0.171)\tLoss 6.4902e-02 (1.0758e-01)\tAcc@1 100.00 ( 97.09)\tAcc@5 100.00 ( 99.63)\n","Epoch: [145][ 90/391]\tTime  0.168 ( 0.170)\tLoss 7.4482e-02 (1.0862e-01)\tAcc@1  97.66 ( 97.15)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][120/391]\tTime  0.168 ( 0.170)\tLoss 9.0094e-02 (1.0798e-01)\tAcc@1  98.44 ( 97.18)\tAcc@5  99.22 ( 99.61)\n","Epoch: [145][150/391]\tTime  0.168 ( 0.170)\tLoss 1.3743e-01 (1.0837e-01)\tAcc@1  96.88 ( 97.18)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][180/391]\tTime  0.168 ( 0.170)\tLoss 2.5122e-02 (1.0635e-01)\tAcc@1  99.22 ( 97.26)\tAcc@5 100.00 ( 99.62)\n","Epoch: [145][210/391]\tTime  0.169 ( 0.170)\tLoss 4.3345e-02 (1.0414e-01)\tAcc@1  99.22 ( 97.29)\tAcc@5 100.00 ( 99.64)\n","Epoch: [145][240/391]\tTime  0.168 ( 0.169)\tLoss 1.7230e-01 (1.0488e-01)\tAcc@1  95.31 ( 97.28)\tAcc@5  99.22 ( 99.64)\n","Epoch: [145][270/391]\tTime  0.168 ( 0.169)\tLoss 1.8366e-01 (1.0605e-01)\tAcc@1  95.31 ( 97.25)\tAcc@5  99.22 ( 99.63)\n","Epoch: [145][300/391]\tTime  0.171 ( 0.169)\tLoss 9.4315e-02 (1.0611e-01)\tAcc@1  97.66 ( 97.25)\tAcc@5 100.00 ( 99.64)\n","Epoch: [145][330/391]\tTime  0.172 ( 0.169)\tLoss 8.4896e-02 (1.0568e-01)\tAcc@1  97.66 ( 97.26)\tAcc@5 100.00 ( 99.63)\n","Epoch: [145][360/391]\tTime  0.169 ( 0.169)\tLoss 9.9328e-02 (1.0519e-01)\tAcc@1  96.09 ( 97.26)\tAcc@5 100.00 ( 99.65)\n","Epoch: [145][390/391]\tTime  0.151 ( 0.169)\tLoss 6.1908e-02 (1.0469e-01)\tAcc@1  98.75 ( 97.28)\tAcc@5 100.00 ( 99.65)\n","==> Train Accuracy: Acc@1 97.276 || Acc@5 99.646\n","==> Test Accuracy:  Acc@1 78.280 || Acc@5 94.560\n","==> 70.42 seconds to train this epoch\n","\n","\n","----- epoch: 146, lr: 0.0008000000000000003 -----\n","Epoch: [146][  0/391]\tTime  0.294 ( 0.294)\tLoss 5.4928e-02 (5.4928e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [146][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.2100e-01 (9.3411e-02)\tAcc@1  96.09 ( 97.61)\tAcc@5 100.00 ( 99.77)\n","Epoch: [146][ 60/391]\tTime  0.170 ( 0.171)\tLoss 7.8734e-02 (9.2938e-02)\tAcc@1  97.66 ( 97.62)\tAcc@5 100.00 ( 99.73)\n","Epoch: [146][ 90/391]\tTime  0.170 ( 0.170)\tLoss 1.0838e-01 (1.0086e-01)\tAcc@1  97.66 ( 97.47)\tAcc@5 100.00 ( 99.67)\n","Epoch: [146][120/391]\tTime  0.170 ( 0.170)\tLoss 1.4105e-01 (1.0029e-01)\tAcc@1  96.88 ( 97.43)\tAcc@5  99.22 ( 99.67)\n","Epoch: [146][150/391]\tTime  0.168 ( 0.170)\tLoss 1.7294e-01 (1.0160e-01)\tAcc@1  95.31 ( 97.39)\tAcc@5 100.00 ( 99.64)\n","Epoch: [146][180/391]\tTime  0.169 ( 0.170)\tLoss 1.1206e-01 (1.0022e-01)\tAcc@1  96.09 ( 97.43)\tAcc@5 100.00 ( 99.67)\n","Epoch: [146][210/391]\tTime  0.170 ( 0.170)\tLoss 1.8654e-01 (1.0167e-01)\tAcc@1  93.75 ( 97.37)\tAcc@5  98.44 ( 99.66)\n","Epoch: [146][240/391]\tTime  0.170 ( 0.170)\tLoss 5.4648e-02 (1.0281e-01)\tAcc@1  99.22 ( 97.34)\tAcc@5 100.00 ( 99.63)\n","Epoch: [146][270/391]\tTime  0.170 ( 0.170)\tLoss 7.4589e-02 (1.0311e-01)\tAcc@1  99.22 ( 97.30)\tAcc@5 100.00 ( 99.64)\n","Epoch: [146][300/391]\tTime  0.169 ( 0.170)\tLoss 1.3987e-01 (1.0247e-01)\tAcc@1  96.09 ( 97.27)\tAcc@5 100.00 ( 99.66)\n","Epoch: [146][330/391]\tTime  0.169 ( 0.170)\tLoss 7.1395e-02 (1.0230e-01)\tAcc@1  98.44 ( 97.28)\tAcc@5 100.00 ( 99.66)\n","Epoch: [146][360/391]\tTime  0.169 ( 0.170)\tLoss 1.8430e-01 (1.0365e-01)\tAcc@1  96.09 ( 97.23)\tAcc@5  98.44 ( 99.65)\n","Epoch: [146][390/391]\tTime  0.154 ( 0.169)\tLoss 1.1585e-01 (1.0339e-01)\tAcc@1  97.50 ( 97.26)\tAcc@5 100.00 ( 99.66)\n","==> Train Accuracy: Acc@1 97.264 || Acc@5 99.658\n","==> Test Accuracy:  Acc@1 78.670 || Acc@5 94.550\n","==> 70.45 seconds to train this epoch\n","\n","\n","----- epoch: 147, lr: 0.0008000000000000003 -----\n","Epoch: [147][  0/391]\tTime  0.275 ( 0.275)\tLoss 9.6406e-02 (9.6406e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [147][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.0679e-01 (1.0539e-01)\tAcc@1  96.88 ( 97.18)\tAcc@5  98.44 ( 99.57)\n","Epoch: [147][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.0747e-01 (1.0531e-01)\tAcc@1  96.88 ( 97.27)\tAcc@5 100.00 ( 99.65)\n","Epoch: [147][ 90/391]\tTime  0.170 ( 0.170)\tLoss 5.2018e-02 (1.0605e-01)\tAcc@1  99.22 ( 97.22)\tAcc@5 100.00 ( 99.62)\n","Epoch: [147][120/391]\tTime  0.170 ( 0.170)\tLoss 1.5287e-01 (1.0402e-01)\tAcc@1  94.53 ( 97.24)\tAcc@5  99.22 ( 99.64)\n","Epoch: [147][150/391]\tTime  0.169 ( 0.170)\tLoss 6.7537e-02 (1.0211e-01)\tAcc@1  98.44 ( 97.30)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][180/391]\tTime  0.169 ( 0.170)\tLoss 7.3592e-02 (1.0394e-01)\tAcc@1  98.44 ( 97.24)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][210/391]\tTime  0.168 ( 0.170)\tLoss 9.4120e-02 (1.0291e-01)\tAcc@1  96.88 ( 97.30)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][240/391]\tTime  0.170 ( 0.170)\tLoss 8.9771e-02 (1.0334e-01)\tAcc@1  98.44 ( 97.29)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][270/391]\tTime  0.171 ( 0.170)\tLoss 9.6735e-02 (1.0364e-01)\tAcc@1  96.88 ( 97.27)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][300/391]\tTime  0.170 ( 0.170)\tLoss 9.2093e-02 (1.0256e-01)\tAcc@1  96.09 ( 97.30)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][330/391]\tTime  0.170 ( 0.169)\tLoss 1.0169e-01 (1.0352e-01)\tAcc@1  98.44 ( 97.26)\tAcc@5 100.00 ( 99.63)\n","Epoch: [147][360/391]\tTime  0.169 ( 0.169)\tLoss 8.7178e-02 (1.0327e-01)\tAcc@1  96.88 ( 97.28)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][390/391]\tTime  0.152 ( 0.169)\tLoss 6.1734e-02 (1.0246e-01)\tAcc@1  98.75 ( 97.30)\tAcc@5 100.00 ( 99.64)\n","==> Train Accuracy: Acc@1 97.304 || Acc@5 99.642\n","==> Test Accuracy:  Acc@1 78.510 || Acc@5 94.480\n","==> 70.46 seconds to train this epoch\n","\n","\n","----- epoch: 148, lr: 0.0008000000000000003 -----\n","Epoch: [148][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.1280e-01 (1.1280e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [148][ 30/391]\tTime  0.171 ( 0.172)\tLoss 3.2828e-02 (1.0236e-01)\tAcc@1  99.22 ( 97.33)\tAcc@5 100.00 ( 99.67)\n","Epoch: [148][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.1988e-01 (9.2444e-02)\tAcc@1  96.09 ( 97.64)\tAcc@5  99.22 ( 99.73)\n","Epoch: [148][ 90/391]\tTime  0.169 ( 0.170)\tLoss 4.9619e-02 (9.2851e-02)\tAcc@1  99.22 ( 97.55)\tAcc@5 100.00 ( 99.76)\n","Epoch: [148][120/391]\tTime  0.170 ( 0.170)\tLoss 1.8809e-01 (9.4443e-02)\tAcc@1  96.09 ( 97.55)\tAcc@5  99.22 ( 99.74)\n","Epoch: [148][150/391]\tTime  0.168 ( 0.170)\tLoss 1.1660e-01 (9.7084e-02)\tAcc@1  95.31 ( 97.43)\tAcc@5 100.00 ( 99.72)\n","Epoch: [148][180/391]\tTime  0.170 ( 0.170)\tLoss 1.3376e-01 (9.8505e-02)\tAcc@1  96.88 ( 97.40)\tAcc@5  99.22 ( 99.69)\n","Epoch: [148][210/391]\tTime  0.172 ( 0.170)\tLoss 7.9202e-02 (9.9241e-02)\tAcc@1  99.22 ( 97.39)\tAcc@5 100.00 ( 99.69)\n","Epoch: [148][240/391]\tTime  0.170 ( 0.169)\tLoss 1.0015e-01 (1.0028e-01)\tAcc@1  97.66 ( 97.36)\tAcc@5 100.00 ( 99.69)\n","Epoch: [148][270/391]\tTime  0.170 ( 0.169)\tLoss 7.4498e-02 (1.0089e-01)\tAcc@1  98.44 ( 97.35)\tAcc@5 100.00 ( 99.69)\n","Epoch: [148][300/391]\tTime  0.170 ( 0.169)\tLoss 9.7466e-02 (1.0102e-01)\tAcc@1  97.66 ( 97.35)\tAcc@5  99.22 ( 99.68)\n","Epoch: [148][330/391]\tTime  0.170 ( 0.169)\tLoss 8.8441e-02 (1.0121e-01)\tAcc@1  97.66 ( 97.34)\tAcc@5 100.00 ( 99.68)\n","Epoch: [148][360/391]\tTime  0.170 ( 0.169)\tLoss 1.0944e-01 (1.0143e-01)\tAcc@1  96.88 ( 97.33)\tAcc@5 100.00 ( 99.67)\n","Epoch: [148][390/391]\tTime  0.151 ( 0.169)\tLoss 1.2890e-01 (1.0150e-01)\tAcc@1  97.50 ( 97.32)\tAcc@5  98.75 ( 99.67)\n","==> Train Accuracy: Acc@1 97.322 || Acc@5 99.666\n","==> Test Accuracy:  Acc@1 78.160 || Acc@5 94.450\n","==> 70.35 seconds to train this epoch\n","\n","\n","----- epoch: 149, lr: 0.0008000000000000003 -----\n","Epoch: [149][  0/391]\tTime  0.304 ( 0.304)\tLoss 8.2256e-02 (8.2256e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [149][ 30/391]\tTime  0.169 ( 0.173)\tLoss 7.5068e-02 (1.0393e-01)\tAcc@1  98.44 ( 97.13)\tAcc@5 100.00 ( 99.60)\n","Epoch: [149][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.0513e-01 (9.7631e-02)\tAcc@1  96.88 ( 97.52)\tAcc@5 100.00 ( 99.58)\n","Epoch: [149][ 90/391]\tTime  0.169 ( 0.170)\tLoss 7.2110e-02 (9.5631e-02)\tAcc@1  98.44 ( 97.58)\tAcc@5 100.00 ( 99.56)\n","Epoch: [149][120/391]\tTime  0.169 ( 0.170)\tLoss 7.1969e-02 (9.3064e-02)\tAcc@1  96.88 ( 97.64)\tAcc@5  99.22 ( 99.61)\n","Epoch: [149][150/391]\tTime  0.171 ( 0.170)\tLoss 8.7082e-02 (9.4118e-02)\tAcc@1  99.22 ( 97.63)\tAcc@5 100.00 ( 99.63)\n","Epoch: [149][180/391]\tTime  0.169 ( 0.170)\tLoss 9.3218e-02 (9.7429e-02)\tAcc@1  97.66 ( 97.51)\tAcc@5 100.00 ( 99.62)\n","Epoch: [149][210/391]\tTime  0.168 ( 0.170)\tLoss 6.6240e-02 (9.7816e-02)\tAcc@1  98.44 ( 97.47)\tAcc@5 100.00 ( 99.62)\n","Epoch: [149][240/391]\tTime  0.169 ( 0.169)\tLoss 1.3621e-01 (9.8341e-02)\tAcc@1  96.09 ( 97.48)\tAcc@5  98.44 ( 99.62)\n","Epoch: [149][270/391]\tTime  0.169 ( 0.169)\tLoss 2.0161e-02 (9.8517e-02)\tAcc@1 100.00 ( 97.48)\tAcc@5 100.00 ( 99.63)\n","Epoch: [149][300/391]\tTime  0.170 ( 0.169)\tLoss 9.3716e-02 (9.9676e-02)\tAcc@1  98.44 ( 97.43)\tAcc@5 100.00 ( 99.62)\n","Epoch: [149][330/391]\tTime  0.169 ( 0.169)\tLoss 1.0875e-01 (1.0048e-01)\tAcc@1  97.66 ( 97.41)\tAcc@5 100.00 ( 99.61)\n","Epoch: [149][360/391]\tTime  0.169 ( 0.169)\tLoss 9.5689e-02 (1.0106e-01)\tAcc@1  96.88 ( 97.39)\tAcc@5 100.00 ( 99.61)\n","Epoch: [149][390/391]\tTime  0.153 ( 0.169)\tLoss 7.6768e-02 (1.0051e-01)\tAcc@1  97.50 ( 97.39)\tAcc@5 100.00 ( 99.62)\n","==> Train Accuracy: Acc@1 97.394 || Acc@5 99.616\n","==> Test Accuracy:  Acc@1 78.530 || Acc@5 94.330\n","==> 70.37 seconds to train this epoch\n","\n","Best Top-1 Accuracy: 78.79\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"83eMee323zwe"},"source":[""],"execution_count":null,"outputs":[]}]}