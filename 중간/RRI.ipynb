{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RRI","provenance":[{"file_id":"1A0wPujbwocqJ1virsb4miBvqIqiNshTP","timestamp":1620923757722},{"file_id":"1NBZijnKI-JSQWMRa_ie6TIGgiCotY-oF","timestamp":1620558492502},{"file_id":"18b80wpeQD1Wj6NjwZFFhZGDuMWWW1TIZ","timestamp":1619286623952},{"file_id":"1pSPNcOLDPSKONSeGALl1Jplu9ET9z-1q","timestamp":1619081668342}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9d9ba54affdd41f3b0a487daadbf3513":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d406d0b39bb04baca6a4701a0c1a7cad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b2f9a8fe18514dcfadc5b7be69dddc1d","IPY_MODEL_79e2a23767294f2394b0e95ccbc59959"]}},"d406d0b39bb04baca6a4701a0c1a7cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2f9a8fe18514dcfadc5b7be69dddc1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9212a8dce9f6494ca40adb89807ffcb1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63bcda510be742809a726add45beccee"}},"79e2a23767294f2394b0e95ccbc59959":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5402c5028d8d4b5cab890e7c30c93e0a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [01:34&lt;00:00, 1779605.77it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d07ba303238436083cf0a4b8420bb1d"}},"9212a8dce9f6494ca40adb89807ffcb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"63bcda510be742809a726add45beccee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5402c5028d8d4b5cab890e7c30c93e0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d07ba303238436083cf0a4b8420bb1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OSFGYaIDG6f0"},"source":["Cutout Data Augmentation.\n","\n","This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"]},{"cell_type":"markdown","metadata":{"id":"vCVSE5-UboYl"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"id":"5YBMwPsubsbX","executionInfo":{"status":"ok","timestamp":1620927873027,"user_tz":-540,"elapsed":4322,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L88afYXKMSdL"},"source":["##**Model - Define ResNet Model**\n"]},{"cell_type":"code","metadata":{"id":"eMFSLTnkMQdq","executionInfo":{"status":"ok","timestamp":1620927874986,"user_tz":-540,"elapsed":795,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["'''ResNet18/34/50/101/152 in Pytorch.'''\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18(num_classes=10):\n","    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n","\n","def ResNet34(num_classes=10):\n","    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n","\n","def ResNet50(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n","\n","def ResNet101(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n","\n","def ResNet152(num_classes=10):\n","    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n","\n","def test_resnet():\n","    net = ResNet50()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test_resnet()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjM3cl279Lvg"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"gIvuSgE49Kvu","executionInfo":{"status":"ok","timestamp":1620927875325,"user_tz":-540,"elapsed":711,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6y3zhSfMbdC"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"iMQI2K4AMopg","executionInfo":{"status":"ok","timestamp":1620927875728,"user_tz":-540,"elapsed":708,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wwiHSMvG-W3_"},"source":["##**InAugment**"]},{"cell_type":"markdown","metadata":{"id":"3Qe0DfFrmMMj"},"source":["InAugment 구현을 위해 autoaugment코드와 randomcolorgitter 코드를 사용하였습니다."]},{"cell_type":"code","metadata":{"id":"pKjdnW7vmxNV","executionInfo":{"status":"ok","timestamp":1620927877587,"user_tz":-540,"elapsed":1962,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["from PIL import Image, ImageEnhance, ImageOps, ImageChops\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import random\n","import pdb\n","import cv2\n","import torchvision.transforms.functional as TF\n","\n","class CIFAR100Policy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n","        Example:\n","        >>> policy = CIFAR10Policy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     CIFAR10Policy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n","            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n","            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n","            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n","\n","            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n","            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n","            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n","            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n","            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n","            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n","            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n","            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n","\n","            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n","            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n","            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n","            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n","\n","            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n","            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n","        ]\n","\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment CIFAR10 Policy\"\n","\n","class SubPolicy(object):\n","    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n","        ranges = {\n","            \"shearX\": np.linspace(0, 0.3, 10),\n","            \"shearY\": np.linspace(0, 0.3, 10),\n","            \"translateX\": np.linspace(0, 150 / 331, 10),\n","            \"translateY\": np.linspace(0, 150 / 331, 10),\n","            \"rotate\": np.linspace(0, 30, 10),\n","            \"color\": np.linspace(0.0, 0.9, 10),\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n","            \"solarize\": np.linspace(256, 0, 10),\n","            \"contrast\": np.linspace(0.0, 0.9, 10),\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\n","            \"brightness\": np.linspace(0.0, 0.9, 10),\n","            \"autocontrast\": [0] * 10,\n","            \"equalize\": [0] * 10,\n","            \"invert\": [0] * 10\n","        }\n","\n","        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n","        def rotate_with_fill(img, magnitude):\n","            rot = img.convert(\"RGBA\").rotate(magnitude)\n","            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n","\n","        func = {\n","            \"shearX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"shearY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"translateX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n","                fillcolor=fillcolor),\n","            \"translateY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n","                fillcolor=fillcolor),\n","            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n","            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n","        }\n","\n","        self.p1 = p1\n","        self.operation1 = func[operation1]\n","        self.magnitude1 = ranges[operation1][magnitude_idx1]\n","        self.p2 = p2\n","        self.operation2 = func[operation2]\n","        self.magnitude2 = ranges[operation2][magnitude_idx2]\n","\n","\n","    def __call__(self, img):\n","        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n","        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n","        return img"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUkFQM-VKEXn","executionInfo":{"status":"ok","timestamp":1620927877590,"user_tz":-540,"elapsed":1765,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["import random\n","import torchvision.transforms.functional as TF\n","\n","class RandomGamma(object):\n","    def __init__(self, gamma_p = 0.5, gamma_ratio=(0,1.5)):\n","        self.gamma_p = gamma_p\n","        self.gamma_ratio = gamma_ratio\n","\n","    def __call__(self,img):\n","        if random.uniform(0, 1) < self.gamma_p:\n","            gamma = random.uniform(self.gamma_ratio[0], self.gamma_ratio[1])\n","            img = TF.adjust_gamma(img, gamma, gain=1)\n","            return img\n","        else:\n","            return img\n","\n","class RandomColorJitter(object):\n","    def __init__(self, p = 0.5, brightness_ratio=(0,2), contrast_ratio=(0,2), \\\n","                saturation_ratio=(0,2), hue_ratio=(-0.5,0.5)):\n","        self.p = p\n","        self.brightness_ratio = brightness_ratio\n","        self.contrast_ratio = contrast_ratio\n","        self.saturation_ratio = saturation_ratio\n","        self.hue_ratio = hue_ratio\n","\n","    @staticmethod\n","    def process(img, brightness_ratio, contrast_ratio, saturation_ratio, hue_ratio):\n","        brightness = random.uniform(brightness_ratio[0], brightness_ratio[1])\n","        contrast = random.uniform(contrast_ratio[0], contrast_ratio[1])\n","        saturation = random.uniform(saturation_ratio[0], saturation_ratio[1])\n","        hue = random.uniform(hue_ratio[0], hue_ratio[1])\n","\n","        img = TF.adjust_brightness(img, brightness)\n","        img = TF.adjust_contrast(img, contrast)\n","        img = TF.adjust_saturation(img, saturation)\n","        img = TF.adjust_hue(img, hue)\n","\n","        return img\n","\n","    def __call__(self,img):\n","        if random.uniform(0, 1) < self.p:\n","            img = self.process(img, self.brightness_ratio, self.contrast_ratio, \\\n","                                self.saturation_ratio, self.hue_ratio)\n","            return img\n","        else:\n","            return img"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"fAl0bU6P-WYq","executionInfo":{"status":"ok","timestamp":1620927877591,"user_tz":-540,"elapsed":1571,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["from PIL import Image\n","class InAugment(object):\n","  def __init__(self, num =1, length=16, re_length=20):\n","    self.num = num\n","    self.length = length\n","    self.re_length = re_length\n","  \n","  def __call__(self,img):\n","    imgs = []\n","    h = img.size[0]\n","    w = img.size[1]\n","    for n in range(self.num):\n","      y = np.random.randint(h)\n","      x = np.random.randint(w)\n","\n","      y1 = np.clip(y - self.length // 2, 0, h)\n","      y2 = np.clip(y + self.length // 2, 0, h)\n","      x1 = np.clip(x - self.length // 2, 0, w)\n","      x2 = np.clip(x + self.length // 2, 0, w)\n","      \n","      # 이미지 자르기 crop함수 이용 ex. crop(left, up, right, down)\n","      croppedImage = img.crop((x1,y1,x2,y2))\n","\n","      # 자른 사진에 대해서 autoaugment 적용\n","      # 트레이닝 시간이 오래 걸려 제외\n","      #policy = CIFAR100Policy()\n","      #augImage = policy(croppedImage)\n","\n","      # Autoaugment 대신에 RandomColorJitter()를 이용해서 변화를 주는 방식으로 대체\n","      #r1 = RandomColorJitter()\n","      #r2 = RandomGamma()\n","      #augImage = r1(croppedImage)\n","      #augImage = r2(augImage)\n","\n","      # random rotate\n","      degree = [0, 90, 180, 270]\n","      augImage = croppedImage.rotate(random.choice(degree))\n","      resizeImage = augImage.resize((self.re_length, self.re_length))\n","      imgs.append(resizeImage)\n","\n","    for n in range(self.num):\n","      img.paste(imgs[n], (random.randint(0,32),random.randint(0,32)))\n","\n","    return img"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s8oXpzdMvol"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"Pjeqawi9cNK6","executionInfo":{"status":"ok","timestamp":1620927877591,"user_tz":-540,"elapsed":1171,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}}},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'resnet34' # resnet18, resnet50, resnet101\n","batch_size = 128  # Input batch size for training (default: 128)\n","epochs = 150 # Number of epochs to train (default: 200)\n","learning_rate = 0.1 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","cutout = False # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","seed = 0 # Random seed (default: 0)\n","print_freq = 30\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","# What we need for our data augmentation\n","re_length = 20\n","inaugment = True\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXL_PBj6cVoe"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119,"referenced_widgets":["9d9ba54affdd41f3b0a487daadbf3513","d406d0b39bb04baca6a4701a0c1a7cad","b2f9a8fe18514dcfadc5b7be69dddc1d","79e2a23767294f2394b0e95ccbc59959","9212a8dce9f6494ca40adb89807ffcb1","63bcda510be742809a726add45beccee","5402c5028d8d4b5cab890e7c30c93e0a","7d07ba303238436083cf0a4b8420bb1d"]},"id":"dvQjH3T9caYs","executionInfo":{"status":"ok","timestamp":1620927886198,"user_tz":-540,"elapsed":9388,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}},"outputId":"a70eba94-cf50-4be9-896c-8e55b7e196c9"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","train_transform = transforms.Compose([])\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","\n","if inaugment:\n","    train_transform.transforms.append(InAugment(num=n_holes,length=length,re_length=re_length))\n","    \n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d9ba54affdd41f3b0a487daadbf3513","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gITLQIAr9lAZ"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"id":"s0-lYvAp9oHA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620938527487,"user_tz":-540,"elapsed":3551410,"user":{"displayName":"류지혜","photoUrl":"","userId":"16809536553687781363"}},"outputId":"1803ac91-1fb8-4592-a2ff-a3d58468b2b3"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","model = ResNet34(num_classes=num_classes).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n","\n","scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","###########################################################\n","best_acc = 0\n","for epoch in range(epochs):\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), 'model_best.pt')\n","\n","torch.save(model.state_dict(),'model_latest.pt')\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\n","----- epoch: 0, lr: 0.1 -----\n","Epoch: [0][  0/391]\tTime  1.261 ( 1.261)\tLoss 4.7385e+00 (4.7385e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   7.03 (  7.03)\n","Epoch: [0][ 30/391]\tTime  0.162 ( 0.194)\tLoss 4.5315e+00 (5.2288e+00)\tAcc@1   3.12 (  1.64)\tAcc@5   7.03 (  6.45)\n","Epoch: [0][ 60/391]\tTime  0.163 ( 0.178)\tLoss 4.3279e+00 (4.8639e+00)\tAcc@1   1.56 (  1.87)\tAcc@5  10.94 (  8.68)\n","Epoch: [0][ 90/391]\tTime  0.158 ( 0.173)\tLoss 4.2136e+00 (4.6848e+00)\tAcc@1   2.34 (  2.48)\tAcc@5  17.97 ( 10.73)\n","Epoch: [0][120/391]\tTime  0.165 ( 0.171)\tLoss 4.2146e+00 (4.5778e+00)\tAcc@1   7.81 (  2.90)\tAcc@5  20.31 ( 12.48)\n","Epoch: [0][150/391]\tTime  0.164 ( 0.170)\tLoss 4.2409e+00 (4.5015e+00)\tAcc@1   3.12 (  3.29)\tAcc@5  18.75 ( 13.87)\n","Epoch: [0][180/391]\tTime  0.168 ( 0.169)\tLoss 4.1336e+00 (4.4384e+00)\tAcc@1   2.34 (  3.59)\tAcc@5  18.75 ( 15.03)\n","Epoch: [0][210/391]\tTime  0.169 ( 0.169)\tLoss 4.0102e+00 (4.3836e+00)\tAcc@1   3.91 (  3.90)\tAcc@5  28.91 ( 16.23)\n","Epoch: [0][240/391]\tTime  0.169 ( 0.169)\tLoss 4.0473e+00 (4.3406e+00)\tAcc@1   7.81 (  4.26)\tAcc@5  24.22 ( 17.21)\n","Epoch: [0][270/391]\tTime  0.170 ( 0.168)\tLoss 4.1211e+00 (4.3058e+00)\tAcc@1   7.03 (  4.55)\tAcc@5  16.41 ( 17.98)\n","Epoch: [0][300/391]\tTime  0.169 ( 0.169)\tLoss 3.9441e+00 (4.2744e+00)\tAcc@1  12.50 (  4.81)\tAcc@5  32.81 ( 18.78)\n","Epoch: [0][330/391]\tTime  0.172 ( 0.169)\tLoss 4.1467e+00 (4.2482e+00)\tAcc@1   3.12 (  5.06)\tAcc@5  22.66 ( 19.40)\n","Epoch: [0][360/391]\tTime  0.170 ( 0.169)\tLoss 3.9857e+00 (4.2237e+00)\tAcc@1   4.69 (  5.27)\tAcc@5  20.31 ( 20.02)\n","Epoch: [0][390/391]\tTime  0.738 ( 0.171)\tLoss 4.0154e+00 (4.2036e+00)\tAcc@1  12.50 (  5.48)\tAcc@5  27.50 ( 20.55)\n","==> Train Accuracy: Acc@1 5.484 || Acc@5 20.548\n","==> Test Accuracy:  Acc@1 10.370 || Acc@5 31.640\n","==> 71.08 seconds to train this epoch\n","\n","\n","----- epoch: 1, lr: 0.1 -----\n","Epoch: [1][  0/391]\tTime  0.287 ( 0.287)\tLoss 3.9774e+00 (3.9774e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  25.78 ( 25.78)\n","Epoch: [1][ 30/391]\tTime  0.170 ( 0.176)\tLoss 3.7055e+00 (3.8427e+00)\tAcc@1   7.81 (  9.70)\tAcc@5  34.38 ( 31.40)\n","Epoch: [1][ 60/391]\tTime  0.171 ( 0.175)\tLoss 3.8273e+00 (3.8413e+00)\tAcc@1   6.25 (  9.57)\tAcc@5  31.25 ( 30.81)\n","Epoch: [1][ 90/391]\tTime  0.172 ( 0.174)\tLoss 3.8369e+00 (3.8360e+00)\tAcc@1   9.38 (  9.60)\tAcc@5  35.16 ( 30.75)\n","Epoch: [1][120/391]\tTime  0.171 ( 0.173)\tLoss 3.8458e+00 (3.8285e+00)\tAcc@1   9.38 (  9.65)\tAcc@5  35.94 ( 31.25)\n","Epoch: [1][150/391]\tTime  0.170 ( 0.173)\tLoss 3.6394e+00 (3.8236e+00)\tAcc@1  13.28 (  9.59)\tAcc@5  34.38 ( 31.31)\n","Epoch: [1][180/391]\tTime  0.170 ( 0.172)\tLoss 3.7803e+00 (3.8191e+00)\tAcc@1  10.94 (  9.64)\tAcc@5  33.59 ( 31.50)\n","Epoch: [1][210/391]\tTime  0.168 ( 0.172)\tLoss 3.5574e+00 (3.8091e+00)\tAcc@1  12.50 (  9.76)\tAcc@5  39.84 ( 31.81)\n","Epoch: [1][240/391]\tTime  0.170 ( 0.172)\tLoss 3.6372e+00 (3.8012e+00)\tAcc@1  12.50 ( 10.00)\tAcc@5  37.50 ( 32.12)\n","Epoch: [1][270/391]\tTime  0.172 ( 0.171)\tLoss 3.7633e+00 (3.7898e+00)\tAcc@1  10.94 ( 10.18)\tAcc@5  37.50 ( 32.51)\n","Epoch: [1][300/391]\tTime  0.170 ( 0.171)\tLoss 3.6604e+00 (3.7796e+00)\tAcc@1  11.72 ( 10.38)\tAcc@5  36.72 ( 32.78)\n","Epoch: [1][330/391]\tTime  0.170 ( 0.171)\tLoss 3.6465e+00 (3.7723e+00)\tAcc@1  13.28 ( 10.50)\tAcc@5  41.41 ( 33.06)\n","Epoch: [1][360/391]\tTime  0.171 ( 0.171)\tLoss 3.7700e+00 (3.7640e+00)\tAcc@1  11.72 ( 10.66)\tAcc@5  35.94 ( 33.38)\n","Epoch: [1][390/391]\tTime  0.153 ( 0.171)\tLoss 3.7603e+00 (3.7536e+00)\tAcc@1  10.00 ( 10.87)\tAcc@5  35.00 ( 33.65)\n","==> Train Accuracy: Acc@1 10.872 || Acc@5 33.650\n","==> Test Accuracy:  Acc@1 15.250 || Acc@5 41.770\n","==> 71.01 seconds to train this epoch\n","\n","\n","----- epoch: 2, lr: 0.1 -----\n","Epoch: [2][  0/391]\tTime  0.277 ( 0.277)\tLoss 3.5230e+00 (3.5230e+00)\tAcc@1  17.19 ( 17.19)\tAcc@5  45.31 ( 45.31)\n","Epoch: [2][ 30/391]\tTime  0.171 ( 0.174)\tLoss 3.5251e+00 (3.5691e+00)\tAcc@1  12.50 ( 13.33)\tAcc@5  38.28 ( 40.30)\n","Epoch: [2][ 60/391]\tTime  0.167 ( 0.173)\tLoss 3.3615e+00 (3.5634e+00)\tAcc@1  21.09 ( 13.86)\tAcc@5  43.75 ( 39.87)\n","Epoch: [2][ 90/391]\tTime  0.170 ( 0.172)\tLoss 3.7161e+00 (3.5557e+00)\tAcc@1  14.84 ( 14.24)\tAcc@5  38.28 ( 40.06)\n","Epoch: [2][120/391]\tTime  0.171 ( 0.172)\tLoss 3.7064e+00 (3.5422e+00)\tAcc@1  14.84 ( 14.57)\tAcc@5  32.03 ( 40.42)\n","Epoch: [2][150/391]\tTime  0.172 ( 0.172)\tLoss 3.4679e+00 (3.5277e+00)\tAcc@1  17.97 ( 14.80)\tAcc@5  44.53 ( 40.88)\n","Epoch: [2][180/391]\tTime  0.172 ( 0.172)\tLoss 3.3989e+00 (3.5192e+00)\tAcc@1  21.09 ( 15.02)\tAcc@5  44.53 ( 41.07)\n","Epoch: [2][210/391]\tTime  0.171 ( 0.172)\tLoss 3.4957e+00 (3.5123e+00)\tAcc@1  21.09 ( 15.17)\tAcc@5  44.53 ( 41.30)\n","Epoch: [2][240/391]\tTime  0.171 ( 0.172)\tLoss 3.4287e+00 (3.4963e+00)\tAcc@1  18.75 ( 15.52)\tAcc@5  42.19 ( 41.73)\n","Epoch: [2][270/391]\tTime  0.171 ( 0.171)\tLoss 3.2448e+00 (3.4803e+00)\tAcc@1  18.75 ( 15.75)\tAcc@5  48.44 ( 42.20)\n","Epoch: [2][300/391]\tTime  0.170 ( 0.171)\tLoss 3.4984e+00 (3.4667e+00)\tAcc@1  14.06 ( 15.99)\tAcc@5  42.97 ( 42.60)\n","Epoch: [2][330/391]\tTime  0.172 ( 0.171)\tLoss 3.2783e+00 (3.4562e+00)\tAcc@1  21.88 ( 16.24)\tAcc@5  52.34 ( 42.90)\n","Epoch: [2][360/391]\tTime  0.169 ( 0.171)\tLoss 3.2130e+00 (3.4471e+00)\tAcc@1  25.00 ( 16.44)\tAcc@5  52.34 ( 43.19)\n","Epoch: [2][390/391]\tTime  0.154 ( 0.171)\tLoss 3.2435e+00 (3.4340e+00)\tAcc@1  25.00 ( 16.66)\tAcc@5  50.00 ( 43.50)\n","==> Train Accuracy: Acc@1 16.664 || Acc@5 43.498\n","==> Test Accuracy:  Acc@1 22.800 || Acc@5 53.770\n","==> 71.08 seconds to train this epoch\n","\n","\n","----- epoch: 3, lr: 0.1 -----\n","Epoch: [3][  0/391]\tTime  0.304 ( 0.304)\tLoss 3.0598e+00 (3.0598e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  50.00 ( 50.00)\n","Epoch: [3][ 30/391]\tTime  0.169 ( 0.174)\tLoss 3.2035e+00 (3.2392e+00)\tAcc@1  25.00 ( 19.91)\tAcc@5  49.22 ( 49.34)\n","Epoch: [3][ 60/391]\tTime  0.171 ( 0.173)\tLoss 3.1630e+00 (3.2231e+00)\tAcc@1  24.22 ( 20.35)\tAcc@5  55.47 ( 49.76)\n","Epoch: [3][ 90/391]\tTime  0.171 ( 0.172)\tLoss 3.2412e+00 (3.2052e+00)\tAcc@1  19.53 ( 20.99)\tAcc@5  48.44 ( 50.02)\n","Epoch: [3][120/391]\tTime  0.171 ( 0.172)\tLoss 3.3032e+00 (3.2069e+00)\tAcc@1  19.53 ( 20.93)\tAcc@5  42.19 ( 49.99)\n","Epoch: [3][150/391]\tTime  0.172 ( 0.172)\tLoss 3.0419e+00 (3.1996e+00)\tAcc@1  23.44 ( 20.98)\tAcc@5  60.16 ( 50.37)\n","Epoch: [3][180/391]\tTime  0.172 ( 0.172)\tLoss 3.2023e+00 (3.1894e+00)\tAcc@1  18.75 ( 21.19)\tAcc@5  52.34 ( 50.61)\n","Epoch: [3][210/391]\tTime  0.173 ( 0.172)\tLoss 3.0610e+00 (3.1835e+00)\tAcc@1  25.00 ( 21.34)\tAcc@5  57.03 ( 50.73)\n","Epoch: [3][240/391]\tTime  0.172 ( 0.172)\tLoss 3.3931e+00 (3.1740e+00)\tAcc@1  19.53 ( 21.48)\tAcc@5  45.31 ( 51.12)\n","Epoch: [3][270/391]\tTime  0.170 ( 0.172)\tLoss 3.3754e+00 (3.1647e+00)\tAcc@1  20.31 ( 21.62)\tAcc@5  46.09 ( 51.36)\n","Epoch: [3][300/391]\tTime  0.173 ( 0.172)\tLoss 3.0575e+00 (3.1556e+00)\tAcc@1  21.09 ( 21.73)\tAcc@5  53.12 ( 51.54)\n","Epoch: [3][330/391]\tTime  0.173 ( 0.172)\tLoss 3.0125e+00 (3.1443e+00)\tAcc@1  25.78 ( 21.94)\tAcc@5  59.38 ( 51.80)\n","Epoch: [3][360/391]\tTime  0.171 ( 0.172)\tLoss 2.9330e+00 (3.1350e+00)\tAcc@1  30.47 ( 22.17)\tAcc@5  54.69 ( 52.06)\n","Epoch: [3][390/391]\tTime  0.154 ( 0.172)\tLoss 3.0196e+00 (3.1222e+00)\tAcc@1  26.25 ( 22.43)\tAcc@5  56.25 ( 52.35)\n","==> Train Accuracy: Acc@1 22.434 || Acc@5 52.350\n","==> Test Accuracy:  Acc@1 25.880 || Acc@5 58.200\n","==> 71.27 seconds to train this epoch\n","\n","\n","----- epoch: 4, lr: 0.1 -----\n","Epoch: [4][  0/391]\tTime  0.281 ( 0.281)\tLoss 2.9394e+00 (2.9394e+00)\tAcc@1  23.44 ( 23.44)\tAcc@5  61.72 ( 61.72)\n","Epoch: [4][ 30/391]\tTime  0.171 ( 0.173)\tLoss 3.0793e+00 (2.9407e+00)\tAcc@1  25.00 ( 25.00)\tAcc@5  51.56 ( 57.48)\n","Epoch: [4][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.8896e+00 (2.9441e+00)\tAcc@1  25.78 ( 25.63)\tAcc@5  59.38 ( 57.11)\n","Epoch: [4][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.8848e+00 (2.9247e+00)\tAcc@1  28.91 ( 26.37)\tAcc@5  58.59 ( 57.37)\n","Epoch: [4][120/391]\tTime  0.170 ( 0.171)\tLoss 2.7716e+00 (2.9147e+00)\tAcc@1  30.47 ( 26.43)\tAcc@5  60.94 ( 57.62)\n","Epoch: [4][150/391]\tTime  0.172 ( 0.171)\tLoss 3.0949e+00 (2.9082e+00)\tAcc@1  15.62 ( 26.47)\tAcc@5  54.69 ( 57.67)\n","Epoch: [4][180/391]\tTime  0.172 ( 0.171)\tLoss 3.2422e+00 (2.9017e+00)\tAcc@1  21.09 ( 26.62)\tAcc@5  49.22 ( 57.58)\n","Epoch: [4][210/391]\tTime  0.172 ( 0.171)\tLoss 2.7237e+00 (2.8955e+00)\tAcc@1  32.03 ( 26.78)\tAcc@5  59.38 ( 57.73)\n","Epoch: [4][240/391]\tTime  0.171 ( 0.171)\tLoss 2.8540e+00 (2.8918e+00)\tAcc@1  28.12 ( 26.92)\tAcc@5  55.47 ( 57.84)\n","Epoch: [4][270/391]\tTime  0.170 ( 0.171)\tLoss 2.9102e+00 (2.8818e+00)\tAcc@1  28.12 ( 27.03)\tAcc@5  57.03 ( 57.99)\n","Epoch: [4][300/391]\tTime  0.170 ( 0.171)\tLoss 2.9445e+00 (2.8772e+00)\tAcc@1  23.44 ( 27.13)\tAcc@5  54.69 ( 58.13)\n","Epoch: [4][330/391]\tTime  0.171 ( 0.171)\tLoss 2.6213e+00 (2.8699e+00)\tAcc@1  32.03 ( 27.28)\tAcc@5  60.94 ( 58.40)\n","Epoch: [4][360/391]\tTime  0.171 ( 0.171)\tLoss 3.0768e+00 (2.8714e+00)\tAcc@1  21.88 ( 27.27)\tAcc@5  53.91 ( 58.47)\n","Epoch: [4][390/391]\tTime  0.153 ( 0.171)\tLoss 2.7879e+00 (2.8631e+00)\tAcc@1  30.00 ( 27.41)\tAcc@5  63.75 ( 58.71)\n","==> Train Accuracy: Acc@1 27.410 || Acc@5 58.712\n","==> Test Accuracy:  Acc@1 30.200 || Acc@5 62.920\n","==> 71.06 seconds to train this epoch\n","\n","\n","----- epoch: 5, lr: 0.1 -----\n","Epoch: [5][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.6863e+00 (2.6863e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  64.84 ( 64.84)\n","Epoch: [5][ 30/391]\tTime  0.172 ( 0.174)\tLoss 2.4379e+00 (2.6896e+00)\tAcc@1  36.72 ( 30.67)\tAcc@5  69.53 ( 62.83)\n","Epoch: [5][ 60/391]\tTime  0.173 ( 0.172)\tLoss 2.6655e+00 (2.6866e+00)\tAcc@1  32.03 ( 31.28)\tAcc@5  64.84 ( 62.55)\n","Epoch: [5][ 90/391]\tTime  0.172 ( 0.172)\tLoss 2.8447e+00 (2.6987e+00)\tAcc@1  27.34 ( 30.80)\tAcc@5  63.28 ( 62.53)\n","Epoch: [5][120/391]\tTime  0.171 ( 0.172)\tLoss 3.0103e+00 (2.7027e+00)\tAcc@1  27.34 ( 30.79)\tAcc@5  52.34 ( 62.55)\n","Epoch: [5][150/391]\tTime  0.172 ( 0.172)\tLoss 2.3419e+00 (2.6926e+00)\tAcc@1  38.28 ( 31.08)\tAcc@5  68.75 ( 62.84)\n","Epoch: [5][180/391]\tTime  0.171 ( 0.172)\tLoss 2.5273e+00 (2.6866e+00)\tAcc@1  38.28 ( 31.16)\tAcc@5  64.84 ( 62.93)\n","Epoch: [5][210/391]\tTime  0.170 ( 0.171)\tLoss 2.7941e+00 (2.6820e+00)\tAcc@1  29.69 ( 31.23)\tAcc@5  60.94 ( 63.09)\n","Epoch: [5][240/391]\tTime  0.172 ( 0.171)\tLoss 2.4660e+00 (2.6812e+00)\tAcc@1  33.59 ( 31.15)\tAcc@5  67.19 ( 63.14)\n","Epoch: [5][270/391]\tTime  0.168 ( 0.171)\tLoss 2.6129e+00 (2.6759e+00)\tAcc@1  36.72 ( 31.34)\tAcc@5  63.28 ( 63.30)\n","Epoch: [5][300/391]\tTime  0.173 ( 0.171)\tLoss 2.7009e+00 (2.6678e+00)\tAcc@1  32.81 ( 31.43)\tAcc@5  65.62 ( 63.44)\n","Epoch: [5][330/391]\tTime  0.171 ( 0.171)\tLoss 2.6269e+00 (2.6628e+00)\tAcc@1  32.81 ( 31.54)\tAcc@5  60.94 ( 63.57)\n","Epoch: [5][360/391]\tTime  0.170 ( 0.171)\tLoss 2.3555e+00 (2.6595e+00)\tAcc@1  39.84 ( 31.65)\tAcc@5  70.31 ( 63.66)\n","Epoch: [5][390/391]\tTime  0.153 ( 0.171)\tLoss 2.8174e+00 (2.6538e+00)\tAcc@1  32.50 ( 31.77)\tAcc@5  60.00 ( 63.75)\n","==> Train Accuracy: Acc@1 31.768 || Acc@5 63.746\n","==> Test Accuracy:  Acc@1 35.310 || Acc@5 68.120\n","==> 71.13 seconds to train this epoch\n","\n","\n","----- epoch: 6, lr: 0.1 -----\n","Epoch: [6][  0/391]\tTime  0.288 ( 0.288)\tLoss 2.7284e+00 (2.7284e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  60.94 ( 60.94)\n","Epoch: [6][ 30/391]\tTime  0.173 ( 0.174)\tLoss 2.4510e+00 (2.5171e+00)\tAcc@1  36.72 ( 34.63)\tAcc@5  65.62 ( 67.74)\n","Epoch: [6][ 60/391]\tTime  0.168 ( 0.172)\tLoss 2.4889e+00 (2.5213e+00)\tAcc@1  32.81 ( 34.59)\tAcc@5  65.62 ( 66.48)\n","Epoch: [6][ 90/391]\tTime  0.170 ( 0.172)\tLoss 2.5308e+00 (2.5273e+00)\tAcc@1  33.59 ( 34.44)\tAcc@5  67.97 ( 66.51)\n","Epoch: [6][120/391]\tTime  0.170 ( 0.171)\tLoss 2.5849e+00 (2.5187e+00)\tAcc@1  34.38 ( 34.71)\tAcc@5  65.62 ( 66.75)\n","Epoch: [6][150/391]\tTime  0.169 ( 0.171)\tLoss 2.2920e+00 (2.5024e+00)\tAcc@1  38.28 ( 35.11)\tAcc@5  73.44 ( 67.20)\n","Epoch: [6][180/391]\tTime  0.171 ( 0.171)\tLoss 2.3096e+00 (2.4949e+00)\tAcc@1  36.72 ( 35.26)\tAcc@5  71.09 ( 67.39)\n","Epoch: [6][210/391]\tTime  0.170 ( 0.171)\tLoss 2.4895e+00 (2.4920e+00)\tAcc@1  34.38 ( 35.31)\tAcc@5  68.75 ( 67.46)\n","Epoch: [6][240/391]\tTime  0.171 ( 0.171)\tLoss 2.2432e+00 (2.4939e+00)\tAcc@1  41.41 ( 35.21)\tAcc@5  72.66 ( 67.36)\n","Epoch: [6][270/391]\tTime  0.171 ( 0.171)\tLoss 2.4243e+00 (2.4898e+00)\tAcc@1  39.84 ( 35.26)\tAcc@5  72.66 ( 67.46)\n","Epoch: [6][300/391]\tTime  0.171 ( 0.171)\tLoss 2.4664e+00 (2.4862e+00)\tAcc@1  33.59 ( 35.27)\tAcc@5  62.50 ( 67.51)\n","Epoch: [6][330/391]\tTime  0.171 ( 0.171)\tLoss 2.7120e+00 (2.4798e+00)\tAcc@1  34.38 ( 35.45)\tAcc@5  64.06 ( 67.68)\n","Epoch: [6][360/391]\tTime  0.171 ( 0.171)\tLoss 2.4974e+00 (2.4740e+00)\tAcc@1  38.28 ( 35.55)\tAcc@5  65.62 ( 67.77)\n","Epoch: [6][390/391]\tTime  0.153 ( 0.171)\tLoss 2.7322e+00 (2.4693e+00)\tAcc@1  32.50 ( 35.65)\tAcc@5  62.50 ( 67.82)\n","==> Train Accuracy: Acc@1 35.650 || Acc@5 67.816\n","==> Test Accuracy:  Acc@1 37.600 || Acc@5 70.290\n","==> 71.02 seconds to train this epoch\n","\n","\n","----- epoch: 7, lr: 0.1 -----\n","Epoch: [7][  0/391]\tTime  0.290 ( 0.290)\tLoss 2.3184e+00 (2.3184e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  68.75 ( 68.75)\n","Epoch: [7][ 30/391]\tTime  0.171 ( 0.174)\tLoss 2.5900e+00 (2.3054e+00)\tAcc@1  32.03 ( 38.79)\tAcc@5  67.97 ( 71.45)\n","Epoch: [7][ 60/391]\tTime  0.170 ( 0.173)\tLoss 2.5890e+00 (2.3144e+00)\tAcc@1  32.03 ( 38.83)\tAcc@5  66.41 ( 71.34)\n","Epoch: [7][ 90/391]\tTime  0.173 ( 0.172)\tLoss 2.2813e+00 (2.3255e+00)\tAcc@1  40.62 ( 38.73)\tAcc@5  66.41 ( 71.27)\n","Epoch: [7][120/391]\tTime  0.171 ( 0.172)\tLoss 2.3002e+00 (2.3389e+00)\tAcc@1  44.53 ( 38.37)\tAcc@5  71.09 ( 70.76)\n","Epoch: [7][150/391]\tTime  0.169 ( 0.172)\tLoss 2.7000e+00 (2.3471e+00)\tAcc@1  29.69 ( 38.09)\tAcc@5  65.62 ( 70.62)\n","Epoch: [7][180/391]\tTime  0.171 ( 0.171)\tLoss 2.3772e+00 (2.3411e+00)\tAcc@1  37.50 ( 38.18)\tAcc@5  70.31 ( 70.70)\n","Epoch: [7][210/391]\tTime  0.173 ( 0.171)\tLoss 2.2900e+00 (2.3401e+00)\tAcc@1  39.06 ( 38.28)\tAcc@5  74.22 ( 70.68)\n","Epoch: [7][240/391]\tTime  0.171 ( 0.171)\tLoss 2.6173e+00 (2.3417e+00)\tAcc@1  32.81 ( 38.30)\tAcc@5  64.84 ( 70.62)\n","Epoch: [7][270/391]\tTime  0.169 ( 0.171)\tLoss 2.4452e+00 (2.3474e+00)\tAcc@1  43.75 ( 38.25)\tAcc@5  70.31 ( 70.51)\n","Epoch: [7][300/391]\tTime  0.170 ( 0.171)\tLoss 2.3864e+00 (2.3478e+00)\tAcc@1  35.94 ( 38.31)\tAcc@5  67.97 ( 70.46)\n","Epoch: [7][330/391]\tTime  0.169 ( 0.171)\tLoss 2.1366e+00 (2.3484e+00)\tAcc@1  42.97 ( 38.24)\tAcc@5  75.00 ( 70.43)\n","Epoch: [7][360/391]\tTime  0.170 ( 0.171)\tLoss 2.4665e+00 (2.3491e+00)\tAcc@1  39.84 ( 38.26)\tAcc@5  70.31 ( 70.38)\n","Epoch: [7][390/391]\tTime  0.154 ( 0.171)\tLoss 2.0545e+00 (2.3464e+00)\tAcc@1  43.75 ( 38.24)\tAcc@5  78.75 ( 70.50)\n","==> Train Accuracy: Acc@1 38.244 || Acc@5 70.504\n","==> Test Accuracy:  Acc@1 42.650 || Acc@5 73.400\n","==> 71.08 seconds to train this epoch\n","\n","\n","----- epoch: 8, lr: 0.1 -----\n","Epoch: [8][  0/391]\tTime  0.284 ( 0.284)\tLoss 2.2608e+00 (2.2608e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  74.22 ( 74.22)\n","Epoch: [8][ 30/391]\tTime  0.171 ( 0.174)\tLoss 2.5338e+00 (2.2381e+00)\tAcc@1  33.59 ( 40.73)\tAcc@5  68.75 ( 72.93)\n","Epoch: [8][ 60/391]\tTime  0.172 ( 0.172)\tLoss 2.0959e+00 (2.2153e+00)\tAcc@1  39.84 ( 41.19)\tAcc@5  79.69 ( 73.50)\n","Epoch: [8][ 90/391]\tTime  0.172 ( 0.172)\tLoss 2.0869e+00 (2.1974e+00)\tAcc@1  46.09 ( 41.42)\tAcc@5  77.34 ( 74.09)\n","Epoch: [8][120/391]\tTime  0.171 ( 0.172)\tLoss 2.2260e+00 (2.2159e+00)\tAcc@1  38.28 ( 41.01)\tAcc@5  71.09 ( 73.56)\n","Epoch: [8][150/391]\tTime  0.170 ( 0.171)\tLoss 2.1409e+00 (2.2236e+00)\tAcc@1  38.28 ( 40.98)\tAcc@5  78.12 ( 73.25)\n","Epoch: [8][180/391]\tTime  0.170 ( 0.171)\tLoss 1.9857e+00 (2.2147e+00)\tAcc@1  50.78 ( 41.18)\tAcc@5  76.56 ( 73.45)\n","Epoch: [8][210/391]\tTime  0.172 ( 0.171)\tLoss 2.1151e+00 (2.2186e+00)\tAcc@1  42.19 ( 41.16)\tAcc@5  74.22 ( 73.30)\n","Epoch: [8][240/391]\tTime  0.169 ( 0.171)\tLoss 2.2692e+00 (2.2198e+00)\tAcc@1  38.28 ( 41.04)\tAcc@5  73.44 ( 73.22)\n","Epoch: [8][270/391]\tTime  0.171 ( 0.171)\tLoss 2.4379e+00 (2.2206e+00)\tAcc@1  40.62 ( 40.96)\tAcc@5  71.09 ( 73.17)\n","Epoch: [8][300/391]\tTime  0.172 ( 0.171)\tLoss 2.1835e+00 (2.2189e+00)\tAcc@1  38.28 ( 40.94)\tAcc@5  70.31 ( 73.16)\n","Epoch: [8][330/391]\tTime  0.170 ( 0.171)\tLoss 2.4298e+00 (2.2218e+00)\tAcc@1  35.16 ( 40.88)\tAcc@5  62.50 ( 73.15)\n","Epoch: [8][360/391]\tTime  0.171 ( 0.171)\tLoss 2.3921e+00 (2.2232e+00)\tAcc@1  31.25 ( 40.83)\tAcc@5  73.44 ( 73.12)\n","Epoch: [8][390/391]\tTime  0.153 ( 0.171)\tLoss 2.0068e+00 (2.2204e+00)\tAcc@1  45.00 ( 40.91)\tAcc@5  77.50 ( 73.21)\n","==> Train Accuracy: Acc@1 40.910 || Acc@5 73.210\n","==> Test Accuracy:  Acc@1 44.600 || Acc@5 76.540\n","==> 70.95 seconds to train this epoch\n","\n","\n","----- epoch: 9, lr: 0.1 -----\n","Epoch: [9][  0/391]\tTime  0.282 ( 0.282)\tLoss 2.2743e+00 (2.2743e+00)\tAcc@1  39.84 ( 39.84)\tAcc@5  72.66 ( 72.66)\n","Epoch: [9][ 30/391]\tTime  0.171 ( 0.174)\tLoss 2.0022e+00 (2.1422e+00)\tAcc@1  46.88 ( 43.15)\tAcc@5  75.00 ( 74.55)\n","Epoch: [9][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.2731e+00 (2.1340e+00)\tAcc@1  39.06 ( 42.98)\tAcc@5  71.88 ( 74.58)\n","Epoch: [9][ 90/391]\tTime  0.172 ( 0.171)\tLoss 2.2053e+00 (2.1359e+00)\tAcc@1  40.62 ( 42.82)\tAcc@5  73.44 ( 74.59)\n","Epoch: [9][120/391]\tTime  0.172 ( 0.171)\tLoss 2.1371e+00 (2.1362e+00)\tAcc@1  40.62 ( 42.76)\tAcc@5  76.56 ( 74.43)\n","Epoch: [9][150/391]\tTime  0.170 ( 0.171)\tLoss 1.9731e+00 (2.1307e+00)\tAcc@1  49.22 ( 43.10)\tAcc@5  76.56 ( 74.58)\n","Epoch: [9][180/391]\tTime  0.169 ( 0.171)\tLoss 2.1383e+00 (2.1268e+00)\tAcc@1  39.84 ( 43.31)\tAcc@5  74.22 ( 74.69)\n","Epoch: [9][210/391]\tTime  0.170 ( 0.171)\tLoss 2.4153e+00 (2.1234e+00)\tAcc@1  34.38 ( 43.28)\tAcc@5  71.88 ( 74.78)\n","Epoch: [9][240/391]\tTime  0.170 ( 0.171)\tLoss 2.2923e+00 (2.1261e+00)\tAcc@1  42.19 ( 43.24)\tAcc@5  71.88 ( 74.69)\n","Epoch: [9][270/391]\tTime  0.170 ( 0.171)\tLoss 1.9553e+00 (2.1268e+00)\tAcc@1  47.66 ( 43.19)\tAcc@5  82.81 ( 74.71)\n","Epoch: [9][300/391]\tTime  0.172 ( 0.171)\tLoss 1.9809e+00 (2.1230e+00)\tAcc@1  48.44 ( 43.24)\tAcc@5  75.78 ( 74.81)\n","Epoch: [9][330/391]\tTime  0.171 ( 0.171)\tLoss 2.0776e+00 (2.1254e+00)\tAcc@1  46.88 ( 43.26)\tAcc@5  71.88 ( 74.73)\n","Epoch: [9][360/391]\tTime  0.170 ( 0.171)\tLoss 2.0922e+00 (2.1215e+00)\tAcc@1  40.62 ( 43.38)\tAcc@5  81.25 ( 74.85)\n","Epoch: [9][390/391]\tTime  0.153 ( 0.171)\tLoss 2.3157e+00 (2.1193e+00)\tAcc@1  35.00 ( 43.36)\tAcc@5  67.50 ( 74.88)\n","==> Train Accuracy: Acc@1 43.364 || Acc@5 74.880\n","==> Test Accuracy:  Acc@1 45.990 || Acc@5 78.070\n","==> 70.87 seconds to train this epoch\n","\n","\n","----- epoch: 10, lr: 0.1 -----\n","Epoch: [10][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.9774e+00 (1.9774e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  75.00 ( 75.00)\n","Epoch: [10][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.3881e+00 (2.0889e+00)\tAcc@1  39.06 ( 44.56)\tAcc@5  66.41 ( 75.55)\n","Epoch: [10][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.0232e+00 (2.0237e+00)\tAcc@1  42.19 ( 45.89)\tAcc@5  79.69 ( 77.15)\n","Epoch: [10][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.8784e+00 (2.0394e+00)\tAcc@1  48.44 ( 45.48)\tAcc@5  77.34 ( 76.68)\n","Epoch: [10][120/391]\tTime  0.170 ( 0.171)\tLoss 2.0531e+00 (2.0352e+00)\tAcc@1  44.53 ( 45.46)\tAcc@5  75.00 ( 76.65)\n","Epoch: [10][150/391]\tTime  0.170 ( 0.171)\tLoss 2.3163e+00 (2.0349e+00)\tAcc@1  42.97 ( 45.33)\tAcc@5  69.53 ( 76.66)\n","Epoch: [10][180/391]\tTime  0.171 ( 0.171)\tLoss 1.9210e+00 (2.0251e+00)\tAcc@1  49.22 ( 45.58)\tAcc@5  78.91 ( 76.96)\n","Epoch: [10][210/391]\tTime  0.171 ( 0.171)\tLoss 1.8643e+00 (2.0257e+00)\tAcc@1  45.31 ( 45.49)\tAcc@5  80.47 ( 76.93)\n","Epoch: [10][240/391]\tTime  0.172 ( 0.171)\tLoss 2.1148e+00 (2.0269e+00)\tAcc@1  43.75 ( 45.48)\tAcc@5  75.78 ( 76.82)\n","Epoch: [10][270/391]\tTime  0.169 ( 0.171)\tLoss 1.7551e+00 (2.0308e+00)\tAcc@1  57.03 ( 45.47)\tAcc@5  80.47 ( 76.73)\n","Epoch: [10][300/391]\tTime  0.171 ( 0.171)\tLoss 1.9452e+00 (2.0334e+00)\tAcc@1  47.66 ( 45.39)\tAcc@5  75.78 ( 76.74)\n","Epoch: [10][330/391]\tTime  0.171 ( 0.171)\tLoss 1.9854e+00 (2.0331e+00)\tAcc@1  44.53 ( 45.37)\tAcc@5  77.34 ( 76.71)\n","Epoch: [10][360/391]\tTime  0.172 ( 0.171)\tLoss 1.9831e+00 (2.0310e+00)\tAcc@1  50.78 ( 45.40)\tAcc@5  80.47 ( 76.76)\n","Epoch: [10][390/391]\tTime  0.154 ( 0.171)\tLoss 2.1111e+00 (2.0304e+00)\tAcc@1  43.75 ( 45.47)\tAcc@5  75.00 ( 76.75)\n","==> Train Accuracy: Acc@1 45.472 || Acc@5 76.752\n","==> Test Accuracy:  Acc@1 48.490 || Acc@5 79.080\n","==> 70.96 seconds to train this epoch\n","\n","\n","----- epoch: 11, lr: 0.1 -----\n","Epoch: [11][  0/391]\tTime  0.281 ( 0.281)\tLoss 2.1961e+00 (2.1961e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  70.31 ( 70.31)\n","Epoch: [11][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.9356e+00 (1.8829e+00)\tAcc@1  45.31 ( 49.19)\tAcc@5  79.69 ( 79.41)\n","Epoch: [11][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.9837e+00 (1.9035e+00)\tAcc@1  45.31 ( 48.63)\tAcc@5  78.91 ( 79.15)\n","Epoch: [11][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.9272e+00 (1.9181e+00)\tAcc@1  50.78 ( 48.27)\tAcc@5  80.47 ( 78.86)\n","Epoch: [11][120/391]\tTime  0.170 ( 0.171)\tLoss 2.2616e+00 (1.9247e+00)\tAcc@1  41.41 ( 47.91)\tAcc@5  71.09 ( 78.67)\n","Epoch: [11][150/391]\tTime  0.171 ( 0.171)\tLoss 1.9202e+00 (1.9272e+00)\tAcc@1  50.00 ( 47.83)\tAcc@5  78.91 ( 78.70)\n","Epoch: [11][180/391]\tTime  0.170 ( 0.171)\tLoss 1.9335e+00 (1.9303e+00)\tAcc@1  40.62 ( 47.57)\tAcc@5  82.81 ( 78.78)\n","Epoch: [11][210/391]\tTime  0.170 ( 0.171)\tLoss 1.9416e+00 (1.9439e+00)\tAcc@1  49.22 ( 47.37)\tAcc@5  76.56 ( 78.41)\n","Epoch: [11][240/391]\tTime  0.169 ( 0.171)\tLoss 2.0384e+00 (1.9413e+00)\tAcc@1  50.00 ( 47.36)\tAcc@5  75.00 ( 78.45)\n","Epoch: [11][270/391]\tTime  0.172 ( 0.171)\tLoss 1.9847e+00 (1.9391e+00)\tAcc@1  48.44 ( 47.43)\tAcc@5  78.12 ( 78.51)\n","Epoch: [11][300/391]\tTime  0.171 ( 0.171)\tLoss 1.7751e+00 (1.9355e+00)\tAcc@1  49.22 ( 47.54)\tAcc@5  76.56 ( 78.61)\n","Epoch: [11][330/391]\tTime  0.172 ( 0.171)\tLoss 1.9918e+00 (1.9387e+00)\tAcc@1  43.75 ( 47.41)\tAcc@5  76.56 ( 78.51)\n","Epoch: [11][360/391]\tTime  0.171 ( 0.171)\tLoss 2.2259e+00 (1.9411e+00)\tAcc@1  39.84 ( 47.35)\tAcc@5  73.44 ( 78.50)\n","Epoch: [11][390/391]\tTime  0.153 ( 0.171)\tLoss 2.0968e+00 (1.9423e+00)\tAcc@1  45.00 ( 47.33)\tAcc@5  70.00 ( 78.45)\n","==> Train Accuracy: Acc@1 47.330 || Acc@5 78.446\n","==> Test Accuracy:  Acc@1 38.740 || Acc@5 70.460\n","==> 70.86 seconds to train this epoch\n","\n","\n","----- epoch: 12, lr: 0.1 -----\n","Epoch: [12][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.6878e+00 (1.6878e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  85.16 ( 85.16)\n","Epoch: [12][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.0237e+00 (1.8821e+00)\tAcc@1  47.66 ( 47.93)\tAcc@5  82.03 ( 79.89)\n","Epoch: [12][ 60/391]\tTime  0.171 ( 0.172)\tLoss 2.0059e+00 (1.8808e+00)\tAcc@1  46.88 ( 48.60)\tAcc@5  78.12 ( 79.66)\n","Epoch: [12][ 90/391]\tTime  0.173 ( 0.171)\tLoss 1.7327e+00 (1.8689e+00)\tAcc@1  52.34 ( 48.97)\tAcc@5  82.03 ( 79.77)\n","Epoch: [12][120/391]\tTime  0.170 ( 0.171)\tLoss 1.8232e+00 (1.8839e+00)\tAcc@1  46.88 ( 48.69)\tAcc@5  82.03 ( 79.52)\n","Epoch: [12][150/391]\tTime  0.171 ( 0.171)\tLoss 2.0070e+00 (1.8836e+00)\tAcc@1  45.31 ( 48.84)\tAcc@5  72.66 ( 79.50)\n","Epoch: [12][180/391]\tTime  0.169 ( 0.171)\tLoss 1.6040e+00 (1.8751e+00)\tAcc@1  53.91 ( 49.05)\tAcc@5  85.94 ( 79.65)\n","Epoch: [12][210/391]\tTime  0.171 ( 0.171)\tLoss 1.7470e+00 (1.8756e+00)\tAcc@1  51.56 ( 48.94)\tAcc@5  82.81 ( 79.77)\n","Epoch: [12][240/391]\tTime  0.170 ( 0.171)\tLoss 2.0703e+00 (1.8766e+00)\tAcc@1  47.66 ( 48.88)\tAcc@5  72.66 ( 79.79)\n","Epoch: [12][270/391]\tTime  0.171 ( 0.171)\tLoss 2.0095e+00 (1.8819e+00)\tAcc@1  50.78 ( 48.71)\tAcc@5  78.91 ( 79.71)\n","Epoch: [12][300/391]\tTime  0.170 ( 0.171)\tLoss 1.9894e+00 (1.8813e+00)\tAcc@1  43.75 ( 48.67)\tAcc@5  81.25 ( 79.70)\n","Epoch: [12][330/391]\tTime  0.172 ( 0.171)\tLoss 1.5930e+00 (1.8792e+00)\tAcc@1  61.72 ( 48.76)\tAcc@5  86.72 ( 79.73)\n","Epoch: [12][360/391]\tTime  0.171 ( 0.171)\tLoss 1.9398e+00 (1.8817e+00)\tAcc@1  50.78 ( 48.71)\tAcc@5  77.34 ( 79.73)\n","Epoch: [12][390/391]\tTime  0.153 ( 0.171)\tLoss 2.0589e+00 (1.8774e+00)\tAcc@1  45.00 ( 48.83)\tAcc@5  75.00 ( 79.82)\n","==> Train Accuracy: Acc@1 48.830 || Acc@5 79.822\n","==> Test Accuracy:  Acc@1 50.810 || Acc@5 81.420\n","==> 70.89 seconds to train this epoch\n","\n","\n","----- epoch: 13, lr: 0.1 -----\n","Epoch: [13][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.9833e+00 (1.9833e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  71.88 ( 71.88)\n","Epoch: [13][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.9233e+00 (1.7764e+00)\tAcc@1  51.56 ( 51.44)\tAcc@5  80.47 ( 80.52)\n","Epoch: [13][ 60/391]\tTime  0.172 ( 0.172)\tLoss 1.7818e+00 (1.7975e+00)\tAcc@1  53.12 ( 51.00)\tAcc@5  85.16 ( 80.55)\n","Epoch: [13][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.9221e+00 (1.7935e+00)\tAcc@1  46.09 ( 50.96)\tAcc@5  81.25 ( 80.86)\n","Epoch: [13][120/391]\tTime  0.170 ( 0.171)\tLoss 1.9067e+00 (1.7978e+00)\tAcc@1  47.66 ( 50.75)\tAcc@5  74.22 ( 80.82)\n","Epoch: [13][150/391]\tTime  0.171 ( 0.171)\tLoss 1.5861e+00 (1.7992e+00)\tAcc@1  57.81 ( 50.63)\tAcc@5  83.59 ( 80.94)\n","Epoch: [13][180/391]\tTime  0.170 ( 0.171)\tLoss 2.0084e+00 (1.7997e+00)\tAcc@1  45.31 ( 50.70)\tAcc@5  84.38 ( 81.02)\n","Epoch: [13][210/391]\tTime  0.169 ( 0.171)\tLoss 1.7387e+00 (1.8036e+00)\tAcc@1  50.00 ( 50.64)\tAcc@5  85.94 ( 80.99)\n","Epoch: [13][240/391]\tTime  0.170 ( 0.171)\tLoss 1.5563e+00 (1.8122e+00)\tAcc@1  59.38 ( 50.45)\tAcc@5  82.03 ( 80.89)\n","Epoch: [13][270/391]\tTime  0.171 ( 0.171)\tLoss 1.9838e+00 (1.8093e+00)\tAcc@1  50.00 ( 50.45)\tAcc@5  81.25 ( 80.94)\n","Epoch: [13][300/391]\tTime  0.169 ( 0.171)\tLoss 2.0209e+00 (1.8096e+00)\tAcc@1  46.09 ( 50.48)\tAcc@5  73.44 ( 80.95)\n","Epoch: [13][330/391]\tTime  0.169 ( 0.171)\tLoss 2.0000e+00 (1.8134e+00)\tAcc@1  46.88 ( 50.45)\tAcc@5  79.69 ( 80.86)\n","Epoch: [13][360/391]\tTime  0.168 ( 0.171)\tLoss 1.6227e+00 (1.8155e+00)\tAcc@1  57.81 ( 50.45)\tAcc@5  84.38 ( 80.80)\n","Epoch: [13][390/391]\tTime  0.153 ( 0.171)\tLoss 1.6388e+00 (1.8170e+00)\tAcc@1  57.50 ( 50.45)\tAcc@5  85.00 ( 80.78)\n","==> Train Accuracy: Acc@1 50.452 || Acc@5 80.784\n","==> Test Accuracy:  Acc@1 52.360 || Acc@5 81.760\n","==> 70.93 seconds to train this epoch\n","\n","\n","----- epoch: 14, lr: 0.1 -----\n","Epoch: [14][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.8774e+00 (1.8774e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  81.25 ( 81.25)\n","Epoch: [14][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.8070e+00 (1.7950e+00)\tAcc@1  48.44 ( 49.97)\tAcc@5  82.81 ( 81.58)\n","Epoch: [14][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.6470e+00 (1.7781e+00)\tAcc@1  54.69 ( 50.82)\tAcc@5  82.81 ( 81.80)\n","Epoch: [14][ 90/391]\tTime  0.172 ( 0.172)\tLoss 1.9046e+00 (1.7530e+00)\tAcc@1  44.53 ( 51.43)\tAcc@5  79.69 ( 82.17)\n","Epoch: [14][120/391]\tTime  0.170 ( 0.171)\tLoss 1.6574e+00 (1.7597e+00)\tAcc@1  50.00 ( 51.10)\tAcc@5  85.16 ( 82.08)\n","Epoch: [14][150/391]\tTime  0.171 ( 0.171)\tLoss 1.6994e+00 (1.7699e+00)\tAcc@1  54.69 ( 50.95)\tAcc@5  82.81 ( 81.86)\n","Epoch: [14][180/391]\tTime  0.172 ( 0.171)\tLoss 1.6390e+00 (1.7719e+00)\tAcc@1  57.03 ( 50.92)\tAcc@5  83.59 ( 81.80)\n","Epoch: [14][210/391]\tTime  0.171 ( 0.171)\tLoss 1.8733e+00 (1.7675e+00)\tAcc@1  48.44 ( 51.06)\tAcc@5  81.25 ( 81.79)\n","Epoch: [14][240/391]\tTime  0.172 ( 0.171)\tLoss 1.9302e+00 (1.7692e+00)\tAcc@1  46.88 ( 51.16)\tAcc@5  78.12 ( 81.69)\n","Epoch: [14][270/391]\tTime  0.172 ( 0.171)\tLoss 1.6414e+00 (1.7670e+00)\tAcc@1  52.34 ( 51.24)\tAcc@5  83.59 ( 81.73)\n","Epoch: [14][300/391]\tTime  0.169 ( 0.171)\tLoss 2.0096e+00 (1.7669e+00)\tAcc@1  42.19 ( 51.32)\tAcc@5  78.91 ( 81.76)\n","Epoch: [14][330/391]\tTime  0.170 ( 0.171)\tLoss 2.0220e+00 (1.7683e+00)\tAcc@1  45.31 ( 51.24)\tAcc@5  78.12 ( 81.80)\n","Epoch: [14][360/391]\tTime  0.171 ( 0.171)\tLoss 1.9140e+00 (1.7716e+00)\tAcc@1  48.44 ( 51.11)\tAcc@5  80.47 ( 81.70)\n","Epoch: [14][390/391]\tTime  0.153 ( 0.171)\tLoss 1.9758e+00 (1.7730e+00)\tAcc@1  38.75 ( 51.04)\tAcc@5  80.00 ( 81.66)\n","==> Train Accuracy: Acc@1 51.036 || Acc@5 81.664\n","==> Test Accuracy:  Acc@1 49.920 || Acc@5 80.340\n","==> 70.93 seconds to train this epoch\n","\n","\n","----- epoch: 15, lr: 0.1 -----\n","Epoch: [15][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.7646e+00 (1.7646e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  78.12 ( 78.12)\n","Epoch: [15][ 30/391]\tTime  0.171 ( 0.174)\tLoss 1.7960e+00 (1.7047e+00)\tAcc@1  49.22 ( 52.72)\tAcc@5  82.03 ( 82.08)\n","Epoch: [15][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.6358e+00 (1.6894e+00)\tAcc@1  50.00 ( 53.27)\tAcc@5  84.38 ( 82.56)\n","Epoch: [15][ 90/391]\tTime  0.170 ( 0.172)\tLoss 1.7141e+00 (1.6984e+00)\tAcc@1  50.78 ( 53.29)\tAcc@5  85.16 ( 82.55)\n","Epoch: [15][120/391]\tTime  0.169 ( 0.171)\tLoss 1.6177e+00 (1.7276e+00)\tAcc@1  54.69 ( 52.60)\tAcc@5  79.69 ( 82.14)\n","Epoch: [15][150/391]\tTime  0.171 ( 0.171)\tLoss 1.8827e+00 (1.7350e+00)\tAcc@1  47.66 ( 52.11)\tAcc@5  80.47 ( 81.97)\n","Epoch: [15][180/391]\tTime  0.171 ( 0.171)\tLoss 1.6867e+00 (1.7283e+00)\tAcc@1  53.91 ( 52.35)\tAcc@5  88.28 ( 82.19)\n","Epoch: [15][210/391]\tTime  0.170 ( 0.171)\tLoss 1.9106e+00 (1.7267e+00)\tAcc@1  46.09 ( 52.46)\tAcc@5  77.34 ( 82.23)\n","Epoch: [15][240/391]\tTime  0.171 ( 0.171)\tLoss 1.6498e+00 (1.7278e+00)\tAcc@1  53.91 ( 52.54)\tAcc@5  84.38 ( 82.24)\n","Epoch: [15][270/391]\tTime  0.170 ( 0.171)\tLoss 1.7730e+00 (1.7286e+00)\tAcc@1  51.56 ( 52.55)\tAcc@5  80.47 ( 82.23)\n","Epoch: [15][300/391]\tTime  0.172 ( 0.171)\tLoss 1.6282e+00 (1.7288e+00)\tAcc@1  53.12 ( 52.61)\tAcc@5  84.38 ( 82.20)\n","Epoch: [15][330/391]\tTime  0.170 ( 0.171)\tLoss 1.9212e+00 (1.7329e+00)\tAcc@1  47.66 ( 52.54)\tAcc@5  78.91 ( 82.07)\n","Epoch: [15][360/391]\tTime  0.170 ( 0.171)\tLoss 1.6826e+00 (1.7290e+00)\tAcc@1  56.25 ( 52.63)\tAcc@5  83.59 ( 82.19)\n","Epoch: [15][390/391]\tTime  0.153 ( 0.171)\tLoss 1.6782e+00 (1.7288e+00)\tAcc@1  48.75 ( 52.57)\tAcc@5  86.25 ( 82.21)\n","==> Train Accuracy: Acc@1 52.574 || Acc@5 82.214\n","==> Test Accuracy:  Acc@1 48.570 || Acc@5 79.460\n","==> 70.94 seconds to train this epoch\n","\n","\n","----- epoch: 16, lr: 0.1 -----\n","Epoch: [16][  0/391]\tTime  0.298 ( 0.298)\tLoss 1.8207e+00 (1.8207e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  81.25 ( 81.25)\n","Epoch: [16][ 30/391]\tTime  0.172 ( 0.174)\tLoss 1.6499e+00 (1.6850e+00)\tAcc@1  49.22 ( 52.72)\tAcc@5  87.50 ( 83.37)\n","Epoch: [16][ 60/391]\tTime  0.167 ( 0.172)\tLoss 1.9003e+00 (1.6851e+00)\tAcc@1  46.09 ( 52.84)\tAcc@5  80.47 ( 83.35)\n","Epoch: [16][ 90/391]\tTime  0.169 ( 0.172)\tLoss 1.7101e+00 (1.6824e+00)\tAcc@1  51.56 ( 52.82)\tAcc@5  85.16 ( 83.61)\n","Epoch: [16][120/391]\tTime  0.169 ( 0.171)\tLoss 1.5739e+00 (1.6810e+00)\tAcc@1  53.91 ( 53.00)\tAcc@5  88.28 ( 83.51)\n","Epoch: [16][150/391]\tTime  0.169 ( 0.171)\tLoss 1.6845e+00 (1.6851e+00)\tAcc@1  57.03 ( 53.05)\tAcc@5  83.59 ( 83.35)\n","Epoch: [16][180/391]\tTime  0.170 ( 0.171)\tLoss 1.6225e+00 (1.6811e+00)\tAcc@1  59.38 ( 53.27)\tAcc@5  87.50 ( 83.46)\n","Epoch: [16][210/391]\tTime  0.171 ( 0.171)\tLoss 1.6280e+00 (1.6769e+00)\tAcc@1  53.91 ( 53.51)\tAcc@5  85.16 ( 83.47)\n","Epoch: [16][240/391]\tTime  0.170 ( 0.171)\tLoss 1.8894e+00 (1.6830e+00)\tAcc@1  50.00 ( 53.40)\tAcc@5  75.78 ( 83.31)\n","Epoch: [16][270/391]\tTime  0.170 ( 0.171)\tLoss 1.5972e+00 (1.6858e+00)\tAcc@1  53.91 ( 53.34)\tAcc@5  85.16 ( 83.22)\n","Epoch: [16][300/391]\tTime  0.170 ( 0.171)\tLoss 1.6128e+00 (1.6912e+00)\tAcc@1  57.81 ( 53.25)\tAcc@5  82.81 ( 83.12)\n","Epoch: [16][330/391]\tTime  0.171 ( 0.171)\tLoss 1.7138e+00 (1.6968e+00)\tAcc@1  47.66 ( 53.06)\tAcc@5  84.38 ( 83.05)\n","Epoch: [16][360/391]\tTime  0.170 ( 0.171)\tLoss 1.5999e+00 (1.6966e+00)\tAcc@1  53.12 ( 53.04)\tAcc@5  83.59 ( 83.04)\n","Epoch: [16][390/391]\tTime  0.154 ( 0.171)\tLoss 1.7836e+00 (1.6973e+00)\tAcc@1  51.25 ( 53.06)\tAcc@5  81.25 ( 83.01)\n","==> Train Accuracy: Acc@1 53.062 || Acc@5 83.010\n","==> Test Accuracy:  Acc@1 53.040 || Acc@5 82.550\n","==> 70.86 seconds to train this epoch\n","\n","\n","----- epoch: 17, lr: 0.1 -----\n","Epoch: [17][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.5891e+00 (1.5891e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  82.81 ( 82.81)\n","Epoch: [17][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.6436e+00 (1.6033e+00)\tAcc@1  57.03 ( 55.14)\tAcc@5  82.03 ( 84.10)\n","Epoch: [17][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.9396e+00 (1.6427e+00)\tAcc@1  50.00 ( 54.35)\tAcc@5  78.12 ( 83.31)\n","Epoch: [17][ 90/391]\tTime  0.173 ( 0.171)\tLoss 1.5880e+00 (1.6394e+00)\tAcc@1  57.03 ( 54.46)\tAcc@5  85.94 ( 83.54)\n","Epoch: [17][120/391]\tTime  0.168 ( 0.171)\tLoss 1.5859e+00 (1.6495e+00)\tAcc@1  53.91 ( 54.19)\tAcc@5  85.94 ( 83.46)\n","Epoch: [17][150/391]\tTime  0.170 ( 0.171)\tLoss 1.7611e+00 (1.6475e+00)\tAcc@1  56.25 ( 54.36)\tAcc@5  78.12 ( 83.53)\n","Epoch: [17][180/391]\tTime  0.171 ( 0.171)\tLoss 2.0737e+00 (1.6637e+00)\tAcc@1  46.09 ( 53.97)\tAcc@5  75.78 ( 83.26)\n","Epoch: [17][210/391]\tTime  0.172 ( 0.171)\tLoss 1.4918e+00 (1.6591e+00)\tAcc@1  58.59 ( 54.05)\tAcc@5  88.28 ( 83.38)\n","Epoch: [17][240/391]\tTime  0.170 ( 0.171)\tLoss 1.7066e+00 (1.6613e+00)\tAcc@1  52.34 ( 54.00)\tAcc@5  85.94 ( 83.39)\n","Epoch: [17][270/391]\tTime  0.172 ( 0.171)\tLoss 1.7375e+00 (1.6613e+00)\tAcc@1  53.91 ( 53.98)\tAcc@5  82.03 ( 83.42)\n","Epoch: [17][300/391]\tTime  0.171 ( 0.171)\tLoss 1.7990e+00 (1.6579e+00)\tAcc@1  53.91 ( 54.11)\tAcc@5  78.12 ( 83.47)\n","Epoch: [17][330/391]\tTime  0.171 ( 0.171)\tLoss 1.8929e+00 (1.6591e+00)\tAcc@1  46.88 ( 54.03)\tAcc@5  78.91 ( 83.40)\n","Epoch: [17][360/391]\tTime  0.171 ( 0.171)\tLoss 1.7992e+00 (1.6597e+00)\tAcc@1  48.44 ( 54.03)\tAcc@5  84.38 ( 83.38)\n","Epoch: [17][390/391]\tTime  0.153 ( 0.171)\tLoss 1.6536e+00 (1.6629e+00)\tAcc@1  57.50 ( 53.98)\tAcc@5  82.50 ( 83.34)\n","==> Train Accuracy: Acc@1 53.984 || Acc@5 83.338\n","==> Test Accuracy:  Acc@1 55.610 || Acc@5 83.660\n","==> 70.90 seconds to train this epoch\n","\n","\n","----- epoch: 18, lr: 0.1 -----\n","Epoch: [18][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.6042e+00 (1.6042e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  82.03 ( 82.03)\n","Epoch: [18][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3033e+00 (1.6194e+00)\tAcc@1  63.28 ( 55.59)\tAcc@5  88.28 ( 84.35)\n","Epoch: [18][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.7934e+00 (1.5979e+00)\tAcc@1  46.09 ( 55.90)\tAcc@5  79.69 ( 84.67)\n","Epoch: [18][ 90/391]\tTime  0.169 ( 0.172)\tLoss 1.6462e+00 (1.6084e+00)\tAcc@1  52.34 ( 55.43)\tAcc@5  84.38 ( 84.44)\n","Epoch: [18][120/391]\tTime  0.168 ( 0.171)\tLoss 1.5175e+00 (1.6124e+00)\tAcc@1  54.69 ( 55.31)\tAcc@5  85.94 ( 84.34)\n","Epoch: [18][150/391]\tTime  0.169 ( 0.171)\tLoss 1.4961e+00 (1.6193e+00)\tAcc@1  58.59 ( 55.39)\tAcc@5  85.94 ( 84.20)\n","Epoch: [18][180/391]\tTime  0.171 ( 0.171)\tLoss 1.6821e+00 (1.6224e+00)\tAcc@1  51.56 ( 55.27)\tAcc@5  82.81 ( 84.18)\n","Epoch: [18][210/391]\tTime  0.171 ( 0.171)\tLoss 1.9002e+00 (1.6287e+00)\tAcc@1  46.09 ( 55.09)\tAcc@5  80.47 ( 84.04)\n","Epoch: [18][240/391]\tTime  0.171 ( 0.171)\tLoss 1.7849e+00 (1.6360e+00)\tAcc@1  51.56 ( 54.85)\tAcc@5  82.03 ( 83.96)\n","Epoch: [18][270/391]\tTime  0.171 ( 0.171)\tLoss 1.2084e+00 (1.6416e+00)\tAcc@1  67.97 ( 54.71)\tAcc@5  91.41 ( 83.87)\n","Epoch: [18][300/391]\tTime  0.169 ( 0.171)\tLoss 1.9542e+00 (1.6420e+00)\tAcc@1  50.00 ( 54.79)\tAcc@5  80.47 ( 83.81)\n","Epoch: [18][330/391]\tTime  0.172 ( 0.171)\tLoss 1.6682e+00 (1.6395e+00)\tAcc@1  53.12 ( 54.85)\tAcc@5  83.59 ( 83.80)\n","Epoch: [18][360/391]\tTime  0.171 ( 0.171)\tLoss 1.7985e+00 (1.6442e+00)\tAcc@1  52.34 ( 54.81)\tAcc@5  82.03 ( 83.70)\n","Epoch: [18][390/391]\tTime  0.153 ( 0.171)\tLoss 1.9596e+00 (1.6456e+00)\tAcc@1  51.25 ( 54.75)\tAcc@5  77.50 ( 83.71)\n","==> Train Accuracy: Acc@1 54.748 || Acc@5 83.710\n","==> Test Accuracy:  Acc@1 56.250 || Acc@5 84.780\n","==> 70.97 seconds to train this epoch\n","\n","\n","----- epoch: 19, lr: 0.1 -----\n","Epoch: [19][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.5570e+00 (1.5570e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  83.59 ( 83.59)\n","Epoch: [19][ 30/391]\tTime  0.171 ( 0.174)\tLoss 1.2780e+00 (1.5376e+00)\tAcc@1  66.41 ( 57.03)\tAcc@5  87.50 ( 85.91)\n","Epoch: [19][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.6544e+00 (1.5719e+00)\tAcc@1  57.81 ( 56.61)\tAcc@5  84.38 ( 84.96)\n","Epoch: [19][ 90/391]\tTime  0.171 ( 0.172)\tLoss 1.5653e+00 (1.5757e+00)\tAcc@1  56.25 ( 56.76)\tAcc@5  83.59 ( 84.56)\n","Epoch: [19][120/391]\tTime  0.171 ( 0.171)\tLoss 1.6643e+00 (1.5784e+00)\tAcc@1  53.12 ( 56.83)\tAcc@5  84.38 ( 84.36)\n","Epoch: [19][150/391]\tTime  0.169 ( 0.171)\tLoss 1.4548e+00 (1.5810e+00)\tAcc@1  57.81 ( 56.63)\tAcc@5  86.72 ( 84.30)\n","Epoch: [19][180/391]\tTime  0.169 ( 0.171)\tLoss 1.7380e+00 (1.5989e+00)\tAcc@1  52.34 ( 56.13)\tAcc@5  84.38 ( 84.05)\n","Epoch: [19][210/391]\tTime  0.171 ( 0.171)\tLoss 1.5394e+00 (1.5999e+00)\tAcc@1  56.25 ( 56.24)\tAcc@5  86.72 ( 84.09)\n","Epoch: [19][240/391]\tTime  0.171 ( 0.171)\tLoss 1.8051e+00 (1.6016e+00)\tAcc@1  46.88 ( 56.13)\tAcc@5  81.25 ( 84.01)\n","Epoch: [19][270/391]\tTime  0.170 ( 0.171)\tLoss 1.6243e+00 (1.6056e+00)\tAcc@1  57.81 ( 55.90)\tAcc@5  80.47 ( 83.99)\n","Epoch: [19][300/391]\tTime  0.169 ( 0.171)\tLoss 1.7844e+00 (1.6094e+00)\tAcc@1  54.69 ( 55.78)\tAcc@5  75.78 ( 83.90)\n","Epoch: [19][330/391]\tTime  0.170 ( 0.171)\tLoss 1.6806e+00 (1.6107e+00)\tAcc@1  60.94 ( 55.75)\tAcc@5  82.03 ( 83.95)\n","Epoch: [19][360/391]\tTime  0.171 ( 0.171)\tLoss 1.4330e+00 (1.6131e+00)\tAcc@1  60.94 ( 55.69)\tAcc@5  87.50 ( 83.91)\n","Epoch: [19][390/391]\tTime  0.153 ( 0.171)\tLoss 1.6474e+00 (1.6174e+00)\tAcc@1  60.00 ( 55.54)\tAcc@5  83.75 ( 83.85)\n","==> Train Accuracy: Acc@1 55.544 || Acc@5 83.846\n","==> Test Accuracy:  Acc@1 53.160 || Acc@5 83.220\n","==> 70.92 seconds to train this epoch\n","\n","\n","----- epoch: 20, lr: 0.1 -----\n","Epoch: [20][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.4834e+00 (1.4834e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  85.16 ( 85.16)\n","Epoch: [20][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.6018e+00 (1.5363e+00)\tAcc@1  56.25 ( 56.15)\tAcc@5  85.94 ( 85.74)\n","Epoch: [20][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.4816e+00 (1.5465e+00)\tAcc@1  59.38 ( 56.35)\tAcc@5  87.50 ( 85.25)\n","Epoch: [20][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.7141e+00 (1.5564e+00)\tAcc@1  52.34 ( 56.44)\tAcc@5  81.25 ( 85.03)\n","Epoch: [20][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4650e+00 (1.5573e+00)\tAcc@1  61.72 ( 56.28)\tAcc@5  83.59 ( 85.14)\n","Epoch: [20][150/391]\tTime  0.171 ( 0.171)\tLoss 1.7240e+00 (1.5642e+00)\tAcc@1  59.38 ( 56.19)\tAcc@5  84.38 ( 85.07)\n","Epoch: [20][180/391]\tTime  0.171 ( 0.171)\tLoss 1.5950e+00 (1.5712e+00)\tAcc@1  53.12 ( 55.95)\tAcc@5  82.03 ( 84.91)\n","Epoch: [20][210/391]\tTime  0.170 ( 0.171)\tLoss 1.8414e+00 (1.5738e+00)\tAcc@1  45.31 ( 55.97)\tAcc@5  82.03 ( 84.89)\n","Epoch: [20][240/391]\tTime  0.170 ( 0.171)\tLoss 1.4482e+00 (1.5787e+00)\tAcc@1  55.47 ( 55.87)\tAcc@5  86.72 ( 84.70)\n","Epoch: [20][270/391]\tTime  0.170 ( 0.171)\tLoss 1.4841e+00 (1.5798e+00)\tAcc@1  57.81 ( 55.90)\tAcc@5  87.50 ( 84.69)\n","Epoch: [20][300/391]\tTime  0.171 ( 0.171)\tLoss 1.4107e+00 (1.5796e+00)\tAcc@1  59.38 ( 55.95)\tAcc@5  90.62 ( 84.70)\n","Epoch: [20][330/391]\tTime  0.171 ( 0.171)\tLoss 1.3915e+00 (1.5854e+00)\tAcc@1  60.94 ( 55.78)\tAcc@5  85.16 ( 84.61)\n","Epoch: [20][360/391]\tTime  0.170 ( 0.171)\tLoss 1.7406e+00 (1.5904e+00)\tAcc@1  52.34 ( 55.70)\tAcc@5  80.47 ( 84.50)\n","Epoch: [20][390/391]\tTime  0.153 ( 0.171)\tLoss 1.5796e+00 (1.5945e+00)\tAcc@1  60.00 ( 55.60)\tAcc@5  82.50 ( 84.43)\n","==> Train Accuracy: Acc@1 55.598 || Acc@5 84.432\n","==> Test Accuracy:  Acc@1 55.220 || Acc@5 84.770\n","==> 70.85 seconds to train this epoch\n","\n","\n","----- epoch: 21, lr: 0.1 -----\n","Epoch: [21][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.6324e+00 (1.6324e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  85.16 ( 85.16)\n","Epoch: [21][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.6126e+00 (1.5366e+00)\tAcc@1  55.47 ( 57.66)\tAcc@5  85.16 ( 85.46)\n","Epoch: [21][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.7028e+00 (1.5186e+00)\tAcc@1  49.22 ( 57.91)\tAcc@5  79.69 ( 85.57)\n","Epoch: [21][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.8941e+00 (1.5221e+00)\tAcc@1  46.09 ( 57.62)\tAcc@5  80.47 ( 85.69)\n","Epoch: [21][120/391]\tTime  0.170 ( 0.171)\tLoss 1.5518e+00 (1.5393e+00)\tAcc@1  60.94 ( 57.54)\tAcc@5  86.72 ( 85.22)\n","Epoch: [21][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4253e+00 (1.5495e+00)\tAcc@1  60.16 ( 57.12)\tAcc@5  86.72 ( 85.16)\n","Epoch: [21][180/391]\tTime  0.169 ( 0.171)\tLoss 1.5936e+00 (1.5571e+00)\tAcc@1  56.25 ( 56.87)\tAcc@5  87.50 ( 85.12)\n","Epoch: [21][210/391]\tTime  0.170 ( 0.171)\tLoss 1.5146e+00 (1.5718e+00)\tAcc@1  53.91 ( 56.51)\tAcc@5  85.94 ( 84.96)\n","Epoch: [21][240/391]\tTime  0.171 ( 0.171)\tLoss 1.7589e+00 (1.5705e+00)\tAcc@1  48.44 ( 56.52)\tAcc@5  81.25 ( 84.99)\n","Epoch: [21][270/391]\tTime  0.171 ( 0.171)\tLoss 1.5157e+00 (1.5691e+00)\tAcc@1  59.38 ( 56.49)\tAcc@5  89.06 ( 85.05)\n","Epoch: [21][300/391]\tTime  0.170 ( 0.171)\tLoss 1.5153e+00 (1.5679e+00)\tAcc@1  54.69 ( 56.53)\tAcc@5  88.28 ( 85.10)\n","Epoch: [21][330/391]\tTime  0.171 ( 0.171)\tLoss 1.5990e+00 (1.5753e+00)\tAcc@1  55.47 ( 56.32)\tAcc@5  85.16 ( 84.99)\n","Epoch: [21][360/391]\tTime  0.169 ( 0.170)\tLoss 1.6867e+00 (1.5787e+00)\tAcc@1  57.81 ( 56.16)\tAcc@5  79.69 ( 84.86)\n","Epoch: [21][390/391]\tTime  0.154 ( 0.170)\tLoss 1.7849e+00 (1.5826e+00)\tAcc@1  47.50 ( 56.03)\tAcc@5  83.75 ( 84.79)\n","==> Train Accuracy: Acc@1 56.032 || Acc@5 84.790\n","==> Test Accuracy:  Acc@1 55.280 || Acc@5 83.270\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 22, lr: 0.1 -----\n","Epoch: [22][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.5347e+00 (1.5347e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  81.25 ( 81.25)\n","Epoch: [22][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.7822e+00 (1.4969e+00)\tAcc@1  46.09 ( 57.71)\tAcc@5  85.16 ( 86.14)\n","Epoch: [22][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.6683e+00 (1.5158e+00)\tAcc@1  53.91 ( 57.43)\tAcc@5  81.25 ( 85.85)\n","Epoch: [22][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.6537e+00 (1.5330e+00)\tAcc@1  57.81 ( 56.70)\tAcc@5  82.03 ( 85.59)\n","Epoch: [22][120/391]\tTime  0.169 ( 0.171)\tLoss 1.1544e+00 (1.5393e+00)\tAcc@1  71.09 ( 56.91)\tAcc@5  86.72 ( 85.31)\n","Epoch: [22][150/391]\tTime  0.171 ( 0.171)\tLoss 1.5473e+00 (1.5394e+00)\tAcc@1  55.47 ( 56.83)\tAcc@5  88.28 ( 85.27)\n","Epoch: [22][180/391]\tTime  0.171 ( 0.171)\tLoss 1.7439e+00 (1.5497e+00)\tAcc@1  50.00 ( 56.60)\tAcc@5  83.59 ( 85.13)\n","Epoch: [22][210/391]\tTime  0.171 ( 0.171)\tLoss 1.4443e+00 (1.5490e+00)\tAcc@1  60.94 ( 56.62)\tAcc@5  85.94 ( 85.12)\n","Epoch: [22][240/391]\tTime  0.171 ( 0.170)\tLoss 1.7278e+00 (1.5587e+00)\tAcc@1  52.34 ( 56.34)\tAcc@5  85.16 ( 85.01)\n","Epoch: [22][270/391]\tTime  0.171 ( 0.170)\tLoss 1.6968e+00 (1.5635e+00)\tAcc@1  57.03 ( 56.24)\tAcc@5  83.59 ( 85.01)\n","Epoch: [22][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4926e+00 (1.5658e+00)\tAcc@1  57.03 ( 56.16)\tAcc@5  89.84 ( 85.01)\n","Epoch: [22][330/391]\tTime  0.170 ( 0.170)\tLoss 1.6569e+00 (1.5625e+00)\tAcc@1  57.81 ( 56.37)\tAcc@5  83.59 ( 84.99)\n","Epoch: [22][360/391]\tTime  0.169 ( 0.170)\tLoss 1.7197e+00 (1.5649e+00)\tAcc@1  57.03 ( 56.38)\tAcc@5  82.81 ( 84.92)\n","Epoch: [22][390/391]\tTime  0.154 ( 0.170)\tLoss 1.4260e+00 (1.5655e+00)\tAcc@1  66.25 ( 56.37)\tAcc@5  86.25 ( 84.95)\n","==> Train Accuracy: Acc@1 56.366 || Acc@5 84.954\n","==> Test Accuracy:  Acc@1 56.700 || Acc@5 85.250\n","==> 70.75 seconds to train this epoch\n","\n","\n","----- epoch: 23, lr: 0.1 -----\n","Epoch: [23][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.6538e+00 (1.6538e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  86.72 ( 86.72)\n","Epoch: [23][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.5268e+00 (1.4957e+00)\tAcc@1  60.16 ( 57.59)\tAcc@5  82.81 ( 86.52)\n","Epoch: [23][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.2961e+00 (1.5149e+00)\tAcc@1  62.50 ( 57.22)\tAcc@5  92.19 ( 86.32)\n","Epoch: [23][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.4718e+00 (1.5223e+00)\tAcc@1  62.50 ( 57.17)\tAcc@5  81.25 ( 86.07)\n","Epoch: [23][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4764e+00 (1.5184e+00)\tAcc@1  52.34 ( 57.24)\tAcc@5  89.06 ( 86.11)\n","Epoch: [23][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4181e+00 (1.5117e+00)\tAcc@1  61.72 ( 57.55)\tAcc@5  86.72 ( 86.06)\n","Epoch: [23][180/391]\tTime  0.171 ( 0.171)\tLoss 1.4756e+00 (1.5216e+00)\tAcc@1  56.25 ( 57.45)\tAcc@5  86.72 ( 85.76)\n","Epoch: [23][210/391]\tTime  0.171 ( 0.171)\tLoss 1.6246e+00 (1.5282e+00)\tAcc@1  55.47 ( 57.23)\tAcc@5  83.59 ( 85.64)\n","Epoch: [23][240/391]\tTime  0.170 ( 0.171)\tLoss 1.5909e+00 (1.5291e+00)\tAcc@1  56.25 ( 57.26)\tAcc@5  85.16 ( 85.68)\n","Epoch: [23][270/391]\tTime  0.171 ( 0.171)\tLoss 1.4919e+00 (1.5336e+00)\tAcc@1  55.47 ( 57.18)\tAcc@5  84.38 ( 85.59)\n","Epoch: [23][300/391]\tTime  0.169 ( 0.171)\tLoss 1.5448e+00 (1.5390e+00)\tAcc@1  60.16 ( 57.08)\tAcc@5  83.59 ( 85.50)\n","Epoch: [23][330/391]\tTime  0.171 ( 0.171)\tLoss 1.5816e+00 (1.5413e+00)\tAcc@1  60.94 ( 56.99)\tAcc@5  85.16 ( 85.48)\n","Epoch: [23][360/391]\tTime  0.171 ( 0.171)\tLoss 1.8789e+00 (1.5442e+00)\tAcc@1  47.66 ( 56.93)\tAcc@5  80.47 ( 85.43)\n","Epoch: [23][390/391]\tTime  0.153 ( 0.171)\tLoss 1.6957e+00 (1.5469e+00)\tAcc@1  57.50 ( 56.89)\tAcc@5  81.25 ( 85.43)\n","==> Train Accuracy: Acc@1 56.890 || Acc@5 85.430\n","==> Test Accuracy:  Acc@1 52.990 || Acc@5 82.610\n","==> 70.87 seconds to train this epoch\n","\n","\n","----- epoch: 24, lr: 0.1 -----\n","Epoch: [24][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.3893e+00 (1.3893e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.16 ( 85.16)\n","Epoch: [24][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.5917e+00 (1.4402e+00)\tAcc@1  60.94 ( 59.83)\tAcc@5  82.81 ( 86.57)\n","Epoch: [24][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.4307e+00 (1.4382e+00)\tAcc@1  61.72 ( 59.72)\tAcc@5  85.16 ( 86.68)\n","Epoch: [24][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.6568e+00 (1.4750e+00)\tAcc@1  52.34 ( 58.72)\tAcc@5  85.16 ( 86.06)\n","Epoch: [24][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4612e+00 (1.4899e+00)\tAcc@1  52.34 ( 58.38)\tAcc@5  85.94 ( 85.82)\n","Epoch: [24][150/391]\tTime  0.171 ( 0.171)\tLoss 1.6455e+00 (1.4987e+00)\tAcc@1  52.34 ( 57.94)\tAcc@5  88.28 ( 85.85)\n","Epoch: [24][180/391]\tTime  0.170 ( 0.171)\tLoss 1.6254e+00 (1.5120e+00)\tAcc@1  55.47 ( 57.70)\tAcc@5  82.03 ( 85.58)\n","Epoch: [24][210/391]\tTime  0.168 ( 0.171)\tLoss 1.6025e+00 (1.5164e+00)\tAcc@1  53.91 ( 57.62)\tAcc@5  84.38 ( 85.55)\n","Epoch: [24][240/391]\tTime  0.170 ( 0.171)\tLoss 1.7938e+00 (1.5243e+00)\tAcc@1  53.91 ( 57.43)\tAcc@5  79.69 ( 85.43)\n","Epoch: [24][270/391]\tTime  0.171 ( 0.171)\tLoss 1.6640e+00 (1.5236e+00)\tAcc@1  53.91 ( 57.41)\tAcc@5  84.38 ( 85.38)\n","Epoch: [24][300/391]\tTime  0.170 ( 0.171)\tLoss 1.3600e+00 (1.5276e+00)\tAcc@1  61.72 ( 57.20)\tAcc@5  89.84 ( 85.35)\n","Epoch: [24][330/391]\tTime  0.171 ( 0.170)\tLoss 1.3818e+00 (1.5294e+00)\tAcc@1  59.38 ( 57.21)\tAcc@5  89.06 ( 85.31)\n","Epoch: [24][360/391]\tTime  0.171 ( 0.170)\tLoss 1.7897e+00 (1.5295e+00)\tAcc@1  46.88 ( 57.14)\tAcc@5  84.38 ( 85.36)\n","Epoch: [24][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5103e+00 (1.5327e+00)\tAcc@1  58.75 ( 57.11)\tAcc@5  83.75 ( 85.34)\n","==> Train Accuracy: Acc@1 57.108 || Acc@5 85.338\n","==> Test Accuracy:  Acc@1 54.610 || Acc@5 83.050\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 25, lr: 0.1 -----\n","Epoch: [25][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.4376e+00 (1.4376e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  84.38 ( 84.38)\n","Epoch: [25][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.4556e+00 (1.4932e+00)\tAcc@1  54.69 ( 59.38)\tAcc@5  86.72 ( 86.04)\n","Epoch: [25][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.3911e+00 (1.4702e+00)\tAcc@1  64.84 ( 59.58)\tAcc@5  89.84 ( 86.28)\n","Epoch: [25][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3230e+00 (1.4839e+00)\tAcc@1  64.06 ( 58.88)\tAcc@5  89.06 ( 86.11)\n","Epoch: [25][120/391]\tTime  0.170 ( 0.171)\tLoss 1.7015e+00 (1.4912e+00)\tAcc@1  56.25 ( 58.69)\tAcc@5  80.47 ( 86.09)\n","Epoch: [25][150/391]\tTime  0.170 ( 0.171)\tLoss 1.5648e+00 (1.4931e+00)\tAcc@1  60.94 ( 58.61)\tAcc@5  85.94 ( 86.14)\n","Epoch: [25][180/391]\tTime  0.170 ( 0.171)\tLoss 1.6388e+00 (1.4985e+00)\tAcc@1  54.69 ( 58.43)\tAcc@5  83.59 ( 86.13)\n","Epoch: [25][210/391]\tTime  0.171 ( 0.171)\tLoss 1.6526e+00 (1.5045e+00)\tAcc@1  57.81 ( 58.28)\tAcc@5  82.03 ( 86.03)\n","Epoch: [25][240/391]\tTime  0.170 ( 0.171)\tLoss 1.3636e+00 (1.5089e+00)\tAcc@1  61.72 ( 58.16)\tAcc@5  88.28 ( 86.01)\n","Epoch: [25][270/391]\tTime  0.170 ( 0.171)\tLoss 1.6248e+00 (1.5139e+00)\tAcc@1  52.34 ( 57.98)\tAcc@5  82.81 ( 85.84)\n","Epoch: [25][300/391]\tTime  0.171 ( 0.171)\tLoss 1.3441e+00 (1.5216e+00)\tAcc@1  60.94 ( 57.76)\tAcc@5  90.62 ( 85.75)\n","Epoch: [25][330/391]\tTime  0.169 ( 0.171)\tLoss 1.2804e+00 (1.5311e+00)\tAcc@1  65.62 ( 57.44)\tAcc@5  88.28 ( 85.60)\n","Epoch: [25][360/391]\tTime  0.170 ( 0.171)\tLoss 1.3695e+00 (1.5312e+00)\tAcc@1  64.06 ( 57.51)\tAcc@5  89.06 ( 85.56)\n","Epoch: [25][390/391]\tTime  0.153 ( 0.171)\tLoss 1.4703e+00 (1.5310e+00)\tAcc@1  63.75 ( 57.52)\tAcc@5  85.00 ( 85.53)\n","==> Train Accuracy: Acc@1 57.520 || Acc@5 85.530\n","==> Test Accuracy:  Acc@1 53.080 || Acc@5 82.550\n","==> 70.87 seconds to train this epoch\n","\n","\n","----- epoch: 26, lr: 0.1 -----\n","Epoch: [26][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.3274e+00 (1.3274e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  89.06 ( 89.06)\n","Epoch: [26][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4917e+00 (1.4397e+00)\tAcc@1  57.03 ( 59.53)\tAcc@5  80.47 ( 86.69)\n","Epoch: [26][ 60/391]\tTime  0.172 ( 0.172)\tLoss 1.6113e+00 (1.4632e+00)\tAcc@1  53.91 ( 58.63)\tAcc@5  87.50 ( 86.97)\n","Epoch: [26][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.2601e+00 (1.4729e+00)\tAcc@1  62.50 ( 58.64)\tAcc@5  87.50 ( 86.68)\n","Epoch: [26][120/391]\tTime  0.170 ( 0.171)\tLoss 1.6497e+00 (1.4842e+00)\tAcc@1  57.81 ( 58.37)\tAcc@5  83.59 ( 86.46)\n","Epoch: [26][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4079e+00 (1.4819e+00)\tAcc@1  63.28 ( 58.46)\tAcc@5  88.28 ( 86.54)\n","Epoch: [26][180/391]\tTime  0.171 ( 0.171)\tLoss 1.4546e+00 (1.4945e+00)\tAcc@1  57.03 ( 58.08)\tAcc@5  87.50 ( 86.37)\n","Epoch: [26][210/391]\tTime  0.170 ( 0.171)\tLoss 1.6101e+00 (1.4994e+00)\tAcc@1  57.03 ( 57.99)\tAcc@5  82.81 ( 86.22)\n","Epoch: [26][240/391]\tTime  0.170 ( 0.171)\tLoss 1.6124e+00 (1.5049e+00)\tAcc@1  50.78 ( 57.82)\tAcc@5  84.38 ( 86.15)\n","Epoch: [26][270/391]\tTime  0.172 ( 0.171)\tLoss 1.4666e+00 (1.5055e+00)\tAcc@1  60.16 ( 57.85)\tAcc@5  85.16 ( 86.06)\n","Epoch: [26][300/391]\tTime  0.171 ( 0.171)\tLoss 1.9308e+00 (1.5105e+00)\tAcc@1  50.78 ( 57.72)\tAcc@5  79.69 ( 86.01)\n","Epoch: [26][330/391]\tTime  0.170 ( 0.171)\tLoss 1.4607e+00 (1.5113e+00)\tAcc@1  59.38 ( 57.74)\tAcc@5  87.50 ( 85.96)\n","Epoch: [26][360/391]\tTime  0.169 ( 0.171)\tLoss 1.3744e+00 (1.5132e+00)\tAcc@1  62.50 ( 57.69)\tAcc@5  87.50 ( 85.95)\n","Epoch: [26][390/391]\tTime  0.154 ( 0.171)\tLoss 1.6203e+00 (1.5150e+00)\tAcc@1  55.00 ( 57.60)\tAcc@5  87.50 ( 85.88)\n","==> Train Accuracy: Acc@1 57.596 || Acc@5 85.882\n","==> Test Accuracy:  Acc@1 49.920 || Acc@5 80.170\n","==> 70.90 seconds to train this epoch\n","\n","\n","----- epoch: 27, lr: 0.1 -----\n","Epoch: [27][  0/391]\tTime  0.270 ( 0.270)\tLoss 1.4108e+00 (1.4108e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  88.28 ( 88.28)\n","Epoch: [27][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4354e+00 (1.5058e+00)\tAcc@1  63.28 ( 58.74)\tAcc@5  88.28 ( 85.28)\n","Epoch: [27][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.5270e+00 (1.4881e+00)\tAcc@1  57.03 ( 58.41)\tAcc@5  85.94 ( 85.73)\n","Epoch: [27][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.3668e+00 (1.4845e+00)\tAcc@1  61.72 ( 58.83)\tAcc@5  89.06 ( 85.89)\n","Epoch: [27][120/391]\tTime  0.170 ( 0.171)\tLoss 1.3952e+00 (1.4840e+00)\tAcc@1  57.81 ( 58.92)\tAcc@5  85.94 ( 85.82)\n","Epoch: [27][150/391]\tTime  0.171 ( 0.171)\tLoss 1.6682e+00 (1.4878e+00)\tAcc@1  55.47 ( 58.88)\tAcc@5  83.59 ( 85.83)\n","Epoch: [27][180/391]\tTime  0.170 ( 0.171)\tLoss 1.4279e+00 (1.4854e+00)\tAcc@1  55.47 ( 58.66)\tAcc@5  88.28 ( 85.92)\n","Epoch: [27][210/391]\tTime  0.171 ( 0.171)\tLoss 1.3085e+00 (1.4890e+00)\tAcc@1  59.38 ( 58.39)\tAcc@5  89.06 ( 85.99)\n","Epoch: [27][240/391]\tTime  0.169 ( 0.171)\tLoss 1.4425e+00 (1.4947e+00)\tAcc@1  58.59 ( 58.20)\tAcc@5  85.16 ( 85.92)\n","Epoch: [27][270/391]\tTime  0.171 ( 0.170)\tLoss 1.5373e+00 (1.4979e+00)\tAcc@1  51.56 ( 58.16)\tAcc@5  89.84 ( 85.87)\n","Epoch: [27][300/391]\tTime  0.171 ( 0.170)\tLoss 1.7306e+00 (1.4975e+00)\tAcc@1  56.25 ( 58.16)\tAcc@5  82.03 ( 85.93)\n","Epoch: [27][330/391]\tTime  0.172 ( 0.170)\tLoss 1.5621e+00 (1.4954e+00)\tAcc@1  56.25 ( 58.23)\tAcc@5  85.94 ( 85.87)\n","Epoch: [27][360/391]\tTime  0.170 ( 0.170)\tLoss 1.7325e+00 (1.4976e+00)\tAcc@1  50.78 ( 58.15)\tAcc@5  80.47 ( 85.86)\n","Epoch: [27][390/391]\tTime  0.153 ( 0.170)\tLoss 1.6073e+00 (1.4977e+00)\tAcc@1  57.50 ( 58.15)\tAcc@5  86.25 ( 85.86)\n","==> Train Accuracy: Acc@1 58.152 || Acc@5 85.858\n","==> Test Accuracy:  Acc@1 54.720 || Acc@5 83.110\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 28, lr: 0.1 -----\n","Epoch: [28][  0/391]\tTime  0.259 ( 0.259)\tLoss 1.5985e+00 (1.5985e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  85.16 ( 85.16)\n","Epoch: [28][ 30/391]\tTime  0.176 ( 0.173)\tLoss 1.4364e+00 (1.4251e+00)\tAcc@1  59.38 ( 60.11)\tAcc@5  86.72 ( 87.90)\n","Epoch: [28][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.5467e+00 (1.4446e+00)\tAcc@1  55.47 ( 59.31)\tAcc@5  85.94 ( 87.49)\n","Epoch: [28][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.3157e+00 (1.4559e+00)\tAcc@1  61.72 ( 58.92)\tAcc@5  89.84 ( 87.16)\n","Epoch: [28][120/391]\tTime  0.170 ( 0.171)\tLoss 1.5116e+00 (1.4639e+00)\tAcc@1  58.59 ( 58.72)\tAcc@5  85.94 ( 87.05)\n","Epoch: [28][150/391]\tTime  0.171 ( 0.171)\tLoss 1.3948e+00 (1.4805e+00)\tAcc@1  67.19 ( 58.50)\tAcc@5  85.16 ( 86.58)\n","Epoch: [28][180/391]\tTime  0.169 ( 0.170)\tLoss 1.6770e+00 (1.4849e+00)\tAcc@1  56.25 ( 58.32)\tAcc@5  78.91 ( 86.42)\n","Epoch: [28][210/391]\tTime  0.168 ( 0.170)\tLoss 1.2927e+00 (1.4822e+00)\tAcc@1  63.28 ( 58.49)\tAcc@5  85.94 ( 86.33)\n","Epoch: [28][240/391]\tTime  0.170 ( 0.170)\tLoss 1.6655e+00 (1.4860e+00)\tAcc@1  53.12 ( 58.44)\tAcc@5  81.25 ( 86.17)\n","Epoch: [28][270/391]\tTime  0.170 ( 0.170)\tLoss 1.5001e+00 (1.4812e+00)\tAcc@1  58.59 ( 58.54)\tAcc@5  85.16 ( 86.17)\n","Epoch: [28][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4869e+00 (1.4826e+00)\tAcc@1  62.50 ( 58.51)\tAcc@5  89.84 ( 86.08)\n","Epoch: [28][330/391]\tTime  0.170 ( 0.170)\tLoss 1.6147e+00 (1.4846e+00)\tAcc@1  57.03 ( 58.42)\tAcc@5  84.38 ( 86.08)\n","Epoch: [28][360/391]\tTime  0.170 ( 0.170)\tLoss 1.4982e+00 (1.4884e+00)\tAcc@1  61.72 ( 58.33)\tAcc@5  82.03 ( 86.00)\n","Epoch: [28][390/391]\tTime  0.153 ( 0.170)\tLoss 1.7608e+00 (1.4922e+00)\tAcc@1  51.25 ( 58.21)\tAcc@5  78.75 ( 85.96)\n","==> Train Accuracy: Acc@1 58.210 || Acc@5 85.960\n","==> Test Accuracy:  Acc@1 56.140 || Acc@5 85.080\n","==> 70.71 seconds to train this epoch\n","\n","\n","----- epoch: 29, lr: 0.1 -----\n","Epoch: [29][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.4202e+00 (1.4202e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  81.25 ( 81.25)\n","Epoch: [29][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.6481e+00 (1.4452e+00)\tAcc@1  56.25 ( 59.90)\tAcc@5  89.84 ( 87.37)\n","Epoch: [29][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.8842e+00 (1.4527e+00)\tAcc@1  52.34 ( 59.67)\tAcc@5  78.12 ( 87.04)\n","Epoch: [29][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.6525e+00 (1.4550e+00)\tAcc@1  54.69 ( 59.55)\tAcc@5  84.38 ( 86.82)\n","Epoch: [29][120/391]\tTime  0.169 ( 0.171)\tLoss 1.6873e+00 (1.4676e+00)\tAcc@1  50.78 ( 59.35)\tAcc@5  82.03 ( 86.60)\n","Epoch: [29][150/391]\tTime  0.171 ( 0.171)\tLoss 1.4412e+00 (1.4622e+00)\tAcc@1  53.91 ( 59.49)\tAcc@5  88.28 ( 86.70)\n","Epoch: [29][180/391]\tTime  0.169 ( 0.171)\tLoss 1.4683e+00 (1.4618e+00)\tAcc@1  54.69 ( 59.33)\tAcc@5  89.06 ( 86.86)\n","Epoch: [29][210/391]\tTime  0.168 ( 0.170)\tLoss 1.3728e+00 (1.4652e+00)\tAcc@1  59.38 ( 59.18)\tAcc@5  89.84 ( 86.80)\n","Epoch: [29][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4591e+00 (1.4670e+00)\tAcc@1  60.94 ( 59.12)\tAcc@5  84.38 ( 86.67)\n","Epoch: [29][270/391]\tTime  0.169 ( 0.170)\tLoss 1.4065e+00 (1.4670e+00)\tAcc@1  61.72 ( 59.14)\tAcc@5  86.72 ( 86.69)\n","Epoch: [29][300/391]\tTime  0.172 ( 0.170)\tLoss 1.4218e+00 (1.4701e+00)\tAcc@1  59.38 ( 59.03)\tAcc@5  89.84 ( 86.64)\n","Epoch: [29][330/391]\tTime  0.170 ( 0.170)\tLoss 1.4841e+00 (1.4759e+00)\tAcc@1  59.38 ( 58.87)\tAcc@5  87.50 ( 86.49)\n","Epoch: [29][360/391]\tTime  0.169 ( 0.170)\tLoss 1.5740e+00 (1.4807e+00)\tAcc@1  52.34 ( 58.74)\tAcc@5  87.50 ( 86.42)\n","Epoch: [29][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3411e+00 (1.4825e+00)\tAcc@1  63.75 ( 58.70)\tAcc@5  87.50 ( 86.34)\n","==> Train Accuracy: Acc@1 58.700 || Acc@5 86.342\n","==> Test Accuracy:  Acc@1 55.160 || Acc@5 84.310\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 30, lr: 0.1 -----\n","Epoch: [30][  0/391]\tTime  0.297 ( 0.297)\tLoss 1.5191e+00 (1.5191e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  82.81 ( 82.81)\n","Epoch: [30][ 30/391]\tTime  0.172 ( 0.174)\tLoss 1.3762e+00 (1.4502e+00)\tAcc@1  59.38 ( 59.55)\tAcc@5  89.84 ( 86.79)\n","Epoch: [30][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.6320e+00 (1.4388e+00)\tAcc@1  54.69 ( 59.89)\tAcc@5  79.69 ( 86.57)\n","Epoch: [30][ 90/391]\tTime  0.172 ( 0.172)\tLoss 1.4955e+00 (1.4579e+00)\tAcc@1  57.81 ( 59.35)\tAcc@5  85.94 ( 86.43)\n","Epoch: [30][120/391]\tTime  0.173 ( 0.171)\tLoss 1.2478e+00 (1.4581e+00)\tAcc@1  68.75 ( 59.20)\tAcc@5  85.94 ( 86.34)\n","Epoch: [30][150/391]\tTime  0.170 ( 0.171)\tLoss 1.3399e+00 (1.4603e+00)\tAcc@1  59.38 ( 59.16)\tAcc@5  87.50 ( 86.30)\n","Epoch: [30][180/391]\tTime  0.170 ( 0.171)\tLoss 1.5029e+00 (1.4574e+00)\tAcc@1  60.94 ( 59.41)\tAcc@5  85.94 ( 86.34)\n","Epoch: [30][210/391]\tTime  0.171 ( 0.171)\tLoss 1.5445e+00 (1.4652e+00)\tAcc@1  60.16 ( 59.15)\tAcc@5  82.03 ( 86.31)\n","Epoch: [30][240/391]\tTime  0.171 ( 0.171)\tLoss 1.5080e+00 (1.4697e+00)\tAcc@1  56.25 ( 59.08)\tAcc@5  87.50 ( 86.29)\n","Epoch: [30][270/391]\tTime  0.171 ( 0.171)\tLoss 1.5403e+00 (1.4733e+00)\tAcc@1  55.47 ( 58.96)\tAcc@5  87.50 ( 86.28)\n","Epoch: [30][300/391]\tTime  0.171 ( 0.171)\tLoss 1.4432e+00 (1.4731e+00)\tAcc@1  54.69 ( 58.87)\tAcc@5  87.50 ( 86.32)\n","Epoch: [30][330/391]\tTime  0.172 ( 0.171)\tLoss 1.4769e+00 (1.4753e+00)\tAcc@1  62.50 ( 58.84)\tAcc@5  85.94 ( 86.27)\n","Epoch: [30][360/391]\tTime  0.171 ( 0.171)\tLoss 1.5439e+00 (1.4766e+00)\tAcc@1  57.03 ( 58.78)\tAcc@5  83.59 ( 86.25)\n","Epoch: [30][390/391]\tTime  0.153 ( 0.171)\tLoss 1.5893e+00 (1.4787e+00)\tAcc@1  56.25 ( 58.70)\tAcc@5  86.25 ( 86.25)\n","==> Train Accuracy: Acc@1 58.698 || Acc@5 86.246\n","==> Test Accuracy:  Acc@1 55.920 || Acc@5 84.490\n","==> 70.93 seconds to train this epoch\n","\n","\n","----- epoch: 31, lr: 0.1 -----\n","Epoch: [31][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.5099e+00 (1.5099e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  83.59 ( 83.59)\n","Epoch: [31][ 30/391]\tTime  0.174 ( 0.173)\tLoss 1.5139e+00 (1.3829e+00)\tAcc@1  56.25 ( 61.79)\tAcc@5  85.16 ( 87.63)\n","Epoch: [31][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.3688e+00 (1.4018e+00)\tAcc@1  61.72 ( 60.86)\tAcc@5  89.84 ( 87.63)\n","Epoch: [31][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.2524e+00 (1.4191e+00)\tAcc@1  64.84 ( 60.49)\tAcc@5  90.62 ( 87.17)\n","Epoch: [31][120/391]\tTime  0.171 ( 0.171)\tLoss 1.6752e+00 (1.4233e+00)\tAcc@1  48.44 ( 60.14)\tAcc@5  80.47 ( 87.20)\n","Epoch: [31][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4433e+00 (1.4371e+00)\tAcc@1  57.81 ( 59.85)\tAcc@5  86.72 ( 86.93)\n","Epoch: [31][180/391]\tTime  0.170 ( 0.171)\tLoss 1.4710e+00 (1.4431e+00)\tAcc@1  57.03 ( 59.90)\tAcc@5  86.72 ( 86.82)\n","Epoch: [31][210/391]\tTime  0.171 ( 0.171)\tLoss 1.5728e+00 (1.4529e+00)\tAcc@1  59.38 ( 59.59)\tAcc@5  82.03 ( 86.68)\n","Epoch: [31][240/391]\tTime  0.170 ( 0.171)\tLoss 1.4035e+00 (1.4538e+00)\tAcc@1  60.16 ( 59.51)\tAcc@5  88.28 ( 86.67)\n","Epoch: [31][270/391]\tTime  0.170 ( 0.171)\tLoss 1.4685e+00 (1.4611e+00)\tAcc@1  57.03 ( 59.32)\tAcc@5  88.28 ( 86.64)\n","Epoch: [31][300/391]\tTime  0.169 ( 0.171)\tLoss 1.5030e+00 (1.4665e+00)\tAcc@1  60.16 ( 59.27)\tAcc@5  89.06 ( 86.54)\n","Epoch: [31][330/391]\tTime  0.170 ( 0.171)\tLoss 1.6272e+00 (1.4672e+00)\tAcc@1  57.03 ( 59.28)\tAcc@5  84.38 ( 86.52)\n","Epoch: [31][360/391]\tTime  0.169 ( 0.171)\tLoss 1.7708e+00 (1.4712e+00)\tAcc@1  52.34 ( 59.10)\tAcc@5  81.25 ( 86.44)\n","Epoch: [31][390/391]\tTime  0.154 ( 0.171)\tLoss 1.2874e+00 (1.4726e+00)\tAcc@1  61.25 ( 59.06)\tAcc@5  91.25 ( 86.36)\n","==> Train Accuracy: Acc@1 59.058 || Acc@5 86.364\n","==> Test Accuracy:  Acc@1 55.940 || Acc@5 84.490\n","==> 70.87 seconds to train this epoch\n","\n","\n","----- epoch: 32, lr: 0.1 -----\n","Epoch: [32][  0/391]\tTime  0.295 ( 0.295)\tLoss 1.2868e+00 (1.2868e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  89.06 ( 89.06)\n","Epoch: [32][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.4278e+00 (1.3590e+00)\tAcc@1  56.25 ( 60.31)\tAcc@5  88.28 ( 88.91)\n","Epoch: [32][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.4768e+00 (1.3736e+00)\tAcc@1  60.16 ( 60.36)\tAcc@5  85.94 ( 88.40)\n","Epoch: [32][ 90/391]\tTime  0.170 ( 0.172)\tLoss 1.6138e+00 (1.3833e+00)\tAcc@1  54.69 ( 60.40)\tAcc@5  85.94 ( 88.04)\n","Epoch: [32][120/391]\tTime  0.171 ( 0.171)\tLoss 1.8218e+00 (1.3920e+00)\tAcc@1  49.22 ( 60.45)\tAcc@5  83.59 ( 87.84)\n","Epoch: [32][150/391]\tTime  0.170 ( 0.171)\tLoss 1.5040e+00 (1.4225e+00)\tAcc@1  61.72 ( 59.74)\tAcc@5  86.72 ( 87.39)\n","Epoch: [32][180/391]\tTime  0.170 ( 0.171)\tLoss 1.3474e+00 (1.4323e+00)\tAcc@1  64.84 ( 59.60)\tAcc@5  85.94 ( 87.22)\n","Epoch: [32][210/391]\tTime  0.169 ( 0.171)\tLoss 1.5014e+00 (1.4366e+00)\tAcc@1  57.81 ( 59.43)\tAcc@5  85.94 ( 87.12)\n","Epoch: [32][240/391]\tTime  0.171 ( 0.171)\tLoss 1.5766e+00 (1.4414e+00)\tAcc@1  57.03 ( 59.32)\tAcc@5  83.59 ( 87.04)\n","Epoch: [32][270/391]\tTime  0.172 ( 0.171)\tLoss 1.3318e+00 (1.4493e+00)\tAcc@1  60.94 ( 59.09)\tAcc@5  88.28 ( 86.92)\n","Epoch: [32][300/391]\tTime  0.169 ( 0.171)\tLoss 1.2609e+00 (1.4498e+00)\tAcc@1  68.75 ( 59.13)\tAcc@5  85.16 ( 86.86)\n","Epoch: [32][330/391]\tTime  0.170 ( 0.171)\tLoss 1.4665e+00 (1.4497e+00)\tAcc@1  57.03 ( 59.13)\tAcc@5  86.72 ( 86.91)\n","Epoch: [32][360/391]\tTime  0.171 ( 0.171)\tLoss 1.6095e+00 (1.4540e+00)\tAcc@1  58.59 ( 59.13)\tAcc@5  86.72 ( 86.81)\n","Epoch: [32][390/391]\tTime  0.153 ( 0.171)\tLoss 1.4861e+00 (1.4579e+00)\tAcc@1  56.25 ( 59.03)\tAcc@5  86.25 ( 86.75)\n","==> Train Accuracy: Acc@1 59.032 || Acc@5 86.752\n","==> Test Accuracy:  Acc@1 57.060 || Acc@5 84.900\n","==> 70.91 seconds to train this epoch\n","\n","\n","----- epoch: 33, lr: 0.1 -----\n","Epoch: [33][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.1548e+00 (1.1548e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  91.41 ( 91.41)\n","Epoch: [33][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.3865e+00 (1.3960e+00)\tAcc@1  65.62 ( 60.81)\tAcc@5  88.28 ( 87.17)\n","Epoch: [33][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.3798e+00 (1.3965e+00)\tAcc@1  63.28 ( 60.75)\tAcc@5  85.94 ( 87.28)\n","Epoch: [33][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.7335e+00 (1.4103e+00)\tAcc@1  49.22 ( 60.67)\tAcc@5  86.72 ( 87.16)\n","Epoch: [33][120/391]\tTime  0.169 ( 0.171)\tLoss 1.0430e+00 (1.4159e+00)\tAcc@1  71.88 ( 60.52)\tAcc@5  91.41 ( 87.05)\n","Epoch: [33][150/391]\tTime  0.169 ( 0.171)\tLoss 1.3383e+00 (1.4256e+00)\tAcc@1  67.19 ( 60.04)\tAcc@5  87.50 ( 86.93)\n","Epoch: [33][180/391]\tTime  0.170 ( 0.171)\tLoss 1.3801e+00 (1.4285e+00)\tAcc@1  62.50 ( 59.87)\tAcc@5  87.50 ( 86.88)\n","Epoch: [33][210/391]\tTime  0.171 ( 0.171)\tLoss 1.4132e+00 (1.4309e+00)\tAcc@1  59.38 ( 59.82)\tAcc@5  90.62 ( 86.81)\n","Epoch: [33][240/391]\tTime  0.169 ( 0.171)\tLoss 1.4559e+00 (1.4381e+00)\tAcc@1  57.03 ( 59.73)\tAcc@5  89.06 ( 86.68)\n","Epoch: [33][270/391]\tTime  0.171 ( 0.171)\tLoss 1.5640e+00 (1.4436e+00)\tAcc@1  59.38 ( 59.53)\tAcc@5  86.72 ( 86.68)\n","Epoch: [33][300/391]\tTime  0.172 ( 0.170)\tLoss 1.3117e+00 (1.4458e+00)\tAcc@1  66.41 ( 59.51)\tAcc@5  85.94 ( 86.61)\n","Epoch: [33][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3413e+00 (1.4482e+00)\tAcc@1  61.72 ( 59.36)\tAcc@5  89.06 ( 86.63)\n","Epoch: [33][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3773e+00 (1.4513e+00)\tAcc@1  61.72 ( 59.33)\tAcc@5  87.50 ( 86.54)\n","Epoch: [33][390/391]\tTime  0.154 ( 0.170)\tLoss 1.4365e+00 (1.4566e+00)\tAcc@1  61.25 ( 59.23)\tAcc@5  85.00 ( 86.48)\n","==> Train Accuracy: Acc@1 59.228 || Acc@5 86.478\n","==> Test Accuracy:  Acc@1 56.650 || Acc@5 84.280\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 34, lr: 0.1 -----\n","Epoch: [34][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.4618e+00 (1.4618e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  86.72 ( 86.72)\n","Epoch: [34][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.3261e+00 (1.3399e+00)\tAcc@1  64.06 ( 62.50)\tAcc@5  88.28 ( 88.79)\n","Epoch: [34][ 60/391]\tTime  0.172 ( 0.171)\tLoss 1.5986e+00 (1.3787e+00)\tAcc@1  59.38 ( 61.39)\tAcc@5  82.03 ( 88.18)\n","Epoch: [34][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3908e+00 (1.3789e+00)\tAcc@1  58.59 ( 61.25)\tAcc@5  88.28 ( 88.06)\n","Epoch: [34][120/391]\tTime  0.171 ( 0.171)\tLoss 1.4518e+00 (1.3897e+00)\tAcc@1  57.03 ( 60.97)\tAcc@5  84.38 ( 87.78)\n","Epoch: [34][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4635e+00 (1.4017e+00)\tAcc@1  53.91 ( 60.65)\tAcc@5  85.94 ( 87.46)\n","Epoch: [34][180/391]\tTime  0.170 ( 0.170)\tLoss 1.7951e+00 (1.4164e+00)\tAcc@1  53.12 ( 60.18)\tAcc@5  82.03 ( 87.34)\n","Epoch: [34][210/391]\tTime  0.171 ( 0.170)\tLoss 1.2624e+00 (1.4223e+00)\tAcc@1  66.41 ( 60.07)\tAcc@5  88.28 ( 87.23)\n","Epoch: [34][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4187e+00 (1.4304e+00)\tAcc@1  57.81 ( 59.99)\tAcc@5  87.50 ( 87.11)\n","Epoch: [34][270/391]\tTime  0.171 ( 0.170)\tLoss 1.5617e+00 (1.4318e+00)\tAcc@1  57.81 ( 59.86)\tAcc@5  84.38 ( 87.15)\n","Epoch: [34][300/391]\tTime  0.171 ( 0.170)\tLoss 1.7043e+00 (1.4393e+00)\tAcc@1  52.34 ( 59.70)\tAcc@5  80.47 ( 86.97)\n","Epoch: [34][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3946e+00 (1.4434e+00)\tAcc@1  62.50 ( 59.52)\tAcc@5  86.72 ( 86.92)\n","Epoch: [34][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3403e+00 (1.4427e+00)\tAcc@1  57.81 ( 59.59)\tAcc@5  85.16 ( 86.83)\n","Epoch: [34][390/391]\tTime  0.155 ( 0.170)\tLoss 1.9680e+00 (1.4460e+00)\tAcc@1  51.25 ( 59.57)\tAcc@5  75.00 ( 86.69)\n","==> Train Accuracy: Acc@1 59.570 || Acc@5 86.688\n","==> Test Accuracy:  Acc@1 55.850 || Acc@5 84.730\n","==> 70.75 seconds to train this epoch\n","\n","\n","----- epoch: 35, lr: 0.1 -----\n","Epoch: [35][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.1906e+00 (1.1906e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  89.84 ( 89.84)\n","Epoch: [35][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.4004e+00 (1.3459e+00)\tAcc@1  64.06 ( 61.92)\tAcc@5  88.28 ( 88.21)\n","Epoch: [35][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.4555e+00 (1.3677e+00)\tAcc@1  63.28 ( 61.16)\tAcc@5  85.94 ( 87.91)\n","Epoch: [35][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4137e+00 (1.3849e+00)\tAcc@1  61.72 ( 60.94)\tAcc@5  89.06 ( 87.67)\n","Epoch: [35][120/391]\tTime  0.170 ( 0.171)\tLoss 1.3777e+00 (1.3990e+00)\tAcc@1  60.16 ( 60.52)\tAcc@5  87.50 ( 87.54)\n","Epoch: [35][150/391]\tTime  0.169 ( 0.171)\tLoss 1.4074e+00 (1.4136e+00)\tAcc@1  60.94 ( 60.25)\tAcc@5  85.94 ( 87.32)\n","Epoch: [35][180/391]\tTime  0.168 ( 0.171)\tLoss 1.2357e+00 (1.4129e+00)\tAcc@1  61.72 ( 60.29)\tAcc@5  92.19 ( 87.28)\n","Epoch: [35][210/391]\tTime  0.169 ( 0.171)\tLoss 1.8070e+00 (1.4273e+00)\tAcc@1  52.34 ( 59.99)\tAcc@5  80.47 ( 87.11)\n","Epoch: [35][240/391]\tTime  0.169 ( 0.171)\tLoss 1.3397e+00 (1.4273e+00)\tAcc@1  64.84 ( 59.96)\tAcc@5  89.84 ( 87.10)\n","Epoch: [35][270/391]\tTime  0.170 ( 0.171)\tLoss 1.5453e+00 (1.4341e+00)\tAcc@1  57.03 ( 59.79)\tAcc@5  84.38 ( 86.92)\n","Epoch: [35][300/391]\tTime  0.171 ( 0.171)\tLoss 1.2705e+00 (1.4357e+00)\tAcc@1  60.16 ( 59.63)\tAcc@5  87.50 ( 86.92)\n","Epoch: [35][330/391]\tTime  0.171 ( 0.171)\tLoss 1.4501e+00 (1.4386e+00)\tAcc@1  60.16 ( 59.57)\tAcc@5  85.94 ( 86.88)\n","Epoch: [35][360/391]\tTime  0.170 ( 0.171)\tLoss 1.5475e+00 (1.4433e+00)\tAcc@1  56.25 ( 59.49)\tAcc@5  87.50 ( 86.82)\n","Epoch: [35][390/391]\tTime  0.152 ( 0.170)\tLoss 1.8816e+00 (1.4429e+00)\tAcc@1  47.50 ( 59.46)\tAcc@5  77.50 ( 86.78)\n","==> Train Accuracy: Acc@1 59.456 || Acc@5 86.780\n","==> Test Accuracy:  Acc@1 59.170 || Acc@5 86.800\n","==> 70.84 seconds to train this epoch\n","\n","\n","----- epoch: 36, lr: 0.1 -----\n","Epoch: [36][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.2581e+00 (1.2581e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  89.06 ( 89.06)\n","Epoch: [36][ 30/391]\tTime  0.168 ( 0.173)\tLoss 1.3409e+00 (1.3914e+00)\tAcc@1  62.50 ( 60.18)\tAcc@5  87.50 ( 87.78)\n","Epoch: [36][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.3884e+00 (1.4264e+00)\tAcc@1  57.81 ( 59.18)\tAcc@5  85.94 ( 87.05)\n","Epoch: [36][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.4972e+00 (1.4162e+00)\tAcc@1  61.72 ( 59.50)\tAcc@5  85.94 ( 87.47)\n","Epoch: [36][120/391]\tTime  0.170 ( 0.171)\tLoss 1.0665e+00 (1.4201e+00)\tAcc@1  67.19 ( 59.50)\tAcc@5  92.19 ( 87.44)\n","Epoch: [36][150/391]\tTime  0.172 ( 0.171)\tLoss 1.7559e+00 (1.4274e+00)\tAcc@1  45.31 ( 59.41)\tAcc@5  86.72 ( 87.29)\n","Epoch: [36][180/391]\tTime  0.169 ( 0.170)\tLoss 1.5493e+00 (1.4358e+00)\tAcc@1  60.94 ( 59.37)\tAcc@5  85.16 ( 87.08)\n","Epoch: [36][210/391]\tTime  0.170 ( 0.170)\tLoss 1.4953e+00 (1.4320e+00)\tAcc@1  57.81 ( 59.57)\tAcc@5  83.59 ( 87.11)\n","Epoch: [36][240/391]\tTime  0.170 ( 0.170)\tLoss 1.3510e+00 (1.4336e+00)\tAcc@1  62.50 ( 59.64)\tAcc@5  89.06 ( 87.17)\n","Epoch: [36][270/391]\tTime  0.169 ( 0.170)\tLoss 1.6968e+00 (1.4399e+00)\tAcc@1  53.91 ( 59.42)\tAcc@5  82.03 ( 87.04)\n","Epoch: [36][300/391]\tTime  0.172 ( 0.170)\tLoss 1.4529e+00 (1.4425e+00)\tAcc@1  57.03 ( 59.40)\tAcc@5  86.72 ( 87.03)\n","Epoch: [36][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3339e+00 (1.4473e+00)\tAcc@1  62.50 ( 59.33)\tAcc@5  84.38 ( 86.87)\n","Epoch: [36][360/391]\tTime  0.170 ( 0.170)\tLoss 1.4151e+00 (1.4476e+00)\tAcc@1  62.50 ( 59.27)\tAcc@5  86.72 ( 86.86)\n","Epoch: [36][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5641e+00 (1.4456e+00)\tAcc@1  56.25 ( 59.37)\tAcc@5  86.25 ( 86.86)\n","==> Train Accuracy: Acc@1 59.374 || Acc@5 86.858\n","==> Test Accuracy:  Acc@1 59.180 || Acc@5 86.680\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 37, lr: 0.1 -----\n","Epoch: [37][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.3417e+00 (1.3417e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  90.62 ( 90.62)\n","Epoch: [37][ 30/391]\tTime  0.172 ( 0.174)\tLoss 1.2705e+00 (1.2979e+00)\tAcc@1  64.06 ( 62.55)\tAcc@5  92.97 ( 89.31)\n","Epoch: [37][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.5027e+00 (1.3418e+00)\tAcc@1  58.59 ( 62.14)\tAcc@5  85.94 ( 88.64)\n","Epoch: [37][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.2607e+00 (1.3699e+00)\tAcc@1  66.41 ( 61.37)\tAcc@5  89.84 ( 88.08)\n","Epoch: [37][120/391]\tTime  0.172 ( 0.171)\tLoss 1.4122e+00 (1.3949e+00)\tAcc@1  59.38 ( 60.74)\tAcc@5  85.16 ( 87.42)\n","Epoch: [37][150/391]\tTime  0.170 ( 0.171)\tLoss 1.5497e+00 (1.3978e+00)\tAcc@1  54.69 ( 60.45)\tAcc@5  83.59 ( 87.40)\n","Epoch: [37][180/391]\tTime  0.170 ( 0.171)\tLoss 1.5322e+00 (1.4121e+00)\tAcc@1  57.03 ( 60.10)\tAcc@5  83.59 ( 87.30)\n","Epoch: [37][210/391]\tTime  0.171 ( 0.171)\tLoss 1.2011e+00 (1.4185e+00)\tAcc@1  67.19 ( 59.91)\tAcc@5  87.50 ( 87.20)\n","Epoch: [37][240/391]\tTime  0.168 ( 0.170)\tLoss 1.3073e+00 (1.4190e+00)\tAcc@1  64.84 ( 59.87)\tAcc@5  87.50 ( 87.24)\n","Epoch: [37][270/391]\tTime  0.169 ( 0.170)\tLoss 1.5503e+00 (1.4223e+00)\tAcc@1  57.03 ( 59.91)\tAcc@5  84.38 ( 87.07)\n","Epoch: [37][300/391]\tTime  0.171 ( 0.170)\tLoss 1.3737e+00 (1.4207e+00)\tAcc@1  63.28 ( 59.97)\tAcc@5  87.50 ( 87.09)\n","Epoch: [37][330/391]\tTime  0.171 ( 0.170)\tLoss 1.4530e+00 (1.4241e+00)\tAcc@1  57.03 ( 59.89)\tAcc@5  87.50 ( 87.06)\n","Epoch: [37][360/391]\tTime  0.170 ( 0.170)\tLoss 1.6832e+00 (1.4272e+00)\tAcc@1  50.00 ( 59.92)\tAcc@5  85.16 ( 87.03)\n","Epoch: [37][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5349e+00 (1.4274e+00)\tAcc@1  61.25 ( 59.89)\tAcc@5  90.00 ( 87.05)\n","==> Train Accuracy: Acc@1 59.894 || Acc@5 87.052\n","==> Test Accuracy:  Acc@1 56.490 || Acc@5 85.230\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 38, lr: 0.1 -----\n","Epoch: [38][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.2685e+00 (1.2685e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.84 ( 89.84)\n","Epoch: [38][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.3868e+00 (1.3425e+00)\tAcc@1  62.50 ( 62.17)\tAcc@5  85.94 ( 88.16)\n","Epoch: [38][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.3686e+00 (1.3607e+00)\tAcc@1  58.59 ( 61.69)\tAcc@5  86.72 ( 88.11)\n","Epoch: [38][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.6922e+00 (1.3841e+00)\tAcc@1  55.47 ( 61.00)\tAcc@5  82.03 ( 87.86)\n","Epoch: [38][120/391]\tTime  0.169 ( 0.171)\tLoss 1.5617e+00 (1.4051e+00)\tAcc@1  61.72 ( 60.52)\tAcc@5  85.94 ( 87.50)\n","Epoch: [38][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4989e+00 (1.4088e+00)\tAcc@1  61.72 ( 60.43)\tAcc@5  89.06 ( 87.46)\n","Epoch: [38][180/391]\tTime  0.170 ( 0.171)\tLoss 1.5458e+00 (1.4177e+00)\tAcc@1  55.47 ( 60.13)\tAcc@5  88.28 ( 87.29)\n","Epoch: [38][210/391]\tTime  0.171 ( 0.171)\tLoss 1.5570e+00 (1.4206e+00)\tAcc@1  57.81 ( 60.01)\tAcc@5  85.16 ( 87.23)\n","Epoch: [38][240/391]\tTime  0.171 ( 0.171)\tLoss 1.2359e+00 (1.4186e+00)\tAcc@1  59.38 ( 60.02)\tAcc@5  90.62 ( 87.27)\n","Epoch: [38][270/391]\tTime  0.170 ( 0.171)\tLoss 1.5046e+00 (1.4204e+00)\tAcc@1  55.47 ( 59.92)\tAcc@5  86.72 ( 87.24)\n","Epoch: [38][300/391]\tTime  0.170 ( 0.171)\tLoss 1.5511e+00 (1.4243e+00)\tAcc@1  56.25 ( 59.82)\tAcc@5  86.72 ( 87.21)\n","Epoch: [38][330/391]\tTime  0.168 ( 0.171)\tLoss 1.4291e+00 (1.4270e+00)\tAcc@1  65.62 ( 59.88)\tAcc@5  85.94 ( 87.08)\n","Epoch: [38][360/391]\tTime  0.168 ( 0.171)\tLoss 1.2564e+00 (1.4274e+00)\tAcc@1  65.62 ( 59.82)\tAcc@5  91.41 ( 87.07)\n","Epoch: [38][390/391]\tTime  0.152 ( 0.171)\tLoss 1.4501e+00 (1.4294e+00)\tAcc@1  62.50 ( 59.85)\tAcc@5  91.25 ( 87.05)\n","==> Train Accuracy: Acc@1 59.854 || Acc@5 87.048\n","==> Test Accuracy:  Acc@1 55.520 || Acc@5 85.270\n","==> 70.85 seconds to train this epoch\n","\n","\n","----- epoch: 39, lr: 0.1 -----\n","Epoch: [39][  0/391]\tTime  0.266 ( 0.266)\tLoss 1.4995e+00 (1.4995e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  84.38 ( 84.38)\n","Epoch: [39][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3686e+00 (1.3650e+00)\tAcc@1  61.72 ( 61.84)\tAcc@5  85.16 ( 87.83)\n","Epoch: [39][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.1440e+00 (1.3810e+00)\tAcc@1  68.75 ( 61.37)\tAcc@5  92.19 ( 87.67)\n","Epoch: [39][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3693e+00 (1.3915e+00)\tAcc@1  60.16 ( 61.30)\tAcc@5  86.72 ( 87.28)\n","Epoch: [39][120/391]\tTime  0.169 ( 0.171)\tLoss 1.4113e+00 (1.3970e+00)\tAcc@1  57.03 ( 61.01)\tAcc@5  90.62 ( 87.31)\n","Epoch: [39][150/391]\tTime  0.170 ( 0.171)\tLoss 1.2695e+00 (1.3998e+00)\tAcc@1  65.62 ( 61.00)\tAcc@5  85.94 ( 87.30)\n","Epoch: [39][180/391]\tTime  0.170 ( 0.171)\tLoss 1.5933e+00 (1.4069e+00)\tAcc@1  52.34 ( 60.53)\tAcc@5  84.38 ( 87.19)\n","Epoch: [39][210/391]\tTime  0.172 ( 0.171)\tLoss 1.2081e+00 (1.4092e+00)\tAcc@1  63.28 ( 60.41)\tAcc@5  89.06 ( 87.17)\n","Epoch: [39][240/391]\tTime  0.170 ( 0.171)\tLoss 1.3890e+00 (1.4111e+00)\tAcc@1  60.16 ( 60.44)\tAcc@5  85.94 ( 87.12)\n","Epoch: [39][270/391]\tTime  0.170 ( 0.171)\tLoss 1.3373e+00 (1.4138e+00)\tAcc@1  64.06 ( 60.48)\tAcc@5  87.50 ( 87.13)\n","Epoch: [39][300/391]\tTime  0.169 ( 0.171)\tLoss 1.5423e+00 (1.4146e+00)\tAcc@1  51.56 ( 60.43)\tAcc@5  89.84 ( 87.21)\n","Epoch: [39][330/391]\tTime  0.171 ( 0.171)\tLoss 1.5072e+00 (1.4180e+00)\tAcc@1  57.81 ( 60.33)\tAcc@5  85.16 ( 87.15)\n","Epoch: [39][360/391]\tTime  0.170 ( 0.171)\tLoss 1.4186e+00 (1.4205e+00)\tAcc@1  57.81 ( 60.24)\tAcc@5  89.06 ( 87.10)\n","Epoch: [39][390/391]\tTime  0.152 ( 0.170)\tLoss 1.4485e+00 (1.4237e+00)\tAcc@1  60.00 ( 60.14)\tAcc@5  90.00 ( 87.09)\n","==> Train Accuracy: Acc@1 60.140 || Acc@5 87.088\n","==> Test Accuracy:  Acc@1 54.120 || Acc@5 83.110\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 40, lr: 0.1 -----\n","Epoch: [40][  0/391]\tTime  0.259 ( 0.259)\tLoss 1.4464e+00 (1.4464e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  84.38 ( 84.38)\n","Epoch: [40][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.4395e+00 (1.3622e+00)\tAcc@1  62.50 ( 61.57)\tAcc@5  88.28 ( 88.23)\n","Epoch: [40][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.1078e+00 (1.3643e+00)\tAcc@1  73.44 ( 61.59)\tAcc@5  90.62 ( 87.65)\n","Epoch: [40][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.8205e+00 (1.3831e+00)\tAcc@1  53.91 ( 61.25)\tAcc@5  78.12 ( 87.46)\n","Epoch: [40][120/391]\tTime  0.171 ( 0.171)\tLoss 1.3044e+00 (1.3791e+00)\tAcc@1  61.72 ( 61.29)\tAcc@5  92.97 ( 87.74)\n","Epoch: [40][150/391]\tTime  0.171 ( 0.171)\tLoss 1.2229e+00 (1.3838e+00)\tAcc@1  64.84 ( 61.19)\tAcc@5  90.62 ( 87.61)\n","Epoch: [40][180/391]\tTime  0.170 ( 0.171)\tLoss 1.5656e+00 (1.3902e+00)\tAcc@1  51.56 ( 61.14)\tAcc@5  86.72 ( 87.47)\n","Epoch: [40][210/391]\tTime  0.170 ( 0.171)\tLoss 1.4404e+00 (1.3954e+00)\tAcc@1  55.47 ( 60.91)\tAcc@5  87.50 ( 87.36)\n","Epoch: [40][240/391]\tTime  0.174 ( 0.171)\tLoss 1.4230e+00 (1.3986e+00)\tAcc@1  60.94 ( 60.79)\tAcc@5  89.84 ( 87.37)\n","Epoch: [40][270/391]\tTime  0.171 ( 0.171)\tLoss 1.4280e+00 (1.4080e+00)\tAcc@1  55.47 ( 60.55)\tAcc@5  86.72 ( 87.30)\n","Epoch: [40][300/391]\tTime  0.172 ( 0.170)\tLoss 1.6608e+00 (1.4136e+00)\tAcc@1  53.12 ( 60.44)\tAcc@5  83.59 ( 87.21)\n","Epoch: [40][330/391]\tTime  0.169 ( 0.170)\tLoss 1.4065e+00 (1.4165e+00)\tAcc@1  60.16 ( 60.44)\tAcc@5  84.38 ( 87.12)\n","Epoch: [40][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3212e+00 (1.4202e+00)\tAcc@1  60.16 ( 60.29)\tAcc@5  89.84 ( 87.03)\n","Epoch: [40][390/391]\tTime  0.152 ( 0.170)\tLoss 1.4562e+00 (1.4212e+00)\tAcc@1  57.50 ( 60.24)\tAcc@5  83.75 ( 87.04)\n","==> Train Accuracy: Acc@1 60.244 || Acc@5 87.040\n","==> Test Accuracy:  Acc@1 58.960 || Acc@5 86.540\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 41, lr: 0.1 -----\n","Epoch: [41][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.2300e+00 (1.2300e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  90.62 ( 90.62)\n","Epoch: [41][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.6278e+00 (1.3306e+00)\tAcc@1  61.72 ( 63.13)\tAcc@5  82.81 ( 88.43)\n","Epoch: [41][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.1458e+00 (1.3267e+00)\tAcc@1  70.31 ( 62.96)\tAcc@5  88.28 ( 88.46)\n","Epoch: [41][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.2800e+00 (1.3501e+00)\tAcc@1  67.97 ( 62.23)\tAcc@5  88.28 ( 88.13)\n","Epoch: [41][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4651e+00 (1.3740e+00)\tAcc@1  61.72 ( 61.44)\tAcc@5  87.50 ( 87.89)\n","Epoch: [41][150/391]\tTime  0.170 ( 0.171)\tLoss 1.6183e+00 (1.3833e+00)\tAcc@1  55.47 ( 61.35)\tAcc@5  81.25 ( 87.75)\n","Epoch: [41][180/391]\tTime  0.171 ( 0.171)\tLoss 1.4659e+00 (1.3836e+00)\tAcc@1  58.59 ( 61.14)\tAcc@5  88.28 ( 87.84)\n","Epoch: [41][210/391]\tTime  0.169 ( 0.171)\tLoss 1.4612e+00 (1.3915e+00)\tAcc@1  60.16 ( 60.92)\tAcc@5  85.16 ( 87.67)\n","Epoch: [41][240/391]\tTime  0.171 ( 0.170)\tLoss 1.4644e+00 (1.3962e+00)\tAcc@1  57.81 ( 60.79)\tAcc@5  89.06 ( 87.63)\n","Epoch: [41][270/391]\tTime  0.168 ( 0.170)\tLoss 1.3679e+00 (1.3994e+00)\tAcc@1  64.84 ( 60.83)\tAcc@5  85.94 ( 87.52)\n","Epoch: [41][300/391]\tTime  0.174 ( 0.170)\tLoss 1.3104e+00 (1.4041e+00)\tAcc@1  63.28 ( 60.66)\tAcc@5  90.62 ( 87.48)\n","Epoch: [41][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3450e+00 (1.4019e+00)\tAcc@1  61.72 ( 60.70)\tAcc@5  92.19 ( 87.56)\n","Epoch: [41][360/391]\tTime  0.171 ( 0.170)\tLoss 1.4267e+00 (1.4071e+00)\tAcc@1  63.28 ( 60.61)\tAcc@5  86.72 ( 87.44)\n","Epoch: [41][390/391]\tTime  0.154 ( 0.170)\tLoss 1.5319e+00 (1.4125e+00)\tAcc@1  58.75 ( 60.47)\tAcc@5  81.25 ( 87.33)\n","==> Train Accuracy: Acc@1 60.472 || Acc@5 87.334\n","==> Test Accuracy:  Acc@1 54.200 || Acc@5 82.910\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 42, lr: 0.1 -----\n","Epoch: [42][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.3164e+00 (1.3164e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  87.50 ( 87.50)\n","Epoch: [42][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.3535e+00 (1.3472e+00)\tAcc@1  64.06 ( 61.47)\tAcc@5  86.72 ( 88.21)\n","Epoch: [42][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.4815e+00 (1.3436e+00)\tAcc@1  54.69 ( 61.65)\tAcc@5  87.50 ( 88.52)\n","Epoch: [42][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.2003e+00 (1.3740e+00)\tAcc@1  68.75 ( 61.26)\tAcc@5  87.50 ( 88.20)\n","Epoch: [42][120/391]\tTime  0.170 ( 0.171)\tLoss 1.1196e+00 (1.3814e+00)\tAcc@1  68.75 ( 61.08)\tAcc@5  91.41 ( 88.06)\n","Epoch: [42][150/391]\tTime  0.170 ( 0.171)\tLoss 1.2899e+00 (1.3927e+00)\tAcc@1  67.97 ( 60.87)\tAcc@5  82.81 ( 87.77)\n","Epoch: [42][180/391]\tTime  0.168 ( 0.171)\tLoss 1.3851e+00 (1.3970e+00)\tAcc@1  60.94 ( 60.87)\tAcc@5  86.72 ( 87.66)\n","Epoch: [42][210/391]\tTime  0.168 ( 0.171)\tLoss 1.3488e+00 (1.4024e+00)\tAcc@1  70.31 ( 60.79)\tAcc@5  88.28 ( 87.55)\n","Epoch: [42][240/391]\tTime  0.170 ( 0.170)\tLoss 1.3084e+00 (1.3990e+00)\tAcc@1  64.84 ( 60.84)\tAcc@5  88.28 ( 87.55)\n","Epoch: [42][270/391]\tTime  0.171 ( 0.170)\tLoss 1.3916e+00 (1.3994e+00)\tAcc@1  58.59 ( 60.71)\tAcc@5  89.06 ( 87.55)\n","Epoch: [42][300/391]\tTime  0.171 ( 0.170)\tLoss 1.2950e+00 (1.4044e+00)\tAcc@1  66.41 ( 60.60)\tAcc@5  86.72 ( 87.44)\n","Epoch: [42][330/391]\tTime  0.170 ( 0.170)\tLoss 1.6805e+00 (1.4069e+00)\tAcc@1  53.12 ( 60.56)\tAcc@5  81.25 ( 87.42)\n","Epoch: [42][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3058e+00 (1.4118e+00)\tAcc@1  62.50 ( 60.40)\tAcc@5  87.50 ( 87.30)\n","Epoch: [42][390/391]\tTime  0.154 ( 0.170)\tLoss 1.6590e+00 (1.4124e+00)\tAcc@1  46.25 ( 60.34)\tAcc@5  83.75 ( 87.27)\n","==> Train Accuracy: Acc@1 60.342 || Acc@5 87.270\n","==> Test Accuracy:  Acc@1 58.920 || Acc@5 86.850\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 43, lr: 0.1 -----\n","Epoch: [43][  0/391]\tTime  0.396 ( 0.396)\tLoss 1.3811e+00 (1.3811e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  85.94 ( 85.94)\n","Epoch: [43][ 30/391]\tTime  0.169 ( 0.177)\tLoss 1.2784e+00 (1.3524e+00)\tAcc@1  60.94 ( 62.10)\tAcc@5  92.97 ( 87.80)\n","Epoch: [43][ 60/391]\tTime  0.171 ( 0.174)\tLoss 1.1555e+00 (1.3544e+00)\tAcc@1  60.94 ( 61.99)\tAcc@5  93.75 ( 88.27)\n","Epoch: [43][ 90/391]\tTime  0.171 ( 0.172)\tLoss 1.4122e+00 (1.3413e+00)\tAcc@1  57.03 ( 62.21)\tAcc@5  92.97 ( 88.29)\n","Epoch: [43][120/391]\tTime  0.170 ( 0.172)\tLoss 1.2423e+00 (1.3581e+00)\tAcc@1  64.84 ( 61.87)\tAcc@5  89.84 ( 87.88)\n","Epoch: [43][150/391]\tTime  0.173 ( 0.171)\tLoss 1.3435e+00 (1.3646e+00)\tAcc@1  61.72 ( 61.69)\tAcc@5  89.84 ( 87.77)\n","Epoch: [43][180/391]\tTime  0.171 ( 0.171)\tLoss 1.4703e+00 (1.3690e+00)\tAcc@1  61.72 ( 61.61)\tAcc@5  85.94 ( 87.78)\n","Epoch: [43][210/391]\tTime  0.174 ( 0.171)\tLoss 1.3433e+00 (1.3790e+00)\tAcc@1  62.50 ( 61.34)\tAcc@5  86.72 ( 87.66)\n","Epoch: [43][240/391]\tTime  0.171 ( 0.171)\tLoss 1.5483e+00 (1.3889e+00)\tAcc@1  55.47 ( 61.15)\tAcc@5  83.59 ( 87.55)\n","Epoch: [43][270/391]\tTime  0.170 ( 0.171)\tLoss 1.3808e+00 (1.3896e+00)\tAcc@1  64.84 ( 61.08)\tAcc@5  87.50 ( 87.62)\n","Epoch: [43][300/391]\tTime  0.170 ( 0.171)\tLoss 1.2775e+00 (1.3904e+00)\tAcc@1  65.62 ( 61.05)\tAcc@5  90.62 ( 87.60)\n","Epoch: [43][330/391]\tTime  0.170 ( 0.171)\tLoss 1.3575e+00 (1.3928e+00)\tAcc@1  58.59 ( 60.99)\tAcc@5  87.50 ( 87.59)\n","Epoch: [43][360/391]\tTime  0.171 ( 0.171)\tLoss 1.6301e+00 (1.4004e+00)\tAcc@1  56.25 ( 60.81)\tAcc@5  83.59 ( 87.50)\n","Epoch: [43][390/391]\tTime  0.152 ( 0.171)\tLoss 1.6099e+00 (1.4024e+00)\tAcc@1  61.25 ( 60.81)\tAcc@5  81.25 ( 87.50)\n","==> Train Accuracy: Acc@1 60.810 || Acc@5 87.498\n","==> Test Accuracy:  Acc@1 57.720 || Acc@5 85.140\n","==> 70.99 seconds to train this epoch\n","\n","\n","----- epoch: 44, lr: 0.1 -----\n","Epoch: [44][  0/391]\tTime  0.382 ( 0.382)\tLoss 1.3879e+00 (1.3879e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  85.94 ( 85.94)\n","Epoch: [44][ 30/391]\tTime  0.169 ( 0.176)\tLoss 1.1770e+00 (1.3735e+00)\tAcc@1  64.84 ( 60.58)\tAcc@5  91.41 ( 88.13)\n","Epoch: [44][ 60/391]\tTime  0.170 ( 0.173)\tLoss 1.4965e+00 (1.3669e+00)\tAcc@1  55.47 ( 61.16)\tAcc@5  87.50 ( 87.97)\n","Epoch: [44][ 90/391]\tTime  0.170 ( 0.172)\tLoss 1.2652e+00 (1.3724e+00)\tAcc@1  61.72 ( 60.97)\tAcc@5  87.50 ( 87.58)\n","Epoch: [44][120/391]\tTime  0.170 ( 0.172)\tLoss 1.5357e+00 (1.3719e+00)\tAcc@1  56.25 ( 60.94)\tAcc@5  87.50 ( 87.76)\n","Epoch: [44][150/391]\tTime  0.171 ( 0.171)\tLoss 1.6212e+00 (1.3796e+00)\tAcc@1  57.81 ( 60.79)\tAcc@5  85.16 ( 87.81)\n","Epoch: [44][180/391]\tTime  0.169 ( 0.171)\tLoss 1.3514e+00 (1.3819e+00)\tAcc@1  61.72 ( 60.90)\tAcc@5  91.41 ( 87.77)\n","Epoch: [44][210/391]\tTime  0.171 ( 0.171)\tLoss 1.5074e+00 (1.3846e+00)\tAcc@1  58.59 ( 60.84)\tAcc@5  86.72 ( 87.82)\n","Epoch: [44][240/391]\tTime  0.170 ( 0.171)\tLoss 1.3526e+00 (1.3945e+00)\tAcc@1  62.50 ( 60.65)\tAcc@5  87.50 ( 87.57)\n","Epoch: [44][270/391]\tTime  0.171 ( 0.171)\tLoss 1.5598e+00 (1.3967e+00)\tAcc@1  59.38 ( 60.68)\tAcc@5  85.94 ( 87.60)\n","Epoch: [44][300/391]\tTime  0.170 ( 0.171)\tLoss 1.5095e+00 (1.4021e+00)\tAcc@1  61.72 ( 60.62)\tAcc@5  85.16 ( 87.49)\n","Epoch: [44][330/391]\tTime  0.170 ( 0.171)\tLoss 1.3130e+00 (1.4052e+00)\tAcc@1  65.62 ( 60.55)\tAcc@5  89.06 ( 87.45)\n","Epoch: [44][360/391]\tTime  0.173 ( 0.171)\tLoss 1.5601e+00 (1.4107e+00)\tAcc@1  52.34 ( 60.39)\tAcc@5  84.38 ( 87.35)\n","Epoch: [44][390/391]\tTime  0.153 ( 0.171)\tLoss 1.6009e+00 (1.4097e+00)\tAcc@1  62.50 ( 60.39)\tAcc@5  80.00 ( 87.39)\n","==> Train Accuracy: Acc@1 60.394 || Acc@5 87.388\n","==> Test Accuracy:  Acc@1 56.080 || Acc@5 84.410\n","==> 70.89 seconds to train this epoch\n","\n","\n","----- epoch: 45, lr: 0.1 -----\n","Epoch: [45][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.5486e+00 (1.5486e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  84.38 ( 84.38)\n","Epoch: [45][ 30/391]\tTime  0.170 ( 0.173)\tLoss 9.7362e-01 (1.3334e+00)\tAcc@1  75.00 ( 62.20)\tAcc@5  93.75 ( 88.41)\n","Epoch: [45][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.5886e+00 (1.3392e+00)\tAcc@1  53.12 ( 61.99)\tAcc@5  82.81 ( 88.41)\n","Epoch: [45][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.3288e+00 (1.3598e+00)\tAcc@1  61.72 ( 61.61)\tAcc@5  89.06 ( 88.06)\n","Epoch: [45][120/391]\tTime  0.170 ( 0.171)\tLoss 1.2804e+00 (1.3686e+00)\tAcc@1  63.28 ( 61.32)\tAcc@5  82.81 ( 88.07)\n","Epoch: [45][150/391]\tTime  0.171 ( 0.171)\tLoss 1.3976e+00 (1.3821e+00)\tAcc@1  60.16 ( 61.07)\tAcc@5  85.16 ( 87.78)\n","Epoch: [45][180/391]\tTime  0.170 ( 0.171)\tLoss 1.3273e+00 (1.3913e+00)\tAcc@1  64.84 ( 60.90)\tAcc@5  89.06 ( 87.47)\n","Epoch: [45][210/391]\tTime  0.171 ( 0.171)\tLoss 1.4862e+00 (1.3903e+00)\tAcc@1  59.38 ( 60.90)\tAcc@5  86.72 ( 87.57)\n","Epoch: [45][240/391]\tTime  0.170 ( 0.171)\tLoss 1.5260e+00 (1.3882e+00)\tAcc@1  53.91 ( 60.99)\tAcc@5  82.81 ( 87.69)\n","Epoch: [45][270/391]\tTime  0.169 ( 0.171)\tLoss 1.5480e+00 (1.3931e+00)\tAcc@1  59.38 ( 60.89)\tAcc@5  84.38 ( 87.65)\n","Epoch: [45][300/391]\tTime  0.171 ( 0.171)\tLoss 1.2635e+00 (1.3963e+00)\tAcc@1  64.84 ( 60.88)\tAcc@5  91.41 ( 87.64)\n","Epoch: [45][330/391]\tTime  0.170 ( 0.171)\tLoss 1.5199e+00 (1.3962e+00)\tAcc@1  50.00 ( 60.82)\tAcc@5  85.16 ( 87.64)\n","Epoch: [45][360/391]\tTime  0.170 ( 0.171)\tLoss 1.4332e+00 (1.3985e+00)\tAcc@1  59.38 ( 60.73)\tAcc@5  86.72 ( 87.60)\n","Epoch: [45][390/391]\tTime  0.154 ( 0.170)\tLoss 1.4124e+00 (1.4006e+00)\tAcc@1  65.00 ( 60.70)\tAcc@5  87.50 ( 87.54)\n","==> Train Accuracy: Acc@1 60.704 || Acc@5 87.540\n","==> Test Accuracy:  Acc@1 55.260 || Acc@5 85.220\n","==> 70.85 seconds to train this epoch\n","\n","\n","----- epoch: 46, lr: 0.1 -----\n","Epoch: [46][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.2070e+00 (1.2070e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  87.50 ( 87.50)\n","Epoch: [46][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.3708e+00 (1.3278e+00)\tAcc@1  61.72 ( 62.93)\tAcc@5  83.59 ( 88.43)\n","Epoch: [46][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.3004e+00 (1.3392e+00)\tAcc@1  60.94 ( 62.68)\tAcc@5  89.84 ( 88.37)\n","Epoch: [46][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4711e+00 (1.3683e+00)\tAcc@1  64.06 ( 61.55)\tAcc@5  86.72 ( 88.04)\n","Epoch: [46][120/391]\tTime  0.171 ( 0.171)\tLoss 1.3810e+00 (1.3724e+00)\tAcc@1  62.50 ( 61.31)\tAcc@5  88.28 ( 87.96)\n","Epoch: [46][150/391]\tTime  0.170 ( 0.171)\tLoss 1.3678e+00 (1.3662e+00)\tAcc@1  60.16 ( 61.40)\tAcc@5  87.50 ( 88.07)\n","Epoch: [46][180/391]\tTime  0.172 ( 0.171)\tLoss 1.2692e+00 (1.3717e+00)\tAcc@1  67.97 ( 61.32)\tAcc@5  89.84 ( 88.00)\n","Epoch: [46][210/391]\tTime  0.170 ( 0.171)\tLoss 1.6431e+00 (1.3772e+00)\tAcc@1  53.12 ( 61.30)\tAcc@5  85.94 ( 87.85)\n","Epoch: [46][240/391]\tTime  0.169 ( 0.171)\tLoss 1.2553e+00 (1.3820e+00)\tAcc@1  60.94 ( 61.22)\tAcc@5  93.75 ( 87.76)\n","Epoch: [46][270/391]\tTime  0.171 ( 0.171)\tLoss 1.5953e+00 (1.3892e+00)\tAcc@1  55.47 ( 61.10)\tAcc@5  85.16 ( 87.65)\n","Epoch: [46][300/391]\tTime  0.170 ( 0.171)\tLoss 1.3054e+00 (1.3937e+00)\tAcc@1  64.06 ( 61.05)\tAcc@5  87.50 ( 87.48)\n","Epoch: [46][330/391]\tTime  0.170 ( 0.171)\tLoss 1.3993e+00 (1.3927e+00)\tAcc@1  53.12 ( 60.99)\tAcc@5  89.06 ( 87.50)\n","Epoch: [46][360/391]\tTime  0.169 ( 0.171)\tLoss 1.2879e+00 (1.3971e+00)\tAcc@1  60.94 ( 60.85)\tAcc@5  90.62 ( 87.47)\n","Epoch: [46][390/391]\tTime  0.153 ( 0.170)\tLoss 1.6900e+00 (1.4020e+00)\tAcc@1  53.75 ( 60.71)\tAcc@5  81.25 ( 87.34)\n","==> Train Accuracy: Acc@1 60.714 || Acc@5 87.338\n","==> Test Accuracy:  Acc@1 60.080 || Acc@5 87.000\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 47, lr: 0.1 -----\n","Epoch: [47][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.3844e+00 (1.3844e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  89.84 ( 89.84)\n","Epoch: [47][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.3087e+00 (1.2987e+00)\tAcc@1  65.62 ( 63.41)\tAcc@5  89.06 ( 89.06)\n","Epoch: [47][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.4949e+00 (1.3239e+00)\tAcc@1  57.03 ( 62.47)\tAcc@5  85.16 ( 88.61)\n","Epoch: [47][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.4919e+00 (1.3351e+00)\tAcc@1  58.59 ( 62.45)\tAcc@5  85.16 ( 88.43)\n","Epoch: [47][120/391]\tTime  0.169 ( 0.171)\tLoss 1.4799e+00 (1.3479e+00)\tAcc@1  58.59 ( 61.97)\tAcc@5  87.50 ( 88.24)\n","Epoch: [47][150/391]\tTime  0.170 ( 0.171)\tLoss 1.6202e+00 (1.3617e+00)\tAcc@1  58.59 ( 61.68)\tAcc@5  85.16 ( 87.99)\n","Epoch: [47][180/391]\tTime  0.171 ( 0.171)\tLoss 1.2753e+00 (1.3727e+00)\tAcc@1  64.06 ( 61.37)\tAcc@5  88.28 ( 87.86)\n","Epoch: [47][210/391]\tTime  0.169 ( 0.170)\tLoss 1.4557e+00 (1.3691e+00)\tAcc@1  61.72 ( 61.57)\tAcc@5  89.06 ( 87.94)\n","Epoch: [47][240/391]\tTime  0.171 ( 0.170)\tLoss 1.6082e+00 (1.3806e+00)\tAcc@1  53.12 ( 61.19)\tAcc@5  83.59 ( 87.76)\n","Epoch: [47][270/391]\tTime  0.172 ( 0.170)\tLoss 1.3869e+00 (1.3866e+00)\tAcc@1  60.94 ( 61.10)\tAcc@5  85.94 ( 87.67)\n","Epoch: [47][300/391]\tTime  0.167 ( 0.170)\tLoss 1.3313e+00 (1.3953e+00)\tAcc@1  57.03 ( 60.92)\tAcc@5  91.41 ( 87.57)\n","Epoch: [47][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3677e+00 (1.3969e+00)\tAcc@1  60.16 ( 60.89)\tAcc@5  90.62 ( 87.51)\n","Epoch: [47][360/391]\tTime  0.165 ( 0.170)\tLoss 1.2519e+00 (1.3936e+00)\tAcc@1  63.28 ( 60.94)\tAcc@5  89.84 ( 87.58)\n","Epoch: [47][390/391]\tTime  0.153 ( 0.170)\tLoss 1.6189e+00 (1.3971e+00)\tAcc@1  45.00 ( 60.81)\tAcc@5  87.50 ( 87.53)\n","==> Train Accuracy: Acc@1 60.806 || Acc@5 87.530\n","==> Test Accuracy:  Acc@1 56.550 || Acc@5 84.890\n","==> 70.74 seconds to train this epoch\n","\n","\n","----- epoch: 48, lr: 0.1 -----\n","Epoch: [48][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.3389e+00 (1.3389e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  89.84 ( 89.84)\n","Epoch: [48][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.2668e+00 (1.3217e+00)\tAcc@1  69.53 ( 63.03)\tAcc@5  92.19 ( 88.58)\n","Epoch: [48][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.4625e+00 (1.3632e+00)\tAcc@1  58.59 ( 61.96)\tAcc@5  85.16 ( 88.04)\n","Epoch: [48][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.4254e+00 (1.3549e+00)\tAcc@1  61.72 ( 62.17)\tAcc@5  85.16 ( 88.02)\n","Epoch: [48][120/391]\tTime  0.172 ( 0.171)\tLoss 1.4202e+00 (1.3531e+00)\tAcc@1  60.94 ( 62.13)\tAcc@5  86.72 ( 88.06)\n","Epoch: [48][150/391]\tTime  0.171 ( 0.171)\tLoss 1.2779e+00 (1.3624e+00)\tAcc@1  65.62 ( 61.96)\tAcc@5  88.28 ( 87.93)\n","Epoch: [48][180/391]\tTime  0.170 ( 0.170)\tLoss 1.3764e+00 (1.3651e+00)\tAcc@1  60.16 ( 61.80)\tAcc@5  86.72 ( 87.83)\n","Epoch: [48][210/391]\tTime  0.169 ( 0.170)\tLoss 1.2674e+00 (1.3757e+00)\tAcc@1  60.94 ( 61.68)\tAcc@5  90.62 ( 87.74)\n","Epoch: [48][240/391]\tTime  0.168 ( 0.170)\tLoss 1.4584e+00 (1.3785e+00)\tAcc@1  57.03 ( 61.56)\tAcc@5  87.50 ( 87.71)\n","Epoch: [48][270/391]\tTime  0.171 ( 0.170)\tLoss 1.2431e+00 (1.3825e+00)\tAcc@1  66.41 ( 61.41)\tAcc@5  89.06 ( 87.67)\n","Epoch: [48][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4191e+00 (1.3875e+00)\tAcc@1  60.16 ( 61.27)\tAcc@5  89.06 ( 87.58)\n","Epoch: [48][330/391]\tTime  0.170 ( 0.170)\tLoss 1.5078e+00 (1.3902e+00)\tAcc@1  57.81 ( 61.19)\tAcc@5  85.94 ( 87.52)\n","Epoch: [48][360/391]\tTime  0.172 ( 0.170)\tLoss 1.2027e+00 (1.3894e+00)\tAcc@1  66.41 ( 61.21)\tAcc@5  89.84 ( 87.48)\n","Epoch: [48][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3726e+00 (1.3925e+00)\tAcc@1  62.50 ( 61.15)\tAcc@5  85.00 ( 87.42)\n","==> Train Accuracy: Acc@1 61.150 || Acc@5 87.416\n","==> Test Accuracy:  Acc@1 59.210 || Acc@5 86.260\n","==> 70.72 seconds to train this epoch\n","\n","\n","----- epoch: 49, lr: 0.1 -----\n","Epoch: [49][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.4343e+00 (1.4343e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  89.06 ( 89.06)\n","Epoch: [49][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3507e+00 (1.3201e+00)\tAcc@1  60.16 ( 63.31)\tAcc@5  90.62 ( 88.76)\n","Epoch: [49][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.5088e+00 (1.3552e+00)\tAcc@1  58.59 ( 62.13)\tAcc@5  85.94 ( 88.04)\n","Epoch: [49][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3689e+00 (1.3562e+00)\tAcc@1  60.94 ( 61.81)\tAcc@5  88.28 ( 87.93)\n","Epoch: [49][120/391]\tTime  0.170 ( 0.171)\tLoss 1.3418e+00 (1.3635e+00)\tAcc@1  63.28 ( 61.55)\tAcc@5  88.28 ( 87.93)\n","Epoch: [49][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4554e+00 (1.3666e+00)\tAcc@1  60.16 ( 61.44)\tAcc@5  86.72 ( 88.01)\n","Epoch: [49][180/391]\tTime  0.169 ( 0.171)\tLoss 1.3546e+00 (1.3646e+00)\tAcc@1  60.16 ( 61.36)\tAcc@5  87.50 ( 88.08)\n","Epoch: [49][210/391]\tTime  0.170 ( 0.171)\tLoss 1.3439e+00 (1.3743e+00)\tAcc@1  64.06 ( 61.24)\tAcc@5  85.94 ( 87.94)\n","Epoch: [49][240/391]\tTime  0.171 ( 0.170)\tLoss 1.3353e+00 (1.3747e+00)\tAcc@1  61.72 ( 61.21)\tAcc@5  87.50 ( 87.94)\n","Epoch: [49][270/391]\tTime  0.169 ( 0.170)\tLoss 1.1466e+00 (1.3723e+00)\tAcc@1  68.75 ( 61.33)\tAcc@5  92.19 ( 87.96)\n","Epoch: [49][300/391]\tTime  0.169 ( 0.170)\tLoss 1.4726e+00 (1.3733e+00)\tAcc@1  60.16 ( 61.29)\tAcc@5  84.38 ( 87.97)\n","Epoch: [49][330/391]\tTime  0.169 ( 0.170)\tLoss 1.3330e+00 (1.3783e+00)\tAcc@1  65.62 ( 61.16)\tAcc@5  86.72 ( 87.88)\n","Epoch: [49][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3765e+00 (1.3840e+00)\tAcc@1  57.81 ( 60.94)\tAcc@5  89.84 ( 87.89)\n","Epoch: [49][390/391]\tTime  0.153 ( 0.170)\tLoss 1.7136e+00 (1.3874e+00)\tAcc@1  55.00 ( 60.81)\tAcc@5  86.25 ( 87.82)\n","==> Train Accuracy: Acc@1 60.808 || Acc@5 87.820\n","==> Test Accuracy:  Acc@1 59.210 || Acc@5 86.370\n","==> 70.71 seconds to train this epoch\n","\n","\n","----- epoch: 50, lr: 0.1 -----\n","Epoch: [50][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.2095e+00 (1.2095e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  89.06 ( 89.06)\n","Epoch: [50][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4002e+00 (1.3598e+00)\tAcc@1  60.94 ( 61.97)\tAcc@5  88.28 ( 87.80)\n","Epoch: [50][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.3247e+00 (1.3513e+00)\tAcc@1  65.62 ( 61.94)\tAcc@5  89.06 ( 87.90)\n","Epoch: [50][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3572e+00 (1.3487e+00)\tAcc@1  62.50 ( 61.92)\tAcc@5  87.50 ( 87.92)\n","Epoch: [50][120/391]\tTime  0.170 ( 0.171)\tLoss 1.5176e+00 (1.3595e+00)\tAcc@1  62.50 ( 61.73)\tAcc@5  83.59 ( 87.81)\n","Epoch: [50][150/391]\tTime  0.169 ( 0.171)\tLoss 1.4679e+00 (1.3560e+00)\tAcc@1  57.03 ( 61.76)\tAcc@5  85.94 ( 87.99)\n","Epoch: [50][180/391]\tTime  0.169 ( 0.170)\tLoss 1.3364e+00 (1.3593e+00)\tAcc@1  57.03 ( 61.59)\tAcc@5  86.72 ( 88.01)\n","Epoch: [50][210/391]\tTime  0.171 ( 0.170)\tLoss 1.4811e+00 (1.3638e+00)\tAcc@1  57.81 ( 61.54)\tAcc@5  85.94 ( 87.96)\n","Epoch: [50][240/391]\tTime  0.170 ( 0.170)\tLoss 1.2673e+00 (1.3690e+00)\tAcc@1  64.06 ( 61.38)\tAcc@5  89.84 ( 87.84)\n","Epoch: [50][270/391]\tTime  0.169 ( 0.170)\tLoss 1.2119e+00 (1.3718e+00)\tAcc@1  63.28 ( 61.29)\tAcc@5  91.41 ( 87.77)\n","Epoch: [50][300/391]\tTime  0.171 ( 0.170)\tLoss 1.2378e+00 (1.3751e+00)\tAcc@1  67.97 ( 61.15)\tAcc@5  87.50 ( 87.73)\n","Epoch: [50][330/391]\tTime  0.170 ( 0.170)\tLoss 1.4134e+00 (1.3776e+00)\tAcc@1  60.94 ( 61.09)\tAcc@5  87.50 ( 87.73)\n","Epoch: [50][360/391]\tTime  0.169 ( 0.170)\tLoss 1.2797e+00 (1.3852e+00)\tAcc@1  63.28 ( 60.89)\tAcc@5  89.84 ( 87.67)\n","Epoch: [50][390/391]\tTime  0.153 ( 0.170)\tLoss 1.4320e+00 (1.3879e+00)\tAcc@1  65.00 ( 60.87)\tAcc@5  87.50 ( 87.62)\n","==> Train Accuracy: Acc@1 60.872 || Acc@5 87.616\n","==> Test Accuracy:  Acc@1 58.640 || Acc@5 86.730\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 51, lr: 0.1 -----\n","Epoch: [51][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.1417e+00 (1.1417e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  90.62 ( 90.62)\n","Epoch: [51][ 30/391]\tTime  0.171 ( 0.174)\tLoss 1.1519e+00 (1.2594e+00)\tAcc@1  69.53 ( 64.04)\tAcc@5  89.84 ( 89.72)\n","Epoch: [51][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.0977e+00 (1.2946e+00)\tAcc@1  67.97 ( 63.32)\tAcc@5  92.97 ( 89.10)\n","Epoch: [51][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.5847e+00 (1.3386e+00)\tAcc@1  57.03 ( 62.47)\tAcc@5  85.94 ( 88.41)\n","Epoch: [51][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4448e+00 (1.3388e+00)\tAcc@1  58.59 ( 62.31)\tAcc@5  85.94 ( 88.35)\n","Epoch: [51][150/391]\tTime  0.171 ( 0.171)\tLoss 1.5530e+00 (1.3397e+00)\tAcc@1  59.38 ( 62.32)\tAcc@5  88.28 ( 88.48)\n","Epoch: [51][180/391]\tTime  0.170 ( 0.171)\tLoss 1.4781e+00 (1.3451e+00)\tAcc@1  58.59 ( 62.10)\tAcc@5  84.38 ( 88.43)\n","Epoch: [51][210/391]\tTime  0.171 ( 0.171)\tLoss 1.5492e+00 (1.3567e+00)\tAcc@1  58.59 ( 61.79)\tAcc@5  85.94 ( 88.20)\n","Epoch: [51][240/391]\tTime  0.170 ( 0.171)\tLoss 1.4516e+00 (1.3578e+00)\tAcc@1  55.47 ( 61.66)\tAcc@5  87.50 ( 88.25)\n","Epoch: [51][270/391]\tTime  0.171 ( 0.171)\tLoss 1.3276e+00 (1.3618e+00)\tAcc@1  61.72 ( 61.59)\tAcc@5  87.50 ( 88.15)\n","Epoch: [51][300/391]\tTime  0.170 ( 0.171)\tLoss 1.5376e+00 (1.3704e+00)\tAcc@1  57.81 ( 61.40)\tAcc@5  87.50 ( 88.05)\n","Epoch: [51][330/391]\tTime  0.170 ( 0.171)\tLoss 1.5335e+00 (1.3743e+00)\tAcc@1  58.59 ( 61.27)\tAcc@5  85.94 ( 88.00)\n","Epoch: [51][360/391]\tTime  0.169 ( 0.171)\tLoss 1.3735e+00 (1.3760e+00)\tAcc@1  64.06 ( 61.30)\tAcc@5  87.50 ( 87.94)\n","Epoch: [51][390/391]\tTime  0.152 ( 0.171)\tLoss 1.9279e+00 (1.3806e+00)\tAcc@1  46.25 ( 61.24)\tAcc@5  80.00 ( 87.84)\n","==> Train Accuracy: Acc@1 61.236 || Acc@5 87.838\n","==> Test Accuracy:  Acc@1 56.950 || Acc@5 85.790\n","==> 70.86 seconds to train this epoch\n","\n","\n","----- epoch: 52, lr: 0.1 -----\n","Epoch: [52][  0/391]\tTime  0.279 ( 0.279)\tLoss 9.9762e-01 (9.9762e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  93.75 ( 93.75)\n","Epoch: [52][ 30/391]\tTime  0.172 ( 0.174)\tLoss 1.3213e+00 (1.2923e+00)\tAcc@1  62.50 ( 63.68)\tAcc@5  90.62 ( 89.11)\n","Epoch: [52][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.3009e+00 (1.3234e+00)\tAcc@1  61.72 ( 62.58)\tAcc@5  89.84 ( 88.63)\n","Epoch: [52][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4981e+00 (1.3260e+00)\tAcc@1  64.06 ( 62.64)\tAcc@5  86.72 ( 88.40)\n","Epoch: [52][120/391]\tTime  0.171 ( 0.171)\tLoss 1.3816e+00 (1.3342e+00)\tAcc@1  61.72 ( 62.35)\tAcc@5  88.28 ( 88.33)\n","Epoch: [52][150/391]\tTime  0.171 ( 0.171)\tLoss 1.5581e+00 (1.3479e+00)\tAcc@1  60.16 ( 61.86)\tAcc@5  87.50 ( 88.16)\n","Epoch: [52][180/391]\tTime  0.169 ( 0.171)\tLoss 1.4409e+00 (1.3618e+00)\tAcc@1  57.03 ( 61.44)\tAcc@5  85.16 ( 87.95)\n","Epoch: [52][210/391]\tTime  0.170 ( 0.171)\tLoss 1.1837e+00 (1.3596e+00)\tAcc@1  70.31 ( 61.61)\tAcc@5  92.19 ( 88.02)\n","Epoch: [52][240/391]\tTime  0.171 ( 0.170)\tLoss 1.5103e+00 (1.3685e+00)\tAcc@1  58.59 ( 61.36)\tAcc@5  82.81 ( 87.88)\n","Epoch: [52][270/391]\tTime  0.170 ( 0.170)\tLoss 1.4498e+00 (1.3660e+00)\tAcc@1  62.50 ( 61.42)\tAcc@5  83.59 ( 87.94)\n","Epoch: [52][300/391]\tTime  0.168 ( 0.170)\tLoss 1.5802e+00 (1.3672e+00)\tAcc@1  53.91 ( 61.42)\tAcc@5  85.16 ( 87.90)\n","Epoch: [52][330/391]\tTime  0.171 ( 0.170)\tLoss 1.4205e+00 (1.3715e+00)\tAcc@1  53.91 ( 61.31)\tAcc@5  89.84 ( 87.89)\n","Epoch: [52][360/391]\tTime  0.169 ( 0.170)\tLoss 1.3870e+00 (1.3738e+00)\tAcc@1  62.50 ( 61.25)\tAcc@5  89.06 ( 87.86)\n","Epoch: [52][390/391]\tTime  0.153 ( 0.170)\tLoss 1.1839e+00 (1.3771e+00)\tAcc@1  63.75 ( 61.18)\tAcc@5  93.75 ( 87.83)\n","==> Train Accuracy: Acc@1 61.182 || Acc@5 87.826\n","==> Test Accuracy:  Acc@1 54.760 || Acc@5 82.870\n","==> 70.75 seconds to train this epoch\n","\n","\n","----- epoch: 53, lr: 0.1 -----\n","Epoch: [53][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.4603e+00 (1.4603e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  86.72 ( 86.72)\n","Epoch: [53][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3699e+00 (1.3191e+00)\tAcc@1  61.72 ( 63.13)\tAcc@5  87.50 ( 88.56)\n","Epoch: [53][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.0408e+00 (1.3086e+00)\tAcc@1  70.31 ( 63.18)\tAcc@5  92.19 ( 88.93)\n","Epoch: [53][ 90/391]\tTime  0.172 ( 0.171)\tLoss 1.2427e+00 (1.3249e+00)\tAcc@1  66.41 ( 62.77)\tAcc@5  85.94 ( 88.62)\n","Epoch: [53][120/391]\tTime  0.172 ( 0.171)\tLoss 1.3443e+00 (1.3426e+00)\tAcc@1  62.50 ( 62.36)\tAcc@5  90.62 ( 88.22)\n","Epoch: [53][150/391]\tTime  0.171 ( 0.171)\tLoss 1.5651e+00 (1.3523e+00)\tAcc@1  55.47 ( 61.99)\tAcc@5  87.50 ( 88.23)\n","Epoch: [53][180/391]\tTime  0.171 ( 0.171)\tLoss 1.3705e+00 (1.3605e+00)\tAcc@1  64.84 ( 61.89)\tAcc@5  87.50 ( 88.10)\n","Epoch: [53][210/391]\tTime  0.169 ( 0.171)\tLoss 1.2230e+00 (1.3661e+00)\tAcc@1  67.19 ( 61.76)\tAcc@5  89.06 ( 87.96)\n","Epoch: [53][240/391]\tTime  0.170 ( 0.171)\tLoss 1.2112e+00 (1.3646e+00)\tAcc@1  64.06 ( 61.76)\tAcc@5  91.41 ( 88.07)\n","Epoch: [53][270/391]\tTime  0.170 ( 0.171)\tLoss 1.7459e+00 (1.3744e+00)\tAcc@1  50.78 ( 61.57)\tAcc@5  83.59 ( 87.94)\n","Epoch: [53][300/391]\tTime  0.170 ( 0.171)\tLoss 1.4362e+00 (1.3770e+00)\tAcc@1  60.16 ( 61.57)\tAcc@5  84.38 ( 87.85)\n","Epoch: [53][330/391]\tTime  0.170 ( 0.171)\tLoss 1.4087e+00 (1.3777e+00)\tAcc@1  60.16 ( 61.52)\tAcc@5  88.28 ( 87.75)\n","Epoch: [53][360/391]\tTime  0.169 ( 0.171)\tLoss 1.1929e+00 (1.3799e+00)\tAcc@1  65.62 ( 61.46)\tAcc@5  90.62 ( 87.71)\n","Epoch: [53][390/391]\tTime  0.152 ( 0.170)\tLoss 1.4490e+00 (1.3795e+00)\tAcc@1  60.00 ( 61.47)\tAcc@5  82.50 ( 87.73)\n","==> Train Accuracy: Acc@1 61.466 || Acc@5 87.726\n","==> Test Accuracy:  Acc@1 55.150 || Acc@5 84.380\n","==> 70.84 seconds to train this epoch\n","\n","\n","----- epoch: 54, lr: 0.1 -----\n","Epoch: [54][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.2638e+00 (1.2638e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  89.06 ( 89.06)\n","Epoch: [54][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3283e+00 (1.3155e+00)\tAcc@1  58.59 ( 62.85)\tAcc@5  91.41 ( 88.63)\n","Epoch: [54][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.3224e+00 (1.3342e+00)\tAcc@1  59.38 ( 62.37)\tAcc@5  89.06 ( 88.24)\n","Epoch: [54][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.3392e+00 (1.3380e+00)\tAcc@1  59.38 ( 62.34)\tAcc@5  90.62 ( 88.38)\n","Epoch: [54][120/391]\tTime  0.170 ( 0.171)\tLoss 1.1271e+00 (1.3374e+00)\tAcc@1  64.84 ( 62.32)\tAcc@5  91.41 ( 88.37)\n","Epoch: [54][150/391]\tTime  0.171 ( 0.171)\tLoss 1.6161e+00 (1.3408e+00)\tAcc@1  58.59 ( 62.26)\tAcc@5  82.81 ( 88.24)\n","Epoch: [54][180/391]\tTime  0.165 ( 0.171)\tLoss 1.3979e+00 (1.3519e+00)\tAcc@1  58.59 ( 62.03)\tAcc@5  85.16 ( 87.99)\n","Epoch: [54][210/391]\tTime  0.170 ( 0.171)\tLoss 1.3664e+00 (1.3554e+00)\tAcc@1  61.72 ( 61.93)\tAcc@5  89.06 ( 87.93)\n","Epoch: [54][240/391]\tTime  0.170 ( 0.171)\tLoss 1.4768e+00 (1.3588e+00)\tAcc@1  57.81 ( 61.86)\tAcc@5  86.72 ( 87.91)\n","Epoch: [54][270/391]\tTime  0.170 ( 0.170)\tLoss 1.1674e+00 (1.3675e+00)\tAcc@1  67.19 ( 61.64)\tAcc@5  91.41 ( 87.76)\n","Epoch: [54][300/391]\tTime  0.170 ( 0.170)\tLoss 1.3808e+00 (1.3784e+00)\tAcc@1  60.94 ( 61.36)\tAcc@5  88.28 ( 87.62)\n","Epoch: [54][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3593e+00 (1.3760e+00)\tAcc@1  59.38 ( 61.40)\tAcc@5  89.84 ( 87.64)\n","Epoch: [54][360/391]\tTime  0.169 ( 0.170)\tLoss 1.1536e+00 (1.3779e+00)\tAcc@1  65.62 ( 61.33)\tAcc@5  90.62 ( 87.63)\n","Epoch: [54][390/391]\tTime  0.152 ( 0.170)\tLoss 1.3901e+00 (1.3820e+00)\tAcc@1  61.25 ( 61.25)\tAcc@5  87.50 ( 87.57)\n","==> Train Accuracy: Acc@1 61.248 || Acc@5 87.574\n","==> Test Accuracy:  Acc@1 55.560 || Acc@5 83.260\n","==> 70.74 seconds to train this epoch\n","\n","\n","----- epoch: 55, lr: 0.1 -----\n","Epoch: [55][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.3996e+00 (1.3996e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  85.94 ( 85.94)\n","Epoch: [55][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.3438e+00 (1.3245e+00)\tAcc@1  61.72 ( 62.15)\tAcc@5  88.28 ( 88.36)\n","Epoch: [55][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.2880e+00 (1.3172e+00)\tAcc@1  65.62 ( 62.62)\tAcc@5  90.62 ( 88.56)\n","Epoch: [55][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.2593e+00 (1.3259e+00)\tAcc@1  68.75 ( 62.27)\tAcc@5  89.84 ( 88.49)\n","Epoch: [55][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4574e+00 (1.3437e+00)\tAcc@1  60.94 ( 62.00)\tAcc@5  85.94 ( 88.29)\n","Epoch: [55][150/391]\tTime  0.170 ( 0.171)\tLoss 1.5883e+00 (1.3525e+00)\tAcc@1  53.12 ( 61.81)\tAcc@5  85.16 ( 88.17)\n","Epoch: [55][180/391]\tTime  0.170 ( 0.171)\tLoss 1.6647e+00 (1.3568e+00)\tAcc@1  56.25 ( 61.66)\tAcc@5  82.81 ( 88.25)\n","Epoch: [55][210/391]\tTime  0.170 ( 0.171)\tLoss 1.3349e+00 (1.3619e+00)\tAcc@1  65.62 ( 61.42)\tAcc@5  90.62 ( 88.15)\n","Epoch: [55][240/391]\tTime  0.170 ( 0.171)\tLoss 1.6800e+00 (1.3718e+00)\tAcc@1  53.91 ( 61.16)\tAcc@5  85.16 ( 88.03)\n","Epoch: [55][270/391]\tTime  0.170 ( 0.171)\tLoss 1.4321e+00 (1.3725e+00)\tAcc@1  62.50 ( 61.19)\tAcc@5  89.06 ( 88.00)\n","Epoch: [55][300/391]\tTime  0.169 ( 0.171)\tLoss 1.6237e+00 (1.3703e+00)\tAcc@1  50.78 ( 61.25)\tAcc@5  86.72 ( 88.02)\n","Epoch: [55][330/391]\tTime  0.170 ( 0.170)\tLoss 1.1739e+00 (1.3693e+00)\tAcc@1  68.75 ( 61.35)\tAcc@5  90.62 ( 88.02)\n","Epoch: [55][360/391]\tTime  0.169 ( 0.170)\tLoss 1.3933e+00 (1.3718e+00)\tAcc@1  59.38 ( 61.25)\tAcc@5  87.50 ( 87.94)\n","Epoch: [55][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3500e+00 (1.3773e+00)\tAcc@1  63.75 ( 61.07)\tAcc@5  90.00 ( 87.87)\n","==> Train Accuracy: Acc@1 61.074 || Acc@5 87.866\n","==> Test Accuracy:  Acc@1 56.850 || Acc@5 84.780\n","==> 70.80 seconds to train this epoch\n","\n","\n","----- epoch: 56, lr: 0.1 -----\n","Epoch: [56][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.2540e+00 (1.2540e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  89.06 ( 89.06)\n","Epoch: [56][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.4260e+00 (1.2859e+00)\tAcc@1  60.16 ( 63.66)\tAcc@5  89.06 ( 89.16)\n","Epoch: [56][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.4386e+00 (1.3170e+00)\tAcc@1  64.06 ( 63.32)\tAcc@5  87.50 ( 88.65)\n","Epoch: [56][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.0831e+00 (1.3280e+00)\tAcc@1  71.09 ( 62.89)\tAcc@5  89.84 ( 88.36)\n","Epoch: [56][120/391]\tTime  0.169 ( 0.171)\tLoss 1.1790e+00 (1.3354e+00)\tAcc@1  64.06 ( 62.56)\tAcc@5  91.41 ( 88.16)\n","Epoch: [56][150/391]\tTime  0.171 ( 0.170)\tLoss 1.4113e+00 (1.3360e+00)\tAcc@1  64.06 ( 62.60)\tAcc@5  88.28 ( 88.22)\n","Epoch: [56][180/391]\tTime  0.171 ( 0.170)\tLoss 1.2586e+00 (1.3352e+00)\tAcc@1  65.62 ( 62.47)\tAcc@5  89.84 ( 88.34)\n","Epoch: [56][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3181e+00 (1.3398e+00)\tAcc@1  60.94 ( 62.30)\tAcc@5  89.84 ( 88.22)\n","Epoch: [56][240/391]\tTime  0.170 ( 0.170)\tLoss 1.3487e+00 (1.3435e+00)\tAcc@1  63.28 ( 62.26)\tAcc@5  89.06 ( 88.13)\n","Epoch: [56][270/391]\tTime  0.170 ( 0.170)\tLoss 1.2832e+00 (1.3481e+00)\tAcc@1  63.28 ( 62.21)\tAcc@5  86.72 ( 88.05)\n","Epoch: [56][300/391]\tTime  0.169 ( 0.170)\tLoss 1.3744e+00 (1.3537e+00)\tAcc@1  60.94 ( 62.10)\tAcc@5  89.06 ( 87.94)\n","Epoch: [56][330/391]\tTime  0.169 ( 0.170)\tLoss 1.3911e+00 (1.3613e+00)\tAcc@1  58.59 ( 61.90)\tAcc@5  85.16 ( 87.83)\n","Epoch: [56][360/391]\tTime  0.171 ( 0.170)\tLoss 1.5588e+00 (1.3650e+00)\tAcc@1  58.59 ( 61.86)\tAcc@5  83.59 ( 87.74)\n","Epoch: [56][390/391]\tTime  0.154 ( 0.170)\tLoss 1.2158e+00 (1.3692e+00)\tAcc@1  62.50 ( 61.71)\tAcc@5  93.75 ( 87.70)\n","==> Train Accuracy: Acc@1 61.708 || Acc@5 87.704\n","==> Test Accuracy:  Acc@1 58.130 || Acc@5 85.420\n","==> 70.74 seconds to train this epoch\n","\n","\n","----- epoch: 57, lr: 0.1 -----\n","Epoch: [57][  0/391]\tTime  0.303 ( 0.303)\tLoss 1.3187e+00 (1.3187e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  88.28 ( 88.28)\n","Epoch: [57][ 30/391]\tTime  0.171 ( 0.174)\tLoss 1.2654e+00 (1.3111e+00)\tAcc@1  62.50 ( 62.58)\tAcc@5  90.62 ( 89.26)\n","Epoch: [57][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.4614e+00 (1.3031e+00)\tAcc@1  60.94 ( 62.60)\tAcc@5  85.94 ( 89.02)\n","Epoch: [57][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.4669e+00 (1.3395e+00)\tAcc@1  53.12 ( 61.45)\tAcc@5  86.72 ( 88.53)\n","Epoch: [57][120/391]\tTime  0.169 ( 0.171)\tLoss 1.5171e+00 (1.3452e+00)\tAcc@1  60.94 ( 61.45)\tAcc@5  87.50 ( 88.62)\n","Epoch: [57][150/391]\tTime  0.170 ( 0.171)\tLoss 1.6067e+00 (1.3433e+00)\tAcc@1  55.47 ( 61.73)\tAcc@5  81.25 ( 88.51)\n","Epoch: [57][180/391]\tTime  0.170 ( 0.171)\tLoss 1.3405e+00 (1.3490e+00)\tAcc@1  63.28 ( 61.55)\tAcc@5  88.28 ( 88.46)\n","Epoch: [57][210/391]\tTime  0.170 ( 0.171)\tLoss 1.3762e+00 (1.3553e+00)\tAcc@1  59.38 ( 61.46)\tAcc@5  87.50 ( 88.27)\n","Epoch: [57][240/391]\tTime  0.171 ( 0.171)\tLoss 1.4475e+00 (1.3613e+00)\tAcc@1  58.59 ( 61.34)\tAcc@5  82.81 ( 88.15)\n","Epoch: [57][270/391]\tTime  0.172 ( 0.171)\tLoss 1.4722e+00 (1.3672e+00)\tAcc@1  57.81 ( 61.13)\tAcc@5  85.94 ( 88.10)\n","Epoch: [57][300/391]\tTime  0.174 ( 0.171)\tLoss 1.1957e+00 (1.3667e+00)\tAcc@1  67.19 ( 61.23)\tAcc@5  89.84 ( 88.12)\n","Epoch: [57][330/391]\tTime  0.170 ( 0.171)\tLoss 1.3216e+00 (1.3661e+00)\tAcc@1  64.84 ( 61.34)\tAcc@5  83.59 ( 88.07)\n","Epoch: [57][360/391]\tTime  0.173 ( 0.170)\tLoss 1.6085e+00 (1.3687e+00)\tAcc@1  59.38 ( 61.31)\tAcc@5  82.81 ( 88.06)\n","Epoch: [57][390/391]\tTime  0.154 ( 0.170)\tLoss 1.3895e+00 (1.3735e+00)\tAcc@1  65.00 ( 61.29)\tAcc@5  83.75 ( 87.96)\n","==> Train Accuracy: Acc@1 61.294 || Acc@5 87.960\n","==> Test Accuracy:  Acc@1 60.310 || Acc@5 87.440\n","==> 70.81 seconds to train this epoch\n","\n","\n","----- epoch: 58, lr: 0.1 -----\n","Epoch: [58][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.1181e+00 (1.1181e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  91.41 ( 91.41)\n","Epoch: [58][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.7061e+00 (1.3218e+00)\tAcc@1  51.56 ( 62.50)\tAcc@5  82.81 ( 88.71)\n","Epoch: [58][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.1778e+00 (1.3225e+00)\tAcc@1  71.09 ( 62.59)\tAcc@5  90.62 ( 88.70)\n","Epoch: [58][ 90/391]\tTime  0.172 ( 0.171)\tLoss 1.5431e+00 (1.3323e+00)\tAcc@1  59.38 ( 62.51)\tAcc@5  83.59 ( 88.10)\n","Epoch: [58][120/391]\tTime  0.170 ( 0.171)\tLoss 1.3812e+00 (1.3453e+00)\tAcc@1  61.72 ( 62.21)\tAcc@5  87.50 ( 88.06)\n","Epoch: [58][150/391]\tTime  0.171 ( 0.171)\tLoss 1.4056e+00 (1.3429e+00)\tAcc@1  56.25 ( 62.26)\tAcc@5  85.94 ( 88.08)\n","Epoch: [58][180/391]\tTime  0.172 ( 0.171)\tLoss 1.0795e+00 (1.3480e+00)\tAcc@1  67.97 ( 62.12)\tAcc@5  91.41 ( 88.01)\n","Epoch: [58][210/391]\tTime  0.171 ( 0.171)\tLoss 1.7310e+00 (1.3528e+00)\tAcc@1  50.78 ( 61.93)\tAcc@5  82.03 ( 87.95)\n","Epoch: [58][240/391]\tTime  0.170 ( 0.171)\tLoss 1.0350e+00 (1.3556e+00)\tAcc@1  73.44 ( 61.88)\tAcc@5  90.62 ( 87.96)\n","Epoch: [58][270/391]\tTime  0.170 ( 0.171)\tLoss 1.2681e+00 (1.3563e+00)\tAcc@1  69.53 ( 62.00)\tAcc@5  88.28 ( 87.92)\n","Epoch: [58][300/391]\tTime  0.174 ( 0.171)\tLoss 1.1466e+00 (1.3568e+00)\tAcc@1  74.22 ( 62.10)\tAcc@5  91.41 ( 87.91)\n","Epoch: [58][330/391]\tTime  0.171 ( 0.171)\tLoss 1.3935e+00 (1.3571e+00)\tAcc@1  58.59 ( 62.08)\tAcc@5  87.50 ( 87.90)\n","Epoch: [58][360/391]\tTime  0.169 ( 0.171)\tLoss 1.3165e+00 (1.3588e+00)\tAcc@1  71.88 ( 62.03)\tAcc@5  88.28 ( 87.88)\n","Epoch: [58][390/391]\tTime  0.154 ( 0.171)\tLoss 1.4312e+00 (1.3616e+00)\tAcc@1  56.25 ( 61.95)\tAcc@5  88.75 ( 87.86)\n","==> Train Accuracy: Acc@1 61.946 || Acc@5 87.862\n","==> Test Accuracy:  Acc@1 59.280 || Acc@5 87.300\n","==> 70.86 seconds to train this epoch\n","\n","\n","----- epoch: 59, lr: 0.1 -----\n","Epoch: [59][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.4807e+00 (1.4807e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  85.16 ( 85.16)\n","Epoch: [59][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.2782e+00 (1.3312e+00)\tAcc@1  61.72 ( 62.20)\tAcc@5  91.41 ( 88.63)\n","Epoch: [59][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.3563e+00 (1.3094e+00)\tAcc@1  61.72 ( 62.72)\tAcc@5  88.28 ( 88.67)\n","Epoch: [59][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3918e+00 (1.3274e+00)\tAcc@1  60.94 ( 62.13)\tAcc@5  92.19 ( 88.54)\n","Epoch: [59][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4559e+00 (1.3291e+00)\tAcc@1  59.38 ( 62.17)\tAcc@5  85.16 ( 88.49)\n","Epoch: [59][150/391]\tTime  0.170 ( 0.171)\tLoss 1.2533e+00 (1.3398e+00)\tAcc@1  65.62 ( 62.03)\tAcc@5  85.16 ( 88.28)\n","Epoch: [59][180/391]\tTime  0.170 ( 0.171)\tLoss 1.3749e+00 (1.3504e+00)\tAcc@1  61.72 ( 61.75)\tAcc@5  85.16 ( 88.12)\n","Epoch: [59][210/391]\tTime  0.171 ( 0.171)\tLoss 1.5939e+00 (1.3545e+00)\tAcc@1  52.34 ( 61.72)\tAcc@5  86.72 ( 88.13)\n","Epoch: [59][240/391]\tTime  0.169 ( 0.171)\tLoss 1.1557e+00 (1.3592e+00)\tAcc@1  71.88 ( 61.59)\tAcc@5  92.19 ( 88.05)\n","Epoch: [59][270/391]\tTime  0.170 ( 0.171)\tLoss 1.2000e+00 (1.3671e+00)\tAcc@1  64.84 ( 61.36)\tAcc@5  86.72 ( 87.90)\n","Epoch: [59][300/391]\tTime  0.170 ( 0.171)\tLoss 1.3313e+00 (1.3622e+00)\tAcc@1  64.84 ( 61.57)\tAcc@5  90.62 ( 87.94)\n","Epoch: [59][330/391]\tTime  0.170 ( 0.171)\tLoss 1.2195e+00 (1.3608e+00)\tAcc@1  66.41 ( 61.59)\tAcc@5  92.19 ( 88.00)\n","Epoch: [59][360/391]\tTime  0.171 ( 0.171)\tLoss 1.4000e+00 (1.3607e+00)\tAcc@1  64.06 ( 61.57)\tAcc@5  85.94 ( 88.03)\n","Epoch: [59][390/391]\tTime  0.152 ( 0.170)\tLoss 1.3931e+00 (1.3662e+00)\tAcc@1  61.25 ( 61.47)\tAcc@5  91.25 ( 87.92)\n","==> Train Accuracy: Acc@1 61.468 || Acc@5 87.922\n","==> Test Accuracy:  Acc@1 57.660 || Acc@5 85.780\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 60, lr: 0.020000000000000004 -----\n","Epoch: [60][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.6193e+00 (1.6193e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  83.59 ( 83.59)\n","Epoch: [60][ 30/391]\tTime  0.169 ( 0.173)\tLoss 9.2382e-01 (1.1871e+00)\tAcc@1  75.00 ( 66.53)\tAcc@5  92.19 ( 90.37)\n","Epoch: [60][ 60/391]\tTime  0.169 ( 0.171)\tLoss 8.6534e-01 (1.1078e+00)\tAcc@1  72.66 ( 68.60)\tAcc@5  94.53 ( 91.30)\n","Epoch: [60][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.1411e+00 (1.0669e+00)\tAcc@1  70.31 ( 69.78)\tAcc@5  88.28 ( 91.66)\n","Epoch: [60][120/391]\tTime  0.171 ( 0.170)\tLoss 9.8199e-01 (1.0332e+00)\tAcc@1  73.44 ( 70.71)\tAcc@5  92.19 ( 91.99)\n","Epoch: [60][150/391]\tTime  0.169 ( 0.170)\tLoss 1.0713e+00 (1.0147e+00)\tAcc@1  74.22 ( 71.22)\tAcc@5  91.41 ( 92.22)\n","Epoch: [60][180/391]\tTime  0.169 ( 0.170)\tLoss 1.0247e+00 (9.9650e-01)\tAcc@1  70.31 ( 71.61)\tAcc@5  92.19 ( 92.49)\n","Epoch: [60][210/391]\tTime  0.171 ( 0.170)\tLoss 9.7067e-01 (9.8253e-01)\tAcc@1  76.56 ( 71.92)\tAcc@5  92.19 ( 92.62)\n","Epoch: [60][240/391]\tTime  0.170 ( 0.170)\tLoss 9.9560e-01 (9.6986e-01)\tAcc@1  67.97 ( 72.12)\tAcc@5  94.53 ( 92.83)\n","Epoch: [60][270/391]\tTime  0.170 ( 0.170)\tLoss 9.1436e-01 (9.6117e-01)\tAcc@1  71.88 ( 72.30)\tAcc@5  92.97 ( 92.89)\n","Epoch: [60][300/391]\tTime  0.169 ( 0.170)\tLoss 6.7752e-01 (9.5075e-01)\tAcc@1  79.69 ( 72.50)\tAcc@5  98.44 ( 93.09)\n","Epoch: [60][330/391]\tTime  0.171 ( 0.170)\tLoss 8.8340e-01 (9.4644e-01)\tAcc@1  75.00 ( 72.62)\tAcc@5  91.41 ( 93.13)\n","Epoch: [60][360/391]\tTime  0.170 ( 0.170)\tLoss 7.8397e-01 (9.4334e-01)\tAcc@1  74.22 ( 72.62)\tAcc@5  96.09 ( 93.15)\n","Epoch: [60][390/391]\tTime  0.152 ( 0.170)\tLoss 8.6120e-01 (9.3610e-01)\tAcc@1  68.75 ( 72.83)\tAcc@5  93.75 ( 93.21)\n","==> Train Accuracy: Acc@1 72.830 || Acc@5 93.212\n","==> Test Accuracy:  Acc@1 74.190 || Acc@5 93.660\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 61, lr: 0.020000000000000004 -----\n","Epoch: [61][  0/391]\tTime  0.293 ( 0.293)\tLoss 8.3036e-01 (8.3036e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  93.75 ( 93.75)\n","Epoch: [61][ 30/391]\tTime  0.171 ( 0.174)\tLoss 6.5630e-01 (7.9743e-01)\tAcc@1  80.47 ( 77.49)\tAcc@5  98.44 ( 94.18)\n","Epoch: [61][ 60/391]\tTime  0.169 ( 0.172)\tLoss 7.8391e-01 (7.7133e-01)\tAcc@1  73.44 ( 78.00)\tAcc@5  94.53 ( 94.71)\n","Epoch: [61][ 90/391]\tTime  0.171 ( 0.171)\tLoss 8.0495e-01 (7.7262e-01)\tAcc@1  72.66 ( 77.81)\tAcc@5  96.88 ( 94.75)\n","Epoch: [61][120/391]\tTime  0.170 ( 0.171)\tLoss 8.8783e-01 (7.8005e-01)\tAcc@1  74.22 ( 77.49)\tAcc@5  96.88 ( 94.81)\n","Epoch: [61][150/391]\tTime  0.171 ( 0.171)\tLoss 8.2445e-01 (7.8344e-01)\tAcc@1  75.78 ( 77.43)\tAcc@5  94.53 ( 94.80)\n","Epoch: [61][180/391]\tTime  0.171 ( 0.170)\tLoss 8.4379e-01 (7.8368e-01)\tAcc@1  75.78 ( 77.31)\tAcc@5  93.75 ( 94.77)\n","Epoch: [61][210/391]\tTime  0.171 ( 0.170)\tLoss 7.6174e-01 (7.8932e-01)\tAcc@1  80.47 ( 77.19)\tAcc@5  95.31 ( 94.72)\n","Epoch: [61][240/391]\tTime  0.169 ( 0.170)\tLoss 5.9105e-01 (7.8692e-01)\tAcc@1  82.81 ( 77.25)\tAcc@5  97.66 ( 94.75)\n","Epoch: [61][270/391]\tTime  0.169 ( 0.170)\tLoss 8.0393e-01 (7.8804e-01)\tAcc@1  76.56 ( 77.06)\tAcc@5  94.53 ( 94.78)\n","Epoch: [61][300/391]\tTime  0.169 ( 0.170)\tLoss 7.3774e-01 (7.8266e-01)\tAcc@1  77.34 ( 77.16)\tAcc@5  94.53 ( 94.85)\n","Epoch: [61][330/391]\tTime  0.169 ( 0.170)\tLoss 8.3971e-01 (7.8257e-01)\tAcc@1  81.25 ( 77.17)\tAcc@5  92.97 ( 94.86)\n","Epoch: [61][360/391]\tTime  0.165 ( 0.170)\tLoss 5.8828e-01 (7.8453e-01)\tAcc@1  82.03 ( 77.08)\tAcc@5  94.53 ( 94.83)\n","Epoch: [61][390/391]\tTime  0.150 ( 0.170)\tLoss 1.0459e+00 (7.8654e-01)\tAcc@1  68.75 ( 77.03)\tAcc@5  95.00 ( 94.80)\n","==> Train Accuracy: Acc@1 77.032 || Acc@5 94.800\n","==> Test Accuracy:  Acc@1 74.230 || Acc@5 93.880\n","==> 70.70 seconds to train this epoch\n","\n","\n","----- epoch: 62, lr: 0.020000000000000004 -----\n","Epoch: [62][  0/391]\tTime  0.292 ( 0.292)\tLoss 7.3587e-01 (7.3587e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  95.31 ( 95.31)\n","Epoch: [62][ 30/391]\tTime  0.169 ( 0.173)\tLoss 6.2428e-01 (6.9438e-01)\tAcc@1  82.03 ( 79.44)\tAcc@5  98.44 ( 95.94)\n","Epoch: [62][ 60/391]\tTime  0.170 ( 0.172)\tLoss 6.6925e-01 (6.9935e-01)\tAcc@1  80.47 ( 78.92)\tAcc@5  98.44 ( 95.81)\n","Epoch: [62][ 90/391]\tTime  0.171 ( 0.171)\tLoss 6.5311e-01 (7.1787e-01)\tAcc@1  80.47 ( 78.74)\tAcc@5  96.88 ( 95.58)\n","Epoch: [62][120/391]\tTime  0.169 ( 0.171)\tLoss 7.7717e-01 (7.1570e-01)\tAcc@1  78.91 ( 78.77)\tAcc@5  94.53 ( 95.70)\n","Epoch: [62][150/391]\tTime  0.170 ( 0.171)\tLoss 6.5981e-01 (7.1978e-01)\tAcc@1  83.59 ( 78.61)\tAcc@5  96.88 ( 95.70)\n","Epoch: [62][180/391]\tTime  0.170 ( 0.171)\tLoss 7.3697e-01 (7.2374e-01)\tAcc@1  78.91 ( 78.47)\tAcc@5  96.09 ( 95.71)\n","Epoch: [62][210/391]\tTime  0.170 ( 0.171)\tLoss 7.2581e-01 (7.3267e-01)\tAcc@1  79.69 ( 78.22)\tAcc@5  94.53 ( 95.60)\n","Epoch: [62][240/391]\tTime  0.169 ( 0.171)\tLoss 6.5093e-01 (7.3685e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  98.44 ( 95.57)\n","Epoch: [62][270/391]\tTime  0.171 ( 0.171)\tLoss 9.7329e-01 (7.3712e-01)\tAcc@1  72.66 ( 78.19)\tAcc@5  92.19 ( 95.49)\n","Epoch: [62][300/391]\tTime  0.169 ( 0.171)\tLoss 8.3647e-01 (7.4222e-01)\tAcc@1  72.66 ( 77.97)\tAcc@5  94.53 ( 95.46)\n","Epoch: [62][330/391]\tTime  0.170 ( 0.171)\tLoss 6.4016e-01 (7.4359e-01)\tAcc@1  82.03 ( 77.91)\tAcc@5  96.09 ( 95.41)\n","Epoch: [62][360/391]\tTime  0.169 ( 0.171)\tLoss 6.8948e-01 (7.4540e-01)\tAcc@1  79.69 ( 77.82)\tAcc@5  96.09 ( 95.41)\n","Epoch: [62][390/391]\tTime  0.153 ( 0.170)\tLoss 5.1817e-01 (7.4658e-01)\tAcc@1  82.50 ( 77.81)\tAcc@5  98.75 ( 95.37)\n","==> Train Accuracy: Acc@1 77.810 || Acc@5 95.370\n","==> Test Accuracy:  Acc@1 74.860 || Acc@5 93.940\n","==> 70.81 seconds to train this epoch\n","\n","\n","----- epoch: 63, lr: 0.020000000000000004 -----\n","Epoch: [63][  0/391]\tTime  0.289 ( 0.289)\tLoss 5.5417e-01 (5.5417e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  97.66 ( 97.66)\n","Epoch: [63][ 30/391]\tTime  0.170 ( 0.173)\tLoss 6.1368e-01 (6.6977e-01)\tAcc@1  82.81 ( 80.52)\tAcc@5  96.09 ( 95.72)\n","Epoch: [63][ 60/391]\tTime  0.170 ( 0.172)\tLoss 7.3330e-01 (6.8739e-01)\tAcc@1  78.12 ( 80.11)\tAcc@5  95.31 ( 95.58)\n","Epoch: [63][ 90/391]\tTime  0.169 ( 0.171)\tLoss 7.6940e-01 (7.0067e-01)\tAcc@1  78.12 ( 79.39)\tAcc@5  94.53 ( 95.63)\n","Epoch: [63][120/391]\tTime  0.168 ( 0.171)\tLoss 6.8557e-01 (6.9819e-01)\tAcc@1  79.69 ( 79.35)\tAcc@5  94.53 ( 95.67)\n","Epoch: [63][150/391]\tTime  0.170 ( 0.170)\tLoss 8.8628e-01 (7.0460e-01)\tAcc@1  73.44 ( 79.21)\tAcc@5  94.53 ( 95.67)\n","Epoch: [63][180/391]\tTime  0.172 ( 0.170)\tLoss 6.5141e-01 (7.0568e-01)\tAcc@1  82.03 ( 79.05)\tAcc@5  94.53 ( 95.68)\n","Epoch: [63][210/391]\tTime  0.170 ( 0.170)\tLoss 6.8423e-01 (7.0773e-01)\tAcc@1  75.00 ( 78.92)\tAcc@5  96.88 ( 95.66)\n","Epoch: [63][240/391]\tTime  0.169 ( 0.170)\tLoss 5.1237e-01 (7.0064e-01)\tAcc@1  87.50 ( 79.14)\tAcc@5  95.31 ( 95.74)\n","Epoch: [63][270/391]\tTime  0.169 ( 0.170)\tLoss 6.7989e-01 (7.0402e-01)\tAcc@1  80.47 ( 78.99)\tAcc@5  94.53 ( 95.72)\n","Epoch: [63][300/391]\tTime  0.168 ( 0.170)\tLoss 6.5806e-01 (7.0644e-01)\tAcc@1  76.56 ( 78.97)\tAcc@5  97.66 ( 95.72)\n","Epoch: [63][330/391]\tTime  0.171 ( 0.170)\tLoss 6.7534e-01 (7.0995e-01)\tAcc@1  76.56 ( 78.87)\tAcc@5  96.09 ( 95.70)\n","Epoch: [63][360/391]\tTime  0.171 ( 0.170)\tLoss 6.1124e-01 (7.0889e-01)\tAcc@1  78.91 ( 78.87)\tAcc@5  97.66 ( 95.70)\n","Epoch: [63][390/391]\tTime  0.153 ( 0.170)\tLoss 7.7868e-01 (7.0897e-01)\tAcc@1  75.00 ( 78.92)\tAcc@5  92.50 ( 95.69)\n","==> Train Accuracy: Acc@1 78.918 || Acc@5 95.692\n","==> Test Accuracy:  Acc@1 74.200 || Acc@5 93.840\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 64, lr: 0.020000000000000004 -----\n","Epoch: [64][  0/391]\tTime  0.281 ( 0.281)\tLoss 7.5842e-01 (7.5842e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  94.53 ( 94.53)\n","Epoch: [64][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.7387e-01 (6.6203e-01)\tAcc@1  82.81 ( 80.77)\tAcc@5  95.31 ( 96.17)\n","Epoch: [64][ 60/391]\tTime  0.169 ( 0.172)\tLoss 7.0947e-01 (6.7060e-01)\tAcc@1  76.56 ( 80.39)\tAcc@5  96.09 ( 96.07)\n","Epoch: [64][ 90/391]\tTime  0.170 ( 0.171)\tLoss 8.2941e-01 (6.7041e-01)\tAcc@1  76.56 ( 80.40)\tAcc@5  94.53 ( 96.03)\n","Epoch: [64][120/391]\tTime  0.170 ( 0.171)\tLoss 6.6653e-01 (6.7510e-01)\tAcc@1  81.25 ( 80.31)\tAcc@5  93.75 ( 95.95)\n","Epoch: [64][150/391]\tTime  0.170 ( 0.171)\tLoss 7.2951e-01 (6.7947e-01)\tAcc@1  73.44 ( 79.99)\tAcc@5  94.53 ( 95.90)\n","Epoch: [64][180/391]\tTime  0.170 ( 0.171)\tLoss 6.1218e-01 (6.8241e-01)\tAcc@1  82.81 ( 79.94)\tAcc@5  95.31 ( 95.85)\n","Epoch: [64][210/391]\tTime  0.171 ( 0.171)\tLoss 4.0194e-01 (6.8499e-01)\tAcc@1  89.84 ( 79.84)\tAcc@5  98.44 ( 95.83)\n","Epoch: [64][240/391]\tTime  0.170 ( 0.170)\tLoss 7.3674e-01 (6.8582e-01)\tAcc@1  75.78 ( 79.74)\tAcc@5  96.88 ( 95.83)\n","Epoch: [64][270/391]\tTime  0.171 ( 0.170)\tLoss 5.8900e-01 (6.9034e-01)\tAcc@1  84.38 ( 79.60)\tAcc@5  97.66 ( 95.75)\n","Epoch: [64][300/391]\tTime  0.169 ( 0.170)\tLoss 7.8104e-01 (6.9220e-01)\tAcc@1  76.56 ( 79.55)\tAcc@5  93.75 ( 95.72)\n","Epoch: [64][330/391]\tTime  0.170 ( 0.170)\tLoss 6.7463e-01 (6.9154e-01)\tAcc@1  77.34 ( 79.54)\tAcc@5  97.66 ( 95.76)\n","Epoch: [64][360/391]\tTime  0.170 ( 0.170)\tLoss 7.8442e-01 (6.9290e-01)\tAcc@1  75.00 ( 79.57)\tAcc@5  96.09 ( 95.75)\n","Epoch: [64][390/391]\tTime  0.152 ( 0.170)\tLoss 8.6907e-01 (6.9544e-01)\tAcc@1  76.25 ( 79.49)\tAcc@5  95.00 ( 95.73)\n","==> Train Accuracy: Acc@1 79.492 || Acc@5 95.734\n","==> Test Accuracy:  Acc@1 74.450 || Acc@5 93.730\n","==> 70.72 seconds to train this epoch\n","\n","\n","----- epoch: 65, lr: 0.020000000000000004 -----\n","Epoch: [65][  0/391]\tTime  0.272 ( 0.272)\tLoss 7.2693e-01 (7.2693e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  95.31 ( 95.31)\n","Epoch: [65][ 30/391]\tTime  0.171 ( 0.172)\tLoss 5.6270e-01 (6.6639e-01)\tAcc@1  85.94 ( 80.65)\tAcc@5  96.09 ( 96.17)\n","Epoch: [65][ 60/391]\tTime  0.171 ( 0.171)\tLoss 6.8722e-01 (6.5461e-01)\tAcc@1  82.03 ( 81.03)\tAcc@5  96.09 ( 96.03)\n","Epoch: [65][ 90/391]\tTime  0.171 ( 0.171)\tLoss 7.4291e-01 (6.4351e-01)\tAcc@1  78.91 ( 81.40)\tAcc@5  96.88 ( 96.24)\n","Epoch: [65][120/391]\tTime  0.170 ( 0.170)\tLoss 6.7330e-01 (6.4748e-01)\tAcc@1  78.12 ( 81.05)\tAcc@5  93.75 ( 96.27)\n","Epoch: [65][150/391]\tTime  0.170 ( 0.170)\tLoss 6.1582e-01 (6.5382e-01)\tAcc@1  82.81 ( 80.77)\tAcc@5  95.31 ( 96.30)\n","Epoch: [65][180/391]\tTime  0.171 ( 0.170)\tLoss 5.7393e-01 (6.6588e-01)\tAcc@1  85.16 ( 80.39)\tAcc@5  97.66 ( 96.18)\n","Epoch: [65][210/391]\tTime  0.169 ( 0.170)\tLoss 4.4698e-01 (6.6312e-01)\tAcc@1  86.72 ( 80.43)\tAcc@5  98.44 ( 96.23)\n","Epoch: [65][240/391]\tTime  0.171 ( 0.170)\tLoss 6.4794e-01 (6.7108e-01)\tAcc@1  84.38 ( 80.24)\tAcc@5  93.75 ( 96.10)\n","Epoch: [65][270/391]\tTime  0.170 ( 0.170)\tLoss 6.3446e-01 (6.7348e-01)\tAcc@1  82.03 ( 80.17)\tAcc@5  96.09 ( 96.08)\n","Epoch: [65][300/391]\tTime  0.171 ( 0.170)\tLoss 6.5606e-01 (6.7384e-01)\tAcc@1  80.47 ( 80.15)\tAcc@5  93.75 ( 96.05)\n","Epoch: [65][330/391]\tTime  0.170 ( 0.170)\tLoss 5.3813e-01 (6.7519e-01)\tAcc@1  82.81 ( 80.06)\tAcc@5  96.09 ( 96.04)\n","Epoch: [65][360/391]\tTime  0.175 ( 0.170)\tLoss 6.3124e-01 (6.7758e-01)\tAcc@1  79.69 ( 79.97)\tAcc@5  99.22 ( 96.04)\n","Epoch: [65][390/391]\tTime  0.154 ( 0.170)\tLoss 8.7507e-01 (6.7984e-01)\tAcc@1  73.75 ( 79.87)\tAcc@5  96.25 ( 96.03)\n","==> Train Accuracy: Acc@1 79.866 || Acc@5 96.028\n","==> Test Accuracy:  Acc@1 73.390 || Acc@5 93.600\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 66, lr: 0.020000000000000004 -----\n","Epoch: [66][  0/391]\tTime  0.300 ( 0.300)\tLoss 6.0690e-01 (6.0690e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.09 ( 96.09)\n","Epoch: [66][ 30/391]\tTime  0.171 ( 0.174)\tLoss 7.0191e-01 (6.4261e-01)\tAcc@1  78.91 ( 80.85)\tAcc@5  96.88 ( 96.09)\n","Epoch: [66][ 60/391]\tTime  0.170 ( 0.172)\tLoss 7.5230e-01 (6.3263e-01)\tAcc@1  78.91 ( 81.43)\tAcc@5  94.53 ( 96.31)\n","Epoch: [66][ 90/391]\tTime  0.170 ( 0.171)\tLoss 4.5357e-01 (6.2500e-01)\tAcc@1  85.16 ( 81.68)\tAcc@5  98.44 ( 96.47)\n","Epoch: [66][120/391]\tTime  0.171 ( 0.171)\tLoss 5.7107e-01 (6.3284e-01)\tAcc@1  87.50 ( 81.53)\tAcc@5  95.31 ( 96.38)\n","Epoch: [66][150/391]\tTime  0.170 ( 0.171)\tLoss 6.3901e-01 (6.4085e-01)\tAcc@1  82.03 ( 81.28)\tAcc@5  97.66 ( 96.26)\n","Epoch: [66][180/391]\tTime  0.169 ( 0.171)\tLoss 7.3055e-01 (6.4827e-01)\tAcc@1  82.03 ( 81.07)\tAcc@5  92.97 ( 96.19)\n","Epoch: [66][210/391]\tTime  0.171 ( 0.171)\tLoss 5.6733e-01 (6.4956e-01)\tAcc@1  78.12 ( 80.99)\tAcc@5  98.44 ( 96.21)\n","Epoch: [66][240/391]\tTime  0.170 ( 0.170)\tLoss 7.1909e-01 (6.5357e-01)\tAcc@1  77.34 ( 80.76)\tAcc@5  97.66 ( 96.17)\n","Epoch: [66][270/391]\tTime  0.171 ( 0.170)\tLoss 8.4629e-01 (6.5723e-01)\tAcc@1  68.75 ( 80.65)\tAcc@5  96.88 ( 96.17)\n","Epoch: [66][300/391]\tTime  0.171 ( 0.170)\tLoss 7.4499e-01 (6.6107e-01)\tAcc@1  77.34 ( 80.46)\tAcc@5  94.53 ( 96.13)\n","Epoch: [66][330/391]\tTime  0.171 ( 0.170)\tLoss 6.0413e-01 (6.6233e-01)\tAcc@1  80.47 ( 80.41)\tAcc@5  97.66 ( 96.10)\n","Epoch: [66][360/391]\tTime  0.170 ( 0.170)\tLoss 7.5035e-01 (6.6600e-01)\tAcc@1  77.34 ( 80.31)\tAcc@5  96.88 ( 96.07)\n","Epoch: [66][390/391]\tTime  0.153 ( 0.170)\tLoss 1.0077e+00 (6.6701e-01)\tAcc@1  70.00 ( 80.31)\tAcc@5  90.00 ( 96.07)\n","==> Train Accuracy: Acc@1 80.306 || Acc@5 96.066\n","==> Test Accuracy:  Acc@1 73.670 || Acc@5 93.730\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 67, lr: 0.020000000000000004 -----\n","Epoch: [67][  0/391]\tTime  0.282 ( 0.282)\tLoss 6.5298e-01 (6.5298e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  98.44 ( 98.44)\n","Epoch: [67][ 30/391]\tTime  0.170 ( 0.173)\tLoss 5.5936e-01 (6.0865e-01)\tAcc@1  82.81 ( 82.26)\tAcc@5  96.88 ( 96.77)\n","Epoch: [67][ 60/391]\tTime  0.174 ( 0.172)\tLoss 5.4720e-01 (6.1602e-01)\tAcc@1  82.03 ( 81.83)\tAcc@5  96.88 ( 96.54)\n","Epoch: [67][ 90/391]\tTime  0.171 ( 0.171)\tLoss 6.6260e-01 (6.1888e-01)\tAcc@1  78.12 ( 81.74)\tAcc@5  98.44 ( 96.51)\n","Epoch: [67][120/391]\tTime  0.170 ( 0.171)\tLoss 5.9904e-01 (6.2123e-01)\tAcc@1  85.16 ( 81.68)\tAcc@5  94.53 ( 96.50)\n","Epoch: [67][150/391]\tTime  0.170 ( 0.171)\tLoss 6.4249e-01 (6.2908e-01)\tAcc@1  79.69 ( 81.42)\tAcc@5  96.88 ( 96.51)\n","Epoch: [67][180/391]\tTime  0.170 ( 0.170)\tLoss 6.2906e-01 (6.3097e-01)\tAcc@1  79.69 ( 81.31)\tAcc@5  98.44 ( 96.55)\n","Epoch: [67][210/391]\tTime  0.171 ( 0.170)\tLoss 6.4763e-01 (6.4053e-01)\tAcc@1  83.59 ( 81.08)\tAcc@5  98.44 ( 96.45)\n","Epoch: [67][240/391]\tTime  0.171 ( 0.170)\tLoss 6.6525e-01 (6.4547e-01)\tAcc@1  80.47 ( 80.96)\tAcc@5  95.31 ( 96.38)\n","Epoch: [67][270/391]\tTime  0.171 ( 0.170)\tLoss 5.5608e-01 (6.5039e-01)\tAcc@1  82.03 ( 80.78)\tAcc@5  98.44 ( 96.35)\n","Epoch: [67][300/391]\tTime  0.170 ( 0.170)\tLoss 6.9292e-01 (6.5154e-01)\tAcc@1  80.47 ( 80.70)\tAcc@5  96.09 ( 96.34)\n","Epoch: [67][330/391]\tTime  0.169 ( 0.170)\tLoss 7.3608e-01 (6.5508e-01)\tAcc@1  77.34 ( 80.61)\tAcc@5  94.53 ( 96.33)\n","Epoch: [67][360/391]\tTime  0.171 ( 0.170)\tLoss 6.0226e-01 (6.5927e-01)\tAcc@1  81.25 ( 80.44)\tAcc@5  98.44 ( 96.26)\n","Epoch: [67][390/391]\tTime  0.152 ( 0.170)\tLoss 7.1859e-01 (6.6261e-01)\tAcc@1  77.50 ( 80.34)\tAcc@5  96.25 ( 96.19)\n","==> Train Accuracy: Acc@1 80.340 || Acc@5 96.190\n","==> Test Accuracy:  Acc@1 73.320 || Acc@5 93.010\n","==> 70.68 seconds to train this epoch\n","\n","\n","----- epoch: 68, lr: 0.020000000000000004 -----\n","Epoch: [68][  0/391]\tTime  0.283 ( 0.283)\tLoss 7.4327e-01 (7.4327e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  95.31 ( 95.31)\n","Epoch: [68][ 30/391]\tTime  0.171 ( 0.173)\tLoss 6.1057e-01 (6.3384e-01)\tAcc@1  78.12 ( 81.20)\tAcc@5  96.88 ( 96.19)\n","Epoch: [68][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.3530e-01 (6.3278e-01)\tAcc@1  82.81 ( 81.11)\tAcc@5  96.09 ( 96.30)\n","Epoch: [68][ 90/391]\tTime  0.170 ( 0.171)\tLoss 7.1711e-01 (6.3261e-01)\tAcc@1  76.56 ( 81.02)\tAcc@5  96.88 ( 96.38)\n","Epoch: [68][120/391]\tTime  0.170 ( 0.171)\tLoss 7.0430e-01 (6.3328e-01)\tAcc@1  79.69 ( 81.13)\tAcc@5  94.53 ( 96.35)\n","Epoch: [68][150/391]\tTime  0.169 ( 0.171)\tLoss 7.5591e-01 (6.3629e-01)\tAcc@1  80.47 ( 81.08)\tAcc@5  93.75 ( 96.33)\n","Epoch: [68][180/391]\tTime  0.169 ( 0.171)\tLoss 7.5036e-01 (6.3935e-01)\tAcc@1  78.12 ( 80.91)\tAcc@5  94.53 ( 96.31)\n","Epoch: [68][210/391]\tTime  0.170 ( 0.170)\tLoss 8.0769e-01 (6.4569e-01)\tAcc@1  74.22 ( 80.76)\tAcc@5  93.75 ( 96.25)\n","Epoch: [68][240/391]\tTime  0.171 ( 0.170)\tLoss 5.4800e-01 (6.4545e-01)\tAcc@1  82.81 ( 80.85)\tAcc@5  97.66 ( 96.23)\n","Epoch: [68][270/391]\tTime  0.170 ( 0.170)\tLoss 6.4769e-01 (6.4636e-01)\tAcc@1  79.69 ( 80.79)\tAcc@5  96.88 ( 96.21)\n","Epoch: [68][300/391]\tTime  0.170 ( 0.170)\tLoss 6.3666e-01 (6.5112e-01)\tAcc@1  80.47 ( 80.58)\tAcc@5  97.66 ( 96.18)\n","Epoch: [68][330/391]\tTime  0.171 ( 0.170)\tLoss 5.5368e-01 (6.5628e-01)\tAcc@1  80.47 ( 80.44)\tAcc@5  98.44 ( 96.16)\n","Epoch: [68][360/391]\tTime  0.170 ( 0.170)\tLoss 5.5182e-01 (6.5747e-01)\tAcc@1  83.59 ( 80.42)\tAcc@5  95.31 ( 96.18)\n","Epoch: [68][390/391]\tTime  0.153 ( 0.170)\tLoss 8.4050e-01 (6.6107e-01)\tAcc@1  71.25 ( 80.32)\tAcc@5  96.25 ( 96.17)\n","==> Train Accuracy: Acc@1 80.316 || Acc@5 96.166\n","==> Test Accuracy:  Acc@1 73.210 || Acc@5 93.130\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 69, lr: 0.020000000000000004 -----\n","Epoch: [69][  0/391]\tTime  0.294 ( 0.294)\tLoss 8.2824e-01 (8.2824e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  93.75 ( 93.75)\n","Epoch: [69][ 30/391]\tTime  0.172 ( 0.174)\tLoss 4.2451e-01 (6.2244e-01)\tAcc@1  87.50 ( 82.01)\tAcc@5  98.44 ( 96.42)\n","Epoch: [69][ 60/391]\tTime  0.171 ( 0.172)\tLoss 6.1621e-01 (6.1639e-01)\tAcc@1  78.91 ( 82.15)\tAcc@5  97.66 ( 96.38)\n","Epoch: [69][ 90/391]\tTime  0.172 ( 0.171)\tLoss 7.8760e-01 (6.1060e-01)\tAcc@1  78.12 ( 82.40)\tAcc@5  93.75 ( 96.45)\n","Epoch: [69][120/391]\tTime  0.170 ( 0.171)\tLoss 7.0368e-01 (6.1583e-01)\tAcc@1  77.34 ( 82.12)\tAcc@5  96.88 ( 96.39)\n","Epoch: [69][150/391]\tTime  0.171 ( 0.171)\tLoss 6.8957e-01 (6.2202e-01)\tAcc@1  80.47 ( 81.79)\tAcc@5  98.44 ( 96.37)\n","Epoch: [69][180/391]\tTime  0.169 ( 0.171)\tLoss 6.6421e-01 (6.2966e-01)\tAcc@1  80.47 ( 81.52)\tAcc@5  98.44 ( 96.37)\n","Epoch: [69][210/391]\tTime  0.170 ( 0.171)\tLoss 4.5336e-01 (6.3245e-01)\tAcc@1  87.50 ( 81.42)\tAcc@5  96.88 ( 96.33)\n","Epoch: [69][240/391]\tTime  0.169 ( 0.171)\tLoss 6.2155e-01 (6.3542e-01)\tAcc@1  78.12 ( 81.26)\tAcc@5  96.88 ( 96.31)\n","Epoch: [69][270/391]\tTime  0.171 ( 0.171)\tLoss 5.7803e-01 (6.3653e-01)\tAcc@1  81.25 ( 81.18)\tAcc@5  95.31 ( 96.32)\n","Epoch: [69][300/391]\tTime  0.169 ( 0.171)\tLoss 5.6777e-01 (6.3601e-01)\tAcc@1  82.81 ( 81.10)\tAcc@5  96.09 ( 96.32)\n","Epoch: [69][330/391]\tTime  0.170 ( 0.170)\tLoss 6.5393e-01 (6.3943e-01)\tAcc@1  78.91 ( 80.97)\tAcc@5  94.53 ( 96.31)\n","Epoch: [69][360/391]\tTime  0.171 ( 0.170)\tLoss 7.7899e-01 (6.4348e-01)\tAcc@1  75.00 ( 80.89)\tAcc@5  95.31 ( 96.30)\n","Epoch: [69][390/391]\tTime  0.154 ( 0.170)\tLoss 6.9237e-01 (6.4497e-01)\tAcc@1  80.00 ( 80.87)\tAcc@5  95.00 ( 96.27)\n","==> Train Accuracy: Acc@1 80.874 || Acc@5 96.270\n","==> Test Accuracy:  Acc@1 72.390 || Acc@5 92.940\n","==> 70.81 seconds to train this epoch\n","\n","\n","----- epoch: 70, lr: 0.020000000000000004 -----\n","Epoch: [70][  0/391]\tTime  0.268 ( 0.268)\tLoss 5.9646e-01 (5.9646e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  97.66 ( 97.66)\n","Epoch: [70][ 30/391]\tTime  0.170 ( 0.173)\tLoss 6.0336e-01 (6.1838e-01)\tAcc@1  82.81 ( 81.85)\tAcc@5  97.66 ( 96.75)\n","Epoch: [70][ 60/391]\tTime  0.171 ( 0.171)\tLoss 7.2372e-01 (6.1300e-01)\tAcc@1  77.34 ( 82.10)\tAcc@5  96.09 ( 96.49)\n","Epoch: [70][ 90/391]\tTime  0.170 ( 0.171)\tLoss 4.1394e-01 (6.1743e-01)\tAcc@1  89.06 ( 81.65)\tAcc@5  99.22 ( 96.36)\n","Epoch: [70][120/391]\tTime  0.169 ( 0.171)\tLoss 5.9054e-01 (6.1621e-01)\tAcc@1  82.03 ( 81.66)\tAcc@5  98.44 ( 96.44)\n","Epoch: [70][150/391]\tTime  0.171 ( 0.170)\tLoss 5.5394e-01 (6.1130e-01)\tAcc@1  81.25 ( 81.66)\tAcc@5 100.00 ( 96.53)\n","Epoch: [70][180/391]\tTime  0.170 ( 0.170)\tLoss 6.7646e-01 (6.1141e-01)\tAcc@1  77.34 ( 81.63)\tAcc@5  98.44 ( 96.56)\n","Epoch: [70][210/391]\tTime  0.169 ( 0.170)\tLoss 8.4927e-01 (6.1913e-01)\tAcc@1  74.22 ( 81.35)\tAcc@5  90.62 ( 96.52)\n","Epoch: [70][240/391]\tTime  0.170 ( 0.170)\tLoss 7.1826e-01 (6.2424e-01)\tAcc@1  79.69 ( 81.24)\tAcc@5  94.53 ( 96.49)\n","Epoch: [70][270/391]\tTime  0.171 ( 0.170)\tLoss 6.3823e-01 (6.2860e-01)\tAcc@1  82.81 ( 81.15)\tAcc@5  96.09 ( 96.45)\n","Epoch: [70][300/391]\tTime  0.169 ( 0.170)\tLoss 4.8060e-01 (6.3376e-01)\tAcc@1  85.16 ( 81.07)\tAcc@5  96.88 ( 96.38)\n","Epoch: [70][330/391]\tTime  0.170 ( 0.170)\tLoss 8.4188e-01 (6.3792e-01)\tAcc@1  75.00 ( 80.95)\tAcc@5  93.75 ( 96.38)\n","Epoch: [70][360/391]\tTime  0.170 ( 0.170)\tLoss 5.9644e-01 (6.4388e-01)\tAcc@1  78.12 ( 80.76)\tAcc@5  97.66 ( 96.37)\n","Epoch: [70][390/391]\tTime  0.154 ( 0.170)\tLoss 6.3045e-01 (6.4852e-01)\tAcc@1  82.50 ( 80.67)\tAcc@5  93.75 ( 96.29)\n","==> Train Accuracy: Acc@1 80.674 || Acc@5 96.294\n","==> Test Accuracy:  Acc@1 72.960 || Acc@5 93.170\n","==> 70.68 seconds to train this epoch\n","\n","\n","----- epoch: 71, lr: 0.020000000000000004 -----\n","Epoch: [71][  0/391]\tTime  0.292 ( 0.292)\tLoss 5.5106e-01 (5.5106e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  98.44 ( 98.44)\n","Epoch: [71][ 30/391]\tTime  0.170 ( 0.174)\tLoss 5.3768e-01 (5.8784e-01)\tAcc@1  87.50 ( 82.84)\tAcc@5  95.31 ( 96.65)\n","Epoch: [71][ 60/391]\tTime  0.170 ( 0.172)\tLoss 5.8369e-01 (5.8653e-01)\tAcc@1  83.59 ( 82.75)\tAcc@5  96.88 ( 96.85)\n","Epoch: [71][ 90/391]\tTime  0.171 ( 0.172)\tLoss 6.3341e-01 (5.9629e-01)\tAcc@1  81.25 ( 82.38)\tAcc@5  93.75 ( 96.73)\n","Epoch: [71][120/391]\tTime  0.169 ( 0.171)\tLoss 7.1194e-01 (6.0398e-01)\tAcc@1  78.12 ( 82.24)\tAcc@5  95.31 ( 96.62)\n","Epoch: [71][150/391]\tTime  0.171 ( 0.171)\tLoss 7.3311e-01 (6.1590e-01)\tAcc@1  78.91 ( 81.88)\tAcc@5  95.31 ( 96.50)\n","Epoch: [71][180/391]\tTime  0.171 ( 0.171)\tLoss 5.7522e-01 (6.2157e-01)\tAcc@1  81.25 ( 81.65)\tAcc@5  99.22 ( 96.43)\n","Epoch: [71][210/391]\tTime  0.170 ( 0.171)\tLoss 6.5890e-01 (6.2207e-01)\tAcc@1  76.56 ( 81.61)\tAcc@5  94.53 ( 96.35)\n","Epoch: [71][240/391]\tTime  0.171 ( 0.171)\tLoss 6.5360e-01 (6.2550e-01)\tAcc@1  82.03 ( 81.50)\tAcc@5  96.88 ( 96.36)\n","Epoch: [71][270/391]\tTime  0.170 ( 0.170)\tLoss 6.7323e-01 (6.2770e-01)\tAcc@1  78.12 ( 81.47)\tAcc@5  94.53 ( 96.36)\n","Epoch: [71][300/391]\tTime  0.169 ( 0.170)\tLoss 6.7628e-01 (6.2912e-01)\tAcc@1  81.25 ( 81.40)\tAcc@5  97.66 ( 96.38)\n","Epoch: [71][330/391]\tTime  0.171 ( 0.170)\tLoss 8.3043e-01 (6.3348e-01)\tAcc@1  78.91 ( 81.29)\tAcc@5  92.97 ( 96.32)\n","Epoch: [71][360/391]\tTime  0.169 ( 0.170)\tLoss 5.4791e-01 (6.3952e-01)\tAcc@1  83.59 ( 81.05)\tAcc@5  97.66 ( 96.30)\n","Epoch: [71][390/391]\tTime  0.152 ( 0.170)\tLoss 9.1236e-01 (6.4615e-01)\tAcc@1  80.00 ( 80.86)\tAcc@5  93.75 ( 96.24)\n","==> Train Accuracy: Acc@1 80.860 || Acc@5 96.238\n","==> Test Accuracy:  Acc@1 71.680 || Acc@5 92.670\n","==> 70.70 seconds to train this epoch\n","\n","\n","----- epoch: 72, lr: 0.020000000000000004 -----\n","Epoch: [72][  0/391]\tTime  0.280 ( 0.280)\tLoss 6.6660e-01 (6.6660e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  95.31 ( 95.31)\n","Epoch: [72][ 30/391]\tTime  0.172 ( 0.173)\tLoss 5.8866e-01 (5.9873e-01)\tAcc@1  82.03 ( 82.54)\tAcc@5  99.22 ( 96.62)\n","Epoch: [72][ 60/391]\tTime  0.169 ( 0.172)\tLoss 6.3595e-01 (6.0928e-01)\tAcc@1  81.25 ( 82.08)\tAcc@5  95.31 ( 96.57)\n","Epoch: [72][ 90/391]\tTime  0.170 ( 0.171)\tLoss 8.0213e-01 (6.1104e-01)\tAcc@1  78.12 ( 82.09)\tAcc@5  95.31 ( 96.62)\n","Epoch: [72][120/391]\tTime  0.171 ( 0.171)\tLoss 5.5204e-01 (6.1455e-01)\tAcc@1  83.59 ( 81.90)\tAcc@5  96.09 ( 96.61)\n","Epoch: [72][150/391]\tTime  0.171 ( 0.171)\tLoss 8.2638e-01 (6.2033e-01)\tAcc@1  78.91 ( 81.63)\tAcc@5  91.41 ( 96.56)\n","Epoch: [72][180/391]\tTime  0.171 ( 0.171)\tLoss 5.3549e-01 (6.1949e-01)\tAcc@1  81.25 ( 81.65)\tAcc@5  99.22 ( 96.57)\n","Epoch: [72][210/391]\tTime  0.169 ( 0.171)\tLoss 7.3258e-01 (6.2535e-01)\tAcc@1  76.56 ( 81.49)\tAcc@5  96.09 ( 96.62)\n","Epoch: [72][240/391]\tTime  0.170 ( 0.171)\tLoss 6.5738e-01 (6.3123e-01)\tAcc@1  78.91 ( 81.28)\tAcc@5  97.66 ( 96.57)\n","Epoch: [72][270/391]\tTime  0.169 ( 0.171)\tLoss 7.3302e-01 (6.3716e-01)\tAcc@1  81.25 ( 81.08)\tAcc@5  96.09 ( 96.50)\n","Epoch: [72][300/391]\tTime  0.169 ( 0.171)\tLoss 5.4173e-01 (6.4175e-01)\tAcc@1  86.72 ( 81.00)\tAcc@5  97.66 ( 96.45)\n","Epoch: [72][330/391]\tTime  0.171 ( 0.170)\tLoss 5.0420e-01 (6.4549e-01)\tAcc@1  81.25 ( 80.86)\tAcc@5  98.44 ( 96.40)\n","Epoch: [72][360/391]\tTime  0.168 ( 0.170)\tLoss 6.7301e-01 (6.4875e-01)\tAcc@1  77.34 ( 80.77)\tAcc@5  96.88 ( 96.41)\n","Epoch: [72][390/391]\tTime  0.154 ( 0.170)\tLoss 6.5429e-01 (6.5199e-01)\tAcc@1  78.75 ( 80.65)\tAcc@5  96.25 ( 96.37)\n","==> Train Accuracy: Acc@1 80.650 || Acc@5 96.372\n","==> Test Accuracy:  Acc@1 72.050 || Acc@5 92.570\n","==> 70.80 seconds to train this epoch\n","\n","\n","----- epoch: 73, lr: 0.020000000000000004 -----\n","Epoch: [73][  0/391]\tTime  0.286 ( 0.286)\tLoss 5.3179e-01 (5.3179e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  96.88 ( 96.88)\n","Epoch: [73][ 30/391]\tTime  0.172 ( 0.174)\tLoss 5.3424e-01 (6.0771e-01)\tAcc@1  82.81 ( 81.78)\tAcc@5  96.88 ( 96.30)\n","Epoch: [73][ 60/391]\tTime  0.171 ( 0.172)\tLoss 6.1157e-01 (5.8835e-01)\tAcc@1  84.38 ( 82.47)\tAcc@5  96.09 ( 96.66)\n","Epoch: [73][ 90/391]\tTime  0.171 ( 0.172)\tLoss 5.7984e-01 (5.9950e-01)\tAcc@1  82.03 ( 82.25)\tAcc@5  97.66 ( 96.69)\n","Epoch: [73][120/391]\tTime  0.171 ( 0.171)\tLoss 7.4174e-01 (6.0041e-01)\tAcc@1  77.34 ( 82.24)\tAcc@5  93.75 ( 96.60)\n","Epoch: [73][150/391]\tTime  0.170 ( 0.171)\tLoss 5.3665e-01 (6.0396e-01)\tAcc@1  83.59 ( 82.09)\tAcc@5  97.66 ( 96.66)\n","Epoch: [73][180/391]\tTime  0.171 ( 0.171)\tLoss 6.6648e-01 (6.1046e-01)\tAcc@1  75.78 ( 81.88)\tAcc@5  96.88 ( 96.64)\n","Epoch: [73][210/391]\tTime  0.170 ( 0.171)\tLoss 6.9464e-01 (6.1589e-01)\tAcc@1  78.12 ( 81.80)\tAcc@5  97.66 ( 96.58)\n","Epoch: [73][240/391]\tTime  0.170 ( 0.171)\tLoss 5.1693e-01 (6.2198e-01)\tAcc@1  86.72 ( 81.64)\tAcc@5  96.09 ( 96.52)\n","Epoch: [73][270/391]\tTime  0.171 ( 0.171)\tLoss 6.9769e-01 (6.2608e-01)\tAcc@1  76.56 ( 81.43)\tAcc@5  95.31 ( 96.52)\n","Epoch: [73][300/391]\tTime  0.171 ( 0.171)\tLoss 6.6672e-01 (6.2601e-01)\tAcc@1  80.47 ( 81.41)\tAcc@5  95.31 ( 96.49)\n","Epoch: [73][330/391]\tTime  0.171 ( 0.171)\tLoss 7.5443e-01 (6.3174e-01)\tAcc@1  80.47 ( 81.27)\tAcc@5  92.97 ( 96.44)\n","Epoch: [73][360/391]\tTime  0.171 ( 0.170)\tLoss 6.1607e-01 (6.3308e-01)\tAcc@1  82.03 ( 81.23)\tAcc@5  97.66 ( 96.44)\n","Epoch: [73][390/391]\tTime  0.154 ( 0.170)\tLoss 7.3294e-01 (6.3618e-01)\tAcc@1  75.00 ( 81.13)\tAcc@5  96.25 ( 96.42)\n","==> Train Accuracy: Acc@1 81.134 || Acc@5 96.422\n","==> Test Accuracy:  Acc@1 71.730 || Acc@5 92.390\n","==> 70.81 seconds to train this epoch\n","\n","\n","----- epoch: 74, lr: 0.020000000000000004 -----\n","Epoch: [74][  0/391]\tTime  0.292 ( 0.292)\tLoss 6.0286e-01 (6.0286e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  96.09 ( 96.09)\n","Epoch: [74][ 30/391]\tTime  0.170 ( 0.174)\tLoss 5.1961e-01 (5.9502e-01)\tAcc@1  83.59 ( 81.80)\tAcc@5  97.66 ( 97.10)\n","Epoch: [74][ 60/391]\tTime  0.170 ( 0.172)\tLoss 5.6295e-01 (5.8110e-01)\tAcc@1  82.81 ( 82.22)\tAcc@5  97.66 ( 97.21)\n","Epoch: [74][ 90/391]\tTime  0.169 ( 0.171)\tLoss 5.1953e-01 (5.8653e-01)\tAcc@1  82.81 ( 82.46)\tAcc@5  97.66 ( 97.02)\n","Epoch: [74][120/391]\tTime  0.170 ( 0.171)\tLoss 7.0557e-01 (5.9485e-01)\tAcc@1  79.69 ( 82.15)\tAcc@5  96.88 ( 97.00)\n","Epoch: [74][150/391]\tTime  0.169 ( 0.171)\tLoss 6.3362e-01 (6.0631e-01)\tAcc@1  82.81 ( 81.92)\tAcc@5  96.09 ( 96.79)\n","Epoch: [74][180/391]\tTime  0.170 ( 0.171)\tLoss 6.6798e-01 (6.0944e-01)\tAcc@1  77.34 ( 81.70)\tAcc@5  99.22 ( 96.76)\n","Epoch: [74][210/391]\tTime  0.169 ( 0.170)\tLoss 6.3690e-01 (6.1566e-01)\tAcc@1  82.03 ( 81.52)\tAcc@5  97.66 ( 96.73)\n","Epoch: [74][240/391]\tTime  0.171 ( 0.170)\tLoss 4.3523e-01 (6.1888e-01)\tAcc@1  88.28 ( 81.47)\tAcc@5  98.44 ( 96.65)\n","Epoch: [74][270/391]\tTime  0.170 ( 0.170)\tLoss 6.3313e-01 (6.2203e-01)\tAcc@1  80.47 ( 81.41)\tAcc@5  96.88 ( 96.61)\n","Epoch: [74][300/391]\tTime  0.171 ( 0.170)\tLoss 8.9193e-01 (6.2721e-01)\tAcc@1  78.12 ( 81.30)\tAcc@5  91.41 ( 96.56)\n","Epoch: [74][330/391]\tTime  0.168 ( 0.170)\tLoss 5.5988e-01 (6.2751e-01)\tAcc@1  83.59 ( 81.30)\tAcc@5  96.88 ( 96.55)\n","Epoch: [74][360/391]\tTime  0.170 ( 0.170)\tLoss 7.4027e-01 (6.3287e-01)\tAcc@1  80.47 ( 81.10)\tAcc@5  97.66 ( 96.49)\n","Epoch: [74][390/391]\tTime  0.152 ( 0.170)\tLoss 6.8355e-01 (6.3691e-01)\tAcc@1  75.00 ( 81.00)\tAcc@5  96.25 ( 96.44)\n","==> Train Accuracy: Acc@1 80.998 || Acc@5 96.444\n","==> Test Accuracy:  Acc@1 71.780 || Acc@5 92.860\n","==> 70.65 seconds to train this epoch\n","\n","\n","----- epoch: 75, lr: 0.020000000000000004 -----\n","Epoch: [75][  0/391]\tTime  0.289 ( 0.289)\tLoss 5.8436e-01 (5.8436e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  96.09 ( 96.09)\n","Epoch: [75][ 30/391]\tTime  0.170 ( 0.173)\tLoss 4.1979e-01 (6.0355e-01)\tAcc@1  89.84 ( 82.51)\tAcc@5  99.22 ( 96.55)\n","Epoch: [75][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.7848e-01 (6.1302e-01)\tAcc@1  82.03 ( 82.02)\tAcc@5  96.88 ( 96.57)\n","Epoch: [75][ 90/391]\tTime  0.170 ( 0.171)\tLoss 5.3949e-01 (6.1298e-01)\tAcc@1  84.38 ( 81.76)\tAcc@5  98.44 ( 96.59)\n","Epoch: [75][120/391]\tTime  0.169 ( 0.170)\tLoss 5.6773e-01 (6.1869e-01)\tAcc@1  83.59 ( 81.69)\tAcc@5  94.53 ( 96.51)\n","Epoch: [75][150/391]\tTime  0.168 ( 0.170)\tLoss 6.5766e-01 (6.2151e-01)\tAcc@1  79.69 ( 81.67)\tAcc@5  97.66 ( 96.49)\n","Epoch: [75][180/391]\tTime  0.170 ( 0.170)\tLoss 5.3977e-01 (6.1973e-01)\tAcc@1  86.72 ( 81.67)\tAcc@5  96.09 ( 96.52)\n","Epoch: [75][210/391]\tTime  0.170 ( 0.170)\tLoss 5.3916e-01 (6.1511e-01)\tAcc@1  84.38 ( 81.79)\tAcc@5  98.44 ( 96.60)\n","Epoch: [75][240/391]\tTime  0.170 ( 0.170)\tLoss 6.5114e-01 (6.2124e-01)\tAcc@1  80.47 ( 81.52)\tAcc@5  96.88 ( 96.55)\n","Epoch: [75][270/391]\tTime  0.170 ( 0.170)\tLoss 6.3115e-01 (6.2372e-01)\tAcc@1  84.38 ( 81.42)\tAcc@5  94.53 ( 96.51)\n","Epoch: [75][300/391]\tTime  0.170 ( 0.170)\tLoss 4.9028e-01 (6.2737e-01)\tAcc@1  82.81 ( 81.32)\tAcc@5  97.66 ( 96.54)\n","Epoch: [75][330/391]\tTime  0.172 ( 0.170)\tLoss 7.2028e-01 (6.3186e-01)\tAcc@1  75.00 ( 81.17)\tAcc@5  96.88 ( 96.50)\n","Epoch: [75][360/391]\tTime  0.170 ( 0.170)\tLoss 7.6419e-01 (6.3617e-01)\tAcc@1  78.12 ( 81.05)\tAcc@5  93.75 ( 96.44)\n","Epoch: [75][390/391]\tTime  0.154 ( 0.170)\tLoss 6.1388e-01 (6.3923e-01)\tAcc@1  80.00 ( 80.93)\tAcc@5  98.75 ( 96.44)\n","==> Train Accuracy: Acc@1 80.930 || Acc@5 96.436\n","==> Test Accuracy:  Acc@1 70.120 || Acc@5 91.490\n","==> 70.67 seconds to train this epoch\n","\n","\n","----- epoch: 76, lr: 0.020000000000000004 -----\n","Epoch: [76][  0/391]\tTime  0.274 ( 0.274)\tLoss 6.1332e-01 (6.1332e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.88 ( 96.88)\n","Epoch: [76][ 30/391]\tTime  0.171 ( 0.173)\tLoss 6.2666e-01 (5.9349e-01)\tAcc@1  82.03 ( 82.56)\tAcc@5  96.09 ( 96.65)\n","Epoch: [76][ 60/391]\tTime  0.171 ( 0.172)\tLoss 6.4628e-01 (5.9345e-01)\tAcc@1  82.03 ( 82.53)\tAcc@5  96.09 ( 96.67)\n","Epoch: [76][ 90/391]\tTime  0.169 ( 0.171)\tLoss 5.4409e-01 (5.9963e-01)\tAcc@1  83.59 ( 82.26)\tAcc@5  99.22 ( 96.72)\n","Epoch: [76][120/391]\tTime  0.169 ( 0.171)\tLoss 5.6533e-01 (6.1130e-01)\tAcc@1  85.94 ( 82.13)\tAcc@5  96.09 ( 96.54)\n","Epoch: [76][150/391]\tTime  0.170 ( 0.170)\tLoss 5.1432e-01 (6.1489e-01)\tAcc@1  83.59 ( 82.00)\tAcc@5  98.44 ( 96.53)\n","Epoch: [76][180/391]\tTime  0.170 ( 0.170)\tLoss 5.4096e-01 (6.1675e-01)\tAcc@1  85.16 ( 82.00)\tAcc@5  98.44 ( 96.47)\n","Epoch: [76][210/391]\tTime  0.170 ( 0.170)\tLoss 6.5489e-01 (6.2279e-01)\tAcc@1  76.56 ( 81.76)\tAcc@5  96.09 ( 96.38)\n","Epoch: [76][240/391]\tTime  0.171 ( 0.170)\tLoss 7.0622e-01 (6.2624e-01)\tAcc@1  85.16 ( 81.65)\tAcc@5  93.75 ( 96.41)\n","Epoch: [76][270/391]\tTime  0.170 ( 0.170)\tLoss 7.6184e-01 (6.2925e-01)\tAcc@1  75.00 ( 81.54)\tAcc@5  96.88 ( 96.41)\n","Epoch: [76][300/391]\tTime  0.169 ( 0.170)\tLoss 5.4916e-01 (6.3053e-01)\tAcc@1  84.38 ( 81.54)\tAcc@5  96.09 ( 96.38)\n","Epoch: [76][330/391]\tTime  0.170 ( 0.170)\tLoss 6.6938e-01 (6.3235e-01)\tAcc@1  82.81 ( 81.52)\tAcc@5  95.31 ( 96.39)\n","Epoch: [76][360/391]\tTime  0.170 ( 0.170)\tLoss 5.5134e-01 (6.3249e-01)\tAcc@1  81.25 ( 81.48)\tAcc@5  98.44 ( 96.40)\n","Epoch: [76][390/391]\tTime  0.149 ( 0.170)\tLoss 6.1667e-01 (6.3215e-01)\tAcc@1  82.50 ( 81.46)\tAcc@5  97.50 ( 96.38)\n","==> Train Accuracy: Acc@1 81.460 || Acc@5 96.384\n","==> Test Accuracy:  Acc@1 72.370 || Acc@5 92.990\n","==> 70.64 seconds to train this epoch\n","\n","\n","----- epoch: 77, lr: 0.020000000000000004 -----\n","Epoch: [77][  0/391]\tTime  0.278 ( 0.278)\tLoss 5.1396e-01 (5.1396e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  97.66 ( 97.66)\n","Epoch: [77][ 30/391]\tTime  0.170 ( 0.173)\tLoss 5.7238e-01 (5.8925e-01)\tAcc@1  82.03 ( 82.23)\tAcc@5  96.88 ( 97.08)\n","Epoch: [77][ 60/391]\tTime  0.171 ( 0.172)\tLoss 5.8988e-01 (5.6803e-01)\tAcc@1  80.47 ( 83.25)\tAcc@5  98.44 ( 97.21)\n","Epoch: [77][ 90/391]\tTime  0.170 ( 0.171)\tLoss 5.1395e-01 (5.7452e-01)\tAcc@1  85.94 ( 83.03)\tAcc@5  99.22 ( 96.99)\n","Epoch: [77][120/391]\tTime  0.170 ( 0.171)\tLoss 8.2789e-01 (5.8799e-01)\tAcc@1  75.78 ( 82.84)\tAcc@5  94.53 ( 96.81)\n","Epoch: [77][150/391]\tTime  0.172 ( 0.171)\tLoss 5.4603e-01 (5.9013e-01)\tAcc@1  82.03 ( 82.80)\tAcc@5  97.66 ( 96.70)\n","Epoch: [77][180/391]\tTime  0.170 ( 0.171)\tLoss 4.7058e-01 (5.9353e-01)\tAcc@1  85.94 ( 82.58)\tAcc@5  99.22 ( 96.68)\n","Epoch: [77][210/391]\tTime  0.168 ( 0.171)\tLoss 8.4752e-01 (5.9905e-01)\tAcc@1  76.56 ( 82.49)\tAcc@5  92.19 ( 96.62)\n","Epoch: [77][240/391]\tTime  0.170 ( 0.170)\tLoss 4.8923e-01 (6.0287e-01)\tAcc@1  86.72 ( 82.39)\tAcc@5  97.66 ( 96.61)\n","Epoch: [77][270/391]\tTime  0.170 ( 0.170)\tLoss 5.7129e-01 (6.0714e-01)\tAcc@1  81.25 ( 82.18)\tAcc@5  98.44 ( 96.57)\n","Epoch: [77][300/391]\tTime  0.170 ( 0.170)\tLoss 6.0597e-01 (6.1445e-01)\tAcc@1  82.03 ( 81.92)\tAcc@5  96.09 ( 96.54)\n","Epoch: [77][330/391]\tTime  0.171 ( 0.170)\tLoss 5.3042e-01 (6.1822e-01)\tAcc@1  81.25 ( 81.79)\tAcc@5  97.66 ( 96.50)\n","Epoch: [77][360/391]\tTime  0.169 ( 0.170)\tLoss 6.6706e-01 (6.2274e-01)\tAcc@1  78.91 ( 81.60)\tAcc@5  96.09 ( 96.48)\n","Epoch: [77][390/391]\tTime  0.152 ( 0.170)\tLoss 7.8560e-01 (6.2786e-01)\tAcc@1  78.75 ( 81.46)\tAcc@5  92.50 ( 96.43)\n","==> Train Accuracy: Acc@1 81.464 || Acc@5 96.434\n","==> Test Accuracy:  Acc@1 71.140 || Acc@5 92.320\n","==> 70.69 seconds to train this epoch\n","\n","\n","----- epoch: 78, lr: 0.020000000000000004 -----\n","Epoch: [78][  0/391]\tTime  0.294 ( 0.294)\tLoss 3.6802e-01 (3.6802e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  98.44 ( 98.44)\n","Epoch: [78][ 30/391]\tTime  0.168 ( 0.173)\tLoss 6.6049e-01 (5.7998e-01)\tAcc@1  82.81 ( 84.02)\tAcc@5  96.88 ( 96.40)\n","Epoch: [78][ 60/391]\tTime  0.168 ( 0.172)\tLoss 5.4236e-01 (5.8807e-01)\tAcc@1  84.38 ( 83.50)\tAcc@5  96.88 ( 96.55)\n","Epoch: [78][ 90/391]\tTime  0.170 ( 0.171)\tLoss 5.9306e-01 (6.0511e-01)\tAcc@1  82.03 ( 82.75)\tAcc@5  96.09 ( 96.53)\n","Epoch: [78][120/391]\tTime  0.170 ( 0.171)\tLoss 6.9112e-01 (6.1283e-01)\tAcc@1  79.69 ( 82.29)\tAcc@5  96.09 ( 96.53)\n","Epoch: [78][150/391]\tTime  0.171 ( 0.171)\tLoss 5.6067e-01 (6.1448e-01)\tAcc@1  82.81 ( 82.13)\tAcc@5  99.22 ( 96.62)\n","Epoch: [78][180/391]\tTime  0.171 ( 0.170)\tLoss 5.6156e-01 (6.2249e-01)\tAcc@1  79.69 ( 81.88)\tAcc@5  97.66 ( 96.46)\n","Epoch: [78][210/391]\tTime  0.171 ( 0.170)\tLoss 4.9622e-01 (6.1863e-01)\tAcc@1  84.38 ( 81.95)\tAcc@5  97.66 ( 96.46)\n","Epoch: [78][240/391]\tTime  0.171 ( 0.170)\tLoss 6.1253e-01 (6.1813e-01)\tAcc@1  82.81 ( 81.90)\tAcc@5  96.09 ( 96.51)\n","Epoch: [78][270/391]\tTime  0.169 ( 0.170)\tLoss 8.8808e-01 (6.2200e-01)\tAcc@1  73.44 ( 81.73)\tAcc@5  92.97 ( 96.46)\n","Epoch: [78][300/391]\tTime  0.170 ( 0.170)\tLoss 6.8255e-01 (6.2228e-01)\tAcc@1  78.12 ( 81.68)\tAcc@5  95.31 ( 96.46)\n","Epoch: [78][330/391]\tTime  0.169 ( 0.170)\tLoss 5.3791e-01 (6.2566e-01)\tAcc@1  83.59 ( 81.60)\tAcc@5  98.44 ( 96.46)\n","Epoch: [78][360/391]\tTime  0.170 ( 0.170)\tLoss 6.1112e-01 (6.2799e-01)\tAcc@1  79.69 ( 81.49)\tAcc@5  97.66 ( 96.45)\n","Epoch: [78][390/391]\tTime  0.153 ( 0.170)\tLoss 8.6066e-01 (6.2996e-01)\tAcc@1  72.50 ( 81.40)\tAcc@5  93.75 ( 96.44)\n","==> Train Accuracy: Acc@1 81.396 || Acc@5 96.436\n","==> Test Accuracy:  Acc@1 70.680 || Acc@5 92.130\n","==> 70.67 seconds to train this epoch\n","\n","\n","----- epoch: 79, lr: 0.020000000000000004 -----\n","Epoch: [79][  0/391]\tTime  0.259 ( 0.259)\tLoss 6.5811e-01 (6.5811e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  94.53 ( 94.53)\n","Epoch: [79][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.0440e-01 (6.1346e-01)\tAcc@1  85.94 ( 82.81)\tAcc@5  96.88 ( 96.52)\n","Epoch: [79][ 60/391]\tTime  0.170 ( 0.171)\tLoss 4.8480e-01 (5.6766e-01)\tAcc@1  86.72 ( 83.70)\tAcc@5  97.66 ( 97.02)\n","Epoch: [79][ 90/391]\tTime  0.169 ( 0.171)\tLoss 5.8928e-01 (5.6818e-01)\tAcc@1  81.25 ( 83.55)\tAcc@5  95.31 ( 96.92)\n","Epoch: [79][120/391]\tTime  0.170 ( 0.171)\tLoss 6.2009e-01 (5.7404e-01)\tAcc@1  83.59 ( 83.28)\tAcc@5  95.31 ( 96.94)\n","Epoch: [79][150/391]\tTime  0.172 ( 0.171)\tLoss 7.3698e-01 (5.8529e-01)\tAcc@1  75.00 ( 82.86)\tAcc@5  94.53 ( 96.93)\n","Epoch: [79][180/391]\tTime  0.170 ( 0.171)\tLoss 4.1760e-01 (5.9446e-01)\tAcc@1  86.72 ( 82.59)\tAcc@5  98.44 ( 96.81)\n","Epoch: [79][210/391]\tTime  0.169 ( 0.170)\tLoss 6.1893e-01 (5.9918e-01)\tAcc@1  83.59 ( 82.50)\tAcc@5  94.53 ( 96.70)\n","Epoch: [79][240/391]\tTime  0.170 ( 0.170)\tLoss 5.4696e-01 (5.9969e-01)\tAcc@1  82.03 ( 82.49)\tAcc@5  98.44 ( 96.66)\n","Epoch: [79][270/391]\tTime  0.170 ( 0.170)\tLoss 6.1917e-01 (6.0734e-01)\tAcc@1  79.69 ( 82.21)\tAcc@5  98.44 ( 96.57)\n","Epoch: [79][300/391]\tTime  0.171 ( 0.170)\tLoss 7.0873e-01 (6.1072e-01)\tAcc@1  79.69 ( 82.07)\tAcc@5  97.66 ( 96.59)\n","Epoch: [79][330/391]\tTime  0.170 ( 0.170)\tLoss 6.1972e-01 (6.1195e-01)\tAcc@1  80.47 ( 81.99)\tAcc@5  97.66 ( 96.57)\n","Epoch: [79][360/391]\tTime  0.170 ( 0.170)\tLoss 6.0314e-01 (6.1690e-01)\tAcc@1  79.69 ( 81.81)\tAcc@5  96.88 ( 96.55)\n","Epoch: [79][390/391]\tTime  0.153 ( 0.170)\tLoss 7.9333e-01 (6.2058e-01)\tAcc@1  77.50 ( 81.69)\tAcc@5  96.25 ( 96.52)\n","==> Train Accuracy: Acc@1 81.686 || Acc@5 96.516\n","==> Test Accuracy:  Acc@1 71.080 || Acc@5 92.500\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 80, lr: 0.020000000000000004 -----\n","Epoch: [80][  0/391]\tTime  0.288 ( 0.288)\tLoss 5.3330e-01 (5.3330e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n","Epoch: [80][ 30/391]\tTime  0.164 ( 0.173)\tLoss 5.1006e-01 (5.8105e-01)\tAcc@1  82.81 ( 82.61)\tAcc@5  98.44 ( 96.98)\n","Epoch: [80][ 60/391]\tTime  0.170 ( 0.172)\tLoss 5.9125e-01 (5.8768e-01)\tAcc@1  80.47 ( 82.44)\tAcc@5  96.09 ( 97.03)\n","Epoch: [80][ 90/391]\tTime  0.170 ( 0.171)\tLoss 7.0983e-01 (5.9283e-01)\tAcc@1  78.91 ( 82.29)\tAcc@5  96.09 ( 97.06)\n","Epoch: [80][120/391]\tTime  0.169 ( 0.171)\tLoss 5.7225e-01 (5.8825e-01)\tAcc@1  83.59 ( 82.53)\tAcc@5  95.31 ( 96.98)\n","Epoch: [80][150/391]\tTime  0.169 ( 0.171)\tLoss 7.1186e-01 (5.9719e-01)\tAcc@1  81.25 ( 82.33)\tAcc@5  94.53 ( 96.96)\n","Epoch: [80][180/391]\tTime  0.170 ( 0.171)\tLoss 7.0311e-01 (5.9933e-01)\tAcc@1  80.47 ( 82.32)\tAcc@5  93.75 ( 96.85)\n","Epoch: [80][210/391]\tTime  0.169 ( 0.171)\tLoss 5.8478e-01 (6.0197e-01)\tAcc@1  82.03 ( 82.29)\tAcc@5  97.66 ( 96.79)\n","Epoch: [80][240/391]\tTime  0.170 ( 0.171)\tLoss 4.4419e-01 (6.0348e-01)\tAcc@1  86.72 ( 82.25)\tAcc@5  97.66 ( 96.76)\n","Epoch: [80][270/391]\tTime  0.169 ( 0.171)\tLoss 6.0663e-01 (6.0774e-01)\tAcc@1  80.47 ( 82.09)\tAcc@5  96.88 ( 96.71)\n","Epoch: [80][300/391]\tTime  0.171 ( 0.171)\tLoss 6.7457e-01 (6.1146e-01)\tAcc@1  78.12 ( 81.95)\tAcc@5  96.09 ( 96.70)\n","Epoch: [80][330/391]\tTime  0.170 ( 0.170)\tLoss 8.1796e-01 (6.1559e-01)\tAcc@1  75.78 ( 81.84)\tAcc@5  92.97 ( 96.68)\n","Epoch: [80][360/391]\tTime  0.169 ( 0.170)\tLoss 6.4026e-01 (6.2343e-01)\tAcc@1  83.59 ( 81.59)\tAcc@5  96.88 ( 96.59)\n","Epoch: [80][390/391]\tTime  0.152 ( 0.170)\tLoss 4.4567e-01 (6.2569e-01)\tAcc@1  86.25 ( 81.52)\tAcc@5  98.75 ( 96.59)\n","==> Train Accuracy: Acc@1 81.516 || Acc@5 96.590\n","==> Test Accuracy:  Acc@1 72.040 || Acc@5 92.660\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 81, lr: 0.020000000000000004 -----\n","Epoch: [81][  0/391]\tTime  0.287 ( 0.287)\tLoss 6.4625e-01 (6.4625e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  96.88 ( 96.88)\n","Epoch: [81][ 30/391]\tTime  0.170 ( 0.173)\tLoss 6.8952e-01 (5.8536e-01)\tAcc@1  81.25 ( 82.03)\tAcc@5  96.88 ( 96.82)\n","Epoch: [81][ 60/391]\tTime  0.171 ( 0.172)\tLoss 5.7660e-01 (5.9276e-01)\tAcc@1  78.91 ( 82.03)\tAcc@5  98.44 ( 96.81)\n","Epoch: [81][ 90/391]\tTime  0.171 ( 0.171)\tLoss 4.7645e-01 (5.8799e-01)\tAcc@1  85.94 ( 82.31)\tAcc@5  96.88 ( 96.79)\n","Epoch: [81][120/391]\tTime  0.169 ( 0.171)\tLoss 4.8413e-01 (5.9189e-01)\tAcc@1  82.03 ( 82.18)\tAcc@5  99.22 ( 96.89)\n","Epoch: [81][150/391]\tTime  0.171 ( 0.171)\tLoss 6.1808e-01 (5.9453e-01)\tAcc@1  80.47 ( 82.17)\tAcc@5  96.88 ( 96.86)\n","Epoch: [81][180/391]\tTime  0.170 ( 0.171)\tLoss 5.6868e-01 (5.9512e-01)\tAcc@1  85.94 ( 82.26)\tAcc@5  96.88 ( 96.80)\n","Epoch: [81][210/391]\tTime  0.170 ( 0.171)\tLoss 7.5645e-01 (5.9652e-01)\tAcc@1  76.56 ( 82.28)\tAcc@5  96.88 ( 96.76)\n","Epoch: [81][240/391]\tTime  0.170 ( 0.171)\tLoss 6.3049e-01 (6.0001e-01)\tAcc@1  80.47 ( 82.17)\tAcc@5  96.09 ( 96.77)\n","Epoch: [81][270/391]\tTime  0.171 ( 0.171)\tLoss 6.3438e-01 (6.0485e-01)\tAcc@1  80.47 ( 82.07)\tAcc@5  96.88 ( 96.68)\n","Epoch: [81][300/391]\tTime  0.172 ( 0.171)\tLoss 6.5365e-01 (6.0691e-01)\tAcc@1  80.47 ( 82.03)\tAcc@5  96.88 ( 96.69)\n","Epoch: [81][330/391]\tTime  0.169 ( 0.170)\tLoss 6.2150e-01 (6.0903e-01)\tAcc@1  79.69 ( 81.89)\tAcc@5  97.66 ( 96.71)\n","Epoch: [81][360/391]\tTime  0.171 ( 0.170)\tLoss 5.9142e-01 (6.1360e-01)\tAcc@1  86.72 ( 81.78)\tAcc@5  95.31 ( 96.67)\n","Epoch: [81][390/391]\tTime  0.152 ( 0.170)\tLoss 8.1401e-01 (6.1725e-01)\tAcc@1  73.75 ( 81.64)\tAcc@5  92.50 ( 96.64)\n","==> Train Accuracy: Acc@1 81.644 || Acc@5 96.638\n","==> Test Accuracy:  Acc@1 72.200 || Acc@5 92.660\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 82, lr: 0.020000000000000004 -----\n","Epoch: [82][  0/391]\tTime  0.263 ( 0.263)\tLoss 5.7584e-01 (5.7584e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  97.66 ( 97.66)\n","Epoch: [82][ 30/391]\tTime  0.169 ( 0.172)\tLoss 4.4308e-01 (5.8715e-01)\tAcc@1  86.72 ( 83.24)\tAcc@5  97.66 ( 96.75)\n","Epoch: [82][ 60/391]\tTime  0.169 ( 0.171)\tLoss 5.3045e-01 (5.9915e-01)\tAcc@1  81.25 ( 82.38)\tAcc@5  97.66 ( 96.61)\n","Epoch: [82][ 90/391]\tTime  0.169 ( 0.170)\tLoss 6.4850e-01 (5.9272e-01)\tAcc@1  82.03 ( 82.67)\tAcc@5  96.88 ( 96.73)\n","Epoch: [82][120/391]\tTime  0.168 ( 0.170)\tLoss 7.7617e-01 (5.9190e-01)\tAcc@1  78.91 ( 82.74)\tAcc@5  96.09 ( 96.77)\n","Epoch: [82][150/391]\tTime  0.169 ( 0.170)\tLoss 5.2254e-01 (5.9421e-01)\tAcc@1  82.81 ( 82.60)\tAcc@5  97.66 ( 96.78)\n","Epoch: [82][180/391]\tTime  0.170 ( 0.170)\tLoss 5.4327e-01 (5.9619e-01)\tAcc@1  83.59 ( 82.51)\tAcc@5  97.66 ( 96.80)\n","Epoch: [82][210/391]\tTime  0.170 ( 0.170)\tLoss 6.5929e-01 (5.9978e-01)\tAcc@1  79.69 ( 82.38)\tAcc@5  96.09 ( 96.73)\n","Epoch: [82][240/391]\tTime  0.171 ( 0.170)\tLoss 7.7414e-01 (6.0444e-01)\tAcc@1  78.91 ( 82.16)\tAcc@5  92.19 ( 96.66)\n","Epoch: [82][270/391]\tTime  0.170 ( 0.170)\tLoss 8.2549e-01 (6.1064e-01)\tAcc@1  80.47 ( 81.96)\tAcc@5  92.97 ( 96.62)\n","Epoch: [82][300/391]\tTime  0.171 ( 0.170)\tLoss 5.9501e-01 (6.1658e-01)\tAcc@1  79.69 ( 81.77)\tAcc@5  96.88 ( 96.58)\n","Epoch: [82][330/391]\tTime  0.170 ( 0.170)\tLoss 6.6947e-01 (6.1553e-01)\tAcc@1  79.69 ( 81.71)\tAcc@5  92.97 ( 96.62)\n","Epoch: [82][360/391]\tTime  0.169 ( 0.170)\tLoss 4.9698e-01 (6.1550e-01)\tAcc@1  85.94 ( 81.73)\tAcc@5  98.44 ( 96.64)\n","Epoch: [82][390/391]\tTime  0.153 ( 0.170)\tLoss 4.8445e-01 (6.1862e-01)\tAcc@1  83.75 ( 81.62)\tAcc@5  97.50 ( 96.62)\n","==> Train Accuracy: Acc@1 81.624 || Acc@5 96.618\n","==> Test Accuracy:  Acc@1 69.840 || Acc@5 91.500\n","==> 70.71 seconds to train this epoch\n","\n","\n","----- epoch: 83, lr: 0.020000000000000004 -----\n","Epoch: [83][  0/391]\tTime  0.300 ( 0.300)\tLoss 3.9651e-01 (3.9651e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  97.66 ( 97.66)\n","Epoch: [83][ 30/391]\tTime  0.171 ( 0.173)\tLoss 4.6700e-01 (5.5450e-01)\tAcc@1  85.94 ( 84.25)\tAcc@5  97.66 ( 96.90)\n","Epoch: [83][ 60/391]\tTime  0.168 ( 0.171)\tLoss 5.3315e-01 (5.5880e-01)\tAcc@1  83.59 ( 84.04)\tAcc@5  98.44 ( 96.88)\n","Epoch: [83][ 90/391]\tTime  0.170 ( 0.171)\tLoss 5.3460e-01 (5.5668e-01)\tAcc@1  88.28 ( 83.86)\tAcc@5  96.09 ( 97.00)\n","Epoch: [83][120/391]\tTime  0.168 ( 0.170)\tLoss 5.1517e-01 (5.5800e-01)\tAcc@1  83.59 ( 83.70)\tAcc@5  98.44 ( 97.00)\n","Epoch: [83][150/391]\tTime  0.170 ( 0.170)\tLoss 6.1914e-01 (5.6002e-01)\tAcc@1  82.03 ( 83.47)\tAcc@5  98.44 ( 97.07)\n","Epoch: [83][180/391]\tTime  0.171 ( 0.170)\tLoss 5.3797e-01 (5.6434e-01)\tAcc@1  87.50 ( 83.33)\tAcc@5  96.09 ( 97.10)\n","Epoch: [83][210/391]\tTime  0.169 ( 0.170)\tLoss 5.5361e-01 (5.7424e-01)\tAcc@1  85.16 ( 83.07)\tAcc@5  96.09 ( 97.00)\n","Epoch: [83][240/391]\tTime  0.170 ( 0.170)\tLoss 5.5822e-01 (5.7951e-01)\tAcc@1  85.94 ( 82.95)\tAcc@5  96.88 ( 96.99)\n","Epoch: [83][270/391]\tTime  0.171 ( 0.170)\tLoss 6.6629e-01 (5.8697e-01)\tAcc@1  82.03 ( 82.75)\tAcc@5  96.09 ( 96.92)\n","Epoch: [83][300/391]\tTime  0.169 ( 0.170)\tLoss 7.0247e-01 (5.8960e-01)\tAcc@1  78.91 ( 82.62)\tAcc@5  95.31 ( 96.89)\n","Epoch: [83][330/391]\tTime  0.169 ( 0.170)\tLoss 6.1861e-01 (5.9499e-01)\tAcc@1  82.03 ( 82.50)\tAcc@5  95.31 ( 96.85)\n","Epoch: [83][360/391]\tTime  0.165 ( 0.170)\tLoss 7.4805e-01 (5.9778e-01)\tAcc@1  77.34 ( 82.36)\tAcc@5  93.75 ( 96.84)\n","Epoch: [83][390/391]\tTime  0.151 ( 0.170)\tLoss 6.6794e-01 (5.9943e-01)\tAcc@1  83.75 ( 82.25)\tAcc@5  95.00 ( 96.83)\n","==> Train Accuracy: Acc@1 82.246 || Acc@5 96.826\n","==> Test Accuracy:  Acc@1 71.240 || Acc@5 92.330\n","==> 70.67 seconds to train this epoch\n","\n","\n","----- epoch: 84, lr: 0.020000000000000004 -----\n","Epoch: [84][  0/391]\tTime  0.275 ( 0.275)\tLoss 4.7842e-01 (4.7842e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n","Epoch: [84][ 30/391]\tTime  0.170 ( 0.173)\tLoss 6.2165e-01 (5.3860e-01)\tAcc@1  79.69 ( 84.30)\tAcc@5  96.88 ( 97.08)\n","Epoch: [84][ 60/391]\tTime  0.170 ( 0.171)\tLoss 4.9095e-01 (5.4671e-01)\tAcc@1  84.38 ( 84.04)\tAcc@5  97.66 ( 97.09)\n","Epoch: [84][ 90/391]\tTime  0.171 ( 0.171)\tLoss 4.1129e-01 (5.5592e-01)\tAcc@1  89.06 ( 83.80)\tAcc@5  98.44 ( 96.98)\n","Epoch: [84][120/391]\tTime  0.168 ( 0.170)\tLoss 6.4692e-01 (5.6912e-01)\tAcc@1  80.47 ( 83.48)\tAcc@5  98.44 ( 96.77)\n","Epoch: [84][150/391]\tTime  0.170 ( 0.170)\tLoss 7.0013e-01 (5.7120e-01)\tAcc@1  78.91 ( 83.45)\tAcc@5  94.53 ( 96.73)\n","Epoch: [84][180/391]\tTime  0.171 ( 0.170)\tLoss 6.2326e-01 (5.7996e-01)\tAcc@1  83.59 ( 83.15)\tAcc@5  96.88 ( 96.67)\n","Epoch: [84][210/391]\tTime  0.169 ( 0.170)\tLoss 5.4765e-01 (5.8352e-01)\tAcc@1  78.91 ( 82.97)\tAcc@5  97.66 ( 96.69)\n","Epoch: [84][240/391]\tTime  0.171 ( 0.170)\tLoss 6.4015e-01 (5.8490e-01)\tAcc@1  82.03 ( 82.91)\tAcc@5  96.09 ( 96.71)\n","Epoch: [84][270/391]\tTime  0.170 ( 0.170)\tLoss 4.9894e-01 (5.8860e-01)\tAcc@1  82.81 ( 82.79)\tAcc@5  98.44 ( 96.71)\n","Epoch: [84][300/391]\tTime  0.168 ( 0.170)\tLoss 5.9053e-01 (5.9314e-01)\tAcc@1  78.91 ( 82.59)\tAcc@5  99.22 ( 96.71)\n","Epoch: [84][330/391]\tTime  0.169 ( 0.170)\tLoss 7.0728e-01 (5.9764e-01)\tAcc@1  80.47 ( 82.40)\tAcc@5  95.31 ( 96.69)\n","Epoch: [84][360/391]\tTime  0.170 ( 0.170)\tLoss 6.7566e-01 (6.0049e-01)\tAcc@1  81.25 ( 82.32)\tAcc@5  94.53 ( 96.68)\n","Epoch: [84][390/391]\tTime  0.152 ( 0.170)\tLoss 7.5302e-01 (6.0462e-01)\tAcc@1  80.00 ( 82.17)\tAcc@5  96.25 ( 96.69)\n","==> Train Accuracy: Acc@1 82.174 || Acc@5 96.694\n","==> Test Accuracy:  Acc@1 70.850 || Acc@5 92.080\n","==> 70.63 seconds to train this epoch\n","\n","\n","----- epoch: 85, lr: 0.020000000000000004 -----\n","Epoch: [85][  0/391]\tTime  0.285 ( 0.285)\tLoss 5.3790e-01 (5.3790e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  98.44 ( 98.44)\n","Epoch: [85][ 30/391]\tTime  0.170 ( 0.173)\tLoss 5.1315e-01 (5.8902e-01)\tAcc@1  85.16 ( 82.64)\tAcc@5  96.88 ( 96.75)\n","Epoch: [85][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.4127e-01 (5.7688e-01)\tAcc@1  77.34 ( 83.13)\tAcc@5  96.88 ( 96.77)\n","Epoch: [85][ 90/391]\tTime  0.169 ( 0.171)\tLoss 4.6810e-01 (5.7150e-01)\tAcc@1  85.94 ( 82.99)\tAcc@5  97.66 ( 96.98)\n","Epoch: [85][120/391]\tTime  0.169 ( 0.171)\tLoss 4.8667e-01 (5.6600e-01)\tAcc@1  85.16 ( 83.21)\tAcc@5  99.22 ( 96.99)\n","Epoch: [85][150/391]\tTime  0.169 ( 0.170)\tLoss 5.7955e-01 (5.7211e-01)\tAcc@1  81.25 ( 83.06)\tAcc@5  96.88 ( 96.98)\n","Epoch: [85][180/391]\tTime  0.169 ( 0.170)\tLoss 3.6890e-01 (5.7529e-01)\tAcc@1  90.62 ( 82.99)\tAcc@5  99.22 ( 96.96)\n","Epoch: [85][210/391]\tTime  0.170 ( 0.170)\tLoss 5.5703e-01 (5.7903e-01)\tAcc@1  82.03 ( 82.86)\tAcc@5  96.88 ( 96.90)\n","Epoch: [85][240/391]\tTime  0.170 ( 0.170)\tLoss 6.3907e-01 (5.8485e-01)\tAcc@1  83.59 ( 82.69)\tAcc@5  95.31 ( 96.85)\n","Epoch: [85][270/391]\tTime  0.170 ( 0.170)\tLoss 7.3368e-01 (5.8948e-01)\tAcc@1  78.91 ( 82.54)\tAcc@5  94.53 ( 96.82)\n","Epoch: [85][300/391]\tTime  0.171 ( 0.170)\tLoss 6.1411e-01 (5.9183e-01)\tAcc@1  80.47 ( 82.44)\tAcc@5  96.09 ( 96.81)\n","Epoch: [85][330/391]\tTime  0.170 ( 0.170)\tLoss 6.9320e-01 (5.9093e-01)\tAcc@1  76.56 ( 82.45)\tAcc@5  96.09 ( 96.86)\n","Epoch: [85][360/391]\tTime  0.169 ( 0.170)\tLoss 4.6631e-01 (5.9536e-01)\tAcc@1  89.06 ( 82.33)\tAcc@5  98.44 ( 96.80)\n","Epoch: [85][390/391]\tTime  0.153 ( 0.170)\tLoss 6.2424e-01 (6.0040e-01)\tAcc@1  81.25 ( 82.18)\tAcc@5  97.50 ( 96.78)\n","==> Train Accuracy: Acc@1 82.184 || Acc@5 96.780\n","==> Test Accuracy:  Acc@1 69.490 || Acc@5 92.050\n","==> 70.75 seconds to train this epoch\n","\n","\n","----- epoch: 86, lr: 0.020000000000000004 -----\n","Epoch: [86][  0/391]\tTime  0.281 ( 0.281)\tLoss 5.4311e-01 (5.4311e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  96.09 ( 96.09)\n","Epoch: [86][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.6987e-01 (6.0150e-01)\tAcc@1  82.81 ( 82.06)\tAcc@5  98.44 ( 97.03)\n","Epoch: [86][ 60/391]\tTime  0.169 ( 0.172)\tLoss 6.2868e-01 (5.7461e-01)\tAcc@1  82.81 ( 82.99)\tAcc@5  96.09 ( 97.07)\n","Epoch: [86][ 90/391]\tTime  0.171 ( 0.171)\tLoss 3.9843e-01 (5.7568e-01)\tAcc@1  85.16 ( 82.91)\tAcc@5  99.22 ( 97.01)\n","Epoch: [86][120/391]\tTime  0.171 ( 0.171)\tLoss 5.5634e-01 (5.7490e-01)\tAcc@1  84.38 ( 82.99)\tAcc@5  96.09 ( 96.98)\n","Epoch: [86][150/391]\tTime  0.171 ( 0.171)\tLoss 5.6639e-01 (5.7850e-01)\tAcc@1  82.81 ( 82.92)\tAcc@5  99.22 ( 96.89)\n","Epoch: [86][180/391]\tTime  0.170 ( 0.171)\tLoss 5.7480e-01 (5.8187e-01)\tAcc@1  82.81 ( 82.83)\tAcc@5  96.09 ( 96.89)\n","Epoch: [86][210/391]\tTime  0.170 ( 0.171)\tLoss 4.8347e-01 (5.8266e-01)\tAcc@1  86.72 ( 82.73)\tAcc@5  99.22 ( 96.89)\n","Epoch: [86][240/391]\tTime  0.170 ( 0.171)\tLoss 5.4573e-01 (5.8390e-01)\tAcc@1  83.59 ( 82.73)\tAcc@5  96.09 ( 96.83)\n","Epoch: [86][270/391]\tTime  0.171 ( 0.171)\tLoss 8.2819e-01 (5.8960e-01)\tAcc@1  75.00 ( 82.54)\tAcc@5  94.53 ( 96.81)\n","Epoch: [86][300/391]\tTime  0.170 ( 0.171)\tLoss 6.2968e-01 (5.9049e-01)\tAcc@1  79.69 ( 82.52)\tAcc@5  96.88 ( 96.80)\n","Epoch: [86][330/391]\tTime  0.169 ( 0.170)\tLoss 5.3653e-01 (5.9319e-01)\tAcc@1  80.47 ( 82.41)\tAcc@5  97.66 ( 96.77)\n","Epoch: [86][360/391]\tTime  0.171 ( 0.170)\tLoss 8.3053e-01 (5.9458e-01)\tAcc@1  71.88 ( 82.39)\tAcc@5  93.75 ( 96.77)\n","Epoch: [86][390/391]\tTime  0.153 ( 0.170)\tLoss 9.3504e-01 (5.9588e-01)\tAcc@1  76.25 ( 82.34)\tAcc@5  92.50 ( 96.73)\n","==> Train Accuracy: Acc@1 82.344 || Acc@5 96.726\n","==> Test Accuracy:  Acc@1 71.560 || Acc@5 92.790\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 87, lr: 0.020000000000000004 -----\n","Epoch: [87][  0/391]\tTime  0.282 ( 0.282)\tLoss 4.3452e-01 (4.3452e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  97.66 ( 97.66)\n","Epoch: [87][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.4539e-01 (5.5054e-01)\tAcc@1  86.72 ( 83.74)\tAcc@5  97.66 ( 97.10)\n","Epoch: [87][ 60/391]\tTime  0.170 ( 0.172)\tLoss 5.6318e-01 (5.6744e-01)\tAcc@1  83.59 ( 83.32)\tAcc@5  95.31 ( 96.70)\n","Epoch: [87][ 90/391]\tTime  0.170 ( 0.171)\tLoss 5.9561e-01 (5.6284e-01)\tAcc@1  85.16 ( 83.57)\tAcc@5  96.09 ( 96.83)\n","Epoch: [87][120/391]\tTime  0.169 ( 0.171)\tLoss 6.6632e-01 (5.5664e-01)\tAcc@1  83.59 ( 83.52)\tAcc@5  95.31 ( 96.94)\n","Epoch: [87][150/391]\tTime  0.170 ( 0.171)\tLoss 5.9948e-01 (5.5787e-01)\tAcc@1  79.69 ( 83.56)\tAcc@5  97.66 ( 96.94)\n","Epoch: [87][180/391]\tTime  0.171 ( 0.171)\tLoss 5.3860e-01 (5.7053e-01)\tAcc@1  82.81 ( 83.24)\tAcc@5  98.44 ( 96.86)\n","Epoch: [87][210/391]\tTime  0.170 ( 0.170)\tLoss 5.8436e-01 (5.7432e-01)\tAcc@1  79.69 ( 83.10)\tAcc@5  96.88 ( 96.79)\n","Epoch: [87][240/391]\tTime  0.171 ( 0.170)\tLoss 5.4563e-01 (5.7712e-01)\tAcc@1  82.03 ( 82.95)\tAcc@5  96.88 ( 96.80)\n","Epoch: [87][270/391]\tTime  0.170 ( 0.170)\tLoss 6.5634e-01 (5.8267e-01)\tAcc@1  78.12 ( 82.78)\tAcc@5  96.88 ( 96.77)\n","Epoch: [87][300/391]\tTime  0.170 ( 0.170)\tLoss 6.4161e-01 (5.8752e-01)\tAcc@1  79.69 ( 82.63)\tAcc@5  96.09 ( 96.72)\n","Epoch: [87][330/391]\tTime  0.169 ( 0.170)\tLoss 5.2072e-01 (5.9129e-01)\tAcc@1  87.50 ( 82.55)\tAcc@5  97.66 ( 96.69)\n","Epoch: [87][360/391]\tTime  0.170 ( 0.170)\tLoss 4.5229e-01 (5.9543e-01)\tAcc@1  89.84 ( 82.46)\tAcc@5  96.88 ( 96.67)\n","Epoch: [87][390/391]\tTime  0.153 ( 0.170)\tLoss 8.4455e-01 (6.0037e-01)\tAcc@1  73.75 ( 82.30)\tAcc@5  95.00 ( 96.66)\n","==> Train Accuracy: Acc@1 82.304 || Acc@5 96.662\n","==> Test Accuracy:  Acc@1 71.560 || Acc@5 91.910\n","==> 70.71 seconds to train this epoch\n","\n","\n","----- epoch: 88, lr: 0.020000000000000004 -----\n","Epoch: [88][  0/391]\tTime  0.273 ( 0.273)\tLoss 7.3869e-01 (7.3869e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  95.31 ( 95.31)\n","Epoch: [88][ 30/391]\tTime  0.171 ( 0.173)\tLoss 5.0452e-01 (5.3986e-01)\tAcc@1  85.94 ( 84.43)\tAcc@5  98.44 ( 97.03)\n","Epoch: [88][ 60/391]\tTime  0.169 ( 0.171)\tLoss 6.1434e-01 (5.4168e-01)\tAcc@1  77.34 ( 84.16)\tAcc@5  96.88 ( 97.07)\n","Epoch: [88][ 90/391]\tTime  0.170 ( 0.171)\tLoss 6.1315e-01 (5.4227e-01)\tAcc@1  82.81 ( 84.11)\tAcc@5  96.88 ( 97.00)\n","Epoch: [88][120/391]\tTime  0.170 ( 0.171)\tLoss 5.8790e-01 (5.4929e-01)\tAcc@1  83.59 ( 83.83)\tAcc@5  98.44 ( 97.04)\n","Epoch: [88][150/391]\tTime  0.171 ( 0.171)\tLoss 5.2009e-01 (5.5356e-01)\tAcc@1  82.81 ( 83.68)\tAcc@5  98.44 ( 97.07)\n","Epoch: [88][180/391]\tTime  0.171 ( 0.170)\tLoss 7.0157e-01 (5.6206e-01)\tAcc@1  81.25 ( 83.39)\tAcc@5  93.75 ( 96.98)\n","Epoch: [88][210/391]\tTime  0.171 ( 0.170)\tLoss 6.5768e-01 (5.6664e-01)\tAcc@1  78.91 ( 83.18)\tAcc@5  96.09 ( 96.94)\n","Epoch: [88][240/391]\tTime  0.171 ( 0.170)\tLoss 7.0008e-01 (5.7557e-01)\tAcc@1  75.78 ( 82.91)\tAcc@5  95.31 ( 96.89)\n","Epoch: [88][270/391]\tTime  0.171 ( 0.170)\tLoss 5.8556e-01 (5.7662e-01)\tAcc@1  82.81 ( 82.90)\tAcc@5  95.31 ( 96.86)\n","Epoch: [88][300/391]\tTime  0.169 ( 0.170)\tLoss 4.6996e-01 (5.7993e-01)\tAcc@1  84.38 ( 82.80)\tAcc@5  96.88 ( 96.84)\n","Epoch: [88][330/391]\tTime  0.171 ( 0.170)\tLoss 7.0762e-01 (5.8317e-01)\tAcc@1  75.00 ( 82.69)\tAcc@5  96.88 ( 96.82)\n","Epoch: [88][360/391]\tTime  0.170 ( 0.170)\tLoss 7.1663e-01 (5.8595e-01)\tAcc@1  76.56 ( 82.57)\tAcc@5  94.53 ( 96.81)\n","Epoch: [88][390/391]\tTime  0.151 ( 0.170)\tLoss 5.4132e-01 (5.9094e-01)\tAcc@1  83.75 ( 82.44)\tAcc@5 100.00 ( 96.79)\n","==> Train Accuracy: Acc@1 82.436 || Acc@5 96.790\n","==> Test Accuracy:  Acc@1 71.370 || Acc@5 91.660\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 89, lr: 0.020000000000000004 -----\n","Epoch: [89][  0/391]\tTime  0.278 ( 0.278)\tLoss 3.7475e-01 (3.7475e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  98.44 ( 98.44)\n","Epoch: [89][ 30/391]\tTime  0.169 ( 0.173)\tLoss 4.3966e-01 (5.6790e-01)\tAcc@1  88.28 ( 83.42)\tAcc@5  97.66 ( 96.90)\n","Epoch: [89][ 60/391]\tTime  0.170 ( 0.172)\tLoss 6.0665e-01 (5.6137e-01)\tAcc@1  80.47 ( 83.47)\tAcc@5  98.44 ( 97.13)\n","Epoch: [89][ 90/391]\tTime  0.170 ( 0.171)\tLoss 5.7792e-01 (5.6412e-01)\tAcc@1  84.38 ( 83.40)\tAcc@5  96.09 ( 97.00)\n","Epoch: [89][120/391]\tTime  0.171 ( 0.171)\tLoss 4.6164e-01 (5.7708e-01)\tAcc@1  89.06 ( 83.23)\tAcc@5  97.66 ( 96.92)\n","Epoch: [89][150/391]\tTime  0.169 ( 0.171)\tLoss 5.9263e-01 (5.8359e-01)\tAcc@1  82.81 ( 82.93)\tAcc@5  97.66 ( 96.91)\n","Epoch: [89][180/391]\tTime  0.170 ( 0.171)\tLoss 3.2526e-01 (5.8836e-01)\tAcc@1  89.06 ( 82.73)\tAcc@5 100.00 ( 96.87)\n","Epoch: [89][210/391]\tTime  0.170 ( 0.171)\tLoss 5.2508e-01 (5.8639e-01)\tAcc@1  85.94 ( 82.70)\tAcc@5  98.44 ( 96.89)\n","Epoch: [89][240/391]\tTime  0.168 ( 0.170)\tLoss 5.6441e-01 (5.8925e-01)\tAcc@1  85.94 ( 82.63)\tAcc@5  97.66 ( 96.84)\n","Epoch: [89][270/391]\tTime  0.171 ( 0.170)\tLoss 7.8490e-01 (5.8827e-01)\tAcc@1  77.34 ( 82.63)\tAcc@5  94.53 ( 96.85)\n","Epoch: [89][300/391]\tTime  0.170 ( 0.170)\tLoss 5.5675e-01 (5.8723e-01)\tAcc@1  81.25 ( 82.70)\tAcc@5  97.66 ( 96.85)\n","Epoch: [89][330/391]\tTime  0.169 ( 0.170)\tLoss 6.2910e-01 (5.8737e-01)\tAcc@1  83.59 ( 82.68)\tAcc@5  96.88 ( 96.87)\n","Epoch: [89][360/391]\tTime  0.171 ( 0.170)\tLoss 5.6121e-01 (5.9049e-01)\tAcc@1  82.03 ( 82.59)\tAcc@5  98.44 ( 96.84)\n","Epoch: [89][390/391]\tTime  0.153 ( 0.170)\tLoss 5.9560e-01 (5.9360e-01)\tAcc@1  83.75 ( 82.52)\tAcc@5  95.00 ( 96.80)\n","==> Train Accuracy: Acc@1 82.518 || Acc@5 96.804\n","==> Test Accuracy:  Acc@1 70.700 || Acc@5 92.240\n","==> 70.73 seconds to train this epoch\n","\n","\n","----- epoch: 90, lr: 0.004000000000000001 -----\n","Epoch: [90][  0/391]\tTime  0.284 ( 0.284)\tLoss 4.1605e-01 (4.1605e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n","Epoch: [90][ 30/391]\tTime  0.172 ( 0.173)\tLoss 4.9263e-01 (4.8753e-01)\tAcc@1  85.16 ( 86.01)\tAcc@5  99.22 ( 97.98)\n","Epoch: [90][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.9373e-01 (4.5884e-01)\tAcc@1  92.19 ( 86.76)\tAcc@5  98.44 ( 97.95)\n","Epoch: [90][ 90/391]\tTime  0.170 ( 0.171)\tLoss 3.9099e-01 (4.3126e-01)\tAcc@1  88.28 ( 87.52)\tAcc@5  99.22 ( 98.09)\n","Epoch: [90][120/391]\tTime  0.170 ( 0.171)\tLoss 4.5117e-01 (4.2154e-01)\tAcc@1  86.72 ( 87.91)\tAcc@5  96.88 ( 98.06)\n","Epoch: [90][150/391]\tTime  0.170 ( 0.171)\tLoss 3.1262e-01 (4.0887e-01)\tAcc@1  89.84 ( 88.26)\tAcc@5  97.66 ( 98.10)\n","Epoch: [90][180/391]\tTime  0.170 ( 0.171)\tLoss 4.2383e-01 (3.9935e-01)\tAcc@1  92.19 ( 88.54)\tAcc@5  96.88 ( 98.14)\n","Epoch: [90][210/391]\tTime  0.170 ( 0.170)\tLoss 4.3106e-01 (3.9356e-01)\tAcc@1  86.72 ( 88.75)\tAcc@5  97.66 ( 98.16)\n","Epoch: [90][240/391]\tTime  0.170 ( 0.170)\tLoss 3.1010e-01 (3.8966e-01)\tAcc@1  90.62 ( 88.84)\tAcc@5 100.00 ( 98.21)\n","Epoch: [90][270/391]\tTime  0.171 ( 0.170)\tLoss 4.2574e-01 (3.8446e-01)\tAcc@1  86.72 ( 89.04)\tAcc@5  97.66 ( 98.25)\n","Epoch: [90][300/391]\tTime  0.169 ( 0.170)\tLoss 3.4499e-01 (3.8089e-01)\tAcc@1  89.06 ( 89.17)\tAcc@5  99.22 ( 98.25)\n","Epoch: [90][330/391]\tTime  0.170 ( 0.170)\tLoss 3.4758e-01 (3.7779e-01)\tAcc@1  90.62 ( 89.23)\tAcc@5  98.44 ( 98.28)\n","Epoch: [90][360/391]\tTime  0.170 ( 0.170)\tLoss 2.9173e-01 (3.7514e-01)\tAcc@1  90.62 ( 89.31)\tAcc@5  99.22 ( 98.30)\n","Epoch: [90][390/391]\tTime  0.153 ( 0.170)\tLoss 4.7271e-01 (3.7254e-01)\tAcc@1  87.50 ( 89.37)\tAcc@5  95.00 ( 98.30)\n","==> Train Accuracy: Acc@1 89.374 || Acc@5 98.302\n","==> Test Accuracy:  Acc@1 77.320 || Acc@5 94.500\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 91, lr: 0.004000000000000001 -----\n","Epoch: [91][  0/391]\tTime  0.282 ( 0.282)\tLoss 2.9299e-01 (2.9299e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  96.88 ( 96.88)\n","Epoch: [91][ 30/391]\tTime  0.170 ( 0.173)\tLoss 3.8780e-01 (2.9371e-01)\tAcc@1  89.84 ( 91.89)\tAcc@5  96.88 ( 98.94)\n","Epoch: [91][ 60/391]\tTime  0.170 ( 0.172)\tLoss 3.3095e-01 (2.9666e-01)\tAcc@1  91.41 ( 91.75)\tAcc@5  99.22 ( 98.91)\n","Epoch: [91][ 90/391]\tTime  0.169 ( 0.171)\tLoss 3.4874e-01 (2.9168e-01)\tAcc@1  87.50 ( 91.96)\tAcc@5  97.66 ( 98.82)\n","Epoch: [91][120/391]\tTime  0.170 ( 0.171)\tLoss 4.5294e-01 (2.9593e-01)\tAcc@1  85.94 ( 91.96)\tAcc@5  96.88 ( 98.73)\n","Epoch: [91][150/391]\tTime  0.170 ( 0.171)\tLoss 2.6336e-01 (2.9766e-01)\tAcc@1  92.97 ( 91.72)\tAcc@5  97.66 ( 98.68)\n","Epoch: [91][180/391]\tTime  0.169 ( 0.170)\tLoss 3.3094e-01 (3.0311e-01)\tAcc@1  91.41 ( 91.51)\tAcc@5  97.66 ( 98.62)\n","Epoch: [91][210/391]\tTime  0.170 ( 0.170)\tLoss 2.4775e-01 (2.9975e-01)\tAcc@1  92.19 ( 91.61)\tAcc@5  99.22 ( 98.66)\n","Epoch: [91][240/391]\tTime  0.171 ( 0.170)\tLoss 4.0117e-01 (2.9952e-01)\tAcc@1  85.94 ( 91.57)\tAcc@5  97.66 ( 98.66)\n","Epoch: [91][270/391]\tTime  0.171 ( 0.170)\tLoss 2.5940e-01 (2.9788e-01)\tAcc@1  91.41 ( 91.60)\tAcc@5  98.44 ( 98.65)\n","Epoch: [91][300/391]\tTime  0.171 ( 0.170)\tLoss 3.1628e-01 (2.9744e-01)\tAcc@1  90.62 ( 91.61)\tAcc@5  96.88 ( 98.66)\n","Epoch: [91][330/391]\tTime  0.170 ( 0.170)\tLoss 4.2109e-01 (2.9671e-01)\tAcc@1  85.16 ( 91.63)\tAcc@5  97.66 ( 98.67)\n","Epoch: [91][360/391]\tTime  0.170 ( 0.170)\tLoss 3.2948e-01 (2.9638e-01)\tAcc@1  89.84 ( 91.68)\tAcc@5  98.44 ( 98.65)\n","Epoch: [91][390/391]\tTime  0.152 ( 0.170)\tLoss 1.2709e-01 (2.9895e-01)\tAcc@1 100.00 ( 91.60)\tAcc@5 100.00 ( 98.61)\n","==> Train Accuracy: Acc@1 91.598 || Acc@5 98.610\n","==> Test Accuracy:  Acc@1 77.750 || Acc@5 94.770\n","==> 70.68 seconds to train this epoch\n","\n","\n","----- epoch: 92, lr: 0.004000000000000001 -----\n","Epoch: [92][  0/391]\tTime  0.276 ( 0.276)\tLoss 2.2846e-01 (2.2846e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [92][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.2274e-01 (2.7368e-01)\tAcc@1  96.09 ( 92.31)\tAcc@5  98.44 ( 98.39)\n","Epoch: [92][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.9611e-01 (2.7839e-01)\tAcc@1  92.97 ( 92.21)\tAcc@5  99.22 ( 98.50)\n","Epoch: [92][ 90/391]\tTime  0.169 ( 0.171)\tLoss 3.0864e-01 (2.7736e-01)\tAcc@1  92.97 ( 92.28)\tAcc@5  98.44 ( 98.53)\n","Epoch: [92][120/391]\tTime  0.169 ( 0.170)\tLoss 1.7157e-01 (2.7603e-01)\tAcc@1  96.88 ( 92.27)\tAcc@5 100.00 ( 98.61)\n","Epoch: [92][150/391]\tTime  0.170 ( 0.170)\tLoss 3.9358e-01 (2.7682e-01)\tAcc@1  89.06 ( 92.23)\tAcc@5  98.44 ( 98.63)\n","Epoch: [92][180/391]\tTime  0.169 ( 0.170)\tLoss 2.4630e-01 (2.7461e-01)\tAcc@1  96.09 ( 92.29)\tAcc@5  97.66 ( 98.67)\n","Epoch: [92][210/391]\tTime  0.170 ( 0.170)\tLoss 3.0236e-01 (2.7598e-01)\tAcc@1  90.62 ( 92.27)\tAcc@5  98.44 ( 98.66)\n","Epoch: [92][240/391]\tTime  0.170 ( 0.170)\tLoss 1.9258e-01 (2.7602e-01)\tAcc@1  92.97 ( 92.23)\tAcc@5 100.00 ( 98.67)\n","Epoch: [92][270/391]\tTime  0.171 ( 0.170)\tLoss 2.5354e-01 (2.7548e-01)\tAcc@1  96.09 ( 92.25)\tAcc@5  99.22 ( 98.69)\n","Epoch: [92][300/391]\tTime  0.169 ( 0.170)\tLoss 3.1757e-01 (2.7511e-01)\tAcc@1  90.62 ( 92.29)\tAcc@5  97.66 ( 98.68)\n","Epoch: [92][330/391]\tTime  0.170 ( 0.170)\tLoss 1.9893e-01 (2.7521e-01)\tAcc@1  93.75 ( 92.25)\tAcc@5  99.22 ( 98.69)\n","Epoch: [92][360/391]\tTime  0.168 ( 0.170)\tLoss 2.8908e-01 (2.7522e-01)\tAcc@1  91.41 ( 92.24)\tAcc@5 100.00 ( 98.71)\n","Epoch: [92][390/391]\tTime  0.154 ( 0.170)\tLoss 3.8401e-01 (2.7533e-01)\tAcc@1  88.75 ( 92.22)\tAcc@5 100.00 ( 98.69)\n","==> Train Accuracy: Acc@1 92.222 || Acc@5 98.694\n","==> Test Accuracy:  Acc@1 77.700 || Acc@5 94.580\n","==> 70.64 seconds to train this epoch\n","\n","\n","----- epoch: 93, lr: 0.004000000000000001 -----\n","Epoch: [93][  0/391]\tTime  0.267 ( 0.267)\tLoss 2.7755e-01 (2.7755e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  97.66 ( 97.66)\n","Epoch: [93][ 30/391]\tTime  0.171 ( 0.173)\tLoss 3.0770e-01 (2.7675e-01)\tAcc@1  92.97 ( 92.31)\tAcc@5  99.22 ( 98.36)\n","Epoch: [93][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.7679e-01 (2.6446e-01)\tAcc@1  94.53 ( 92.67)\tAcc@5  97.66 ( 98.58)\n","Epoch: [93][ 90/391]\tTime  0.170 ( 0.171)\tLoss 3.5293e-01 (2.6581e-01)\tAcc@1  92.19 ( 92.69)\tAcc@5  97.66 ( 98.66)\n","Epoch: [93][120/391]\tTime  0.170 ( 0.171)\tLoss 3.0966e-01 (2.6265e-01)\tAcc@1  91.41 ( 92.73)\tAcc@5  97.66 ( 98.76)\n","Epoch: [93][150/391]\tTime  0.170 ( 0.171)\tLoss 2.1781e-01 (2.6554e-01)\tAcc@1  95.31 ( 92.62)\tAcc@5  98.44 ( 98.75)\n","Epoch: [93][180/391]\tTime  0.171 ( 0.170)\tLoss 2.9166e-01 (2.6314e-01)\tAcc@1  92.97 ( 92.68)\tAcc@5  99.22 ( 98.74)\n","Epoch: [93][210/391]\tTime  0.169 ( 0.170)\tLoss 3.5575e-01 (2.6389e-01)\tAcc@1  89.06 ( 92.63)\tAcc@5  96.09 ( 98.74)\n","Epoch: [93][240/391]\tTime  0.170 ( 0.170)\tLoss 3.0464e-01 (2.6367e-01)\tAcc@1  91.41 ( 92.60)\tAcc@5  97.66 ( 98.76)\n","Epoch: [93][270/391]\tTime  0.170 ( 0.170)\tLoss 2.3804e-01 (2.6428e-01)\tAcc@1  91.41 ( 92.57)\tAcc@5  98.44 ( 98.73)\n","Epoch: [93][300/391]\tTime  0.170 ( 0.170)\tLoss 2.2241e-01 (2.6562e-01)\tAcc@1  92.97 ( 92.49)\tAcc@5  99.22 ( 98.74)\n","Epoch: [93][330/391]\tTime  0.169 ( 0.170)\tLoss 1.8791e-01 (2.6471e-01)\tAcc@1  97.66 ( 92.53)\tAcc@5  99.22 ( 98.73)\n","Epoch: [93][360/391]\tTime  0.169 ( 0.170)\tLoss 3.0842e-01 (2.6505e-01)\tAcc@1  92.19 ( 92.54)\tAcc@5  99.22 ( 98.71)\n","Epoch: [93][390/391]\tTime  0.154 ( 0.170)\tLoss 2.6436e-01 (2.6572e-01)\tAcc@1  91.25 ( 92.49)\tAcc@5  98.75 ( 98.72)\n","==> Train Accuracy: Acc@1 92.492 || Acc@5 98.716\n","==> Test Accuracy:  Acc@1 77.950 || Acc@5 94.570\n","==> 70.75 seconds to train this epoch\n","\n","\n","----- epoch: 94, lr: 0.004000000000000001 -----\n","Epoch: [94][  0/391]\tTime  0.282 ( 0.282)\tLoss 2.0475e-01 (2.0475e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n","Epoch: [94][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.1161e-01 (2.4979e-01)\tAcc@1  97.66 ( 93.17)\tAcc@5 100.00 ( 98.94)\n","Epoch: [94][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.6461e-01 (2.4615e-01)\tAcc@1  91.41 ( 93.07)\tAcc@5  99.22 ( 98.95)\n","Epoch: [94][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.8462e-01 (2.4751e-01)\tAcc@1  93.75 ( 93.07)\tAcc@5 100.00 ( 98.88)\n","Epoch: [94][120/391]\tTime  0.170 ( 0.171)\tLoss 3.5721e-01 (2.4379e-01)\tAcc@1  89.06 ( 93.20)\tAcc@5  97.66 ( 98.89)\n","Epoch: [94][150/391]\tTime  0.170 ( 0.171)\tLoss 1.6380e-01 (2.4580e-01)\tAcc@1  94.53 ( 93.19)\tAcc@5 100.00 ( 98.87)\n","Epoch: [94][180/391]\tTime  0.170 ( 0.171)\tLoss 2.1101e-01 (2.4649e-01)\tAcc@1  95.31 ( 93.14)\tAcc@5  99.22 ( 98.90)\n","Epoch: [94][210/391]\tTime  0.169 ( 0.171)\tLoss 2.6436e-01 (2.4754e-01)\tAcc@1  91.41 ( 93.08)\tAcc@5 100.00 ( 98.92)\n","Epoch: [94][240/391]\tTime  0.171 ( 0.171)\tLoss 2.7255e-01 (2.4732e-01)\tAcc@1  90.62 ( 93.03)\tAcc@5 100.00 ( 98.93)\n","Epoch: [94][270/391]\tTime  0.171 ( 0.171)\tLoss 2.0996e-01 (2.5089e-01)\tAcc@1  92.97 ( 92.94)\tAcc@5 100.00 ( 98.89)\n","Epoch: [94][300/391]\tTime  0.171 ( 0.170)\tLoss 3.1108e-01 (2.5003e-01)\tAcc@1  91.41 ( 92.95)\tAcc@5 100.00 ( 98.90)\n","Epoch: [94][330/391]\tTime  0.171 ( 0.170)\tLoss 2.1842e-01 (2.5086e-01)\tAcc@1  93.75 ( 92.95)\tAcc@5  98.44 ( 98.91)\n","Epoch: [94][360/391]\tTime  0.170 ( 0.170)\tLoss 2.2926e-01 (2.5038e-01)\tAcc@1  93.75 ( 92.93)\tAcc@5 100.00 ( 98.91)\n","Epoch: [94][390/391]\tTime  0.153 ( 0.170)\tLoss 3.4857e-01 (2.5152e-01)\tAcc@1  90.00 ( 92.92)\tAcc@5  98.75 ( 98.91)\n","==> Train Accuracy: Acc@1 92.918 || Acc@5 98.908\n","==> Test Accuracy:  Acc@1 78.040 || Acc@5 94.760\n","==> 70.85 seconds to train this epoch\n","\n","\n","----- epoch: 95, lr: 0.004000000000000001 -----\n","Epoch: [95][  0/391]\tTime  0.271 ( 0.271)\tLoss 2.3034e-01 (2.3034e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n","Epoch: [95][ 30/391]\tTime  0.171 ( 0.174)\tLoss 1.9837e-01 (2.2435e-01)\tAcc@1  94.53 ( 93.90)\tAcc@5  98.44 ( 99.07)\n","Epoch: [95][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.9634e-01 (2.3327e-01)\tAcc@1  91.41 ( 93.53)\tAcc@5  98.44 ( 98.91)\n","Epoch: [95][ 90/391]\tTime  0.171 ( 0.172)\tLoss 2.7742e-01 (2.2960e-01)\tAcc@1  92.19 ( 93.66)\tAcc@5  97.66 ( 98.95)\n","Epoch: [95][120/391]\tTime  0.170 ( 0.171)\tLoss 1.8947e-01 (2.3185e-01)\tAcc@1  96.09 ( 93.60)\tAcc@5  97.66 ( 98.92)\n","Epoch: [95][150/391]\tTime  0.170 ( 0.171)\tLoss 2.9564e-01 (2.3363e-01)\tAcc@1  89.84 ( 93.62)\tAcc@5  99.22 ( 98.86)\n","Epoch: [95][180/391]\tTime  0.171 ( 0.171)\tLoss 2.2617e-01 (2.3846e-01)\tAcc@1  94.53 ( 93.46)\tAcc@5  99.22 ( 98.80)\n","Epoch: [95][210/391]\tTime  0.171 ( 0.171)\tLoss 2.3088e-01 (2.3972e-01)\tAcc@1  94.53 ( 93.42)\tAcc@5  99.22 ( 98.80)\n","Epoch: [95][240/391]\tTime  0.168 ( 0.171)\tLoss 2.0571e-01 (2.3798e-01)\tAcc@1  96.09 ( 93.49)\tAcc@5 100.00 ( 98.84)\n","Epoch: [95][270/391]\tTime  0.169 ( 0.171)\tLoss 1.7996e-01 (2.3710e-01)\tAcc@1  94.53 ( 93.50)\tAcc@5 100.00 ( 98.88)\n","Epoch: [95][300/391]\tTime  0.169 ( 0.171)\tLoss 1.4061e-01 (2.3738e-01)\tAcc@1  94.53 ( 93.48)\tAcc@5 100.00 ( 98.90)\n","Epoch: [95][330/391]\tTime  0.171 ( 0.171)\tLoss 1.9487e-01 (2.3760e-01)\tAcc@1  93.75 ( 93.44)\tAcc@5 100.00 ( 98.91)\n","Epoch: [95][360/391]\tTime  0.172 ( 0.171)\tLoss 2.2484e-01 (2.3775e-01)\tAcc@1  92.97 ( 93.43)\tAcc@5  98.44 ( 98.90)\n","Epoch: [95][390/391]\tTime  0.154 ( 0.170)\tLoss 1.5471e-01 (2.3895e-01)\tAcc@1  95.00 ( 93.39)\tAcc@5 100.00 ( 98.88)\n","==> Train Accuracy: Acc@1 93.390 || Acc@5 98.876\n","==> Test Accuracy:  Acc@1 77.690 || Acc@5 94.820\n","==> 70.84 seconds to train this epoch\n","\n","\n","----- epoch: 96, lr: 0.004000000000000001 -----\n","Epoch: [96][  0/391]\tTime  0.274 ( 0.274)\tLoss 2.3321e-01 (2.3321e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n","Epoch: [96][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.3527e-01 (2.3264e-01)\tAcc@1  92.19 ( 93.42)\tAcc@5  99.22 ( 98.84)\n","Epoch: [96][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.9636e-01 (2.2709e-01)\tAcc@1  92.97 ( 93.49)\tAcc@5  99.22 ( 98.95)\n","Epoch: [96][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.6439e-01 (2.2843e-01)\tAcc@1  89.84 ( 93.48)\tAcc@5  99.22 ( 99.00)\n","Epoch: [96][120/391]\tTime  0.170 ( 0.171)\tLoss 2.7244e-01 (2.3072e-01)\tAcc@1  92.19 ( 93.38)\tAcc@5  99.22 ( 98.97)\n","Epoch: [96][150/391]\tTime  0.170 ( 0.171)\tLoss 1.5483e-01 (2.3073e-01)\tAcc@1  96.09 ( 93.37)\tAcc@5  99.22 ( 99.00)\n","Epoch: [96][180/391]\tTime  0.171 ( 0.170)\tLoss 1.2107e-01 (2.3341e-01)\tAcc@1  96.88 ( 93.31)\tAcc@5 100.00 ( 99.00)\n","Epoch: [96][210/391]\tTime  0.163 ( 0.170)\tLoss 2.0973e-01 (2.3607e-01)\tAcc@1  93.75 ( 93.22)\tAcc@5  99.22 ( 99.00)\n","Epoch: [96][240/391]\tTime  0.165 ( 0.170)\tLoss 2.2268e-01 (2.3514e-01)\tAcc@1  94.53 ( 93.27)\tAcc@5  98.44 ( 99.00)\n","Epoch: [96][270/391]\tTime  0.169 ( 0.170)\tLoss 1.6022e-01 (2.3569e-01)\tAcc@1  96.88 ( 93.28)\tAcc@5 100.00 ( 99.01)\n","Epoch: [96][300/391]\tTime  0.170 ( 0.170)\tLoss 1.6828e-01 (2.3365e-01)\tAcc@1  95.31 ( 93.36)\tAcc@5 100.00 ( 99.03)\n","Epoch: [96][330/391]\tTime  0.170 ( 0.170)\tLoss 2.3979e-01 (2.3314e-01)\tAcc@1  91.41 ( 93.36)\tAcc@5  99.22 ( 99.02)\n","Epoch: [96][360/391]\tTime  0.170 ( 0.170)\tLoss 1.2447e-01 (2.3233e-01)\tAcc@1  95.31 ( 93.37)\tAcc@5  99.22 ( 99.03)\n","Epoch: [96][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3807e-01 (2.3132e-01)\tAcc@1  97.50 ( 93.40)\tAcc@5 100.00 ( 99.04)\n","==> Train Accuracy: Acc@1 93.402 || Acc@5 99.036\n","==> Test Accuracy:  Acc@1 78.250 || Acc@5 94.460\n","==> 70.70 seconds to train this epoch\n","\n","\n","----- epoch: 97, lr: 0.004000000000000001 -----\n","Epoch: [97][  0/391]\tTime  0.279 ( 0.279)\tLoss 2.4496e-01 (2.4496e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n","Epoch: [97][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.3487e-01 (2.2352e-01)\tAcc@1  93.75 ( 94.05)\tAcc@5 100.00 ( 98.89)\n","Epoch: [97][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.7882e-01 (2.2440e-01)\tAcc@1  93.75 ( 93.83)\tAcc@5  99.22 ( 99.04)\n","Epoch: [97][ 90/391]\tTime  0.169 ( 0.171)\tLoss 2.2368e-01 (2.1755e-01)\tAcc@1  91.41 ( 93.92)\tAcc@5 100.00 ( 99.18)\n","Epoch: [97][120/391]\tTime  0.169 ( 0.171)\tLoss 1.4274e-01 (2.1607e-01)\tAcc@1  95.31 ( 94.05)\tAcc@5  99.22 ( 99.13)\n","Epoch: [97][150/391]\tTime  0.169 ( 0.171)\tLoss 2.8783e-01 (2.1835e-01)\tAcc@1  92.19 ( 93.95)\tAcc@5  96.88 ( 99.15)\n","Epoch: [97][180/391]\tTime  0.169 ( 0.170)\tLoss 3.4171e-01 (2.1819e-01)\tAcc@1  92.97 ( 94.02)\tAcc@5  96.09 ( 99.08)\n","Epoch: [97][210/391]\tTime  0.172 ( 0.170)\tLoss 2.4015e-01 (2.2165e-01)\tAcc@1  92.19 ( 93.91)\tAcc@5  99.22 ( 99.05)\n","Epoch: [97][240/391]\tTime  0.173 ( 0.170)\tLoss 1.6951e-01 (2.2151e-01)\tAcc@1  95.31 ( 93.95)\tAcc@5  99.22 ( 99.04)\n","Epoch: [97][270/391]\tTime  0.169 ( 0.170)\tLoss 3.2187e-01 (2.2364e-01)\tAcc@1  91.41 ( 93.89)\tAcc@5  96.88 ( 99.01)\n","Epoch: [97][300/391]\tTime  0.170 ( 0.170)\tLoss 2.2705e-01 (2.2513e-01)\tAcc@1  93.75 ( 93.84)\tAcc@5  99.22 ( 99.01)\n","Epoch: [97][330/391]\tTime  0.170 ( 0.170)\tLoss 3.9556e-01 (2.2610e-01)\tAcc@1  87.50 ( 93.83)\tAcc@5  97.66 ( 98.99)\n","Epoch: [97][360/391]\tTime  0.171 ( 0.170)\tLoss 2.0036e-01 (2.2671e-01)\tAcc@1  94.53 ( 93.84)\tAcc@5  98.44 ( 98.98)\n","Epoch: [97][390/391]\tTime  0.154 ( 0.170)\tLoss 1.5805e-01 (2.2596e-01)\tAcc@1  96.25 ( 93.84)\tAcc@5 100.00 ( 98.99)\n","==> Train Accuracy: Acc@1 93.844 || Acc@5 98.994\n","==> Test Accuracy:  Acc@1 77.800 || Acc@5 94.430\n","==> 70.71 seconds to train this epoch\n","\n","\n","----- epoch: 98, lr: 0.004000000000000001 -----\n","Epoch: [98][  0/391]\tTime  0.282 ( 0.282)\tLoss 2.3104e-01 (2.3104e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n","Epoch: [98][ 30/391]\tTime  0.169 ( 0.173)\tLoss 3.2415e-01 (2.0135e-01)\tAcc@1  88.28 ( 94.43)\tAcc@5  98.44 ( 99.17)\n","Epoch: [98][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.7032e-01 (2.0367e-01)\tAcc@1  93.75 ( 94.33)\tAcc@5  99.22 ( 99.14)\n","Epoch: [98][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.7149e-01 (2.0881e-01)\tAcc@1  96.09 ( 94.15)\tAcc@5 100.00 ( 99.13)\n","Epoch: [98][120/391]\tTime  0.169 ( 0.171)\tLoss 1.5828e-01 (2.1221e-01)\tAcc@1  94.53 ( 94.12)\tAcc@5 100.00 ( 99.08)\n","Epoch: [98][150/391]\tTime  0.170 ( 0.170)\tLoss 2.3976e-01 (2.1591e-01)\tAcc@1  92.19 ( 93.99)\tAcc@5  98.44 ( 99.07)\n","Epoch: [98][180/391]\tTime  0.170 ( 0.170)\tLoss 2.4411e-01 (2.1747e-01)\tAcc@1  94.53 ( 93.91)\tAcc@5  97.66 ( 99.05)\n","Epoch: [98][210/391]\tTime  0.171 ( 0.170)\tLoss 2.9421e-01 (2.2372e-01)\tAcc@1  89.84 ( 93.71)\tAcc@5  99.22 ( 98.96)\n","Epoch: [98][240/391]\tTime  0.170 ( 0.170)\tLoss 2.1637e-01 (2.2557e-01)\tAcc@1  96.09 ( 93.68)\tAcc@5  99.22 ( 98.95)\n","Epoch: [98][270/391]\tTime  0.170 ( 0.170)\tLoss 3.2229e-01 (2.2467e-01)\tAcc@1  89.06 ( 93.68)\tAcc@5  97.66 ( 98.97)\n","Epoch: [98][300/391]\tTime  0.171 ( 0.170)\tLoss 2.8659e-01 (2.2583e-01)\tAcc@1  92.97 ( 93.66)\tAcc@5  97.66 ( 98.95)\n","Epoch: [98][330/391]\tTime  0.169 ( 0.170)\tLoss 1.8490e-01 (2.2497e-01)\tAcc@1  95.31 ( 93.71)\tAcc@5  99.22 ( 98.95)\n","Epoch: [98][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3918e-01 (2.2478e-01)\tAcc@1  97.66 ( 93.70)\tAcc@5  98.44 ( 98.95)\n","Epoch: [98][390/391]\tTime  0.152 ( 0.170)\tLoss 3.1020e-01 (2.2251e-01)\tAcc@1  92.50 ( 93.74)\tAcc@5  97.50 ( 98.98)\n","==> Train Accuracy: Acc@1 93.738 || Acc@5 98.980\n","==> Test Accuracy:  Acc@1 77.700 || Acc@5 94.560\n","==> 70.69 seconds to train this epoch\n","\n","\n","----- epoch: 99, lr: 0.004000000000000001 -----\n","Epoch: [99][  0/391]\tTime  0.270 ( 0.270)\tLoss 3.0487e-01 (3.0487e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  99.22 ( 99.22)\n","Epoch: [99][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.4087e-01 (1.9400e-01)\tAcc@1  96.88 ( 94.53)\tAcc@5 100.00 ( 99.32)\n","Epoch: [99][ 60/391]\tTime  0.170 ( 0.171)\tLoss 1.2784e-01 (1.9843e-01)\tAcc@1  97.66 ( 94.61)\tAcc@5 100.00 ( 99.26)\n","Epoch: [99][ 90/391]\tTime  0.170 ( 0.171)\tLoss 3.0393e-01 (2.0455e-01)\tAcc@1  90.62 ( 94.41)\tAcc@5  96.09 ( 99.18)\n","Epoch: [99][120/391]\tTime  0.170 ( 0.171)\tLoss 2.8938e-01 (2.1115e-01)\tAcc@1  92.97 ( 94.20)\tAcc@5  97.66 ( 99.10)\n","Epoch: [99][150/391]\tTime  0.168 ( 0.171)\tLoss 2.3899e-01 (2.1039e-01)\tAcc@1  93.75 ( 94.27)\tAcc@5 100.00 ( 99.12)\n","Epoch: [99][180/391]\tTime  0.169 ( 0.170)\tLoss 2.3537e-01 (2.1289e-01)\tAcc@1  92.97 ( 94.20)\tAcc@5  98.44 ( 99.06)\n","Epoch: [99][210/391]\tTime  0.172 ( 0.170)\tLoss 2.2158e-01 (2.1268e-01)\tAcc@1  93.75 ( 94.15)\tAcc@5  99.22 ( 99.07)\n","Epoch: [99][240/391]\tTime  0.170 ( 0.170)\tLoss 3.0651e-01 (2.1418e-01)\tAcc@1  91.41 ( 94.12)\tAcc@5  98.44 ( 99.05)\n","Epoch: [99][270/391]\tTime  0.171 ( 0.170)\tLoss 1.8092e-01 (2.1518e-01)\tAcc@1  95.31 ( 94.09)\tAcc@5  99.22 ( 99.03)\n","Epoch: [99][300/391]\tTime  0.169 ( 0.170)\tLoss 2.5752e-01 (2.1604e-01)\tAcc@1  92.19 ( 94.04)\tAcc@5  97.66 ( 99.02)\n","Epoch: [99][330/391]\tTime  0.170 ( 0.170)\tLoss 2.0928e-01 (2.1497e-01)\tAcc@1  94.53 ( 94.04)\tAcc@5  99.22 ( 99.04)\n","Epoch: [99][360/391]\tTime  0.168 ( 0.170)\tLoss 1.6124e-01 (2.1564e-01)\tAcc@1  97.66 ( 94.04)\tAcc@5 100.00 ( 99.03)\n","Epoch: [99][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3971e-01 (2.1578e-01)\tAcc@1  97.50 ( 94.02)\tAcc@5 100.00 ( 99.04)\n","==> Train Accuracy: Acc@1 94.018 || Acc@5 99.038\n","==> Test Accuracy:  Acc@1 77.610 || Acc@5 94.450\n","==> 70.69 seconds to train this epoch\n","\n","\n","----- epoch: 100, lr: 0.004000000000000001 -----\n","Epoch: [100][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.6399e-01 (1.6399e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [100][ 30/391]\tTime  0.171 ( 0.172)\tLoss 2.7387e-01 (2.0447e-01)\tAcc@1  93.75 ( 94.18)\tAcc@5  98.44 ( 99.14)\n","Epoch: [100][ 60/391]\tTime  0.171 ( 0.171)\tLoss 2.1507e-01 (2.0841e-01)\tAcc@1  94.53 ( 94.15)\tAcc@5  97.66 ( 99.15)\n","Epoch: [100][ 90/391]\tTime  0.169 ( 0.171)\tLoss 2.5554e-01 (2.0719e-01)\tAcc@1  94.53 ( 94.34)\tAcc@5  98.44 ( 99.13)\n","Epoch: [100][120/391]\tTime  0.169 ( 0.170)\tLoss 2.0471e-01 (2.0986e-01)\tAcc@1  95.31 ( 94.29)\tAcc@5  98.44 ( 99.13)\n","Epoch: [100][150/391]\tTime  0.170 ( 0.170)\tLoss 1.9930e-01 (2.1072e-01)\tAcc@1  92.97 ( 94.29)\tAcc@5 100.00 ( 99.05)\n","Epoch: [100][180/391]\tTime  0.169 ( 0.170)\tLoss 4.1573e-01 (2.1548e-01)\tAcc@1  87.50 ( 94.17)\tAcc@5  95.31 ( 98.99)\n","Epoch: [100][210/391]\tTime  0.170 ( 0.170)\tLoss 1.9078e-01 (2.1266e-01)\tAcc@1  96.88 ( 94.25)\tAcc@5  99.22 ( 99.03)\n","Epoch: [100][240/391]\tTime  0.170 ( 0.170)\tLoss 1.6793e-01 (2.1241e-01)\tAcc@1  95.31 ( 94.25)\tAcc@5 100.00 ( 99.05)\n","Epoch: [100][270/391]\tTime  0.171 ( 0.170)\tLoss 2.1811e-01 (2.1141e-01)\tAcc@1  92.19 ( 94.30)\tAcc@5  99.22 ( 99.07)\n","Epoch: [100][300/391]\tTime  0.170 ( 0.170)\tLoss 1.3298e-01 (2.1073e-01)\tAcc@1  96.88 ( 94.28)\tAcc@5 100.00 ( 99.06)\n","Epoch: [100][330/391]\tTime  0.167 ( 0.170)\tLoss 2.3714e-01 (2.0974e-01)\tAcc@1  91.41 ( 94.29)\tAcc@5  97.66 ( 99.06)\n","Epoch: [100][360/391]\tTime  0.170 ( 0.170)\tLoss 1.1662e-01 (2.1002e-01)\tAcc@1  96.09 ( 94.28)\tAcc@5 100.00 ( 99.06)\n","Epoch: [100][390/391]\tTime  0.153 ( 0.170)\tLoss 2.1353e-01 (2.0987e-01)\tAcc@1  95.00 ( 94.26)\tAcc@5 100.00 ( 99.07)\n","==> Train Accuracy: Acc@1 94.262 || Acc@5 99.070\n","==> Test Accuracy:  Acc@1 77.960 || Acc@5 94.570\n","==> 70.61 seconds to train this epoch\n","\n","\n","----- epoch: 101, lr: 0.004000000000000001 -----\n","Epoch: [101][  0/391]\tTime  0.276 ( 0.276)\tLoss 2.4253e-01 (2.4253e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5 100.00 (100.00)\n","Epoch: [101][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.8242e-01 (2.2342e-01)\tAcc@1  92.97 ( 94.10)\tAcc@5  99.22 ( 98.87)\n","Epoch: [101][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.7361e-01 (2.0996e-01)\tAcc@1  92.97 ( 94.30)\tAcc@5  97.66 ( 99.03)\n","Epoch: [101][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.6094e-01 (2.1669e-01)\tAcc@1  92.97 ( 94.13)\tAcc@5  98.44 ( 98.94)\n","Epoch: [101][120/391]\tTime  0.171 ( 0.171)\tLoss 1.8121e-01 (2.1359e-01)\tAcc@1  97.66 ( 94.28)\tAcc@5  99.22 ( 98.93)\n","Epoch: [101][150/391]\tTime  0.169 ( 0.170)\tLoss 1.3697e-01 (2.1618e-01)\tAcc@1  96.09 ( 94.18)\tAcc@5 100.00 ( 98.92)\n","Epoch: [101][180/391]\tTime  0.169 ( 0.170)\tLoss 1.5333e-01 (2.1322e-01)\tAcc@1  96.09 ( 94.23)\tAcc@5  98.44 ( 98.94)\n","Epoch: [101][210/391]\tTime  0.169 ( 0.170)\tLoss 2.6774e-01 (2.1552e-01)\tAcc@1  89.84 ( 94.15)\tAcc@5  97.66 ( 98.92)\n","Epoch: [101][240/391]\tTime  0.170 ( 0.170)\tLoss 4.2189e-01 (2.1686e-01)\tAcc@1  90.62 ( 94.13)\tAcc@5  96.88 ( 98.88)\n","Epoch: [101][270/391]\tTime  0.170 ( 0.170)\tLoss 2.2671e-01 (2.1693e-01)\tAcc@1  95.31 ( 94.14)\tAcc@5  97.66 ( 98.90)\n","Epoch: [101][300/391]\tTime  0.170 ( 0.170)\tLoss 1.4339e-01 (2.1739e-01)\tAcc@1  96.09 ( 94.10)\tAcc@5  99.22 ( 98.89)\n","Epoch: [101][330/391]\tTime  0.170 ( 0.170)\tLoss 1.6410e-01 (2.1705e-01)\tAcc@1  97.66 ( 94.09)\tAcc@5  99.22 ( 98.90)\n","Epoch: [101][360/391]\tTime  0.172 ( 0.170)\tLoss 1.9163e-01 (2.1634e-01)\tAcc@1  94.53 ( 94.10)\tAcc@5  99.22 ( 98.91)\n","Epoch: [101][390/391]\tTime  0.155 ( 0.170)\tLoss 1.7124e-01 (2.1605e-01)\tAcc@1  96.25 ( 94.10)\tAcc@5  98.75 ( 98.92)\n","==> Train Accuracy: Acc@1 94.096 || Acc@5 98.922\n","==> Test Accuracy:  Acc@1 78.020 || Acc@5 94.680\n","==> 70.65 seconds to train this epoch\n","\n","\n","----- epoch: 102, lr: 0.004000000000000001 -----\n","Epoch: [102][  0/391]\tTime  0.295 ( 0.295)\tLoss 2.2507e-01 (2.2507e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  98.44 ( 98.44)\n","Epoch: [102][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.2778e-01 (1.8500e-01)\tAcc@1  96.09 ( 94.98)\tAcc@5 100.00 ( 99.40)\n","Epoch: [102][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.0075e-01 (1.9183e-01)\tAcc@1  95.31 ( 94.79)\tAcc@5  98.44 ( 99.31)\n","Epoch: [102][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.7326e-01 (1.9626e-01)\tAcc@1  95.31 ( 94.63)\tAcc@5 100.00 ( 99.28)\n","Epoch: [102][120/391]\tTime  0.171 ( 0.171)\tLoss 2.0956e-01 (1.9740e-01)\tAcc@1  95.31 ( 94.65)\tAcc@5  98.44 ( 99.21)\n","Epoch: [102][150/391]\tTime  0.169 ( 0.170)\tLoss 1.6967e-01 (1.9782e-01)\tAcc@1  96.09 ( 94.61)\tAcc@5 100.00 ( 99.21)\n","Epoch: [102][180/391]\tTime  0.170 ( 0.170)\tLoss 3.7301e-01 (1.9903e-01)\tAcc@1  90.62 ( 94.57)\tAcc@5  96.88 ( 99.17)\n","Epoch: [102][210/391]\tTime  0.170 ( 0.170)\tLoss 1.2915e-01 (2.0054e-01)\tAcc@1  96.88 ( 94.50)\tAcc@5  99.22 ( 99.15)\n","Epoch: [102][240/391]\tTime  0.170 ( 0.170)\tLoss 1.4888e-01 (2.0239e-01)\tAcc@1  95.31 ( 94.44)\tAcc@5  98.44 ( 99.12)\n","Epoch: [102][270/391]\tTime  0.170 ( 0.170)\tLoss 1.5456e-01 (2.0386e-01)\tAcc@1  96.88 ( 94.41)\tAcc@5  99.22 ( 99.10)\n","Epoch: [102][300/391]\tTime  0.168 ( 0.170)\tLoss 1.1932e-01 (2.0300e-01)\tAcc@1  97.66 ( 94.40)\tAcc@5  99.22 ( 99.10)\n","Epoch: [102][330/391]\tTime  0.170 ( 0.170)\tLoss 2.8263e-01 (2.0360e-01)\tAcc@1  92.19 ( 94.40)\tAcc@5  98.44 ( 99.11)\n","Epoch: [102][360/391]\tTime  0.169 ( 0.170)\tLoss 2.8873e-01 (2.0439e-01)\tAcc@1  92.97 ( 94.37)\tAcc@5  98.44 ( 99.09)\n","Epoch: [102][390/391]\tTime  0.154 ( 0.170)\tLoss 2.6412e-01 (2.0443e-01)\tAcc@1  91.25 ( 94.34)\tAcc@5  98.75 ( 99.09)\n","==> Train Accuracy: Acc@1 94.344 || Acc@5 99.092\n","==> Test Accuracy:  Acc@1 78.030 || Acc@5 94.620\n","==> 70.64 seconds to train this epoch\n","\n","\n","----- epoch: 103, lr: 0.004000000000000001 -----\n","Epoch: [103][  0/391]\tTime  0.288 ( 0.288)\tLoss 2.4126e-01 (2.4126e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  97.66 ( 97.66)\n","Epoch: [103][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.1670e-01 (2.0032e-01)\tAcc@1  96.88 ( 94.41)\tAcc@5  99.22 ( 99.04)\n","Epoch: [103][ 60/391]\tTime  0.169 ( 0.172)\tLoss 8.8003e-02 (2.0220e-01)\tAcc@1  98.44 ( 94.57)\tAcc@5 100.00 ( 99.13)\n","Epoch: [103][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.2180e-01 (1.9965e-01)\tAcc@1  93.75 ( 94.67)\tAcc@5  98.44 ( 99.13)\n","Epoch: [103][120/391]\tTime  0.171 ( 0.171)\tLoss 1.5884e-01 (1.9914e-01)\tAcc@1  96.09 ( 94.64)\tAcc@5  99.22 ( 99.13)\n","Epoch: [103][150/391]\tTime  0.170 ( 0.171)\tLoss 1.7005e-01 (2.0040e-01)\tAcc@1  96.09 ( 94.60)\tAcc@5  99.22 ( 99.12)\n","Epoch: [103][180/391]\tTime  0.170 ( 0.171)\tLoss 2.5789e-01 (2.0412e-01)\tAcc@1  92.97 ( 94.50)\tAcc@5 100.00 ( 99.10)\n","Epoch: [103][210/391]\tTime  0.170 ( 0.171)\tLoss 3.5288e-01 (2.0550e-01)\tAcc@1  88.28 ( 94.39)\tAcc@5  97.66 ( 99.08)\n","Epoch: [103][240/391]\tTime  0.171 ( 0.170)\tLoss 1.1237e-01 (2.0392e-01)\tAcc@1  96.88 ( 94.40)\tAcc@5 100.00 ( 99.10)\n","Epoch: [103][270/391]\tTime  0.170 ( 0.170)\tLoss 2.9004e-01 (2.0520e-01)\tAcc@1  92.19 ( 94.39)\tAcc@5  97.66 ( 99.06)\n","Epoch: [103][300/391]\tTime  0.170 ( 0.170)\tLoss 2.7011e-01 (2.0726e-01)\tAcc@1  89.06 ( 94.29)\tAcc@5  99.22 ( 99.05)\n","Epoch: [103][330/391]\tTime  0.169 ( 0.170)\tLoss 2.4398e-01 (2.0649e-01)\tAcc@1  94.53 ( 94.28)\tAcc@5  99.22 ( 99.07)\n","Epoch: [103][360/391]\tTime  0.170 ( 0.170)\tLoss 2.9396e-01 (2.0686e-01)\tAcc@1  92.19 ( 94.28)\tAcc@5  96.88 ( 99.07)\n","Epoch: [103][390/391]\tTime  0.151 ( 0.170)\tLoss 1.7043e-01 (2.0720e-01)\tAcc@1  95.00 ( 94.26)\tAcc@5  98.75 ( 99.07)\n","==> Train Accuracy: Acc@1 94.264 || Acc@5 99.068\n","==> Test Accuracy:  Acc@1 78.150 || Acc@5 94.470\n","==> 70.67 seconds to train this epoch\n","\n","\n","----- epoch: 104, lr: 0.004000000000000001 -----\n","Epoch: [104][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.7430e-01 (1.7430e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [104][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.8201e-01 (1.8924e-01)\tAcc@1  93.75 ( 94.63)\tAcc@5 100.00 ( 99.42)\n","Epoch: [104][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.6358e-01 (1.9020e-01)\tAcc@1  96.09 ( 94.66)\tAcc@5  99.22 ( 99.33)\n","Epoch: [104][ 90/391]\tTime  0.172 ( 0.171)\tLoss 2.0324e-01 (1.9340e-01)\tAcc@1  93.75 ( 94.52)\tAcc@5  99.22 ( 99.30)\n","Epoch: [104][120/391]\tTime  0.171 ( 0.171)\tLoss 1.4637e-01 (1.9650e-01)\tAcc@1  92.97 ( 94.44)\tAcc@5 100.00 ( 99.25)\n","Epoch: [104][150/391]\tTime  0.171 ( 0.171)\tLoss 1.3006e-01 (1.9410e-01)\tAcc@1  96.09 ( 94.56)\tAcc@5 100.00 ( 99.28)\n","Epoch: [104][180/391]\tTime  0.171 ( 0.171)\tLoss 1.8541e-01 (1.9460e-01)\tAcc@1  94.53 ( 94.60)\tAcc@5  99.22 ( 99.26)\n","Epoch: [104][210/391]\tTime  0.170 ( 0.171)\tLoss 1.3937e-01 (1.9439e-01)\tAcc@1  94.53 ( 94.62)\tAcc@5  99.22 ( 99.22)\n","Epoch: [104][240/391]\tTime  0.168 ( 0.171)\tLoss 2.3372e-01 (1.9453e-01)\tAcc@1  91.41 ( 94.65)\tAcc@5  99.22 ( 99.21)\n","Epoch: [104][270/391]\tTime  0.170 ( 0.171)\tLoss 1.3877e-01 (1.9598e-01)\tAcc@1  96.88 ( 94.60)\tAcc@5  99.22 ( 99.23)\n","Epoch: [104][300/391]\tTime  0.169 ( 0.170)\tLoss 2.3195e-01 (1.9636e-01)\tAcc@1  95.31 ( 94.59)\tAcc@5  99.22 ( 99.22)\n","Epoch: [104][330/391]\tTime  0.169 ( 0.170)\tLoss 1.1235e-01 (1.9652e-01)\tAcc@1  98.44 ( 94.60)\tAcc@5  99.22 ( 99.21)\n","Epoch: [104][360/391]\tTime  0.170 ( 0.170)\tLoss 2.2141e-01 (1.9749e-01)\tAcc@1  95.31 ( 94.56)\tAcc@5  98.44 ( 99.19)\n","Epoch: [104][390/391]\tTime  0.158 ( 0.170)\tLoss 8.9339e-02 (1.9701e-01)\tAcc@1  96.25 ( 94.56)\tAcc@5 100.00 ( 99.21)\n","==> Train Accuracy: Acc@1 94.562 || Acc@5 99.206\n","==> Test Accuracy:  Acc@1 77.820 || Acc@5 94.360\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 105, lr: 0.004000000000000001 -----\n","Epoch: [105][  0/391]\tTime  0.283 ( 0.283)\tLoss 2.4204e-01 (2.4204e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n","Epoch: [105][ 30/391]\tTime  0.169 ( 0.173)\tLoss 3.2021e-01 (2.0646e-01)\tAcc@1  94.53 ( 94.38)\tAcc@5  97.66 ( 99.24)\n","Epoch: [105][ 60/391]\tTime  0.177 ( 0.172)\tLoss 1.8060e-01 (1.9936e-01)\tAcc@1  95.31 ( 94.65)\tAcc@5  99.22 ( 99.24)\n","Epoch: [105][ 90/391]\tTime  0.172 ( 0.171)\tLoss 2.5461e-01 (2.0851e-01)\tAcc@1  93.75 ( 94.28)\tAcc@5  99.22 ( 99.22)\n","Epoch: [105][120/391]\tTime  0.171 ( 0.171)\tLoss 2.2126e-01 (2.0519e-01)\tAcc@1  92.97 ( 94.40)\tAcc@5  99.22 ( 99.17)\n","Epoch: [105][150/391]\tTime  0.170 ( 0.171)\tLoss 7.5861e-02 (2.0285e-01)\tAcc@1  98.44 ( 94.48)\tAcc@5 100.00 ( 99.17)\n","Epoch: [105][180/391]\tTime  0.170 ( 0.171)\tLoss 1.9012e-01 (2.0342e-01)\tAcc@1  92.19 ( 94.44)\tAcc@5  99.22 ( 99.17)\n","Epoch: [105][210/391]\tTime  0.168 ( 0.171)\tLoss 2.0095e-01 (2.0555e-01)\tAcc@1  94.53 ( 94.42)\tAcc@5  99.22 ( 99.15)\n","Epoch: [105][240/391]\tTime  0.170 ( 0.171)\tLoss 1.6634e-01 (2.0391e-01)\tAcc@1  93.75 ( 94.46)\tAcc@5 100.00 ( 99.17)\n","Epoch: [105][270/391]\tTime  0.171 ( 0.171)\tLoss 1.9271e-01 (2.0520e-01)\tAcc@1  96.09 ( 94.46)\tAcc@5 100.00 ( 99.16)\n","Epoch: [105][300/391]\tTime  0.170 ( 0.171)\tLoss 2.7231e-01 (2.0613e-01)\tAcc@1  93.75 ( 94.41)\tAcc@5  98.44 ( 99.18)\n","Epoch: [105][330/391]\tTime  0.170 ( 0.171)\tLoss 1.5429e-01 (2.0594e-01)\tAcc@1  95.31 ( 94.38)\tAcc@5  99.22 ( 99.18)\n","Epoch: [105][360/391]\tTime  0.171 ( 0.171)\tLoss 1.3411e-01 (2.0599e-01)\tAcc@1  96.88 ( 94.35)\tAcc@5  99.22 ( 99.19)\n","Epoch: [105][390/391]\tTime  0.153 ( 0.170)\tLoss 1.2772e-01 (2.0644e-01)\tAcc@1  96.25 ( 94.33)\tAcc@5 100.00 ( 99.18)\n","==> Train Accuracy: Acc@1 94.332 || Acc@5 99.184\n","==> Test Accuracy:  Acc@1 78.220 || Acc@5 94.110\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 106, lr: 0.004000000000000001 -----\n","Epoch: [106][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.3883e-01 (1.3883e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [106][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.4388e-01 (1.7249e-01)\tAcc@1  93.75 ( 95.21)\tAcc@5  98.44 ( 99.22)\n","Epoch: [106][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.5807e-01 (1.7682e-01)\tAcc@1  95.31 ( 94.80)\tAcc@5  99.22 ( 99.30)\n","Epoch: [106][ 90/391]\tTime  0.169 ( 0.171)\tLoss 2.2677e-01 (1.8496e-01)\tAcc@1  94.53 ( 94.63)\tAcc@5  99.22 ( 99.25)\n","Epoch: [106][120/391]\tTime  0.171 ( 0.171)\tLoss 3.0296e-01 (1.9139e-01)\tAcc@1  91.41 ( 94.49)\tAcc@5  99.22 ( 99.24)\n","Epoch: [106][150/391]\tTime  0.170 ( 0.171)\tLoss 1.2843e-01 (1.8976e-01)\tAcc@1  94.53 ( 94.63)\tAcc@5  99.22 ( 99.26)\n","Epoch: [106][180/391]\tTime  0.169 ( 0.171)\tLoss 8.7425e-02 (1.9270e-01)\tAcc@1  96.88 ( 94.49)\tAcc@5 100.00 ( 99.22)\n","Epoch: [106][210/391]\tTime  0.171 ( 0.171)\tLoss 1.8439e-01 (1.9367e-01)\tAcc@1  95.31 ( 94.49)\tAcc@5  99.22 ( 99.20)\n","Epoch: [106][240/391]\tTime  0.170 ( 0.171)\tLoss 1.2369e-01 (1.9245e-01)\tAcc@1  96.88 ( 94.55)\tAcc@5 100.00 ( 99.23)\n","Epoch: [106][270/391]\tTime  0.170 ( 0.170)\tLoss 1.2637e-01 (1.9291e-01)\tAcc@1  96.09 ( 94.59)\tAcc@5 100.00 ( 99.20)\n","Epoch: [106][300/391]\tTime  0.170 ( 0.170)\tLoss 1.7544e-01 (1.9482e-01)\tAcc@1  95.31 ( 94.54)\tAcc@5  99.22 ( 99.17)\n","Epoch: [106][330/391]\tTime  0.170 ( 0.170)\tLoss 1.8784e-01 (1.9630e-01)\tAcc@1  95.31 ( 94.53)\tAcc@5  99.22 ( 99.15)\n","Epoch: [106][360/391]\tTime  0.170 ( 0.170)\tLoss 2.0081e-01 (1.9650e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 ( 99.15)\n","Epoch: [106][390/391]\tTime  0.154 ( 0.170)\tLoss 2.9199e-01 (1.9768e-01)\tAcc@1  92.50 ( 94.49)\tAcc@5  97.50 ( 99.14)\n","==> Train Accuracy: Acc@1 94.494 || Acc@5 99.144\n","==> Test Accuracy:  Acc@1 78.090 || Acc@5 94.340\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 107, lr: 0.004000000000000001 -----\n","Epoch: [107][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.1300e-01 (1.1300e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [107][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.8413e-01 (1.8973e-01)\tAcc@1  92.19 ( 94.83)\tAcc@5  98.44 ( 99.29)\n","Epoch: [107][ 60/391]\tTime  0.170 ( 0.171)\tLoss 3.1531e-01 (1.8963e-01)\tAcc@1  92.19 ( 94.68)\tAcc@5  99.22 ( 99.26)\n","Epoch: [107][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.1247e-01 (1.9372e-01)\tAcc@1  96.88 ( 94.58)\tAcc@5 100.00 ( 99.20)\n","Epoch: [107][120/391]\tTime  0.170 ( 0.171)\tLoss 1.8741e-01 (1.9481e-01)\tAcc@1  94.53 ( 94.62)\tAcc@5  99.22 ( 99.14)\n","Epoch: [107][150/391]\tTime  0.170 ( 0.171)\tLoss 2.1408e-01 (1.9307e-01)\tAcc@1  94.53 ( 94.61)\tAcc@5  99.22 ( 99.18)\n","Epoch: [107][180/391]\tTime  0.170 ( 0.170)\tLoss 2.2479e-01 (1.9449e-01)\tAcc@1  96.09 ( 94.57)\tAcc@5  98.44 ( 99.17)\n","Epoch: [107][210/391]\tTime  0.170 ( 0.170)\tLoss 2.3179e-01 (1.9107e-01)\tAcc@1  93.75 ( 94.69)\tAcc@5 100.00 ( 99.20)\n","Epoch: [107][240/391]\tTime  0.172 ( 0.170)\tLoss 2.0312e-01 (1.9262e-01)\tAcc@1  93.75 ( 94.66)\tAcc@5  99.22 ( 99.18)\n","Epoch: [107][270/391]\tTime  0.171 ( 0.170)\tLoss 1.5926e-01 (1.9208e-01)\tAcc@1  94.53 ( 94.70)\tAcc@5  99.22 ( 99.15)\n","Epoch: [107][300/391]\tTime  0.171 ( 0.170)\tLoss 2.0963e-01 (1.9183e-01)\tAcc@1  94.53 ( 94.67)\tAcc@5  99.22 ( 99.17)\n","Epoch: [107][330/391]\tTime  0.170 ( 0.170)\tLoss 2.1377e-01 (1.9206e-01)\tAcc@1  92.97 ( 94.68)\tAcc@5  99.22 ( 99.17)\n","Epoch: [107][360/391]\tTime  0.169 ( 0.170)\tLoss 2.2024e-01 (1.9271e-01)\tAcc@1  94.53 ( 94.68)\tAcc@5  97.66 ( 99.16)\n","Epoch: [107][390/391]\tTime  0.152 ( 0.170)\tLoss 1.1857e-01 (1.9175e-01)\tAcc@1  95.00 ( 94.70)\tAcc@5 100.00 ( 99.18)\n","==> Train Accuracy: Acc@1 94.702 || Acc@5 99.184\n","==> Test Accuracy:  Acc@1 77.910 || Acc@5 94.410\n","==> 70.72 seconds to train this epoch\n","\n","\n","----- epoch: 108, lr: 0.004000000000000001 -----\n","Epoch: [108][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.8893e-01 (1.8893e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [108][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.4269e-01 (1.9013e-01)\tAcc@1  96.88 ( 94.66)\tAcc@5 100.00 ( 99.34)\n","Epoch: [108][ 60/391]\tTime  0.177 ( 0.172)\tLoss 9.8733e-02 (1.9817e-01)\tAcc@1  97.66 ( 94.40)\tAcc@5 100.00 ( 99.21)\n","Epoch: [108][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.5937e-01 (1.9735e-01)\tAcc@1  95.31 ( 94.54)\tAcc@5  99.22 ( 99.16)\n","Epoch: [108][120/391]\tTime  0.171 ( 0.171)\tLoss 3.2922e-01 (1.9495e-01)\tAcc@1  92.19 ( 94.57)\tAcc@5  99.22 ( 99.19)\n","Epoch: [108][150/391]\tTime  0.169 ( 0.171)\tLoss 2.5345e-01 (1.9725e-01)\tAcc@1  92.97 ( 94.55)\tAcc@5  96.88 ( 99.14)\n","Epoch: [108][180/391]\tTime  0.171 ( 0.171)\tLoss 2.3838e-01 (1.9836e-01)\tAcc@1  96.09 ( 94.51)\tAcc@5  97.66 ( 99.11)\n","Epoch: [108][210/391]\tTime  0.170 ( 0.171)\tLoss 1.6528e-01 (2.0042e-01)\tAcc@1  96.88 ( 94.49)\tAcc@5  99.22 ( 99.07)\n","Epoch: [108][240/391]\tTime  0.169 ( 0.170)\tLoss 1.2997e-01 (2.0110e-01)\tAcc@1  96.09 ( 94.47)\tAcc@5 100.00 ( 99.10)\n","Epoch: [108][270/391]\tTime  0.171 ( 0.170)\tLoss 2.3805e-01 (2.0111e-01)\tAcc@1  94.53 ( 94.48)\tAcc@5  97.66 ( 99.10)\n","Epoch: [108][300/391]\tTime  0.170 ( 0.170)\tLoss 1.8200e-01 (2.0038e-01)\tAcc@1  92.97 ( 94.52)\tAcc@5 100.00 ( 99.11)\n","Epoch: [108][330/391]\tTime  0.170 ( 0.170)\tLoss 2.8088e-01 (1.9842e-01)\tAcc@1  92.19 ( 94.56)\tAcc@5  98.44 ( 99.11)\n","Epoch: [108][360/391]\tTime  0.170 ( 0.170)\tLoss 2.3091e-01 (1.9943e-01)\tAcc@1  92.19 ( 94.52)\tAcc@5 100.00 ( 99.10)\n","Epoch: [108][390/391]\tTime  0.152 ( 0.170)\tLoss 1.8690e-01 (1.9861e-01)\tAcc@1  95.00 ( 94.55)\tAcc@5 100.00 ( 99.12)\n","==> Train Accuracy: Acc@1 94.554 || Acc@5 99.116\n","==> Test Accuracy:  Acc@1 77.710 || Acc@5 94.250\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 109, lr: 0.004000000000000001 -----\n","Epoch: [109][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.9902e-01 (1.9902e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n","Epoch: [109][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.6462e-01 (1.8959e-01)\tAcc@1  96.09 ( 95.01)\tAcc@5  99.22 ( 99.14)\n","Epoch: [109][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.2125e-01 (1.8889e-01)\tAcc@1  92.19 ( 94.89)\tAcc@5  99.22 ( 99.17)\n","Epoch: [109][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.1852e-01 (1.8472e-01)\tAcc@1  97.66 ( 94.95)\tAcc@5 100.00 ( 99.18)\n","Epoch: [109][120/391]\tTime  0.170 ( 0.171)\tLoss 1.9503e-01 (1.8109e-01)\tAcc@1  94.53 ( 95.02)\tAcc@5 100.00 ( 99.22)\n","Epoch: [109][150/391]\tTime  0.170 ( 0.170)\tLoss 9.4775e-02 (1.8337e-01)\tAcc@1  96.88 ( 94.92)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][180/391]\tTime  0.170 ( 0.170)\tLoss 2.1968e-01 (1.8530e-01)\tAcc@1  94.53 ( 94.90)\tAcc@5 100.00 ( 99.21)\n","Epoch: [109][210/391]\tTime  0.169 ( 0.170)\tLoss 1.7835e-01 (1.8796e-01)\tAcc@1  94.53 ( 94.82)\tAcc@5  99.22 ( 99.22)\n","Epoch: [109][240/391]\tTime  0.169 ( 0.170)\tLoss 1.3121e-01 (1.8685e-01)\tAcc@1  98.44 ( 94.88)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][270/391]\tTime  0.170 ( 0.170)\tLoss 1.4186e-01 (1.8745e-01)\tAcc@1  96.88 ( 94.85)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][300/391]\tTime  0.171 ( 0.170)\tLoss 1.4410e-01 (1.8821e-01)\tAcc@1  95.31 ( 94.78)\tAcc@5 100.00 ( 99.23)\n","Epoch: [109][330/391]\tTime  0.168 ( 0.170)\tLoss 1.8789e-01 (1.8790e-01)\tAcc@1  93.75 ( 94.77)\tAcc@5  99.22 ( 99.24)\n","Epoch: [109][360/391]\tTime  0.170 ( 0.170)\tLoss 2.3245e-01 (1.8899e-01)\tAcc@1  92.97 ( 94.75)\tAcc@5  99.22 ( 99.23)\n","Epoch: [109][390/391]\tTime  0.152 ( 0.170)\tLoss 2.6359e-01 (1.9025e-01)\tAcc@1  95.00 ( 94.70)\tAcc@5  98.75 ( 99.23)\n","==> Train Accuracy: Acc@1 94.696 || Acc@5 99.228\n","==> Test Accuracy:  Acc@1 78.320 || Acc@5 94.560\n","==> 70.66 seconds to train this epoch\n","\n","\n","----- epoch: 110, lr: 0.004000000000000001 -----\n","Epoch: [110][  0/391]\tTime  0.301 ( 0.301)\tLoss 2.1901e-01 (2.1901e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n","Epoch: [110][ 30/391]\tTime  0.165 ( 0.173)\tLoss 1.4132e-01 (1.7626e-01)\tAcc@1  95.31 ( 95.39)\tAcc@5 100.00 ( 99.17)\n","Epoch: [110][ 60/391]\tTime  0.168 ( 0.172)\tLoss 2.4519e-01 (1.8351e-01)\tAcc@1  92.19 ( 95.11)\tAcc@5  97.66 ( 99.03)\n","Epoch: [110][ 90/391]\tTime  0.168 ( 0.171)\tLoss 1.8811e-01 (1.8645e-01)\tAcc@1  94.53 ( 94.96)\tAcc@5  99.22 ( 99.05)\n","Epoch: [110][120/391]\tTime  0.170 ( 0.171)\tLoss 2.5938e-01 (1.8937e-01)\tAcc@1  94.53 ( 94.97)\tAcc@5  97.66 ( 99.04)\n","Epoch: [110][150/391]\tTime  0.169 ( 0.170)\tLoss 2.1550e-01 (1.8867e-01)\tAcc@1  93.75 ( 94.97)\tAcc@5  98.44 ( 99.06)\n","Epoch: [110][180/391]\tTime  0.169 ( 0.170)\tLoss 1.6524e-01 (1.9092e-01)\tAcc@1  92.97 ( 94.92)\tAcc@5 100.00 ( 99.07)\n","Epoch: [110][210/391]\tTime  0.170 ( 0.170)\tLoss 1.9913e-01 (1.9368e-01)\tAcc@1  95.31 ( 94.78)\tAcc@5  99.22 ( 99.09)\n","Epoch: [110][240/391]\tTime  0.168 ( 0.170)\tLoss 1.8877e-01 (1.9137e-01)\tAcc@1  94.53 ( 94.85)\tAcc@5  99.22 ( 99.12)\n","Epoch: [110][270/391]\tTime  0.170 ( 0.170)\tLoss 1.6876e-01 (1.9257e-01)\tAcc@1  95.31 ( 94.77)\tAcc@5  99.22 ( 99.11)\n","Epoch: [110][300/391]\tTime  0.171 ( 0.170)\tLoss 1.6794e-01 (1.9208e-01)\tAcc@1  93.75 ( 94.75)\tAcc@5 100.00 ( 99.11)\n","Epoch: [110][330/391]\tTime  0.170 ( 0.170)\tLoss 1.2650e-01 (1.9465e-01)\tAcc@1  96.88 ( 94.67)\tAcc@5 100.00 ( 99.11)\n","Epoch: [110][360/391]\tTime  0.169 ( 0.170)\tLoss 2.7255e-01 (1.9417e-01)\tAcc@1  92.19 ( 94.69)\tAcc@5  97.66 ( 99.11)\n","Epoch: [110][390/391]\tTime  0.154 ( 0.170)\tLoss 1.3829e-01 (1.9375e-01)\tAcc@1  96.25 ( 94.68)\tAcc@5 100.00 ( 99.14)\n","==> Train Accuracy: Acc@1 94.682 || Acc@5 99.142\n","==> Test Accuracy:  Acc@1 77.840 || Acc@5 94.400\n","==> 70.65 seconds to train this epoch\n","\n","\n","----- epoch: 111, lr: 0.004000000000000001 -----\n","Epoch: [111][  0/391]\tTime  0.287 ( 0.287)\tLoss 2.0791e-01 (2.0791e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [111][ 30/391]\tTime  0.171 ( 0.174)\tLoss 1.7843e-01 (1.9057e-01)\tAcc@1  96.88 ( 95.19)\tAcc@5  98.44 ( 98.92)\n","Epoch: [111][ 60/391]\tTime  0.169 ( 0.172)\tLoss 2.8384e-01 (1.9878e-01)\tAcc@1  92.19 ( 94.75)\tAcc@5  99.22 ( 99.00)\n","Epoch: [111][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.0091e-01 (1.9958e-01)\tAcc@1  95.31 ( 94.69)\tAcc@5  99.22 ( 99.01)\n","Epoch: [111][120/391]\tTime  0.170 ( 0.171)\tLoss 2.3751e-01 (1.9448e-01)\tAcc@1  94.53 ( 94.80)\tAcc@5  98.44 ( 99.08)\n","Epoch: [111][150/391]\tTime  0.170 ( 0.171)\tLoss 1.3129e-01 (1.9504e-01)\tAcc@1  96.09 ( 94.74)\tAcc@5  99.22 ( 99.10)\n","Epoch: [111][180/391]\tTime  0.170 ( 0.171)\tLoss 2.5541e-01 (1.9374e-01)\tAcc@1  93.75 ( 94.74)\tAcc@5 100.00 ( 99.14)\n","Epoch: [111][210/391]\tTime  0.171 ( 0.171)\tLoss 2.5487e-01 (1.9127e-01)\tAcc@1  92.19 ( 94.81)\tAcc@5  98.44 ( 99.20)\n","Epoch: [111][240/391]\tTime  0.170 ( 0.171)\tLoss 1.3059e-01 (1.9202e-01)\tAcc@1  96.09 ( 94.79)\tAcc@5 100.00 ( 99.21)\n","Epoch: [111][270/391]\tTime  0.172 ( 0.171)\tLoss 2.5466e-01 (1.9151e-01)\tAcc@1  91.41 ( 94.75)\tAcc@5 100.00 ( 99.23)\n","Epoch: [111][300/391]\tTime  0.171 ( 0.171)\tLoss 1.4869e-01 (1.9040e-01)\tAcc@1  96.88 ( 94.81)\tAcc@5 100.00 ( 99.24)\n","Epoch: [111][330/391]\tTime  0.168 ( 0.170)\tLoss 1.7096e-01 (1.9173e-01)\tAcc@1  96.09 ( 94.76)\tAcc@5  98.44 ( 99.23)\n","Epoch: [111][360/391]\tTime  0.169 ( 0.170)\tLoss 2.3007e-01 (1.9181e-01)\tAcc@1  92.97 ( 94.74)\tAcc@5  98.44 ( 99.23)\n","Epoch: [111][390/391]\tTime  0.152 ( 0.170)\tLoss 2.9899e-01 (1.9321e-01)\tAcc@1  91.25 ( 94.71)\tAcc@5  98.75 ( 99.22)\n","==> Train Accuracy: Acc@1 94.706 || Acc@5 99.222\n","==> Test Accuracy:  Acc@1 78.030 || Acc@5 94.280\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 112, lr: 0.004000000000000001 -----\n","Epoch: [112][  0/391]\tTime  0.287 ( 0.287)\tLoss 2.1711e-01 (2.1711e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [112][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.1589e-01 (1.8224e-01)\tAcc@1  93.75 ( 94.96)\tAcc@5  98.44 ( 99.37)\n","Epoch: [112][ 60/391]\tTime  0.168 ( 0.171)\tLoss 1.5388e-01 (1.8699e-01)\tAcc@1  95.31 ( 94.97)\tAcc@5 100.00 ( 99.24)\n","Epoch: [112][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.7395e-01 (1.9005e-01)\tAcc@1  95.31 ( 94.82)\tAcc@5  98.44 ( 99.16)\n","Epoch: [112][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4829e-01 (1.8667e-01)\tAcc@1  96.09 ( 94.94)\tAcc@5 100.00 ( 99.23)\n","Epoch: [112][150/391]\tTime  0.170 ( 0.170)\tLoss 2.2012e-01 (1.8599e-01)\tAcc@1  95.31 ( 94.92)\tAcc@5  99.22 ( 99.24)\n","Epoch: [112][180/391]\tTime  0.170 ( 0.170)\tLoss 1.2088e-01 (1.8423e-01)\tAcc@1  96.09 ( 94.94)\tAcc@5 100.00 ( 99.27)\n","Epoch: [112][210/391]\tTime  0.170 ( 0.170)\tLoss 1.0645e-01 (1.8326e-01)\tAcc@1  96.88 ( 94.99)\tAcc@5  99.22 ( 99.26)\n","Epoch: [112][240/391]\tTime  0.170 ( 0.170)\tLoss 9.9075e-02 (1.8402e-01)\tAcc@1  96.09 ( 94.96)\tAcc@5 100.00 ( 99.27)\n","Epoch: [112][270/391]\tTime  0.171 ( 0.170)\tLoss 2.5503e-01 (1.8379e-01)\tAcc@1  92.97 ( 94.96)\tAcc@5  99.22 ( 99.28)\n","Epoch: [112][300/391]\tTime  0.170 ( 0.170)\tLoss 1.2774e-01 (1.8519e-01)\tAcc@1  96.88 ( 94.91)\tAcc@5  99.22 ( 99.26)\n","Epoch: [112][330/391]\tTime  0.170 ( 0.170)\tLoss 9.3909e-02 (1.8530e-01)\tAcc@1  97.66 ( 94.92)\tAcc@5 100.00 ( 99.25)\n","Epoch: [112][360/391]\tTime  0.171 ( 0.170)\tLoss 1.9379e-01 (1.8541e-01)\tAcc@1  92.97 ( 94.93)\tAcc@5  99.22 ( 99.24)\n","Epoch: [112][390/391]\tTime  0.153 ( 0.170)\tLoss 1.7772e-01 (1.8551e-01)\tAcc@1  93.75 ( 94.91)\tAcc@5 100.00 ( 99.25)\n","==> Train Accuracy: Acc@1 94.914 || Acc@5 99.248\n","==> Test Accuracy:  Acc@1 77.820 || Acc@5 94.560\n","==> 70.72 seconds to train this epoch\n","\n","\n","----- epoch: 113, lr: 0.004000000000000001 -----\n","Epoch: [113][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.4583e-01 (1.4583e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [113][ 30/391]\tTime  0.169 ( 0.173)\tLoss 1.1338e-01 (1.6951e-01)\tAcc@1  98.44 ( 95.64)\tAcc@5 100.00 ( 99.32)\n","Epoch: [113][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.3255e-01 (1.6855e-01)\tAcc@1  96.88 ( 95.56)\tAcc@5  99.22 ( 99.36)\n","Epoch: [113][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.2719e-01 (1.7096e-01)\tAcc@1  92.97 ( 95.43)\tAcc@5  98.44 ( 99.35)\n","Epoch: [113][120/391]\tTime  0.171 ( 0.171)\tLoss 1.8045e-01 (1.7864e-01)\tAcc@1  97.66 ( 95.24)\tAcc@5  99.22 ( 99.26)\n","Epoch: [113][150/391]\tTime  0.170 ( 0.171)\tLoss 2.2683e-01 (1.8347e-01)\tAcc@1  91.41 ( 95.07)\tAcc@5  99.22 ( 99.22)\n","Epoch: [113][180/391]\tTime  0.169 ( 0.171)\tLoss 1.5780e-01 (1.8451e-01)\tAcc@1  96.09 ( 95.06)\tAcc@5  99.22 ( 99.21)\n","Epoch: [113][210/391]\tTime  0.169 ( 0.170)\tLoss 2.8812e-01 (1.8542e-01)\tAcc@1  90.62 ( 94.99)\tAcc@5  97.66 ( 99.19)\n","Epoch: [113][240/391]\tTime  0.172 ( 0.170)\tLoss 1.2472e-01 (1.8544e-01)\tAcc@1  98.44 ( 94.96)\tAcc@5  99.22 ( 99.19)\n","Epoch: [113][270/391]\tTime  0.170 ( 0.170)\tLoss 1.5163e-01 (1.8785e-01)\tAcc@1  96.09 ( 94.90)\tAcc@5  99.22 ( 99.16)\n","Epoch: [113][300/391]\tTime  0.170 ( 0.170)\tLoss 1.6477e-01 (1.8813e-01)\tAcc@1  95.31 ( 94.87)\tAcc@5  99.22 ( 99.17)\n","Epoch: [113][330/391]\tTime  0.170 ( 0.170)\tLoss 1.0812e-01 (1.8931e-01)\tAcc@1  96.88 ( 94.82)\tAcc@5  99.22 ( 99.17)\n","Epoch: [113][360/391]\tTime  0.170 ( 0.170)\tLoss 1.8921e-01 (1.9031e-01)\tAcc@1  96.09 ( 94.80)\tAcc@5 100.00 ( 99.17)\n","Epoch: [113][390/391]\tTime  0.152 ( 0.170)\tLoss 2.3586e-01 (1.8953e-01)\tAcc@1  95.00 ( 94.82)\tAcc@5  98.75 ( 99.19)\n","==> Train Accuracy: Acc@1 94.820 || Acc@5 99.186\n","==> Test Accuracy:  Acc@1 77.240 || Acc@5 94.330\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 114, lr: 0.004000000000000001 -----\n","Epoch: [114][  0/391]\tTime  0.289 ( 0.289)\tLoss 2.4715e-01 (2.4715e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  98.44 ( 98.44)\n","Epoch: [114][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.7611e-01 (1.7705e-01)\tAcc@1  94.53 ( 95.04)\tAcc@5  99.22 ( 99.29)\n","Epoch: [114][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.6679e-01 (1.7402e-01)\tAcc@1  96.88 ( 95.30)\tAcc@5  99.22 ( 99.31)\n","Epoch: [114][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.6390e-01 (1.8205e-01)\tAcc@1  95.31 ( 95.00)\tAcc@5 100.00 ( 99.31)\n","Epoch: [114][120/391]\tTime  0.169 ( 0.171)\tLoss 1.8425e-01 (1.7754e-01)\tAcc@1  91.41 ( 95.06)\tAcc@5 100.00 ( 99.37)\n","Epoch: [114][150/391]\tTime  0.170 ( 0.171)\tLoss 1.9691e-01 (1.7642e-01)\tAcc@1  95.31 ( 95.07)\tAcc@5  99.22 ( 99.36)\n","Epoch: [114][180/391]\tTime  0.171 ( 0.171)\tLoss 1.8223e-01 (1.7510e-01)\tAcc@1  96.09 ( 95.12)\tAcc@5 100.00 ( 99.36)\n","Epoch: [114][210/391]\tTime  0.169 ( 0.171)\tLoss 2.1953e-01 (1.7770e-01)\tAcc@1  94.53 ( 95.06)\tAcc@5  98.44 ( 99.31)\n","Epoch: [114][240/391]\tTime  0.170 ( 0.171)\tLoss 1.7681e-01 (1.7752e-01)\tAcc@1  94.53 ( 95.06)\tAcc@5  99.22 ( 99.32)\n","Epoch: [114][270/391]\tTime  0.170 ( 0.171)\tLoss 1.9236e-01 (1.7745e-01)\tAcc@1  94.53 ( 95.11)\tAcc@5  99.22 ( 99.32)\n","Epoch: [114][300/391]\tTime  0.170 ( 0.171)\tLoss 1.6000e-01 (1.7835e-01)\tAcc@1  96.09 ( 95.10)\tAcc@5  97.66 ( 99.31)\n","Epoch: [114][330/391]\tTime  0.170 ( 0.170)\tLoss 8.0477e-02 (1.7909e-01)\tAcc@1  98.44 ( 95.07)\tAcc@5 100.00 ( 99.31)\n","Epoch: [114][360/391]\tTime  0.170 ( 0.170)\tLoss 1.9711e-01 (1.8001e-01)\tAcc@1  94.53 ( 95.05)\tAcc@5 100.00 ( 99.29)\n","Epoch: [114][390/391]\tTime  0.153 ( 0.170)\tLoss 2.1480e-01 (1.8044e-01)\tAcc@1  95.00 ( 95.03)\tAcc@5  96.25 ( 99.28)\n","==> Train Accuracy: Acc@1 95.032 || Acc@5 99.282\n","==> Test Accuracy:  Acc@1 77.950 || Acc@5 94.220\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 115, lr: 0.004000000000000001 -----\n","Epoch: [115][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.4283e-01 (1.4283e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [115][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.8559e-01 (1.7027e-01)\tAcc@1  96.88 ( 95.54)\tAcc@5  98.44 ( 99.22)\n","Epoch: [115][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.9729e-01 (1.7233e-01)\tAcc@1  94.53 ( 95.38)\tAcc@5 100.00 ( 99.23)\n","Epoch: [115][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.7443e-01 (1.7942e-01)\tAcc@1  92.97 ( 95.01)\tAcc@5  99.22 ( 99.19)\n","Epoch: [115][120/391]\tTime  0.170 ( 0.170)\tLoss 2.9139e-01 (1.8066e-01)\tAcc@1  92.19 ( 94.95)\tAcc@5  98.44 ( 99.20)\n","Epoch: [115][150/391]\tTime  0.170 ( 0.170)\tLoss 1.6972e-01 (1.8233e-01)\tAcc@1  95.31 ( 94.90)\tAcc@5 100.00 ( 99.18)\n","Epoch: [115][180/391]\tTime  0.169 ( 0.170)\tLoss 1.1772e-01 (1.8342e-01)\tAcc@1  96.88 ( 94.86)\tAcc@5 100.00 ( 99.15)\n","Epoch: [115][210/391]\tTime  0.170 ( 0.170)\tLoss 1.1511e-01 (1.8437e-01)\tAcc@1  96.88 ( 94.85)\tAcc@5 100.00 ( 99.14)\n","Epoch: [115][240/391]\tTime  0.168 ( 0.170)\tLoss 1.8682e-01 (1.8606e-01)\tAcc@1  96.09 ( 94.78)\tAcc@5  99.22 ( 99.14)\n","Epoch: [115][270/391]\tTime  0.167 ( 0.170)\tLoss 1.4711e-01 (1.8637e-01)\tAcc@1  96.09 ( 94.80)\tAcc@5 100.00 ( 99.12)\n","Epoch: [115][300/391]\tTime  0.170 ( 0.170)\tLoss 1.7968e-01 (1.8564e-01)\tAcc@1  94.53 ( 94.84)\tAcc@5  99.22 ( 99.11)\n","Epoch: [115][330/391]\tTime  0.172 ( 0.170)\tLoss 1.7988e-01 (1.8650e-01)\tAcc@1  96.09 ( 94.82)\tAcc@5  99.22 ( 99.13)\n","Epoch: [115][360/391]\tTime  0.171 ( 0.170)\tLoss 1.4292e-01 (1.8498e-01)\tAcc@1  97.66 ( 94.87)\tAcc@5  99.22 ( 99.16)\n","Epoch: [115][390/391]\tTime  0.152 ( 0.170)\tLoss 1.0606e-01 (1.8588e-01)\tAcc@1  96.25 ( 94.84)\tAcc@5 100.00 ( 99.16)\n","==> Train Accuracy: Acc@1 94.840 || Acc@5 99.162\n","==> Test Accuracy:  Acc@1 78.000 || Acc@5 94.310\n","==> 70.73 seconds to train this epoch\n","\n","\n","----- epoch: 116, lr: 0.004000000000000001 -----\n","Epoch: [116][  0/391]\tTime  0.279 ( 0.279)\tLoss 2.6889e-01 (2.6889e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  98.44 ( 98.44)\n","Epoch: [116][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.2309e-01 (1.6718e-01)\tAcc@1  96.09 ( 95.26)\tAcc@5 100.00 ( 99.27)\n","Epoch: [116][ 60/391]\tTime  0.168 ( 0.172)\tLoss 1.7276e-01 (1.6860e-01)\tAcc@1  95.31 ( 95.45)\tAcc@5  99.22 ( 99.22)\n","Epoch: [116][ 90/391]\tTime  0.168 ( 0.171)\tLoss 1.7526e-01 (1.6951e-01)\tAcc@1  94.53 ( 95.40)\tAcc@5 100.00 ( 99.28)\n","Epoch: [116][120/391]\tTime  0.169 ( 0.171)\tLoss 1.6673e-01 (1.7226e-01)\tAcc@1  95.31 ( 95.35)\tAcc@5 100.00 ( 99.25)\n","Epoch: [116][150/391]\tTime  0.170 ( 0.171)\tLoss 2.0555e-01 (1.7705e-01)\tAcc@1  95.31 ( 95.25)\tAcc@5  96.88 ( 99.17)\n","Epoch: [116][180/391]\tTime  0.169 ( 0.170)\tLoss 2.0291e-01 (1.7883e-01)\tAcc@1  93.75 ( 95.20)\tAcc@5  99.22 ( 99.21)\n","Epoch: [116][210/391]\tTime  0.171 ( 0.170)\tLoss 1.0802e-01 (1.7861e-01)\tAcc@1  97.66 ( 95.17)\tAcc@5 100.00 ( 99.20)\n","Epoch: [116][240/391]\tTime  0.169 ( 0.170)\tLoss 2.5990e-01 (1.7779e-01)\tAcc@1  92.19 ( 95.14)\tAcc@5  98.44 ( 99.21)\n","Epoch: [116][270/391]\tTime  0.170 ( 0.170)\tLoss 2.0346e-01 (1.8175e-01)\tAcc@1  94.53 ( 95.02)\tAcc@5  99.22 ( 99.18)\n","Epoch: [116][300/391]\tTime  0.170 ( 0.170)\tLoss 1.8757e-01 (1.8257e-01)\tAcc@1  93.75 ( 95.01)\tAcc@5 100.00 ( 99.20)\n","Epoch: [116][330/391]\tTime  0.170 ( 0.170)\tLoss 1.8009e-01 (1.8249e-01)\tAcc@1  95.31 ( 95.02)\tAcc@5  99.22 ( 99.20)\n","Epoch: [116][360/391]\tTime  0.169 ( 0.170)\tLoss 1.4694e-01 (1.8234e-01)\tAcc@1  96.09 ( 95.03)\tAcc@5 100.00 ( 99.20)\n","Epoch: [116][390/391]\tTime  0.152 ( 0.170)\tLoss 2.1408e-01 (1.8401e-01)\tAcc@1  95.00 ( 94.93)\tAcc@5  98.75 ( 99.20)\n","==> Train Accuracy: Acc@1 94.932 || Acc@5 99.200\n","==> Test Accuracy:  Acc@1 77.700 || Acc@5 94.210\n","==> 70.68 seconds to train this epoch\n","\n","\n","----- epoch: 117, lr: 0.004000000000000001 -----\n","Epoch: [117][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.5626e-01 (1.5626e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [117][ 30/391]\tTime  0.168 ( 0.173)\tLoss 1.1178e-01 (1.8968e-01)\tAcc@1  97.66 ( 94.86)\tAcc@5 100.00 ( 99.32)\n","Epoch: [117][ 60/391]\tTime  0.170 ( 0.171)\tLoss 2.1312e-01 (1.8007e-01)\tAcc@1  94.53 ( 95.17)\tAcc@5  98.44 ( 99.24)\n","Epoch: [117][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.7105e-01 (1.8574e-01)\tAcc@1  95.31 ( 95.00)\tAcc@5 100.00 ( 99.13)\n","Epoch: [117][120/391]\tTime  0.171 ( 0.171)\tLoss 1.6185e-01 (1.8724e-01)\tAcc@1  94.53 ( 94.93)\tAcc@5 100.00 ( 99.16)\n","Epoch: [117][150/391]\tTime  0.171 ( 0.171)\tLoss 2.0851e-01 (1.8651e-01)\tAcc@1  96.09 ( 94.89)\tAcc@5  98.44 ( 99.18)\n","Epoch: [117][180/391]\tTime  0.171 ( 0.171)\tLoss 2.0309e-01 (1.8371e-01)\tAcc@1  94.53 ( 94.99)\tAcc@5  99.22 ( 99.22)\n","Epoch: [117][210/391]\tTime  0.171 ( 0.171)\tLoss 2.2213e-01 (1.8372e-01)\tAcc@1  96.09 ( 94.98)\tAcc@5  98.44 ( 99.22)\n","Epoch: [117][240/391]\tTime  0.172 ( 0.171)\tLoss 1.2810e-01 (1.8488e-01)\tAcc@1  96.88 ( 94.92)\tAcc@5 100.00 ( 99.22)\n","Epoch: [117][270/391]\tTime  0.172 ( 0.171)\tLoss 1.4653e-01 (1.8402e-01)\tAcc@1  96.88 ( 94.94)\tAcc@5 100.00 ( 99.22)\n","Epoch: [117][300/391]\tTime  0.169 ( 0.170)\tLoss 1.2812e-01 (1.8567e-01)\tAcc@1  95.31 ( 94.89)\tAcc@5 100.00 ( 99.21)\n","Epoch: [117][330/391]\tTime  0.169 ( 0.170)\tLoss 2.7100e-01 (1.8635e-01)\tAcc@1  90.62 ( 94.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [117][360/391]\tTime  0.170 ( 0.170)\tLoss 2.0003e-01 (1.8802e-01)\tAcc@1  94.53 ( 94.86)\tAcc@5  98.44 ( 99.19)\n","Epoch: [117][390/391]\tTime  0.154 ( 0.170)\tLoss 2.3718e-01 (1.8753e-01)\tAcc@1  95.00 ( 94.86)\tAcc@5 100.00 ( 99.19)\n","==> Train Accuracy: Acc@1 94.862 || Acc@5 99.188\n","==> Test Accuracy:  Acc@1 77.840 || Acc@5 94.380\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 118, lr: 0.004000000000000001 -----\n","Epoch: [118][  0/391]\tTime  0.295 ( 0.295)\tLoss 2.3004e-01 (2.3004e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  98.44 ( 98.44)\n","Epoch: [118][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.1042e-01 (1.8213e-01)\tAcc@1  96.88 ( 95.16)\tAcc@5 100.00 ( 99.22)\n","Epoch: [118][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.7034e-01 (1.8335e-01)\tAcc@1  96.09 ( 95.15)\tAcc@5  99.22 ( 99.22)\n","Epoch: [118][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.4210e-01 (1.8109e-01)\tAcc@1  95.31 ( 95.19)\tAcc@5 100.00 ( 99.23)\n","Epoch: [118][120/391]\tTime  0.170 ( 0.171)\tLoss 1.9917e-01 (1.7807e-01)\tAcc@1  95.31 ( 95.22)\tAcc@5  99.22 ( 99.28)\n","Epoch: [118][150/391]\tTime  0.170 ( 0.171)\tLoss 1.6358e-01 (1.7929e-01)\tAcc@1  94.53 ( 95.16)\tAcc@5 100.00 ( 99.28)\n","Epoch: [118][180/391]\tTime  0.171 ( 0.171)\tLoss 1.7061e-01 (1.8120e-01)\tAcc@1  96.88 ( 95.09)\tAcc@5  98.44 ( 99.29)\n","Epoch: [118][210/391]\tTime  0.170 ( 0.170)\tLoss 1.6590e-01 (1.7990e-01)\tAcc@1  96.88 ( 95.11)\tAcc@5 100.00 ( 99.30)\n","Epoch: [118][240/391]\tTime  0.171 ( 0.170)\tLoss 1.7814e-01 (1.8156e-01)\tAcc@1  96.09 ( 95.03)\tAcc@5  99.22 ( 99.29)\n","Epoch: [118][270/391]\tTime  0.171 ( 0.170)\tLoss 8.1274e-02 (1.8284e-01)\tAcc@1  98.44 ( 94.96)\tAcc@5 100.00 ( 99.29)\n","Epoch: [118][300/391]\tTime  0.170 ( 0.170)\tLoss 2.1397e-01 (1.8265e-01)\tAcc@1  95.31 ( 94.96)\tAcc@5  98.44 ( 99.29)\n","Epoch: [118][330/391]\tTime  0.170 ( 0.170)\tLoss 2.2727e-01 (1.8456e-01)\tAcc@1  95.31 ( 94.91)\tAcc@5  99.22 ( 99.28)\n","Epoch: [118][360/391]\tTime  0.171 ( 0.170)\tLoss 1.5509e-01 (1.8375e-01)\tAcc@1  96.88 ( 94.93)\tAcc@5 100.00 ( 99.28)\n","Epoch: [118][390/391]\tTime  0.153 ( 0.170)\tLoss 2.8643e-01 (1.8332e-01)\tAcc@1  95.00 ( 94.97)\tAcc@5  98.75 ( 99.28)\n","==> Train Accuracy: Acc@1 94.970 || Acc@5 99.282\n","==> Test Accuracy:  Acc@1 77.400 || Acc@5 94.110\n","==> 70.79 seconds to train this epoch\n","\n","\n","----- epoch: 119, lr: 0.004000000000000001 -----\n","Epoch: [119][  0/391]\tTime  0.293 ( 0.293)\tLoss 1.0382e-01 (1.0382e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [119][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.3098e-01 (1.7070e-01)\tAcc@1  95.31 ( 95.19)\tAcc@5 100.00 ( 99.14)\n","Epoch: [119][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.0649e-01 (1.6904e-01)\tAcc@1  93.75 ( 95.24)\tAcc@5  98.44 ( 99.24)\n","Epoch: [119][ 90/391]\tTime  0.169 ( 0.171)\tLoss 2.1822e-01 (1.7360e-01)\tAcc@1  92.97 ( 95.03)\tAcc@5  98.44 ( 99.26)\n","Epoch: [119][120/391]\tTime  0.170 ( 0.171)\tLoss 2.7150e-01 (1.7724e-01)\tAcc@1  92.19 ( 95.05)\tAcc@5  98.44 ( 99.26)\n","Epoch: [119][150/391]\tTime  0.170 ( 0.171)\tLoss 9.9105e-02 (1.7403e-01)\tAcc@1  96.88 ( 95.07)\tAcc@5 100.00 ( 99.30)\n","Epoch: [119][180/391]\tTime  0.170 ( 0.171)\tLoss 1.4476e-01 (1.7684e-01)\tAcc@1  96.09 ( 95.04)\tAcc@5  99.22 ( 99.29)\n","Epoch: [119][210/391]\tTime  0.171 ( 0.171)\tLoss 1.7567e-01 (1.7875e-01)\tAcc@1  95.31 ( 95.03)\tAcc@5 100.00 ( 99.29)\n","Epoch: [119][240/391]\tTime  0.171 ( 0.170)\tLoss 1.9639e-01 (1.7980e-01)\tAcc@1  94.53 ( 95.02)\tAcc@5  98.44 ( 99.30)\n","Epoch: [119][270/391]\tTime  0.171 ( 0.170)\tLoss 1.9274e-01 (1.8039e-01)\tAcc@1  95.31 ( 95.01)\tAcc@5 100.00 ( 99.32)\n","Epoch: [119][300/391]\tTime  0.172 ( 0.170)\tLoss 1.8450e-01 (1.7922e-01)\tAcc@1  94.53 ( 95.03)\tAcc@5  99.22 ( 99.32)\n","Epoch: [119][330/391]\tTime  0.169 ( 0.170)\tLoss 2.5429e-01 (1.7867e-01)\tAcc@1  93.75 ( 95.04)\tAcc@5  99.22 ( 99.33)\n","Epoch: [119][360/391]\tTime  0.171 ( 0.170)\tLoss 1.3804e-01 (1.7918e-01)\tAcc@1  95.31 ( 95.03)\tAcc@5  99.22 ( 99.32)\n","Epoch: [119][390/391]\tTime  0.153 ( 0.170)\tLoss 2.3410e-01 (1.7971e-01)\tAcc@1  92.50 ( 95.02)\tAcc@5 100.00 ( 99.32)\n","==> Train Accuracy: Acc@1 95.022 || Acc@5 99.322\n","==> Test Accuracy:  Acc@1 77.610 || Acc@5 94.070\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 120, lr: 0.0008000000000000003 -----\n","Epoch: [120][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.4499e-01 (1.4499e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n","Epoch: [120][ 30/391]\tTime  0.170 ( 0.173)\tLoss 2.4186e-01 (1.6472e-01)\tAcc@1  96.09 ( 95.49)\tAcc@5  97.66 ( 99.29)\n","Epoch: [120][ 60/391]\tTime  0.171 ( 0.172)\tLoss 2.2362e-01 (1.5702e-01)\tAcc@1  95.31 ( 95.84)\tAcc@5  96.09 ( 99.31)\n","Epoch: [120][ 90/391]\tTime  0.171 ( 0.171)\tLoss 2.1869e-01 (1.6006e-01)\tAcc@1  92.97 ( 95.66)\tAcc@5  97.66 ( 99.38)\n","Epoch: [120][120/391]\tTime  0.173 ( 0.171)\tLoss 1.0996e-01 (1.6138e-01)\tAcc@1  97.66 ( 95.60)\tAcc@5  99.22 ( 99.34)\n","Epoch: [120][150/391]\tTime  0.170 ( 0.171)\tLoss 1.7048e-01 (1.5994e-01)\tAcc@1  93.75 ( 95.67)\tAcc@5  98.44 ( 99.34)\n","Epoch: [120][180/391]\tTime  0.171 ( 0.171)\tLoss 1.6547e-01 (1.5941e-01)\tAcc@1  96.88 ( 95.68)\tAcc@5  99.22 ( 99.34)\n","Epoch: [120][210/391]\tTime  0.169 ( 0.171)\tLoss 1.6875e-01 (1.5933e-01)\tAcc@1  94.53 ( 95.66)\tAcc@5  99.22 ( 99.35)\n","Epoch: [120][240/391]\tTime  0.171 ( 0.171)\tLoss 2.1056e-01 (1.5979e-01)\tAcc@1  92.97 ( 95.61)\tAcc@5  97.66 ( 99.33)\n","Epoch: [120][270/391]\tTime  0.170 ( 0.170)\tLoss 1.8211e-01 (1.5847e-01)\tAcc@1  96.88 ( 95.69)\tAcc@5  98.44 ( 99.33)\n","Epoch: [120][300/391]\tTime  0.171 ( 0.170)\tLoss 1.1938e-01 (1.5804e-01)\tAcc@1  96.09 ( 95.69)\tAcc@5  99.22 ( 99.32)\n","Epoch: [120][330/391]\tTime  0.170 ( 0.170)\tLoss 1.2426e-01 (1.5776e-01)\tAcc@1  96.09 ( 95.69)\tAcc@5  99.22 ( 99.34)\n","Epoch: [120][360/391]\tTime  0.170 ( 0.170)\tLoss 7.2855e-02 (1.5609e-01)\tAcc@1  99.22 ( 95.73)\tAcc@5 100.00 ( 99.35)\n","Epoch: [120][390/391]\tTime  0.153 ( 0.170)\tLoss 1.2141e-01 (1.5536e-01)\tAcc@1  97.50 ( 95.76)\tAcc@5  98.75 ( 99.34)\n","==> Train Accuracy: Acc@1 95.764 || Acc@5 99.342\n","==> Test Accuracy:  Acc@1 78.790 || Acc@5 94.330\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 121, lr: 0.0008000000000000003 -----\n","Epoch: [121][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.2382e-01 (1.2382e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [121][ 30/391]\tTime  0.171 ( 0.173)\tLoss 2.4446e-01 (1.5350e-01)\tAcc@1  92.97 ( 95.84)\tAcc@5  98.44 ( 99.42)\n","Epoch: [121][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.4864e-01 (1.4266e-01)\tAcc@1  96.88 ( 96.20)\tAcc@5  99.22 ( 99.42)\n","Epoch: [121][ 90/391]\tTime  0.169 ( 0.171)\tLoss 8.0289e-02 (1.4120e-01)\tAcc@1  97.66 ( 96.33)\tAcc@5 100.00 ( 99.41)\n","Epoch: [121][120/391]\tTime  0.171 ( 0.171)\tLoss 1.5387e-01 (1.4106e-01)\tAcc@1  96.88 ( 96.32)\tAcc@5  98.44 ( 99.39)\n","Epoch: [121][150/391]\tTime  0.169 ( 0.171)\tLoss 1.1451e-01 (1.4237e-01)\tAcc@1  96.09 ( 96.26)\tAcc@5  98.44 ( 99.37)\n","Epoch: [121][180/391]\tTime  0.169 ( 0.171)\tLoss 1.0726e-01 (1.4112e-01)\tAcc@1  96.88 ( 96.31)\tAcc@5 100.00 ( 99.41)\n","Epoch: [121][210/391]\tTime  0.171 ( 0.171)\tLoss 8.8114e-02 (1.4025e-01)\tAcc@1  97.66 ( 96.29)\tAcc@5  99.22 ( 99.42)\n","Epoch: [121][240/391]\tTime  0.169 ( 0.170)\tLoss 1.5385e-01 (1.3837e-01)\tAcc@1  96.88 ( 96.37)\tAcc@5 100.00 ( 99.43)\n","Epoch: [121][270/391]\tTime  0.170 ( 0.170)\tLoss 1.2921e-01 (1.3837e-01)\tAcc@1  97.66 ( 96.34)\tAcc@5  98.44 ( 99.43)\n","Epoch: [121][300/391]\tTime  0.169 ( 0.170)\tLoss 1.5821e-01 (1.3925e-01)\tAcc@1  96.09 ( 96.28)\tAcc@5  99.22 ( 99.44)\n","Epoch: [121][330/391]\tTime  0.170 ( 0.170)\tLoss 1.7115e-01 (1.3972e-01)\tAcc@1  95.31 ( 96.27)\tAcc@5 100.00 ( 99.43)\n","Epoch: [121][360/391]\tTime  0.171 ( 0.170)\tLoss 1.5317e-01 (1.3870e-01)\tAcc@1  96.88 ( 96.29)\tAcc@5  98.44 ( 99.45)\n","Epoch: [121][390/391]\tTime  0.152 ( 0.170)\tLoss 5.2072e-02 (1.3841e-01)\tAcc@1 100.00 ( 96.32)\tAcc@5 100.00 ( 99.44)\n","==> Train Accuracy: Acc@1 96.318 || Acc@5 99.438\n","==> Test Accuracy:  Acc@1 79.380 || Acc@5 94.540\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 122, lr: 0.0008000000000000003 -----\n","Epoch: [122][  0/391]\tTime  0.297 ( 0.297)\tLoss 1.2143e-01 (1.2143e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [122][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.1310e-01 (1.3252e-01)\tAcc@1  98.44 ( 96.45)\tAcc@5 100.00 ( 99.45)\n","Epoch: [122][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.3124e-01 (1.2900e-01)\tAcc@1  96.09 ( 96.55)\tAcc@5 100.00 ( 99.49)\n","Epoch: [122][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.4346e-01 (1.2747e-01)\tAcc@1  95.31 ( 96.55)\tAcc@5 100.00 ( 99.52)\n","Epoch: [122][120/391]\tTime  0.168 ( 0.171)\tLoss 1.9209e-01 (1.3265e-01)\tAcc@1  96.88 ( 96.44)\tAcc@5  99.22 ( 99.45)\n","Epoch: [122][150/391]\tTime  0.171 ( 0.171)\tLoss 1.3566e-01 (1.3293e-01)\tAcc@1  96.09 ( 96.36)\tAcc@5 100.00 ( 99.47)\n","Epoch: [122][180/391]\tTime  0.168 ( 0.171)\tLoss 1.0834e-01 (1.3456e-01)\tAcc@1  97.66 ( 96.31)\tAcc@5 100.00 ( 99.45)\n","Epoch: [122][210/391]\tTime  0.169 ( 0.171)\tLoss 1.1486e-01 (1.3353e-01)\tAcc@1  96.88 ( 96.38)\tAcc@5 100.00 ( 99.46)\n","Epoch: [122][240/391]\tTime  0.169 ( 0.171)\tLoss 1.0065e-01 (1.3434e-01)\tAcc@1  95.31 ( 96.38)\tAcc@5 100.00 ( 99.46)\n","Epoch: [122][270/391]\tTime  0.170 ( 0.171)\tLoss 7.6512e-02 (1.3377e-01)\tAcc@1  96.88 ( 96.41)\tAcc@5 100.00 ( 99.46)\n","Epoch: [122][300/391]\tTime  0.170 ( 0.171)\tLoss 1.4602e-01 (1.3403e-01)\tAcc@1  95.31 ( 96.41)\tAcc@5 100.00 ( 99.47)\n","Epoch: [122][330/391]\tTime  0.170 ( 0.171)\tLoss 1.4193e-01 (1.3322e-01)\tAcc@1  96.09 ( 96.43)\tAcc@5 100.00 ( 99.47)\n","Epoch: [122][360/391]\tTime  0.171 ( 0.170)\tLoss 1.1606e-01 (1.3347e-01)\tAcc@1  96.88 ( 96.43)\tAcc@5 100.00 ( 99.48)\n","Epoch: [122][390/391]\tTime  0.152 ( 0.170)\tLoss 1.2504e-01 (1.3356e-01)\tAcc@1  96.25 ( 96.43)\tAcc@5  98.75 ( 99.48)\n","==> Train Accuracy: Acc@1 96.432 || Acc@5 99.476\n","==> Test Accuracy:  Acc@1 79.200 || Acc@5 94.510\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 123, lr: 0.0008000000000000003 -----\n","Epoch: [123][  0/391]\tTime  0.287 ( 0.287)\tLoss 9.6424e-02 (9.6424e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5  99.22 ( 99.22)\n","Epoch: [123][ 30/391]\tTime  0.170 ( 0.173)\tLoss 9.0488e-02 (1.2696e-01)\tAcc@1  96.09 ( 96.42)\tAcc@5 100.00 ( 99.57)\n","Epoch: [123][ 60/391]\tTime  0.169 ( 0.172)\tLoss 7.0040e-02 (1.2030e-01)\tAcc@1  99.22 ( 96.55)\tAcc@5 100.00 ( 99.62)\n","Epoch: [123][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.2667e-01 (1.2420e-01)\tAcc@1  96.88 ( 96.48)\tAcc@5 100.00 ( 99.61)\n","Epoch: [123][120/391]\tTime  0.170 ( 0.171)\tLoss 1.5886e-01 (1.2546e-01)\tAcc@1  92.97 ( 96.40)\tAcc@5 100.00 ( 99.63)\n","Epoch: [123][150/391]\tTime  0.169 ( 0.171)\tLoss 7.8863e-02 (1.2393e-01)\tAcc@1  98.44 ( 96.49)\tAcc@5 100.00 ( 99.63)\n","Epoch: [123][180/391]\tTime  0.169 ( 0.171)\tLoss 1.3662e-01 (1.2497e-01)\tAcc@1  96.88 ( 96.48)\tAcc@5  98.44 ( 99.60)\n","Epoch: [123][210/391]\tTime  0.172 ( 0.171)\tLoss 9.8708e-02 (1.2574e-01)\tAcc@1  96.88 ( 96.45)\tAcc@5 100.00 ( 99.59)\n","Epoch: [123][240/391]\tTime  0.171 ( 0.171)\tLoss 1.6042e-01 (1.2669e-01)\tAcc@1  96.88 ( 96.45)\tAcc@5  99.22 ( 99.57)\n","Epoch: [123][270/391]\tTime  0.170 ( 0.170)\tLoss 8.8593e-02 (1.2873e-01)\tAcc@1  98.44 ( 96.40)\tAcc@5 100.00 ( 99.54)\n","Epoch: [123][300/391]\tTime  0.170 ( 0.170)\tLoss 1.7604e-01 (1.2993e-01)\tAcc@1  94.53 ( 96.38)\tAcc@5  99.22 ( 99.51)\n","Epoch: [123][330/391]\tTime  0.169 ( 0.170)\tLoss 1.2563e-01 (1.2858e-01)\tAcc@1  97.66 ( 96.44)\tAcc@5  99.22 ( 99.54)\n","Epoch: [123][360/391]\tTime  0.172 ( 0.170)\tLoss 2.0233e-01 (1.2963e-01)\tAcc@1  95.31 ( 96.42)\tAcc@5  98.44 ( 99.52)\n","Epoch: [123][390/391]\tTime  0.154 ( 0.170)\tLoss 4.8614e-02 (1.3060e-01)\tAcc@1  98.75 ( 96.41)\tAcc@5 100.00 ( 99.51)\n","==> Train Accuracy: Acc@1 96.406 || Acc@5 99.514\n","==> Test Accuracy:  Acc@1 79.170 || Acc@5 94.540\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 124, lr: 0.0008000000000000003 -----\n","Epoch: [124][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.1188e-01 (1.1188e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [124][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.0961e-01 (1.3912e-01)\tAcc@1  97.66 ( 96.14)\tAcc@5  99.22 ( 99.57)\n","Epoch: [124][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.6875e-01 (1.3215e-01)\tAcc@1  96.88 ( 96.48)\tAcc@5  98.44 ( 99.54)\n","Epoch: [124][ 90/391]\tTime  0.169 ( 0.171)\tLoss 9.2288e-02 (1.3335e-01)\tAcc@1  98.44 ( 96.39)\tAcc@5 100.00 ( 99.49)\n","Epoch: [124][120/391]\tTime  0.170 ( 0.171)\tLoss 5.7456e-02 (1.3580e-01)\tAcc@1  99.22 ( 96.33)\tAcc@5 100.00 ( 99.45)\n","Epoch: [124][150/391]\tTime  0.170 ( 0.171)\tLoss 2.2569e-01 (1.3542e-01)\tAcc@1  94.53 ( 96.31)\tAcc@5 100.00 ( 99.49)\n","Epoch: [124][180/391]\tTime  0.170 ( 0.171)\tLoss 1.7122e-01 (1.3498e-01)\tAcc@1  96.09 ( 96.35)\tAcc@5  99.22 ( 99.50)\n","Epoch: [124][210/391]\tTime  0.170 ( 0.171)\tLoss 7.3986e-02 (1.3319e-01)\tAcc@1  98.44 ( 96.43)\tAcc@5 100.00 ( 99.51)\n","Epoch: [124][240/391]\tTime  0.171 ( 0.171)\tLoss 8.1896e-02 (1.3579e-01)\tAcc@1  97.66 ( 96.38)\tAcc@5 100.00 ( 99.48)\n","Epoch: [124][270/391]\tTime  0.168 ( 0.171)\tLoss 8.9850e-02 (1.3539e-01)\tAcc@1  99.22 ( 96.38)\tAcc@5  99.22 ( 99.48)\n","Epoch: [124][300/391]\tTime  0.170 ( 0.170)\tLoss 1.1083e-01 (1.3354e-01)\tAcc@1  97.66 ( 96.41)\tAcc@5 100.00 ( 99.48)\n","Epoch: [124][330/391]\tTime  0.170 ( 0.170)\tLoss 1.9520e-01 (1.3327e-01)\tAcc@1  96.09 ( 96.44)\tAcc@5  98.44 ( 99.46)\n","Epoch: [124][360/391]\tTime  0.170 ( 0.170)\tLoss 8.5208e-02 (1.3268e-01)\tAcc@1  98.44 ( 96.46)\tAcc@5 100.00 ( 99.46)\n","Epoch: [124][390/391]\tTime  0.154 ( 0.170)\tLoss 1.4703e-01 (1.3281e-01)\tAcc@1  97.50 ( 96.48)\tAcc@5  98.75 ( 99.47)\n","==> Train Accuracy: Acc@1 96.478 || Acc@5 99.468\n","==> Test Accuracy:  Acc@1 78.950 || Acc@5 94.540\n","==> 70.80 seconds to train this epoch\n","\n","\n","----- epoch: 125, lr: 0.0008000000000000003 -----\n","Epoch: [125][  0/391]\tTime  0.298 ( 0.298)\tLoss 1.2629e-01 (1.2629e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [125][ 30/391]\tTime  0.170 ( 0.174)\tLoss 9.4647e-02 (1.2875e-01)\tAcc@1  96.09 ( 96.37)\tAcc@5 100.00 ( 99.50)\n","Epoch: [125][ 60/391]\tTime  0.168 ( 0.172)\tLoss 6.8067e-02 (1.2714e-01)\tAcc@1  99.22 ( 96.50)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.1505e-01 (1.2619e-01)\tAcc@1  96.09 ( 96.45)\tAcc@5 100.00 ( 99.60)\n","Epoch: [125][120/391]\tTime  0.170 ( 0.171)\tLoss 2.2661e-01 (1.2531e-01)\tAcc@1  94.53 ( 96.51)\tAcc@5  99.22 ( 99.61)\n","Epoch: [125][150/391]\tTime  0.170 ( 0.171)\tLoss 2.9932e-02 (1.2434e-01)\tAcc@1  99.22 ( 96.59)\tAcc@5 100.00 ( 99.58)\n","Epoch: [125][180/391]\tTime  0.170 ( 0.171)\tLoss 1.0825e-01 (1.2415e-01)\tAcc@1  96.88 ( 96.60)\tAcc@5  99.22 ( 99.57)\n","Epoch: [125][210/391]\tTime  0.170 ( 0.171)\tLoss 1.9851e-01 (1.2463e-01)\tAcc@1  95.31 ( 96.58)\tAcc@5  99.22 ( 99.58)\n","Epoch: [125][240/391]\tTime  0.172 ( 0.170)\tLoss 5.2252e-02 (1.2512e-01)\tAcc@1  97.66 ( 96.56)\tAcc@5 100.00 ( 99.57)\n","Epoch: [125][270/391]\tTime  0.170 ( 0.170)\tLoss 1.2107e-01 (1.2680e-01)\tAcc@1  95.31 ( 96.51)\tAcc@5  99.22 ( 99.54)\n","Epoch: [125][300/391]\tTime  0.171 ( 0.170)\tLoss 1.5418e-01 (1.2843e-01)\tAcc@1  94.53 ( 96.49)\tAcc@5  99.22 ( 99.54)\n","Epoch: [125][330/391]\tTime  0.169 ( 0.170)\tLoss 1.0792e-01 (1.2933e-01)\tAcc@1  96.09 ( 96.45)\tAcc@5 100.00 ( 99.53)\n","Epoch: [125][360/391]\tTime  0.169 ( 0.170)\tLoss 2.1605e-01 (1.2893e-01)\tAcc@1  90.62 ( 96.47)\tAcc@5 100.00 ( 99.53)\n","Epoch: [125][390/391]\tTime  0.153 ( 0.170)\tLoss 3.3583e-02 (1.2763e-01)\tAcc@1  98.75 ( 96.51)\tAcc@5 100.00 ( 99.54)\n","==> Train Accuracy: Acc@1 96.514 || Acc@5 99.542\n","==> Test Accuracy:  Acc@1 79.110 || Acc@5 94.560\n","==> 70.73 seconds to train this epoch\n","\n","\n","----- epoch: 126, lr: 0.0008000000000000003 -----\n","Epoch: [126][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.9265e-01 (1.9265e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n","Epoch: [126][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.0729e-01 (1.2799e-01)\tAcc@1  97.66 ( 96.47)\tAcc@5  99.22 ( 99.37)\n","Epoch: [126][ 60/391]\tTime  0.171 ( 0.171)\tLoss 1.5747e-01 (1.2600e-01)\tAcc@1  95.31 ( 96.59)\tAcc@5  98.44 ( 99.40)\n","Epoch: [126][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.6911e-01 (1.2587e-01)\tAcc@1  95.31 ( 96.61)\tAcc@5  99.22 ( 99.42)\n","Epoch: [126][120/391]\tTime  0.171 ( 0.171)\tLoss 8.4236e-02 (1.2438e-01)\tAcc@1  98.44 ( 96.67)\tAcc@5 100.00 ( 99.43)\n","Epoch: [126][150/391]\tTime  0.171 ( 0.170)\tLoss 7.0517e-02 (1.2295e-01)\tAcc@1  97.66 ( 96.68)\tAcc@5 100.00 ( 99.48)\n","Epoch: [126][180/391]\tTime  0.169 ( 0.170)\tLoss 1.3850e-01 (1.2378e-01)\tAcc@1  94.53 ( 96.65)\tAcc@5 100.00 ( 99.49)\n","Epoch: [126][210/391]\tTime  0.170 ( 0.170)\tLoss 5.2506e-02 (1.2457e-01)\tAcc@1  99.22 ( 96.64)\tAcc@5 100.00 ( 99.49)\n","Epoch: [126][240/391]\tTime  0.168 ( 0.170)\tLoss 1.6811e-01 (1.2401e-01)\tAcc@1  94.53 ( 96.63)\tAcc@5  99.22 ( 99.50)\n","Epoch: [126][270/391]\tTime  0.170 ( 0.170)\tLoss 2.5895e-01 (1.2427e-01)\tAcc@1  94.53 ( 96.60)\tAcc@5  98.44 ( 99.49)\n","Epoch: [126][300/391]\tTime  0.172 ( 0.170)\tLoss 1.1472e-01 (1.2383e-01)\tAcc@1  96.88 ( 96.63)\tAcc@5 100.00 ( 99.51)\n","Epoch: [126][330/391]\tTime  0.169 ( 0.170)\tLoss 1.5520e-01 (1.2412e-01)\tAcc@1  96.09 ( 96.63)\tAcc@5 100.00 ( 99.51)\n","Epoch: [126][360/391]\tTime  0.170 ( 0.170)\tLoss 1.4794e-01 (1.2494e-01)\tAcc@1  96.09 ( 96.61)\tAcc@5 100.00 ( 99.52)\n","Epoch: [126][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5337e-01 (1.2395e-01)\tAcc@1  96.25 ( 96.63)\tAcc@5  98.75 ( 99.52)\n","==> Train Accuracy: Acc@1 96.634 || Acc@5 99.524\n","==> Test Accuracy:  Acc@1 79.210 || Acc@5 94.650\n","==> 70.65 seconds to train this epoch\n","\n","\n","----- epoch: 127, lr: 0.0008000000000000003 -----\n","Epoch: [127][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.0697e-01 (1.0697e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [127][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.0960e-01 (1.2907e-01)\tAcc@1  96.88 ( 96.57)\tAcc@5  99.22 ( 99.37)\n","Epoch: [127][ 60/391]\tTime  0.168 ( 0.172)\tLoss 1.1356e-01 (1.3079e-01)\tAcc@1  99.22 ( 96.44)\tAcc@5  99.22 ( 99.45)\n","Epoch: [127][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.2501e-01 (1.3031e-01)\tAcc@1  97.66 ( 96.39)\tAcc@5  97.66 ( 99.45)\n","Epoch: [127][120/391]\tTime  0.170 ( 0.171)\tLoss 9.9622e-02 (1.2914e-01)\tAcc@1  97.66 ( 96.35)\tAcc@5  99.22 ( 99.48)\n","Epoch: [127][150/391]\tTime  0.171 ( 0.171)\tLoss 8.1508e-02 (1.2898e-01)\tAcc@1  98.44 ( 96.42)\tAcc@5  99.22 ( 99.45)\n","Epoch: [127][180/391]\tTime  0.171 ( 0.171)\tLoss 1.3560e-01 (1.2771e-01)\tAcc@1  97.66 ( 96.55)\tAcc@5  98.44 ( 99.45)\n","Epoch: [127][210/391]\tTime  0.169 ( 0.170)\tLoss 2.0138e-01 (1.2725e-01)\tAcc@1  95.31 ( 96.56)\tAcc@5  98.44 ( 99.44)\n","Epoch: [127][240/391]\tTime  0.170 ( 0.170)\tLoss 1.9439e-01 (1.2843e-01)\tAcc@1  94.53 ( 96.52)\tAcc@5  99.22 ( 99.43)\n","Epoch: [127][270/391]\tTime  0.169 ( 0.170)\tLoss 4.7677e-02 (1.2602e-01)\tAcc@1  99.22 ( 96.60)\tAcc@5 100.00 ( 99.44)\n","Epoch: [127][300/391]\tTime  0.170 ( 0.170)\tLoss 1.2803e-01 (1.2532e-01)\tAcc@1  96.09 ( 96.61)\tAcc@5  99.22 ( 99.45)\n","Epoch: [127][330/391]\tTime  0.170 ( 0.170)\tLoss 1.3722e-01 (1.2621e-01)\tAcc@1  96.88 ( 96.60)\tAcc@5  99.22 ( 99.44)\n","Epoch: [127][360/391]\tTime  0.171 ( 0.170)\tLoss 1.1590e-01 (1.2591e-01)\tAcc@1  96.09 ( 96.61)\tAcc@5 100.00 ( 99.45)\n","Epoch: [127][390/391]\tTime  0.153 ( 0.170)\tLoss 1.8240e-01 (1.2553e-01)\tAcc@1  96.25 ( 96.61)\tAcc@5  98.75 ( 99.46)\n","==> Train Accuracy: Acc@1 96.608 || Acc@5 99.456\n","==> Test Accuracy:  Acc@1 79.000 || Acc@5 94.590\n","==> 70.74 seconds to train this epoch\n","\n","\n","----- epoch: 128, lr: 0.0008000000000000003 -----\n","Epoch: [128][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.5830e-01 (1.5830e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [128][ 30/391]\tTime  0.171 ( 0.173)\tLoss 7.1294e-02 (1.1905e-01)\tAcc@1  98.44 ( 96.55)\tAcc@5  99.22 ( 99.52)\n","Epoch: [128][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.6311e-01 (1.1954e-01)\tAcc@1  93.75 ( 96.68)\tAcc@5  99.22 ( 99.51)\n","Epoch: [128][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.7900e-01 (1.2277e-01)\tAcc@1  96.09 ( 96.51)\tAcc@5  98.44 ( 99.47)\n","Epoch: [128][120/391]\tTime  0.170 ( 0.171)\tLoss 1.2079e-01 (1.1814e-01)\tAcc@1  96.09 ( 96.69)\tAcc@5 100.00 ( 99.51)\n","Epoch: [128][150/391]\tTime  0.170 ( 0.171)\tLoss 5.7236e-02 (1.1861e-01)\tAcc@1  97.66 ( 96.69)\tAcc@5 100.00 ( 99.51)\n","Epoch: [128][180/391]\tTime  0.170 ( 0.171)\tLoss 7.4155e-02 (1.1846e-01)\tAcc@1  97.66 ( 96.70)\tAcc@5 100.00 ( 99.54)\n","Epoch: [128][210/391]\tTime  0.169 ( 0.170)\tLoss 1.3868e-01 (1.1978e-01)\tAcc@1  97.66 ( 96.68)\tAcc@5  99.22 ( 99.52)\n","Epoch: [128][240/391]\tTime  0.170 ( 0.170)\tLoss 1.1304e-01 (1.1948e-01)\tAcc@1  96.09 ( 96.65)\tAcc@5 100.00 ( 99.56)\n","Epoch: [128][270/391]\tTime  0.170 ( 0.170)\tLoss 1.0200e-01 (1.1918e-01)\tAcc@1  95.31 ( 96.64)\tAcc@5  99.22 ( 99.56)\n","Epoch: [128][300/391]\tTime  0.170 ( 0.170)\tLoss 6.8224e-02 (1.1905e-01)\tAcc@1  99.22 ( 96.66)\tAcc@5 100.00 ( 99.56)\n","Epoch: [128][330/391]\tTime  0.169 ( 0.170)\tLoss 9.8391e-02 (1.1941e-01)\tAcc@1  97.66 ( 96.67)\tAcc@5  99.22 ( 99.56)\n","Epoch: [128][360/391]\tTime  0.169 ( 0.170)\tLoss 7.2416e-02 (1.2011e-01)\tAcc@1  96.88 ( 96.66)\tAcc@5 100.00 ( 99.57)\n","Epoch: [128][390/391]\tTime  0.153 ( 0.170)\tLoss 1.5578e-01 (1.1940e-01)\tAcc@1  97.50 ( 96.70)\tAcc@5  98.75 ( 99.57)\n","==> Train Accuracy: Acc@1 96.696 || Acc@5 99.568\n","==> Test Accuracy:  Acc@1 78.730 || Acc@5 94.620\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 129, lr: 0.0008000000000000003 -----\n","Epoch: [129][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.7189e-01 (1.7189e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  98.44 ( 98.44)\n","Epoch: [129][ 30/391]\tTime  0.169 ( 0.173)\tLoss 9.9150e-02 (1.2601e-01)\tAcc@1  96.09 ( 96.60)\tAcc@5 100.00 ( 99.42)\n","Epoch: [129][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.2729e-01 (1.3064e-01)\tAcc@1  92.19 ( 96.50)\tAcc@5  99.22 ( 99.41)\n","Epoch: [129][ 90/391]\tTime  0.169 ( 0.171)\tLoss 1.9684e-01 (1.2857e-01)\tAcc@1  94.53 ( 96.48)\tAcc@5  98.44 ( 99.43)\n","Epoch: [129][120/391]\tTime  0.169 ( 0.171)\tLoss 6.9474e-02 (1.2934e-01)\tAcc@1  98.44 ( 96.45)\tAcc@5 100.00 ( 99.44)\n","Epoch: [129][150/391]\tTime  0.171 ( 0.171)\tLoss 1.6171e-01 (1.2604e-01)\tAcc@1  96.88 ( 96.62)\tAcc@5  99.22 ( 99.44)\n","Epoch: [129][180/391]\tTime  0.170 ( 0.171)\tLoss 1.7622e-01 (1.2380e-01)\tAcc@1  94.53 ( 96.67)\tAcc@5 100.00 ( 99.46)\n","Epoch: [129][210/391]\tTime  0.170 ( 0.171)\tLoss 1.9547e-01 (1.2298e-01)\tAcc@1  94.53 ( 96.66)\tAcc@5  99.22 ( 99.49)\n","Epoch: [129][240/391]\tTime  0.171 ( 0.170)\tLoss 4.5207e-02 (1.2137e-01)\tAcc@1  99.22 ( 96.67)\tAcc@5 100.00 ( 99.48)\n","Epoch: [129][270/391]\tTime  0.172 ( 0.170)\tLoss 9.8553e-02 (1.2005e-01)\tAcc@1  96.88 ( 96.70)\tAcc@5 100.00 ( 99.50)\n","Epoch: [129][300/391]\tTime  0.171 ( 0.170)\tLoss 7.1127e-02 (1.1862e-01)\tAcc@1  97.66 ( 96.76)\tAcc@5 100.00 ( 99.51)\n","Epoch: [129][330/391]\tTime  0.171 ( 0.170)\tLoss 6.8923e-02 (1.1836e-01)\tAcc@1  98.44 ( 96.77)\tAcc@5 100.00 ( 99.51)\n","Epoch: [129][360/391]\tTime  0.171 ( 0.170)\tLoss 7.8695e-02 (1.1806e-01)\tAcc@1  97.66 ( 96.78)\tAcc@5 100.00 ( 99.53)\n","Epoch: [129][390/391]\tTime  0.148 ( 0.170)\tLoss 5.9991e-02 (1.1730e-01)\tAcc@1  98.75 ( 96.82)\tAcc@5 100.00 ( 99.54)\n","==> Train Accuracy: Acc@1 96.820 || Acc@5 99.536\n","==> Test Accuracy:  Acc@1 79.460 || Acc@5 94.670\n","==> 70.78 seconds to train this epoch\n","\n","\n","----- epoch: 130, lr: 0.0008000000000000003 -----\n","Epoch: [130][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.4538e-01 (1.4538e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [130][ 30/391]\tTime  0.171 ( 0.173)\tLoss 3.5847e-02 (1.0707e-01)\tAcc@1 100.00 ( 97.40)\tAcc@5 100.00 ( 99.60)\n","Epoch: [130][ 60/391]\tTime  0.169 ( 0.172)\tLoss 8.5456e-02 (1.0943e-01)\tAcc@1  97.66 ( 97.30)\tAcc@5 100.00 ( 99.58)\n","Epoch: [130][ 90/391]\tTime  0.169 ( 0.171)\tLoss 8.1884e-02 (1.1334e-01)\tAcc@1  98.44 ( 97.10)\tAcc@5 100.00 ( 99.60)\n","Epoch: [130][120/391]\tTime  0.169 ( 0.171)\tLoss 1.6272e-01 (1.1642e-01)\tAcc@1  94.53 ( 97.02)\tAcc@5  99.22 ( 99.55)\n","Epoch: [130][150/391]\tTime  0.169 ( 0.171)\tLoss 8.4840e-02 (1.1367e-01)\tAcc@1  97.66 ( 97.10)\tAcc@5  99.22 ( 99.55)\n","Epoch: [130][180/391]\tTime  0.169 ( 0.171)\tLoss 4.4740e-02 (1.1115e-01)\tAcc@1 100.00 ( 97.21)\tAcc@5 100.00 ( 99.55)\n","Epoch: [130][210/391]\tTime  0.170 ( 0.171)\tLoss 9.1422e-02 (1.1205e-01)\tAcc@1  96.88 ( 97.13)\tAcc@5 100.00 ( 99.57)\n","Epoch: [130][240/391]\tTime  0.170 ( 0.171)\tLoss 1.5480e-01 (1.1198e-01)\tAcc@1  96.09 ( 97.12)\tAcc@5  99.22 ( 99.57)\n","Epoch: [130][270/391]\tTime  0.171 ( 0.171)\tLoss 1.5033e-01 (1.1303e-01)\tAcc@1  96.09 ( 97.07)\tAcc@5 100.00 ( 99.57)\n","Epoch: [130][300/391]\tTime  0.171 ( 0.171)\tLoss 1.1141e-01 (1.1433e-01)\tAcc@1  96.88 ( 97.00)\tAcc@5 100.00 ( 99.57)\n","Epoch: [130][330/391]\tTime  0.171 ( 0.170)\tLoss 1.4617e-01 (1.1455e-01)\tAcc@1  96.09 ( 97.00)\tAcc@5  99.22 ( 99.55)\n","Epoch: [130][360/391]\tTime  0.169 ( 0.170)\tLoss 1.1052e-01 (1.1455e-01)\tAcc@1  96.88 ( 97.02)\tAcc@5 100.00 ( 99.56)\n","Epoch: [130][390/391]\tTime  0.152 ( 0.170)\tLoss 2.1631e-01 (1.1547e-01)\tAcc@1  92.50 ( 97.00)\tAcc@5 100.00 ( 99.55)\n","==> Train Accuracy: Acc@1 97.000 || Acc@5 99.548\n","==> Test Accuracy:  Acc@1 79.130 || Acc@5 94.640\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 131, lr: 0.0008000000000000003 -----\n","Epoch: [131][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.0615e-01 (1.0615e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [131][ 30/391]\tTime  0.170 ( 0.173)\tLoss 7.7821e-02 (1.1277e-01)\tAcc@1  99.22 ( 97.23)\tAcc@5 100.00 ( 99.45)\n","Epoch: [131][ 60/391]\tTime  0.171 ( 0.172)\tLoss 7.5279e-02 (1.1055e-01)\tAcc@1  97.66 ( 97.14)\tAcc@5 100.00 ( 99.55)\n","Epoch: [131][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.3425e-01 (1.1324e-01)\tAcc@1  94.53 ( 97.02)\tAcc@5 100.00 ( 99.51)\n","Epoch: [131][120/391]\tTime  0.171 ( 0.171)\tLoss 1.0642e-01 (1.1636e-01)\tAcc@1  98.44 ( 96.93)\tAcc@5 100.00 ( 99.48)\n","Epoch: [131][150/391]\tTime  0.170 ( 0.171)\tLoss 1.0838e-01 (1.1799e-01)\tAcc@1  98.44 ( 96.90)\tAcc@5  98.44 ( 99.45)\n","Epoch: [131][180/391]\tTime  0.170 ( 0.171)\tLoss 1.2394e-01 (1.1598e-01)\tAcc@1  98.44 ( 96.97)\tAcc@5 100.00 ( 99.47)\n","Epoch: [131][210/391]\tTime  0.171 ( 0.171)\tLoss 1.4732e-01 (1.1593e-01)\tAcc@1  96.09 ( 96.96)\tAcc@5 100.00 ( 99.51)\n","Epoch: [131][240/391]\tTime  0.169 ( 0.171)\tLoss 1.7900e-01 (1.1573e-01)\tAcc@1  95.31 ( 96.96)\tAcc@5  99.22 ( 99.52)\n","Epoch: [131][270/391]\tTime  0.170 ( 0.170)\tLoss 1.3815e-01 (1.1590e-01)\tAcc@1  96.88 ( 96.95)\tAcc@5  99.22 ( 99.51)\n","Epoch: [131][300/391]\tTime  0.170 ( 0.170)\tLoss 1.3550e-01 (1.1697e-01)\tAcc@1  96.09 ( 96.91)\tAcc@5  99.22 ( 99.51)\n","Epoch: [131][330/391]\tTime  0.169 ( 0.170)\tLoss 1.8553e-01 (1.1660e-01)\tAcc@1  95.31 ( 96.91)\tAcc@5  99.22 ( 99.52)\n","Epoch: [131][360/391]\tTime  0.171 ( 0.170)\tLoss 7.4270e-02 (1.1658e-01)\tAcc@1  97.66 ( 96.90)\tAcc@5 100.00 ( 99.52)\n","Epoch: [131][390/391]\tTime  0.150 ( 0.170)\tLoss 9.1570e-02 (1.1696e-01)\tAcc@1  95.00 ( 96.89)\tAcc@5 100.00 ( 99.50)\n","==> Train Accuracy: Acc@1 96.886 || Acc@5 99.502\n","==> Test Accuracy:  Acc@1 79.070 || Acc@5 94.720\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 132, lr: 0.0008000000000000003 -----\n","Epoch: [132][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.0742e-01 (1.0742e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [132][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.7247e-01 (1.1006e-01)\tAcc@1  96.09 ( 97.33)\tAcc@5  98.44 ( 99.57)\n","Epoch: [132][ 60/391]\tTime  0.170 ( 0.172)\tLoss 2.0222e-01 (1.1392e-01)\tAcc@1  94.53 ( 97.05)\tAcc@5  98.44 ( 99.64)\n","Epoch: [132][ 90/391]\tTime  0.170 ( 0.171)\tLoss 2.1753e-01 (1.1948e-01)\tAcc@1  90.62 ( 96.82)\tAcc@5  99.22 ( 99.61)\n","Epoch: [132][120/391]\tTime  0.169 ( 0.171)\tLoss 1.3367e-01 (1.1777e-01)\tAcc@1  95.31 ( 96.85)\tAcc@5  98.44 ( 99.57)\n","Epoch: [132][150/391]\tTime  0.170 ( 0.171)\tLoss 1.8855e-01 (1.1712e-01)\tAcc@1  93.75 ( 96.84)\tAcc@5  99.22 ( 99.60)\n","Epoch: [132][180/391]\tTime  0.170 ( 0.171)\tLoss 9.7616e-02 (1.1705e-01)\tAcc@1  98.44 ( 96.84)\tAcc@5  99.22 ( 99.59)\n","Epoch: [132][210/391]\tTime  0.170 ( 0.171)\tLoss 8.1287e-02 (1.1788e-01)\tAcc@1  98.44 ( 96.79)\tAcc@5 100.00 ( 99.57)\n","Epoch: [132][240/391]\tTime  0.171 ( 0.171)\tLoss 6.6684e-02 (1.1726e-01)\tAcc@1  96.88 ( 96.82)\tAcc@5 100.00 ( 99.58)\n","Epoch: [132][270/391]\tTime  0.170 ( 0.171)\tLoss 7.0935e-02 (1.1598e-01)\tAcc@1  97.66 ( 96.87)\tAcc@5 100.00 ( 99.58)\n","Epoch: [132][300/391]\tTime  0.171 ( 0.171)\tLoss 8.3791e-02 (1.1675e-01)\tAcc@1  96.88 ( 96.85)\tAcc@5 100.00 ( 99.55)\n","Epoch: [132][330/391]\tTime  0.171 ( 0.171)\tLoss 5.9771e-02 (1.1550e-01)\tAcc@1  98.44 ( 96.89)\tAcc@5 100.00 ( 99.56)\n","Epoch: [132][360/391]\tTime  0.171 ( 0.170)\tLoss 1.2901e-01 (1.1707e-01)\tAcc@1  95.31 ( 96.85)\tAcc@5 100.00 ( 99.55)\n","Epoch: [132][390/391]\tTime  0.155 ( 0.170)\tLoss 2.0224e-01 (1.1790e-01)\tAcc@1  93.75 ( 96.81)\tAcc@5  98.75 ( 99.55)\n","==> Train Accuracy: Acc@1 96.812 || Acc@5 99.550\n","==> Test Accuracy:  Acc@1 78.790 || Acc@5 94.660\n","==> 70.81 seconds to train this epoch\n","\n","\n","----- epoch: 133, lr: 0.0008000000000000003 -----\n","Epoch: [133][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.4251e-01 (1.4251e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [133][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.1152e-01 (1.2130e-01)\tAcc@1  96.88 ( 96.60)\tAcc@5  99.22 ( 99.47)\n","Epoch: [133][ 60/391]\tTime  0.169 ( 0.171)\tLoss 1.5619e-01 (1.2063e-01)\tAcc@1  94.53 ( 96.49)\tAcc@5  99.22 ( 99.63)\n","Epoch: [133][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.7919e-01 (1.2097e-01)\tAcc@1  95.31 ( 96.54)\tAcc@5  98.44 ( 99.54)\n","Epoch: [133][120/391]\tTime  0.170 ( 0.171)\tLoss 1.1057e-01 (1.2097e-01)\tAcc@1  96.88 ( 96.58)\tAcc@5 100.00 ( 99.55)\n","Epoch: [133][150/391]\tTime  0.170 ( 0.171)\tLoss 2.0194e-01 (1.2300e-01)\tAcc@1  92.97 ( 96.52)\tAcc@5 100.00 ( 99.54)\n","Epoch: [133][180/391]\tTime  0.170 ( 0.170)\tLoss 1.3901e-01 (1.2128e-01)\tAcc@1  97.66 ( 96.60)\tAcc@5 100.00 ( 99.56)\n","Epoch: [133][210/391]\tTime  0.169 ( 0.170)\tLoss 8.7874e-02 (1.2093e-01)\tAcc@1  98.44 ( 96.64)\tAcc@5 100.00 ( 99.56)\n","Epoch: [133][240/391]\tTime  0.170 ( 0.170)\tLoss 5.5973e-02 (1.1953e-01)\tAcc@1  98.44 ( 96.69)\tAcc@5 100.00 ( 99.55)\n","Epoch: [133][270/391]\tTime  0.170 ( 0.170)\tLoss 9.6546e-02 (1.1921e-01)\tAcc@1  98.44 ( 96.69)\tAcc@5  99.22 ( 99.57)\n","Epoch: [133][300/391]\tTime  0.170 ( 0.170)\tLoss 1.2465e-01 (1.1841e-01)\tAcc@1  97.66 ( 96.71)\tAcc@5 100.00 ( 99.58)\n","Epoch: [133][330/391]\tTime  0.170 ( 0.170)\tLoss 1.8593e-01 (1.1806e-01)\tAcc@1  95.31 ( 96.74)\tAcc@5  98.44 ( 99.58)\n","Epoch: [133][360/391]\tTime  0.170 ( 0.170)\tLoss 1.1650e-01 (1.1785e-01)\tAcc@1  96.88 ( 96.77)\tAcc@5 100.00 ( 99.57)\n","Epoch: [133][390/391]\tTime  0.152 ( 0.170)\tLoss 1.4346e-01 (1.1775e-01)\tAcc@1  96.25 ( 96.77)\tAcc@5  98.75 ( 99.57)\n","==> Train Accuracy: Acc@1 96.774 || Acc@5 99.570\n","==> Test Accuracy:  Acc@1 79.190 || Acc@5 94.510\n","==> 70.71 seconds to train this epoch\n","\n","\n","----- epoch: 134, lr: 0.0008000000000000003 -----\n","Epoch: [134][  0/391]\tTime  0.288 ( 0.288)\tLoss 2.2658e-01 (2.2658e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n","Epoch: [134][ 30/391]\tTime  0.170 ( 0.173)\tLoss 1.0229e-01 (1.1142e-01)\tAcc@1  96.09 ( 96.90)\tAcc@5 100.00 ( 99.72)\n","Epoch: [134][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.3947e-01 (1.1019e-01)\tAcc@1  97.66 ( 97.03)\tAcc@5 100.00 ( 99.72)\n","Epoch: [134][ 90/391]\tTime  0.172 ( 0.171)\tLoss 8.7442e-02 (1.1131e-01)\tAcc@1  97.66 ( 97.06)\tAcc@5 100.00 ( 99.66)\n","Epoch: [134][120/391]\tTime  0.170 ( 0.171)\tLoss 1.0456e-01 (1.1333e-01)\tAcc@1  96.09 ( 96.95)\tAcc@5 100.00 ( 99.62)\n","Epoch: [134][150/391]\tTime  0.170 ( 0.171)\tLoss 1.6258e-01 (1.1081e-01)\tAcc@1  95.31 ( 97.04)\tAcc@5  98.44 ( 99.64)\n","Epoch: [134][180/391]\tTime  0.169 ( 0.170)\tLoss 1.4480e-01 (1.1238e-01)\tAcc@1  95.31 ( 96.96)\tAcc@5  99.22 ( 99.62)\n","Epoch: [134][210/391]\tTime  0.170 ( 0.170)\tLoss 1.3548e-01 (1.1340e-01)\tAcc@1  96.09 ( 96.91)\tAcc@5 100.00 ( 99.63)\n","Epoch: [134][240/391]\tTime  0.170 ( 0.170)\tLoss 1.2978e-01 (1.1242e-01)\tAcc@1  95.31 ( 96.92)\tAcc@5 100.00 ( 99.64)\n","Epoch: [134][270/391]\tTime  0.171 ( 0.170)\tLoss 7.3134e-02 (1.1252e-01)\tAcc@1  97.66 ( 96.91)\tAcc@5  99.22 ( 99.62)\n","Epoch: [134][300/391]\tTime  0.170 ( 0.170)\tLoss 1.3527e-01 (1.1421e-01)\tAcc@1  95.31 ( 96.87)\tAcc@5  98.44 ( 99.61)\n","Epoch: [134][330/391]\tTime  0.171 ( 0.170)\tLoss 1.1710e-01 (1.1395e-01)\tAcc@1  97.66 ( 96.87)\tAcc@5  98.44 ( 99.60)\n","Epoch: [134][360/391]\tTime  0.172 ( 0.170)\tLoss 1.3980e-01 (1.1440e-01)\tAcc@1  93.75 ( 96.86)\tAcc@5 100.00 ( 99.61)\n","Epoch: [134][390/391]\tTime  0.153 ( 0.170)\tLoss 8.4675e-02 (1.1393e-01)\tAcc@1  96.25 ( 96.87)\tAcc@5 100.00 ( 99.62)\n","==> Train Accuracy: Acc@1 96.874 || Acc@5 99.618\n","==> Test Accuracy:  Acc@1 79.230 || Acc@5 94.620\n","==> 70.73 seconds to train this epoch\n","\n","\n","----- epoch: 135, lr: 0.0008000000000000003 -----\n","Epoch: [135][  0/391]\tTime  0.281 ( 0.281)\tLoss 9.9649e-02 (9.9649e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [135][ 30/391]\tTime  0.171 ( 0.173)\tLoss 1.9160e-01 (1.0701e-01)\tAcc@1  94.53 ( 96.98)\tAcc@5  99.22 ( 99.47)\n","Epoch: [135][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.0047e-01 (1.0912e-01)\tAcc@1  97.66 ( 97.00)\tAcc@5 100.00 ( 99.55)\n","Epoch: [135][ 90/391]\tTime  0.170 ( 0.171)\tLoss 8.9108e-02 (1.0903e-01)\tAcc@1  98.44 ( 97.05)\tAcc@5 100.00 ( 99.60)\n","Epoch: [135][120/391]\tTime  0.170 ( 0.171)\tLoss 8.7681e-02 (1.0765e-01)\tAcc@1  97.66 ( 97.10)\tAcc@5  99.22 ( 99.58)\n","Epoch: [135][150/391]\tTime  0.171 ( 0.171)\tLoss 1.0179e-01 (1.0649e-01)\tAcc@1  97.66 ( 97.19)\tAcc@5  99.22 ( 99.61)\n","Epoch: [135][180/391]\tTime  0.169 ( 0.171)\tLoss 2.3507e-01 (1.1081e-01)\tAcc@1  95.31 ( 97.06)\tAcc@5  99.22 ( 99.59)\n","Epoch: [135][210/391]\tTime  0.171 ( 0.171)\tLoss 1.4564e-01 (1.1067e-01)\tAcc@1  96.88 ( 97.06)\tAcc@5 100.00 ( 99.61)\n","Epoch: [135][240/391]\tTime  0.170 ( 0.171)\tLoss 1.4824e-01 (1.1264e-01)\tAcc@1  96.09 ( 97.04)\tAcc@5  99.22 ( 99.58)\n","Epoch: [135][270/391]\tTime  0.170 ( 0.171)\tLoss 1.4237e-01 (1.1329e-01)\tAcc@1  96.88 ( 96.98)\tAcc@5  99.22 ( 99.57)\n","Epoch: [135][300/391]\tTime  0.170 ( 0.170)\tLoss 7.8946e-02 (1.1326e-01)\tAcc@1  98.44 ( 97.00)\tAcc@5 100.00 ( 99.56)\n","Epoch: [135][330/391]\tTime  0.169 ( 0.170)\tLoss 1.8720e-01 (1.1327e-01)\tAcc@1  95.31 ( 96.98)\tAcc@5  98.44 ( 99.58)\n","Epoch: [135][360/391]\tTime  0.171 ( 0.170)\tLoss 5.4471e-02 (1.1377e-01)\tAcc@1  99.22 ( 96.97)\tAcc@5 100.00 ( 99.57)\n","Epoch: [135][390/391]\tTime  0.153 ( 0.170)\tLoss 1.1006e-01 (1.1325e-01)\tAcc@1  96.25 ( 96.97)\tAcc@5 100.00 ( 99.59)\n","==> Train Accuracy: Acc@1 96.968 || Acc@5 99.590\n","==> Test Accuracy:  Acc@1 78.820 || Acc@5 94.550\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 136, lr: 0.0008000000000000003 -----\n","Epoch: [136][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.6944e-01 (1.6944e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [136][ 30/391]\tTime  0.170 ( 0.174)\tLoss 4.8037e-02 (1.2328e-01)\tAcc@1 100.00 ( 96.35)\tAcc@5 100.00 ( 99.60)\n","Epoch: [136][ 60/391]\tTime  0.171 ( 0.172)\tLoss 8.9029e-02 (1.1960e-01)\tAcc@1  98.44 ( 96.59)\tAcc@5 100.00 ( 99.55)\n","Epoch: [136][ 90/391]\tTime  0.170 ( 0.171)\tLoss 6.7973e-02 (1.1388e-01)\tAcc@1  98.44 ( 96.81)\tAcc@5 100.00 ( 99.63)\n","Epoch: [136][120/391]\tTime  0.172 ( 0.171)\tLoss 6.3214e-02 (1.1304e-01)\tAcc@1  98.44 ( 96.93)\tAcc@5 100.00 ( 99.57)\n","Epoch: [136][150/391]\tTime  0.171 ( 0.171)\tLoss 1.3883e-01 (1.1642e-01)\tAcc@1  95.31 ( 96.81)\tAcc@5  99.22 ( 99.56)\n","Epoch: [136][180/391]\tTime  0.170 ( 0.171)\tLoss 1.4230e-01 (1.1580e-01)\tAcc@1  95.31 ( 96.84)\tAcc@5  99.22 ( 99.56)\n","Epoch: [136][210/391]\tTime  0.170 ( 0.171)\tLoss 2.3283e-01 (1.1522e-01)\tAcc@1  92.97 ( 96.86)\tAcc@5  98.44 ( 99.58)\n","Epoch: [136][240/391]\tTime  0.171 ( 0.171)\tLoss 5.2019e-02 (1.1378e-01)\tAcc@1  99.22 ( 96.88)\tAcc@5 100.00 ( 99.57)\n","Epoch: [136][270/391]\tTime  0.171 ( 0.171)\tLoss 1.1695e-01 (1.1397e-01)\tAcc@1  96.88 ( 96.90)\tAcc@5 100.00 ( 99.56)\n","Epoch: [136][300/391]\tTime  0.171 ( 0.171)\tLoss 1.1833e-01 (1.1520e-01)\tAcc@1  97.66 ( 96.88)\tAcc@5  99.22 ( 99.56)\n","Epoch: [136][330/391]\tTime  0.171 ( 0.171)\tLoss 6.8241e-02 (1.1462e-01)\tAcc@1  97.66 ( 96.90)\tAcc@5 100.00 ( 99.56)\n","Epoch: [136][360/391]\tTime  0.171 ( 0.171)\tLoss 7.4171e-02 (1.1621e-01)\tAcc@1  97.66 ( 96.84)\tAcc@5 100.00 ( 99.54)\n","Epoch: [136][390/391]\tTime  0.153 ( 0.171)\tLoss 2.1146e-01 (1.1645e-01)\tAcc@1  92.50 ( 96.84)\tAcc@5 100.00 ( 99.55)\n","==> Train Accuracy: Acc@1 96.840 || Acc@5 99.548\n","==> Test Accuracy:  Acc@1 79.100 || Acc@5 94.440\n","==> 70.86 seconds to train this epoch\n","\n","\n","----- epoch: 137, lr: 0.0008000000000000003 -----\n","Epoch: [137][  0/391]\tTime  0.294 ( 0.294)\tLoss 8.4280e-02 (8.4280e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [137][ 30/391]\tTime  0.171 ( 0.174)\tLoss 9.9391e-02 (1.0151e-01)\tAcc@1  97.66 ( 97.15)\tAcc@5 100.00 ( 99.80)\n","Epoch: [137][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.6414e-01 (1.1917e-01)\tAcc@1  95.31 ( 96.66)\tAcc@5  99.22 ( 99.60)\n","Epoch: [137][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.7096e-01 (1.1936e-01)\tAcc@1  96.09 ( 96.72)\tAcc@5  99.22 ( 99.61)\n","Epoch: [137][120/391]\tTime  0.169 ( 0.171)\tLoss 9.1932e-02 (1.1834e-01)\tAcc@1  97.66 ( 96.73)\tAcc@5  99.22 ( 99.61)\n","Epoch: [137][150/391]\tTime  0.171 ( 0.171)\tLoss 1.8334e-01 (1.1927e-01)\tAcc@1  96.09 ( 96.77)\tAcc@5 100.00 ( 99.57)\n","Epoch: [137][180/391]\tTime  0.171 ( 0.171)\tLoss 1.1044e-01 (1.1902e-01)\tAcc@1  97.66 ( 96.78)\tAcc@5 100.00 ( 99.59)\n","Epoch: [137][210/391]\tTime  0.171 ( 0.171)\tLoss 2.4232e-02 (1.1752e-01)\tAcc@1 100.00 ( 96.84)\tAcc@5 100.00 ( 99.60)\n","Epoch: [137][240/391]\tTime  0.166 ( 0.171)\tLoss 5.5486e-02 (1.1663e-01)\tAcc@1  99.22 ( 96.85)\tAcc@5 100.00 ( 99.60)\n","Epoch: [137][270/391]\tTime  0.171 ( 0.171)\tLoss 1.0596e-01 (1.1507e-01)\tAcc@1  96.09 ( 96.90)\tAcc@5  99.22 ( 99.60)\n","Epoch: [137][300/391]\tTime  0.170 ( 0.171)\tLoss 1.0443e-01 (1.1561e-01)\tAcc@1  96.88 ( 96.87)\tAcc@5 100.00 ( 99.59)\n","Epoch: [137][330/391]\tTime  0.171 ( 0.171)\tLoss 4.8443e-02 (1.1505e-01)\tAcc@1  99.22 ( 96.86)\tAcc@5 100.00 ( 99.59)\n","Epoch: [137][360/391]\tTime  0.170 ( 0.171)\tLoss 5.3762e-02 (1.1564e-01)\tAcc@1  99.22 ( 96.83)\tAcc@5 100.00 ( 99.60)\n","Epoch: [137][390/391]\tTime  0.152 ( 0.170)\tLoss 1.0851e-01 (1.1538e-01)\tAcc@1  95.00 ( 96.85)\tAcc@5 100.00 ( 99.59)\n","==> Train Accuracy: Acc@1 96.850 || Acc@5 99.594\n","==> Test Accuracy:  Acc@1 79.050 || Acc@5 94.630\n","==> 70.86 seconds to train this epoch\n","\n","\n","----- epoch: 138, lr: 0.0008000000000000003 -----\n","Epoch: [138][  0/391]\tTime  0.279 ( 0.279)\tLoss 7.1856e-02 (7.1856e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5  99.22 ( 99.22)\n","Epoch: [138][ 30/391]\tTime  0.170 ( 0.173)\tLoss 6.2287e-02 (1.0576e-01)\tAcc@1  98.44 ( 97.08)\tAcc@5 100.00 ( 99.52)\n","Epoch: [138][ 60/391]\tTime  0.170 ( 0.172)\tLoss 6.9776e-02 (1.0807e-01)\tAcc@1  97.66 ( 97.08)\tAcc@5 100.00 ( 99.53)\n","Epoch: [138][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.5821e-01 (1.1317e-01)\tAcc@1  96.09 ( 96.94)\tAcc@5  99.22 ( 99.48)\n","Epoch: [138][120/391]\tTime  0.168 ( 0.171)\tLoss 8.7356e-02 (1.1011e-01)\tAcc@1  97.66 ( 97.02)\tAcc@5  99.22 ( 99.48)\n","Epoch: [138][150/391]\tTime  0.169 ( 0.171)\tLoss 1.0094e-01 (1.0960e-01)\tAcc@1  96.88 ( 97.06)\tAcc@5 100.00 ( 99.53)\n","Epoch: [138][180/391]\tTime  0.170 ( 0.171)\tLoss 7.3847e-02 (1.0959e-01)\tAcc@1  98.44 ( 97.03)\tAcc@5 100.00 ( 99.56)\n","Epoch: [138][210/391]\tTime  0.171 ( 0.171)\tLoss 1.9256e-01 (1.0925e-01)\tAcc@1  95.31 ( 97.03)\tAcc@5  97.66 ( 99.57)\n","Epoch: [138][240/391]\tTime  0.171 ( 0.171)\tLoss 9.7226e-02 (1.1089e-01)\tAcc@1  96.88 ( 97.00)\tAcc@5 100.00 ( 99.58)\n","Epoch: [138][270/391]\tTime  0.172 ( 0.171)\tLoss 9.8746e-02 (1.0973e-01)\tAcc@1  97.66 ( 97.05)\tAcc@5  99.22 ( 99.58)\n","Epoch: [138][300/391]\tTime  0.169 ( 0.171)\tLoss 1.1139e-01 (1.0990e-01)\tAcc@1  96.88 ( 97.05)\tAcc@5 100.00 ( 99.58)\n","Epoch: [138][330/391]\tTime  0.170 ( 0.171)\tLoss 9.5146e-02 (1.1008e-01)\tAcc@1  98.44 ( 97.05)\tAcc@5  99.22 ( 99.58)\n","Epoch: [138][360/391]\tTime  0.170 ( 0.170)\tLoss 1.0616e-01 (1.0959e-01)\tAcc@1  97.66 ( 97.04)\tAcc@5 100.00 ( 99.59)\n","Epoch: [138][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3984e-01 (1.0890e-01)\tAcc@1  96.25 ( 97.06)\tAcc@5  98.75 ( 99.60)\n","==> Train Accuracy: Acc@1 97.064 || Acc@5 99.600\n","==> Test Accuracy:  Acc@1 78.870 || Acc@5 94.590\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 139, lr: 0.0008000000000000003 -----\n","Epoch: [139][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.1395e-01 (1.1395e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [139][ 30/391]\tTime  0.171 ( 0.174)\tLoss 9.0087e-02 (1.0038e-01)\tAcc@1  98.44 ( 97.23)\tAcc@5 100.00 ( 99.70)\n","Epoch: [139][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.6099e-01 (1.1482e-01)\tAcc@1  94.53 ( 96.80)\tAcc@5  98.44 ( 99.58)\n","Epoch: [139][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.0473e-01 (1.1458e-01)\tAcc@1  96.88 ( 96.81)\tAcc@5 100.00 ( 99.59)\n","Epoch: [139][120/391]\tTime  0.170 ( 0.171)\tLoss 1.4298e-01 (1.1495e-01)\tAcc@1  96.09 ( 96.80)\tAcc@5  98.44 ( 99.53)\n","Epoch: [139][150/391]\tTime  0.170 ( 0.171)\tLoss 1.1392e-01 (1.1535e-01)\tAcc@1  97.66 ( 96.85)\tAcc@5 100.00 ( 99.53)\n","Epoch: [139][180/391]\tTime  0.170 ( 0.171)\tLoss 1.6679e-01 (1.1442e-01)\tAcc@1  95.31 ( 96.87)\tAcc@5  98.44 ( 99.53)\n","Epoch: [139][210/391]\tTime  0.171 ( 0.171)\tLoss 5.4151e-02 (1.1546e-01)\tAcc@1  99.22 ( 96.90)\tAcc@5 100.00 ( 99.49)\n","Epoch: [139][240/391]\tTime  0.170 ( 0.171)\tLoss 1.5663e-01 (1.1359e-01)\tAcc@1  93.75 ( 96.93)\tAcc@5 100.00 ( 99.52)\n","Epoch: [139][270/391]\tTime  0.170 ( 0.171)\tLoss 6.2525e-02 (1.1246e-01)\tAcc@1  98.44 ( 96.96)\tAcc@5 100.00 ( 99.55)\n","Epoch: [139][300/391]\tTime  0.171 ( 0.171)\tLoss 1.1876e-01 (1.1188e-01)\tAcc@1  97.66 ( 96.95)\tAcc@5  99.22 ( 99.58)\n","Epoch: [139][330/391]\tTime  0.170 ( 0.171)\tLoss 1.8991e-01 (1.1131e-01)\tAcc@1  95.31 ( 96.98)\tAcc@5  99.22 ( 99.58)\n","Epoch: [139][360/391]\tTime  0.169 ( 0.171)\tLoss 1.0800e-01 (1.1116e-01)\tAcc@1  98.44 ( 96.99)\tAcc@5  99.22 ( 99.58)\n","Epoch: [139][390/391]\tTime  0.153 ( 0.170)\tLoss 1.1051e-01 (1.1058e-01)\tAcc@1  96.25 ( 97.01)\tAcc@5 100.00 ( 99.59)\n","==> Train Accuracy: Acc@1 97.008 || Acc@5 99.586\n","==> Test Accuracy:  Acc@1 79.050 || Acc@5 94.550\n","==> 70.84 seconds to train this epoch\n","\n","\n","----- epoch: 140, lr: 0.0008000000000000003 -----\n","Epoch: [140][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.1527e-01 (1.1527e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [140][ 30/391]\tTime  0.170 ( 0.173)\tLoss 8.2576e-02 (1.0070e-01)\tAcc@1  96.88 ( 97.28)\tAcc@5 100.00 ( 99.65)\n","Epoch: [140][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.0986e-01 (1.1218e-01)\tAcc@1  97.66 ( 97.07)\tAcc@5 100.00 ( 99.58)\n","Epoch: [140][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.1972e-01 (1.1876e-01)\tAcc@1  95.31 ( 96.80)\tAcc@5 100.00 ( 99.52)\n","Epoch: [140][120/391]\tTime  0.169 ( 0.171)\tLoss 1.2546e-01 (1.1361e-01)\tAcc@1  96.88 ( 96.97)\tAcc@5 100.00 ( 99.54)\n","Epoch: [140][150/391]\tTime  0.171 ( 0.171)\tLoss 1.1603e-01 (1.1227e-01)\tAcc@1  96.88 ( 97.01)\tAcc@5 100.00 ( 99.58)\n","Epoch: [140][180/391]\tTime  0.171 ( 0.171)\tLoss 6.3314e-02 (1.1249e-01)\tAcc@1  98.44 ( 97.02)\tAcc@5 100.00 ( 99.56)\n","Epoch: [140][210/391]\tTime  0.170 ( 0.171)\tLoss 7.9745e-02 (1.1370e-01)\tAcc@1  96.88 ( 96.97)\tAcc@5 100.00 ( 99.56)\n","Epoch: [140][240/391]\tTime  0.171 ( 0.171)\tLoss 5.7507e-02 (1.1261e-01)\tAcc@1  99.22 ( 96.97)\tAcc@5 100.00 ( 99.57)\n","Epoch: [140][270/391]\tTime  0.169 ( 0.170)\tLoss 7.8604e-02 (1.1203e-01)\tAcc@1  96.88 ( 96.99)\tAcc@5 100.00 ( 99.57)\n","Epoch: [140][300/391]\tTime  0.169 ( 0.170)\tLoss 1.7110e-01 (1.1305e-01)\tAcc@1  95.31 ( 96.94)\tAcc@5 100.00 ( 99.57)\n","Epoch: [140][330/391]\tTime  0.169 ( 0.170)\tLoss 1.1970e-01 (1.1222e-01)\tAcc@1  96.88 ( 96.96)\tAcc@5  99.22 ( 99.57)\n","Epoch: [140][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3979e-01 (1.1242e-01)\tAcc@1  95.31 ( 96.96)\tAcc@5  99.22 ( 99.56)\n","Epoch: [140][390/391]\tTime  0.153 ( 0.170)\tLoss 1.2606e-01 (1.1191e-01)\tAcc@1  96.25 ( 96.98)\tAcc@5 100.00 ( 99.57)\n","==> Train Accuracy: Acc@1 96.980 || Acc@5 99.570\n","==> Test Accuracy:  Acc@1 79.130 || Acc@5 94.680\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 141, lr: 0.0008000000000000003 -----\n","Epoch: [141][  0/391]\tTime  0.293 ( 0.293)\tLoss 4.2352e-02 (4.2352e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [141][ 30/391]\tTime  0.171 ( 0.174)\tLoss 1.0340e-01 (1.1326e-01)\tAcc@1  97.66 ( 96.85)\tAcc@5  99.22 ( 99.55)\n","Epoch: [141][ 60/391]\tTime  0.170 ( 0.172)\tLoss 6.3706e-02 (1.0671e-01)\tAcc@1  99.22 ( 97.04)\tAcc@5 100.00 ( 99.63)\n","Epoch: [141][ 90/391]\tTime  0.169 ( 0.171)\tLoss 6.2328e-02 (1.0690e-01)\tAcc@1  98.44 ( 97.03)\tAcc@5 100.00 ( 99.64)\n","Epoch: [141][120/391]\tTime  0.170 ( 0.171)\tLoss 9.1791e-02 (1.1123e-01)\tAcc@1  96.09 ( 96.93)\tAcc@5 100.00 ( 99.59)\n","Epoch: [141][150/391]\tTime  0.169 ( 0.171)\tLoss 1.2285e-01 (1.1220e-01)\tAcc@1  96.09 ( 96.92)\tAcc@5 100.00 ( 99.57)\n","Epoch: [141][180/391]\tTime  0.170 ( 0.170)\tLoss 1.7107e-01 (1.1066e-01)\tAcc@1  95.31 ( 96.97)\tAcc@5  99.22 ( 99.58)\n","Epoch: [141][210/391]\tTime  0.169 ( 0.170)\tLoss 7.5962e-02 (1.0978e-01)\tAcc@1  99.22 ( 96.96)\tAcc@5 100.00 ( 99.59)\n","Epoch: [141][240/391]\tTime  0.170 ( 0.170)\tLoss 1.1715e-01 (1.1036e-01)\tAcc@1  96.09 ( 96.95)\tAcc@5 100.00 ( 99.58)\n","Epoch: [141][270/391]\tTime  0.169 ( 0.170)\tLoss 1.2040e-01 (1.1030e-01)\tAcc@1  96.88 ( 96.91)\tAcc@5 100.00 ( 99.59)\n","Epoch: [141][300/391]\tTime  0.170 ( 0.170)\tLoss 7.4517e-02 (1.1042e-01)\tAcc@1  97.66 ( 96.92)\tAcc@5 100.00 ( 99.59)\n","Epoch: [141][330/391]\tTime  0.171 ( 0.170)\tLoss 1.5119e-01 (1.1083e-01)\tAcc@1  96.09 ( 96.90)\tAcc@5  98.44 ( 99.58)\n","Epoch: [141][360/391]\tTime  0.171 ( 0.170)\tLoss 6.8701e-02 (1.0977e-01)\tAcc@1  98.44 ( 96.94)\tAcc@5 100.00 ( 99.59)\n","Epoch: [141][390/391]\tTime  0.153 ( 0.170)\tLoss 2.2795e-01 (1.0974e-01)\tAcc@1  93.75 ( 96.95)\tAcc@5  98.75 ( 99.58)\n","==> Train Accuracy: Acc@1 96.952 || Acc@5 99.582\n","==> Test Accuracy:  Acc@1 78.980 || Acc@5 94.570\n","==> 70.67 seconds to train this epoch\n","\n","\n","----- epoch: 142, lr: 0.0008000000000000003 -----\n","Epoch: [142][  0/391]\tTime  0.280 ( 0.280)\tLoss 8.3968e-02 (8.3968e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [142][ 30/391]\tTime  0.172 ( 0.173)\tLoss 9.3268e-02 (1.0891e-01)\tAcc@1  96.88 ( 96.95)\tAcc@5 100.00 ( 99.60)\n","Epoch: [142][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.3260e-01 (1.1348e-01)\tAcc@1  96.88 ( 96.95)\tAcc@5 100.00 ( 99.56)\n","Epoch: [142][ 90/391]\tTime  0.171 ( 0.171)\tLoss 1.1892e-01 (1.1532e-01)\tAcc@1  95.31 ( 96.81)\tAcc@5 100.00 ( 99.60)\n","Epoch: [142][120/391]\tTime  0.169 ( 0.171)\tLoss 1.0509e-01 (1.1280e-01)\tAcc@1  96.88 ( 96.91)\tAcc@5 100.00 ( 99.63)\n","Epoch: [142][150/391]\tTime  0.172 ( 0.171)\tLoss 1.6564e-01 (1.1303e-01)\tAcc@1  94.53 ( 96.93)\tAcc@5 100.00 ( 99.61)\n","Epoch: [142][180/391]\tTime  0.170 ( 0.170)\tLoss 1.4870e-01 (1.1150e-01)\tAcc@1  96.09 ( 96.97)\tAcc@5  99.22 ( 99.62)\n","Epoch: [142][210/391]\tTime  0.169 ( 0.170)\tLoss 1.8095e-01 (1.0956e-01)\tAcc@1  96.09 ( 97.03)\tAcc@5 100.00 ( 99.64)\n","Epoch: [142][240/391]\tTime  0.173 ( 0.170)\tLoss 4.5226e-02 (1.0675e-01)\tAcc@1  99.22 ( 97.11)\tAcc@5 100.00 ( 99.67)\n","Epoch: [142][270/391]\tTime  0.170 ( 0.170)\tLoss 5.4432e-02 (1.0505e-01)\tAcc@1  98.44 ( 97.14)\tAcc@5 100.00 ( 99.67)\n","Epoch: [142][300/391]\tTime  0.170 ( 0.170)\tLoss 1.5196e-01 (1.0549e-01)\tAcc@1  94.53 ( 97.13)\tAcc@5  99.22 ( 99.65)\n","Epoch: [142][330/391]\tTime  0.170 ( 0.170)\tLoss 1.2609e-01 (1.0536e-01)\tAcc@1  97.66 ( 97.17)\tAcc@5  98.44 ( 99.65)\n","Epoch: [142][360/391]\tTime  0.171 ( 0.170)\tLoss 1.4775e-01 (1.0493e-01)\tAcc@1  97.66 ( 97.18)\tAcc@5  99.22 ( 99.66)\n","Epoch: [142][390/391]\tTime  0.154 ( 0.170)\tLoss 1.4130e-01 (1.0553e-01)\tAcc@1  97.50 ( 97.17)\tAcc@5 100.00 ( 99.66)\n","==> Train Accuracy: Acc@1 97.168 || Acc@5 99.662\n","==> Test Accuracy:  Acc@1 78.850 || Acc@5 94.580\n","==> 70.73 seconds to train this epoch\n","\n","\n","----- epoch: 143, lr: 0.0008000000000000003 -----\n","Epoch: [143][  0/391]\tTime  0.290 ( 0.290)\tLoss 6.1801e-02 (6.1801e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [143][ 30/391]\tTime  0.169 ( 0.174)\tLoss 7.0391e-02 (1.0085e-01)\tAcc@1  98.44 ( 97.30)\tAcc@5 100.00 ( 99.70)\n","Epoch: [143][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.5553e-01 (1.1115e-01)\tAcc@1  95.31 ( 97.08)\tAcc@5  99.22 ( 99.47)\n","Epoch: [143][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.7951e-01 (1.0976e-01)\tAcc@1  95.31 ( 97.11)\tAcc@5 100.00 ( 99.50)\n","Epoch: [143][120/391]\tTime  0.170 ( 0.171)\tLoss 5.2931e-02 (1.0656e-01)\tAcc@1  99.22 ( 97.13)\tAcc@5 100.00 ( 99.57)\n","Epoch: [143][150/391]\tTime  0.171 ( 0.171)\tLoss 8.6016e-02 (1.0733e-01)\tAcc@1  97.66 ( 97.10)\tAcc@5 100.00 ( 99.57)\n","Epoch: [143][180/391]\tTime  0.170 ( 0.171)\tLoss 1.1878e-01 (1.0824e-01)\tAcc@1  97.66 ( 97.04)\tAcc@5 100.00 ( 99.58)\n","Epoch: [143][210/391]\tTime  0.169 ( 0.171)\tLoss 1.1507e-01 (1.0735e-01)\tAcc@1  97.66 ( 97.09)\tAcc@5 100.00 ( 99.59)\n","Epoch: [143][240/391]\tTime  0.168 ( 0.170)\tLoss 1.3061e-01 (1.0681e-01)\tAcc@1  95.31 ( 97.10)\tAcc@5  99.22 ( 99.59)\n","Epoch: [143][270/391]\tTime  0.171 ( 0.170)\tLoss 1.2573e-01 (1.0616e-01)\tAcc@1  96.88 ( 97.13)\tAcc@5 100.00 ( 99.59)\n","Epoch: [143][300/391]\tTime  0.169 ( 0.170)\tLoss 2.6133e-02 (1.0690e-01)\tAcc@1 100.00 ( 97.11)\tAcc@5 100.00 ( 99.60)\n","Epoch: [143][330/391]\tTime  0.171 ( 0.170)\tLoss 1.1535e-01 (1.0772e-01)\tAcc@1  96.09 ( 97.09)\tAcc@5 100.00 ( 99.59)\n","Epoch: [143][360/391]\tTime  0.169 ( 0.170)\tLoss 1.1530e-01 (1.0766e-01)\tAcc@1  97.66 ( 97.10)\tAcc@5 100.00 ( 99.59)\n","Epoch: [143][390/391]\tTime  0.154 ( 0.170)\tLoss 1.2207e-01 (1.0795e-01)\tAcc@1  97.50 ( 97.11)\tAcc@5  98.75 ( 99.59)\n","==> Train Accuracy: Acc@1 97.112 || Acc@5 99.586\n","==> Test Accuracy:  Acc@1 78.940 || Acc@5 94.380\n","==> 70.76 seconds to train this epoch\n","\n","\n","----- epoch: 144, lr: 0.0008000000000000003 -----\n","Epoch: [144][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.2873e-01 (1.2873e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [144][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.8033e-01 (1.1283e-01)\tAcc@1  96.09 ( 97.15)\tAcc@5  98.44 ( 99.57)\n","Epoch: [144][ 60/391]\tTime  0.168 ( 0.172)\tLoss 1.4995e-01 (1.0294e-01)\tAcc@1  97.66 ( 97.35)\tAcc@5  99.22 ( 99.60)\n","Epoch: [144][ 90/391]\tTime  0.171 ( 0.171)\tLoss 8.0509e-02 (1.0727e-01)\tAcc@1  97.66 ( 97.15)\tAcc@5 100.00 ( 99.55)\n","Epoch: [144][120/391]\tTime  0.170 ( 0.171)\tLoss 9.1324e-02 (1.0646e-01)\tAcc@1  96.88 ( 97.09)\tAcc@5 100.00 ( 99.57)\n","Epoch: [144][150/391]\tTime  0.171 ( 0.171)\tLoss 7.8554e-02 (1.0383e-01)\tAcc@1  98.44 ( 97.18)\tAcc@5 100.00 ( 99.59)\n","Epoch: [144][180/391]\tTime  0.170 ( 0.171)\tLoss 7.4844e-02 (1.0528e-01)\tAcc@1  98.44 ( 97.16)\tAcc@5  99.22 ( 99.57)\n","Epoch: [144][210/391]\tTime  0.170 ( 0.171)\tLoss 1.4017e-01 (1.0701e-01)\tAcc@1  96.88 ( 97.10)\tAcc@5  99.22 ( 99.57)\n","Epoch: [144][240/391]\tTime  0.171 ( 0.170)\tLoss 1.0234e-01 (1.0738e-01)\tAcc@1  98.44 ( 97.10)\tAcc@5  98.44 ( 99.57)\n","Epoch: [144][270/391]\tTime  0.170 ( 0.170)\tLoss 9.5777e-02 (1.0705e-01)\tAcc@1  96.09 ( 97.11)\tAcc@5 100.00 ( 99.58)\n","Epoch: [144][300/391]\tTime  0.169 ( 0.170)\tLoss 1.0422e-01 (1.0791e-01)\tAcc@1  96.09 ( 97.08)\tAcc@5 100.00 ( 99.57)\n","Epoch: [144][330/391]\tTime  0.171 ( 0.170)\tLoss 2.8326e-02 (1.0779e-01)\tAcc@1  99.22 ( 97.08)\tAcc@5 100.00 ( 99.58)\n","Epoch: [144][360/391]\tTime  0.171 ( 0.170)\tLoss 1.2110e-01 (1.0837e-01)\tAcc@1  96.88 ( 97.09)\tAcc@5 100.00 ( 99.57)\n","Epoch: [144][390/391]\tTime  0.154 ( 0.170)\tLoss 3.1407e-02 (1.0785e-01)\tAcc@1  98.75 ( 97.09)\tAcc@5 100.00 ( 99.58)\n","==> Train Accuracy: Acc@1 97.094 || Acc@5 99.578\n","==> Test Accuracy:  Acc@1 78.970 || Acc@5 94.390\n","==> 70.77 seconds to train this epoch\n","\n","\n","----- epoch: 145, lr: 0.0008000000000000003 -----\n","Epoch: [145][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.5803e-01 (1.5803e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [145][ 30/391]\tTime  0.171 ( 0.173)\tLoss 8.7003e-02 (1.1816e-01)\tAcc@1  96.09 ( 96.88)\tAcc@5 100.00 ( 99.47)\n","Epoch: [145][ 60/391]\tTime  0.169 ( 0.172)\tLoss 2.4724e-02 (1.0878e-01)\tAcc@1  99.22 ( 97.22)\tAcc@5 100.00 ( 99.55)\n","Epoch: [145][ 90/391]\tTime  0.169 ( 0.171)\tLoss 8.5087e-02 (1.0748e-01)\tAcc@1  96.88 ( 97.23)\tAcc@5 100.00 ( 99.53)\n","Epoch: [145][120/391]\tTime  0.170 ( 0.171)\tLoss 1.0674e-01 (1.0696e-01)\tAcc@1  96.09 ( 97.24)\tAcc@5 100.00 ( 99.54)\n","Epoch: [145][150/391]\tTime  0.170 ( 0.171)\tLoss 1.0760e-01 (1.0600e-01)\tAcc@1  96.88 ( 97.20)\tAcc@5 100.00 ( 99.59)\n","Epoch: [145][180/391]\tTime  0.170 ( 0.171)\tLoss 1.1648e-01 (1.0777e-01)\tAcc@1  96.88 ( 97.12)\tAcc@5  99.22 ( 99.56)\n","Epoch: [145][210/391]\tTime  0.169 ( 0.170)\tLoss 1.4586e-01 (1.0780e-01)\tAcc@1  96.88 ( 97.11)\tAcc@5  99.22 ( 99.58)\n","Epoch: [145][240/391]\tTime  0.168 ( 0.170)\tLoss 1.5240e-01 (1.0775e-01)\tAcc@1  93.75 ( 97.07)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][270/391]\tTime  0.170 ( 0.170)\tLoss 1.0388e-01 (1.0808e-01)\tAcc@1  96.88 ( 97.06)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][300/391]\tTime  0.170 ( 0.170)\tLoss 1.0326e-01 (1.0826e-01)\tAcc@1  97.66 ( 97.07)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][330/391]\tTime  0.170 ( 0.170)\tLoss 5.6077e-02 (1.0738e-01)\tAcc@1  98.44 ( 97.11)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][360/391]\tTime  0.171 ( 0.170)\tLoss 7.9830e-02 (1.0713e-01)\tAcc@1  98.44 ( 97.12)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][390/391]\tTime  0.154 ( 0.170)\tLoss 1.1582e-01 (1.0627e-01)\tAcc@1  95.00 ( 97.13)\tAcc@5 100.00 ( 99.62)\n","==> Train Accuracy: Acc@1 97.134 || Acc@5 99.618\n","==> Test Accuracy:  Acc@1 78.850 || Acc@5 94.370\n","==> 70.75 seconds to train this epoch\n","\n","\n","----- epoch: 146, lr: 0.0008000000000000003 -----\n","Epoch: [146][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.0221e-01 (1.0221e-01)\tAcc@1  98.44 ( 98.44)\tAcc@5  99.22 ( 99.22)\n","Epoch: [146][ 30/391]\tTime  0.171 ( 0.173)\tLoss 7.6737e-02 (1.0475e-01)\tAcc@1  99.22 ( 97.18)\tAcc@5 100.00 ( 99.70)\n","Epoch: [146][ 60/391]\tTime  0.171 ( 0.172)\tLoss 1.1016e-01 (1.0940e-01)\tAcc@1  96.88 ( 97.03)\tAcc@5 100.00 ( 99.64)\n","Epoch: [146][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.9532e-01 (1.0659e-01)\tAcc@1  96.09 ( 97.08)\tAcc@5  98.44 ( 99.63)\n","Epoch: [146][120/391]\tTime  0.171 ( 0.171)\tLoss 7.5752e-02 (1.0473e-01)\tAcc@1  99.22 ( 97.17)\tAcc@5 100.00 ( 99.65)\n","Epoch: [146][150/391]\tTime  0.169 ( 0.171)\tLoss 1.1295e-01 (1.0561e-01)\tAcc@1  97.66 ( 97.13)\tAcc@5  99.22 ( 99.66)\n","Epoch: [146][180/391]\tTime  0.169 ( 0.171)\tLoss 1.3889e-01 (1.0702e-01)\tAcc@1  95.31 ( 97.09)\tAcc@5  99.22 ( 99.63)\n","Epoch: [146][210/391]\tTime  0.170 ( 0.171)\tLoss 8.8226e-02 (1.0731e-01)\tAcc@1  97.66 ( 97.11)\tAcc@5 100.00 ( 99.61)\n","Epoch: [146][240/391]\tTime  0.170 ( 0.171)\tLoss 8.9797e-02 (1.0688e-01)\tAcc@1  97.66 ( 97.11)\tAcc@5  99.22 ( 99.62)\n","Epoch: [146][270/391]\tTime  0.169 ( 0.170)\tLoss 1.1145e-01 (1.0554e-01)\tAcc@1  96.09 ( 97.13)\tAcc@5 100.00 ( 99.65)\n","Epoch: [146][300/391]\tTime  0.171 ( 0.170)\tLoss 1.1378e-01 (1.0558e-01)\tAcc@1  97.66 ( 97.13)\tAcc@5  99.22 ( 99.64)\n","Epoch: [146][330/391]\tTime  0.171 ( 0.170)\tLoss 5.0717e-02 (1.0412e-01)\tAcc@1  99.22 ( 97.20)\tAcc@5 100.00 ( 99.64)\n","Epoch: [146][360/391]\tTime  0.170 ( 0.170)\tLoss 1.1872e-01 (1.0390e-01)\tAcc@1  96.09 ( 97.19)\tAcc@5 100.00 ( 99.65)\n","Epoch: [146][390/391]\tTime  0.152 ( 0.170)\tLoss 8.5574e-02 (1.0343e-01)\tAcc@1  98.75 ( 97.21)\tAcc@5 100.00 ( 99.65)\n","==> Train Accuracy: Acc@1 97.214 || Acc@5 99.648\n","==> Test Accuracy:  Acc@1 79.090 || Acc@5 94.350\n","==> 70.80 seconds to train this epoch\n","\n","\n","----- epoch: 147, lr: 0.0008000000000000003 -----\n","Epoch: [147][  0/391]\tTime  0.284 ( 0.284)\tLoss 4.5886e-02 (4.5886e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [147][ 30/391]\tTime  0.170 ( 0.174)\tLoss 1.2958e-01 (1.2174e-01)\tAcc@1  96.88 ( 96.55)\tAcc@5 100.00 ( 99.57)\n","Epoch: [147][ 60/391]\tTime  0.169 ( 0.172)\tLoss 1.1473e-01 (1.0794e-01)\tAcc@1  97.66 ( 97.00)\tAcc@5 100.00 ( 99.69)\n","Epoch: [147][ 90/391]\tTime  0.170 ( 0.171)\tLoss 1.3551e-01 (1.0916e-01)\tAcc@1  96.88 ( 97.00)\tAcc@5 100.00 ( 99.62)\n","Epoch: [147][120/391]\tTime  0.170 ( 0.171)\tLoss 1.3122e-01 (1.0860e-01)\tAcc@1  96.88 ( 96.96)\tAcc@5  99.22 ( 99.66)\n","Epoch: [147][150/391]\tTime  0.170 ( 0.171)\tLoss 1.4366e-01 (1.0978e-01)\tAcc@1  95.31 ( 96.94)\tAcc@5 100.00 ( 99.63)\n","Epoch: [147][180/391]\tTime  0.171 ( 0.171)\tLoss 9.5409e-02 (1.1074e-01)\tAcc@1  98.44 ( 96.95)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][210/391]\tTime  0.169 ( 0.171)\tLoss 8.9944e-02 (1.1013e-01)\tAcc@1  98.44 ( 96.99)\tAcc@5 100.00 ( 99.64)\n","Epoch: [147][240/391]\tTime  0.170 ( 0.171)\tLoss 7.3144e-02 (1.0748e-01)\tAcc@1  97.66 ( 97.07)\tAcc@5 100.00 ( 99.67)\n","Epoch: [147][270/391]\tTime  0.171 ( 0.171)\tLoss 9.1942e-02 (1.0710e-01)\tAcc@1  97.66 ( 97.10)\tAcc@5  99.22 ( 99.65)\n","Epoch: [147][300/391]\tTime  0.171 ( 0.171)\tLoss 2.2488e-01 (1.0798e-01)\tAcc@1  93.75 ( 97.10)\tAcc@5  98.44 ( 99.63)\n","Epoch: [147][330/391]\tTime  0.170 ( 0.170)\tLoss 6.9412e-02 (1.0785e-01)\tAcc@1  98.44 ( 97.09)\tAcc@5 100.00 ( 99.63)\n","Epoch: [147][360/391]\tTime  0.170 ( 0.170)\tLoss 1.3012e-01 (1.0680e-01)\tAcc@1  96.09 ( 97.12)\tAcc@5 100.00 ( 99.65)\n","Epoch: [147][390/391]\tTime  0.152 ( 0.170)\tLoss 6.2247e-02 (1.0497e-01)\tAcc@1  98.75 ( 97.18)\tAcc@5 100.00 ( 99.66)\n","==> Train Accuracy: Acc@1 97.180 || Acc@5 99.658\n","==> Test Accuracy:  Acc@1 78.870 || Acc@5 94.240\n","==> 70.82 seconds to train this epoch\n","\n","\n","----- epoch: 148, lr: 0.0008000000000000003 -----\n","Epoch: [148][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.0198e-01 (1.0198e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [148][ 30/391]\tTime  0.171 ( 0.174)\tLoss 7.4244e-02 (9.4482e-02)\tAcc@1  96.88 ( 97.48)\tAcc@5 100.00 ( 99.75)\n","Epoch: [148][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.5244e-01 (9.3304e-02)\tAcc@1  97.66 ( 97.55)\tAcc@5  98.44 ( 99.67)\n","Epoch: [148][ 90/391]\tTime  0.170 ( 0.171)\tLoss 6.0215e-02 (9.5883e-02)\tAcc@1  99.22 ( 97.50)\tAcc@5 100.00 ( 99.61)\n","Epoch: [148][120/391]\tTime  0.170 ( 0.171)\tLoss 9.9311e-02 (9.5270e-02)\tAcc@1  98.44 ( 97.58)\tAcc@5 100.00 ( 99.63)\n","Epoch: [148][150/391]\tTime  0.171 ( 0.171)\tLoss 9.8048e-02 (9.7972e-02)\tAcc@1  96.88 ( 97.46)\tAcc@5 100.00 ( 99.64)\n","Epoch: [148][180/391]\tTime  0.170 ( 0.171)\tLoss 8.4507e-02 (1.0024e-01)\tAcc@1  96.88 ( 97.35)\tAcc@5 100.00 ( 99.65)\n","Epoch: [148][210/391]\tTime  0.171 ( 0.171)\tLoss 2.0635e-01 (1.0083e-01)\tAcc@1  95.31 ( 97.33)\tAcc@5  98.44 ( 99.66)\n","Epoch: [148][240/391]\tTime  0.170 ( 0.171)\tLoss 8.0063e-02 (1.0210e-01)\tAcc@1  99.22 ( 97.30)\tAcc@5  99.22 ( 99.64)\n","Epoch: [148][270/391]\tTime  0.171 ( 0.171)\tLoss 1.6826e-01 (1.0181e-01)\tAcc@1  96.09 ( 97.28)\tAcc@5  99.22 ( 99.63)\n","Epoch: [148][300/391]\tTime  0.171 ( 0.171)\tLoss 1.1954e-01 (1.0335e-01)\tAcc@1  97.66 ( 97.23)\tAcc@5 100.00 ( 99.60)\n","Epoch: [148][330/391]\tTime  0.171 ( 0.170)\tLoss 4.4329e-02 (1.0232e-01)\tAcc@1  99.22 ( 97.26)\tAcc@5 100.00 ( 99.61)\n","Epoch: [148][360/391]\tTime  0.171 ( 0.170)\tLoss 2.2129e-01 (1.0278e-01)\tAcc@1  93.75 ( 97.25)\tAcc@5  98.44 ( 99.60)\n","Epoch: [148][390/391]\tTime  0.154 ( 0.170)\tLoss 4.1044e-02 (1.0283e-01)\tAcc@1 100.00 ( 97.26)\tAcc@5 100.00 ( 99.61)\n","==> Train Accuracy: Acc@1 97.256 || Acc@5 99.606\n","==> Test Accuracy:  Acc@1 78.930 || Acc@5 94.570\n","==> 70.83 seconds to train this epoch\n","\n","\n","----- epoch: 149, lr: 0.0008000000000000003 -----\n","Epoch: [149][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.6682e-01 (1.6682e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  98.44 ( 98.44)\n","Epoch: [149][ 30/391]\tTime  0.172 ( 0.173)\tLoss 1.1005e-01 (1.1374e-01)\tAcc@1  96.09 ( 96.88)\tAcc@5  99.22 ( 99.57)\n","Epoch: [149][ 60/391]\tTime  0.170 ( 0.172)\tLoss 1.2658e-01 (1.0498e-01)\tAcc@1  96.09 ( 97.23)\tAcc@5 100.00 ( 99.62)\n","Epoch: [149][ 90/391]\tTime  0.169 ( 0.171)\tLoss 8.7179e-02 (1.0434e-01)\tAcc@1  96.88 ( 97.18)\tAcc@5  99.22 ( 99.60)\n","Epoch: [149][120/391]\tTime  0.171 ( 0.171)\tLoss 1.1015e-01 (1.0186e-01)\tAcc@1  95.31 ( 97.26)\tAcc@5  99.22 ( 99.63)\n","Epoch: [149][150/391]\tTime  0.170 ( 0.171)\tLoss 9.6098e-02 (1.0260e-01)\tAcc@1  97.66 ( 97.26)\tAcc@5 100.00 ( 99.61)\n","Epoch: [149][180/391]\tTime  0.170 ( 0.171)\tLoss 6.4654e-02 (1.0241e-01)\tAcc@1  98.44 ( 97.27)\tAcc@5 100.00 ( 99.63)\n","Epoch: [149][210/391]\tTime  0.170 ( 0.171)\tLoss 3.3223e-02 (1.0195e-01)\tAcc@1 100.00 ( 97.29)\tAcc@5 100.00 ( 99.63)\n","Epoch: [149][240/391]\tTime  0.171 ( 0.171)\tLoss 8.1454e-02 (1.0141e-01)\tAcc@1  96.88 ( 97.31)\tAcc@5 100.00 ( 99.63)\n","Epoch: [149][270/391]\tTime  0.172 ( 0.171)\tLoss 6.9102e-02 (1.0256e-01)\tAcc@1  99.22 ( 97.26)\tAcc@5  99.22 ( 99.62)\n","Epoch: [149][300/391]\tTime  0.171 ( 0.171)\tLoss 3.8753e-02 (1.0330e-01)\tAcc@1  99.22 ( 97.23)\tAcc@5 100.00 ( 99.62)\n","Epoch: [149][330/391]\tTime  0.169 ( 0.170)\tLoss 1.8017e-01 (1.0432e-01)\tAcc@1  95.31 ( 97.20)\tAcc@5 100.00 ( 99.62)\n","Epoch: [149][360/391]\tTime  0.171 ( 0.170)\tLoss 2.0524e-01 (1.0585e-01)\tAcc@1  95.31 ( 97.15)\tAcc@5  99.22 ( 99.61)\n","Epoch: [149][390/391]\tTime  0.153 ( 0.170)\tLoss 1.3868e-01 (1.0482e-01)\tAcc@1  96.25 ( 97.20)\tAcc@5  98.75 ( 99.62)\n","==> Train Accuracy: Acc@1 97.200 || Acc@5 99.620\n","==> Test Accuracy:  Acc@1 79.100 || Acc@5 94.560\n","==> 70.81 seconds to train this epoch\n","\n","Best Top-1 Accuracy: 79.46\n"],"name":"stdout"}]}]}