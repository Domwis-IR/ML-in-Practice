{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RandomShadows","provenance":[{"file_id":"1NBZijnKI-JSQWMRa_ie6TIGgiCotY-oF","timestamp":1620412557373},{"file_id":"18b80wpeQD1Wj6NjwZFFhZGDuMWWW1TIZ","timestamp":1619286623952},{"file_id":"1pSPNcOLDPSKONSeGALl1Jplu9ET9z-1q","timestamp":1619081668342}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"907d0e8565a6423da6bcd922b72ed4c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_146732bdbfb54b1d9b3a8b2c0e666376","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_081a7c701d864f74a095df81fc8ca3a8","IPY_MODEL_9107cd0ec252469ab12e2bd580d62168"]}},"146732bdbfb54b1d9b3a8b2c0e666376":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"081a7c701d864f74a095df81fc8ca3a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0d97381f0d924522aae98451d3415b7c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e430b99df21f4904ad5fb8e91b2b0f77"}},"9107cd0ec252469ab12e2bd580d62168":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f935dd6905644a12b6218e76f503ea8b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [00:24&lt;00:00, 6976512.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_097395ee398d4604be95d2f610bfb0bd"}},"0d97381f0d924522aae98451d3415b7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e430b99df21f4904ad5fb8e91b2b0f77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f935dd6905644a12b6218e76f503ea8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"097395ee398d4604be95d2f610bfb0bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OSFGYaIDG6f0"},"source":["Cutout Data Augmentation.\n","\n","This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"]},{"cell_type":"markdown","metadata":{"id":"vCVSE5-UboYl"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"id":"5YBMwPsubsbX"},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L88afYXKMSdL"},"source":["##**Model - Define ResNet Model**\n"]},{"cell_type":"code","metadata":{"id":"eMFSLTnkMQdq"},"source":["'''ResNet18/34/50/101/152 in Pytorch.'''\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18(num_classes=10):\n","    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n","\n","def ResNet34(num_classes=10):\n","    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n","\n","def ResNet50(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n","\n","def ResNet101(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n","\n","def ResNet152(num_classes=10):\n","    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n","\n","def test_resnet():\n","    net = ResNet50()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test_resnet()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjM3cl279Lvg"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"gIvuSgE49Kvu"},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6y3zhSfMbdC"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"iMQI2K4AMopg"},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1zGEvEi9W_g"},"source":["##**Random-Shadows-Highlights**"]},{"cell_type":"code","metadata":{"id":"kElVGH4g9WoB"},"source":["import random\n","import numpy as np\n","import cv2\n","from PIL import Image, ImageChops\n","import torchvision.transforms.functional as TF\n","\n","class RandomShadows(object):\n","    def __init__(self, p=0.5, high_ratio=(1,2), low_ratio=(0.01, 0.5), left_low_ratio=(0.4,0.6), \\\n","    left_high_ratio=(0,0.2), right_low_ratio=(0.4,0.6), right_high_ratio = (0,0.2)):\n","        self.p = p\n","        self.high_ratio = high_ratio\n","        self.low_ratio = low_ratio\n","        self.left_low_ratio = left_low_ratio\n","        self.left_high_ratio = left_high_ratio\n","        self.right_low_ratio = right_low_ratio\n","        self.right_high_ratio = right_high_ratio\n","\n","    @staticmethod\n","    def process(img, high_ratio, low_ratio, left_low_ratio, left_high_ratio, \\\n","            right_low_ratio, right_high_ratio):\n","\n","        w, h = img.size\n","        high_bright_factor = random.uniform(high_ratio[0], high_ratio[1])\n","        low_bright_factor = random.uniform(low_ratio[0], low_ratio[1])\n","\n","        left_low_factor = random.uniform(left_low_ratio[0]*h, left_low_ratio[1]*h)\n","        left_high_factor = random.uniform(left_high_ratio[0]*h, left_high_ratio[1]*h)\n","        right_low_factor = random.uniform(right_low_ratio[0]*h, right_low_ratio[1]*h)\n","        right_high_factor = random.uniform(right_high_ratio[0]*h, right_high_ratio[1]*h)\n","\n","        tl = (0, left_high_factor)\n","        bl = (0, left_high_factor+left_low_factor)\n","\n","        tr = (w, right_high_factor)\n","        br = (w, right_high_factor+right_low_factor)\n","\n","        contour = np.array([tl, tr, br, bl], dtype=np.int32)\n","\n","        mask = np.zeros([h, w, 3],np.uint8)\n","        cv2.fillPoly(mask,[contour],(random.randint(0,255),random.randint(0,255),random.randint(0,255)))\n","        inverted_mask = cv2.bitwise_not(mask)\n","        # we need to convert this cv2 masks to PIL images\n","        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        # we skip the above convertion because our mask is just black and white\n","        mask_pil = Image.fromarray(mask)\n","        inverted_mask_pil = Image.fromarray(inverted_mask)\n","\n","        low_brightness = TF.adjust_brightness(img, low_bright_factor)\n","        low_brightness_masked = ImageChops.multiply(low_brightness, mask_pil)\n","        high_brightness = TF.adjust_brightness(img, high_bright_factor)\n","        high_brightness_masked = ImageChops.multiply(high_brightness, inverted_mask_pil)\n","\n","        return ImageChops.add(low_brightness_masked, high_brightness_masked)\n","\n","    def __call__(self, img):\n","        if random.uniform(0, 1) < self.p:\n","            img = self.process(img, self.high_ratio, self.low_ratio, \\\n","            self.left_low_ratio, self.left_high_ratio, self.right_low_ratio, \\\n","            self.right_high_ratio)\n","            return img\n","        else:\n","            return img\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mn0_Uk9FfqNv"},"source":["** random shadow 논문에 포함된 추가적인 함수 **\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"smUnhknvfplB"},"source":["import operator\n","import numpy as np\n","import cv2\n","import random\n","from PIL import Image\n","\n","class DiskAugmenter(object):\n","    def __init__(self, local_mask=(120, 160), global_mask=(40, 80),\n","                 flip_and_noise=False, augmenting_prob=0.67):\n","\n","        self.augmenting_prob = augmenting_prob\n","        self.local_mask = local_mask\n","        self.global_mask = global_mask\n","        self.flip_and_noise = flip_and_noise\n","        self.augment_illumination = any(x > 0 for x in list(local_mask) + list(global_mask))\n","\n","    def __call__(self, img):\n","        if random.uniform(0, 1) < self.augmenting_prob:\n","            img = illumination_augmenter(img, self.global_mask, self.local_mask)\n","            return img\n","        else:\n","            return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUkFQM-VKEXn"},"source":["import random\n","import torchvision.transforms.functional as TF\n","\n","class RandomGamma(object):\n","    def __init__(self, gamma_p = 0.5, gamma_ratio=(0,1.5)):\n","        self.gamma_p = gamma_p\n","        self.gamma_ratio = gamma_ratio\n","\n","    def __call__(self,img):\n","        if random.uniform(0, 1) < self.gamma_p:\n","            gamma = random.uniform(self.gamma_ratio[0], self.gamma_ratio[1])\n","            img = TF.adjust_gamma(img, gamma, gain=1)\n","            return img\n","        else:\n","            return img\n","\n","class RandomColorJitter(object):\n","    def __init__(self, p = 0.5, brightness_ratio=(0,2), contrast_ratio=(0,2), \\\n","                saturation_ratio=(0,2), hue_ratio=(-0.5,0.5)):\n","        self.p = p\n","        self.brightness_ratio = brightness_ratio\n","        self.contrast_ratio = contrast_ratio\n","        self.saturation_ratio = saturation_ratio\n","        self.hue_ratio = hue_ratio\n","\n","    @staticmethod\n","    def process(img, brightness_ratio, contrast_ratio, saturation_ratio, hue_ratio):\n","        brightness = random.uniform(brightness_ratio[0], brightness_ratio[1])\n","        contrast = random.uniform(contrast_ratio[0], contrast_ratio[1])\n","        saturation = random.uniform(saturation_ratio[0], saturation_ratio[1])\n","        hue = random.uniform(hue_ratio[0], hue_ratio[1])\n","\n","        img = TF.adjust_brightness(img, brightness)\n","        img = TF.adjust_contrast(img, contrast)\n","        img = TF.adjust_saturation(img, saturation)\n","        img = TF.adjust_hue(img, hue)\n","\n","        return img\n","\n","    def __call__(self,img):\n","        if random.uniform(0, 1) < self.p:\n","            img = self.process(img, self.brightness_ratio, self.contrast_ratio, \\\n","                                self.saturation_ratio, self.hue_ratio)\n","            return img\n","        else:\n","            return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s8oXpzdMvol"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"Pjeqawi9cNK6"},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'resnet34' # resnet18, resnet50, resnet101\n","batch_size = 128  # Input batch size for training (default: 128)\n","epochs = 150 # Number of epochs to train (default: 200)\n","learning_rate = 0.1 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","cutout = True # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","seed = 0 # Random seed (default: 0)\n","print_freq = 30\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","# What we need for our data augmentation\n","randomshadows = True\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXL_PBj6cVoe"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313,"referenced_widgets":["907d0e8565a6423da6bcd922b72ed4c5","146732bdbfb54b1d9b3a8b2c0e666376","081a7c701d864f74a095df81fc8ca3a8","9107cd0ec252469ab12e2bd580d62168","0d97381f0d924522aae98451d3415b7c","e430b99df21f4904ad5fb8e91b2b0f77","f935dd6905644a12b6218e76f503ea8b","097395ee398d4604be95d2f610bfb0bd"]},"id":"dvQjH3T9caYs","executionInfo":{"status":"ok","timestamp":1620927175068,"user_tz":-540,"elapsed":6581,"user":{"displayName":"khusw12 S","photoUrl":"","userId":"10296797425522902262"}},"outputId":"e75bb4ee-bc44-419f-b815-84ad8a9cee0a"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","train_transform = transforms.Compose([])\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","if randomshadows:\n","    p = np.round(np.arange(0, 1.1, 0.1), 2)\n","    for i_p in p:\n","        print('RSH p value: ', i_p)\n","        data_transforms = {\n","            'train': transforms.Compose([\n","                # For CIFAR-10 and CIFAR100, either change the model or resize images to 64x64 (uncomment the transform below)\n","                # transforms.Resize(64),\n","                DiskAugmenter(local_mask=(120, 160), global_mask=(40, 80), augmenting_prob=0),\n","                RandomShadows(p=i_p, high_ratio=(1,2), low_ratio=(0,1), \\\n","                left_low_ratio=(0.4,0.8), left_high_ratio=(0,0.3), right_low_ratio=(0.4,0.8),\n","                right_high_ratio = (0,0.3)), ## high means from top of image, low means from top to bottom low\n","                #RandomGamma(gamma_p = 0, gamma_ratio=(0, 1.5)),\n","                #RandomColorJitter(p = 0, brightness_ratio=(0,2), contrast_ratio=(0,2), \\\n","                #           saturation_ratio=(0,2), hue_ratio=(-0.5,0.5)),\n","                \n","                #transforms.ToTensor(),\n","                #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","                # transforms.RandomErasing(p=i_p)\n","            ]),\n","            'val': transforms.Compose([\n","                # For CIFAR-10 and CIFAR100, either change the model or resize images to 64x64 (uncomment the transform below)\n","                # transforms.Resize(64),\n","                RandomShadows(p=1, high_ratio=(1,2), low_ratio=(0,1), \\\n","                left_low_ratio=(0.4,0.8), left_high_ratio=(0,0.3), right_low_ratio=(0.4,0.8),\n","                right_high_ratio = (0,0.3)), ## high means from top of image, low means from top to bottom low\n","                #transforms.ToTensor(),\n","                #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","            ]),\n","            'test': transforms.Compose([\n","                #transforms.ToTensor(),\n","            ])\n","        }\n","\n","    \n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RSH p value:  0.0\n","RSH p value:  0.1\n","RSH p value:  0.2\n","RSH p value:  0.3\n","RSH p value:  0.4\n","RSH p value:  0.5\n","RSH p value:  0.6\n","RSH p value:  0.7\n","RSH p value:  0.8\n","RSH p value:  0.9\n","RSH p value:  1.0\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"907d0e8565a6423da6bcd922b72ed4c5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gITLQIAr9lAZ"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0-lYvAp9oHA","executionInfo":{"status":"ok","timestamp":1620938092117,"user_tz":-540,"elapsed":2901010,"user":{"displayName":"khusw12 S","photoUrl":"","userId":"10296797425522902262"}},"outputId":"d3287221-9059-4659-a771-9aae874ded69"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","model = ResNet34(num_classes=num_classes).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n","\n","scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","###########################################################\n","best_acc = 0\n","for epoch in range(epochs):\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), 'model_best.pt')\n","\n","torch.save(model.state_dict(),'model_latest.pt')\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","----- epoch: 0, lr: 0.1 -----\n","Epoch: [0][  0/391]\tTime  1.281 ( 1.281)\tLoss 4.7337e+00 (4.7337e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   5.47 (  5.47)\n","Epoch: [0][ 30/391]\tTime  0.162 ( 0.193)\tLoss 4.6855e+00 (5.2570e+00)\tAcc@1   1.56 (  1.18)\tAcc@5   8.59 (  6.00)\n","Epoch: [0][ 60/391]\tTime  0.162 ( 0.178)\tLoss 4.5426e+00 (4.9527e+00)\tAcc@1   2.34 (  1.52)\tAcc@5   5.47 (  6.86)\n","Epoch: [0][ 90/391]\tTime  0.164 ( 0.173)\tLoss 4.4225e+00 (4.7956e+00)\tAcc@1   2.34 (  1.85)\tAcc@5  10.16 (  8.16)\n","Epoch: [0][120/391]\tTime  0.164 ( 0.170)\tLoss 4.2529e+00 (4.6857e+00)\tAcc@1   5.47 (  2.19)\tAcc@5  13.28 (  9.63)\n","Epoch: [0][150/391]\tTime  0.164 ( 0.169)\tLoss 4.3695e+00 (4.6075e+00)\tAcc@1   4.69 (  2.47)\tAcc@5   9.38 ( 10.90)\n","Epoch: [0][180/391]\tTime  0.166 ( 0.169)\tLoss 4.2494e+00 (4.5465e+00)\tAcc@1   4.69 (  2.90)\tAcc@5  14.06 ( 12.08)\n","Epoch: [0][210/391]\tTime  0.166 ( 0.168)\tLoss 4.1728e+00 (4.4956e+00)\tAcc@1   4.69 (  3.24)\tAcc@5  17.97 ( 13.13)\n","Epoch: [0][240/391]\tTime  0.170 ( 0.168)\tLoss 4.2309e+00 (4.4503e+00)\tAcc@1   5.47 (  3.51)\tAcc@5  17.97 ( 14.19)\n","Epoch: [0][270/391]\tTime  0.169 ( 0.169)\tLoss 4.1052e+00 (4.4093e+00)\tAcc@1   4.69 (  3.75)\tAcc@5  21.09 ( 15.02)\n","Epoch: [0][300/391]\tTime  0.173 ( 0.169)\tLoss 4.0928e+00 (4.3776e+00)\tAcc@1   6.25 (  3.98)\tAcc@5  22.66 ( 15.78)\n","Epoch: [0][330/391]\tTime  0.174 ( 0.169)\tLoss 4.0098e+00 (4.3459e+00)\tAcc@1   6.25 (  4.24)\tAcc@5  27.34 ( 16.64)\n","Epoch: [0][360/391]\tTime  0.175 ( 0.170)\tLoss 4.0248e+00 (4.3183e+00)\tAcc@1   6.25 (  4.50)\tAcc@5  25.78 ( 17.35)\n","Epoch: [0][390/391]\tTime  0.766 ( 0.172)\tLoss 4.0541e+00 (4.2931e+00)\tAcc@1   6.25 (  4.67)\tAcc@5  23.75 ( 18.04)\n","==> Train Accuracy: Acc@1 4.672 || Acc@5 18.038\n","==> Test Accuracy:  Acc@1 8.270 || Acc@5 28.400\n","==> 71.63 seconds to train this epoch\n","\n","\n","----- epoch: 1, lr: 0.1 -----\n","Epoch: [1][  0/391]\tTime  0.260 ( 0.260)\tLoss 4.0642e+00 (4.0642e+00)\tAcc@1   4.69 (  4.69)\tAcc@5  25.78 ( 25.78)\n","Epoch: [1][ 30/391]\tTime  0.182 ( 0.183)\tLoss 4.0666e+00 (3.9797e+00)\tAcc@1   5.47 (  7.26)\tAcc@5  28.12 ( 27.04)\n","Epoch: [1][ 60/391]\tTime  0.182 ( 0.182)\tLoss 3.9599e+00 (3.9728e+00)\tAcc@1   7.81 (  7.30)\tAcc@5  23.44 ( 26.72)\n","Epoch: [1][ 90/391]\tTime  0.179 ( 0.181)\tLoss 4.0233e+00 (3.9497e+00)\tAcc@1   7.03 (  7.58)\tAcc@5  21.09 ( 27.43)\n","Epoch: [1][120/391]\tTime  0.173 ( 0.180)\tLoss 3.8853e+00 (3.9380e+00)\tAcc@1   9.38 (  7.92)\tAcc@5  27.34 ( 27.76)\n","Epoch: [1][150/391]\tTime  0.172 ( 0.179)\tLoss 3.9590e+00 (3.9242e+00)\tAcc@1  10.94 (  8.22)\tAcc@5  28.12 ( 28.29)\n","Epoch: [1][180/391]\tTime  0.173 ( 0.178)\tLoss 4.0299e+00 (3.9093e+00)\tAcc@1   6.25 (  8.56)\tAcc@5  25.00 ( 28.79)\n","Epoch: [1][210/391]\tTime  0.175 ( 0.177)\tLoss 3.7384e+00 (3.8961e+00)\tAcc@1   8.59 (  8.75)\tAcc@5  33.59 ( 29.31)\n","Epoch: [1][240/391]\tTime  0.173 ( 0.177)\tLoss 3.9027e+00 (3.8840e+00)\tAcc@1   7.81 (  8.89)\tAcc@5  26.56 ( 29.63)\n","Epoch: [1][270/391]\tTime  0.172 ( 0.176)\tLoss 3.7421e+00 (3.8746e+00)\tAcc@1  14.84 (  9.02)\tAcc@5  39.06 ( 29.93)\n","Epoch: [1][300/391]\tTime  0.173 ( 0.176)\tLoss 3.8031e+00 (3.8628e+00)\tAcc@1  11.72 (  9.26)\tAcc@5  33.59 ( 30.32)\n","Epoch: [1][330/391]\tTime  0.181 ( 0.176)\tLoss 3.8372e+00 (3.8535e+00)\tAcc@1   8.59 (  9.37)\tAcc@5  28.12 ( 30.59)\n","Epoch: [1][360/391]\tTime  0.175 ( 0.176)\tLoss 3.7580e+00 (3.8419e+00)\tAcc@1  14.84 (  9.53)\tAcc@5  32.81 ( 30.98)\n","Epoch: [1][390/391]\tTime  0.158 ( 0.175)\tLoss 3.7712e+00 (3.8351e+00)\tAcc@1  15.00 (  9.63)\tAcc@5  35.00 ( 31.24)\n","==> Train Accuracy: Acc@1 9.628 || Acc@5 31.240\n","==> Test Accuracy:  Acc@1 13.230 || Acc@5 38.420\n","==> 72.92 seconds to train this epoch\n","\n","\n","----- epoch: 2, lr: 0.1 -----\n","Epoch: [2][  0/391]\tTime  0.252 ( 0.252)\tLoss 3.5960e+00 (3.5960e+00)\tAcc@1  13.28 ( 13.28)\tAcc@5  34.38 ( 34.38)\n","Epoch: [2][ 30/391]\tTime  0.173 ( 0.178)\tLoss 3.7184e+00 (3.6848e+00)\tAcc@1  13.28 ( 12.25)\tAcc@5  33.59 ( 35.33)\n","Epoch: [2][ 60/391]\tTime  0.176 ( 0.177)\tLoss 3.5932e+00 (3.6569e+00)\tAcc@1  13.28 ( 12.87)\tAcc@5  40.62 ( 36.86)\n","Epoch: [2][ 90/391]\tTime  0.180 ( 0.177)\tLoss 3.6792e+00 (3.6403e+00)\tAcc@1  15.62 ( 13.14)\tAcc@5  36.72 ( 37.32)\n","Epoch: [2][120/391]\tTime  0.177 ( 0.177)\tLoss 3.4869e+00 (3.6269e+00)\tAcc@1  13.28 ( 13.07)\tAcc@5  44.53 ( 37.62)\n","Epoch: [2][150/391]\tTime  0.180 ( 0.176)\tLoss 3.4979e+00 (3.6122e+00)\tAcc@1  15.62 ( 13.46)\tAcc@5  39.06 ( 38.05)\n","Epoch: [2][180/391]\tTime  0.177 ( 0.176)\tLoss 3.5574e+00 (3.6000e+00)\tAcc@1  17.19 ( 13.67)\tAcc@5  39.06 ( 38.29)\n","Epoch: [2][210/391]\tTime  0.175 ( 0.176)\tLoss 3.6063e+00 (3.5947e+00)\tAcc@1  14.06 ( 13.74)\tAcc@5  37.50 ( 38.48)\n","Epoch: [2][240/391]\tTime  0.172 ( 0.176)\tLoss 3.5325e+00 (3.5848e+00)\tAcc@1  14.06 ( 13.89)\tAcc@5  42.19 ( 38.99)\n","Epoch: [2][270/391]\tTime  0.173 ( 0.176)\tLoss 3.4150e+00 (3.5762e+00)\tAcc@1  19.53 ( 14.06)\tAcc@5  42.97 ( 39.34)\n","Epoch: [2][300/391]\tTime  0.174 ( 0.176)\tLoss 3.5230e+00 (3.5676e+00)\tAcc@1  13.28 ( 14.22)\tAcc@5  40.62 ( 39.59)\n","Epoch: [2][330/391]\tTime  0.175 ( 0.176)\tLoss 3.4308e+00 (3.5521e+00)\tAcc@1  17.97 ( 14.49)\tAcc@5  43.75 ( 40.08)\n","Epoch: [2][360/391]\tTime  0.177 ( 0.176)\tLoss 3.5844e+00 (3.5421e+00)\tAcc@1  10.94 ( 14.66)\tAcc@5  39.84 ( 40.35)\n","Epoch: [2][390/391]\tTime  0.155 ( 0.175)\tLoss 3.6829e+00 (3.5315e+00)\tAcc@1  13.75 ( 14.88)\tAcc@5  40.00 ( 40.63)\n","==> Train Accuracy: Acc@1 14.884 || Acc@5 40.628\n","==> Test Accuracy:  Acc@1 20.010 || Acc@5 47.910\n","==> 72.95 seconds to train this epoch\n","\n","\n","----- epoch: 3, lr: 0.1 -----\n","Epoch: [3][  0/391]\tTime  0.267 ( 0.267)\tLoss 3.3031e+00 (3.3031e+00)\tAcc@1  25.00 ( 25.00)\tAcc@5  45.31 ( 45.31)\n","Epoch: [3][ 30/391]\tTime  0.174 ( 0.177)\tLoss 3.3557e+00 (3.3219e+00)\tAcc@1  22.66 ( 19.20)\tAcc@5  51.56 ( 47.18)\n","Epoch: [3][ 60/391]\tTime  0.173 ( 0.176)\tLoss 3.1659e+00 (3.2971e+00)\tAcc@1  19.53 ( 19.40)\tAcc@5  51.56 ( 47.90)\n","Epoch: [3][ 90/391]\tTime  0.174 ( 0.176)\tLoss 3.4384e+00 (3.3094e+00)\tAcc@1  16.41 ( 19.13)\tAcc@5  41.41 ( 47.42)\n","Epoch: [3][120/391]\tTime  0.176 ( 0.175)\tLoss 3.1125e+00 (3.2962e+00)\tAcc@1  19.53 ( 19.23)\tAcc@5  51.56 ( 47.89)\n","Epoch: [3][150/391]\tTime  0.176 ( 0.175)\tLoss 3.3675e+00 (3.2943e+00)\tAcc@1  18.75 ( 19.31)\tAcc@5  43.75 ( 47.91)\n","Epoch: [3][180/391]\tTime  0.175 ( 0.175)\tLoss 3.2463e+00 (3.2884e+00)\tAcc@1  20.31 ( 19.48)\tAcc@5  54.69 ( 48.06)\n","Epoch: [3][210/391]\tTime  0.175 ( 0.175)\tLoss 3.1324e+00 (3.2815e+00)\tAcc@1  15.62 ( 19.56)\tAcc@5  54.69 ( 48.18)\n","Epoch: [3][240/391]\tTime  0.175 ( 0.175)\tLoss 3.1518e+00 (3.2735e+00)\tAcc@1  21.88 ( 19.74)\tAcc@5  52.34 ( 48.41)\n","Epoch: [3][270/391]\tTime  0.176 ( 0.175)\tLoss 3.2418e+00 (3.2668e+00)\tAcc@1  16.41 ( 19.85)\tAcc@5  50.78 ( 48.55)\n","Epoch: [3][300/391]\tTime  0.177 ( 0.175)\tLoss 2.9744e+00 (3.2599e+00)\tAcc@1  28.91 ( 19.93)\tAcc@5  56.25 ( 48.70)\n","Epoch: [3][330/391]\tTime  0.175 ( 0.175)\tLoss 3.2266e+00 (3.2473e+00)\tAcc@1  20.31 ( 20.09)\tAcc@5  51.56 ( 49.08)\n","Epoch: [3][360/391]\tTime  0.176 ( 0.175)\tLoss 3.1036e+00 (3.2394e+00)\tAcc@1  21.09 ( 20.18)\tAcc@5  53.12 ( 49.27)\n","Epoch: [3][390/391]\tTime  0.158 ( 0.175)\tLoss 3.2097e+00 (3.2299e+00)\tAcc@1  23.75 ( 20.38)\tAcc@5  51.25 ( 49.56)\n","==> Train Accuracy: Acc@1 20.380 || Acc@5 49.558\n","==> Test Accuracy:  Acc@1 22.680 || Acc@5 52.650\n","==> 72.84 seconds to train this epoch\n","\n","\n","----- epoch: 4, lr: 0.1 -----\n","Epoch: [4][  0/391]\tTime  0.259 ( 0.259)\tLoss 3.1524e+00 (3.1524e+00)\tAcc@1  22.66 ( 22.66)\tAcc@5  51.56 ( 51.56)\n","Epoch: [4][ 30/391]\tTime  0.176 ( 0.178)\tLoss 2.8377e+00 (2.9944e+00)\tAcc@1  29.69 ( 24.22)\tAcc@5  56.25 ( 55.90)\n","Epoch: [4][ 60/391]\tTime  0.176 ( 0.177)\tLoss 3.0010e+00 (3.0354e+00)\tAcc@1  22.66 ( 23.72)\tAcc@5  57.81 ( 54.76)\n","Epoch: [4][ 90/391]\tTime  0.177 ( 0.176)\tLoss 2.9344e+00 (3.0163e+00)\tAcc@1  24.22 ( 24.12)\tAcc@5  60.16 ( 55.45)\n","Epoch: [4][120/391]\tTime  0.177 ( 0.176)\tLoss 2.6928e+00 (3.0104e+00)\tAcc@1  32.81 ( 24.32)\tAcc@5  64.84 ( 55.39)\n","Epoch: [4][150/391]\tTime  0.178 ( 0.176)\tLoss 2.9962e+00 (3.0138e+00)\tAcc@1  19.53 ( 24.29)\tAcc@5  54.69 ( 55.12)\n","Epoch: [4][180/391]\tTime  0.174 ( 0.176)\tLoss 3.0326e+00 (3.0088e+00)\tAcc@1  29.69 ( 24.23)\tAcc@5  56.25 ( 55.32)\n","Epoch: [4][210/391]\tTime  0.179 ( 0.176)\tLoss 2.9637e+00 (3.0043e+00)\tAcc@1  24.22 ( 24.35)\tAcc@5  58.59 ( 55.38)\n","Epoch: [4][240/391]\tTime  0.174 ( 0.176)\tLoss 3.1282e+00 (3.0000e+00)\tAcc@1  21.09 ( 24.46)\tAcc@5  57.03 ( 55.49)\n","Epoch: [4][270/391]\tTime  0.175 ( 0.176)\tLoss 2.9459e+00 (2.9958e+00)\tAcc@1  25.78 ( 24.63)\tAcc@5  55.47 ( 55.61)\n","Epoch: [4][300/391]\tTime  0.180 ( 0.176)\tLoss 2.9374e+00 (2.9897e+00)\tAcc@1  28.12 ( 24.81)\tAcc@5  51.56 ( 55.73)\n","Epoch: [4][330/391]\tTime  0.176 ( 0.176)\tLoss 2.9355e+00 (2.9867e+00)\tAcc@1  25.78 ( 24.92)\tAcc@5  58.59 ( 55.85)\n","Epoch: [4][360/391]\tTime  0.177 ( 0.176)\tLoss 3.1235e+00 (2.9783e+00)\tAcc@1  21.09 ( 25.02)\tAcc@5  56.25 ( 56.04)\n","Epoch: [4][390/391]\tTime  0.156 ( 0.176)\tLoss 2.7565e+00 (2.9741e+00)\tAcc@1  32.50 ( 25.12)\tAcc@5  57.50 ( 56.18)\n","==> Train Accuracy: Acc@1 25.120 || Acc@5 56.176\n","==> Test Accuracy:  Acc@1 28.030 || Acc@5 59.060\n","==> 73.05 seconds to train this epoch\n","\n","\n","----- epoch: 5, lr: 0.1 -----\n","Epoch: [5][  0/391]\tTime  0.275 ( 0.275)\tLoss 2.7721e+00 (2.7721e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  60.94 ( 60.94)\n","Epoch: [5][ 30/391]\tTime  0.176 ( 0.178)\tLoss 2.8787e+00 (2.8262e+00)\tAcc@1  22.66 ( 27.52)\tAcc@5  59.38 ( 60.46)\n","Epoch: [5][ 60/391]\tTime  0.172 ( 0.176)\tLoss 2.8051e+00 (2.8168e+00)\tAcc@1  32.81 ( 27.25)\tAcc@5  55.47 ( 60.50)\n","Epoch: [5][ 90/391]\tTime  0.176 ( 0.176)\tLoss 2.6686e+00 (2.8001e+00)\tAcc@1  34.38 ( 27.93)\tAcc@5  64.06 ( 60.95)\n","Epoch: [5][120/391]\tTime  0.176 ( 0.176)\tLoss 2.9850e+00 (2.7998e+00)\tAcc@1  28.91 ( 28.20)\tAcc@5  59.38 ( 61.00)\n","Epoch: [5][150/391]\tTime  0.176 ( 0.175)\tLoss 2.8517e+00 (2.7999e+00)\tAcc@1  28.12 ( 28.30)\tAcc@5  58.59 ( 60.99)\n","Epoch: [5][180/391]\tTime  0.173 ( 0.175)\tLoss 2.8680e+00 (2.7960e+00)\tAcc@1  25.78 ( 28.37)\tAcc@5  61.72 ( 60.98)\n","Epoch: [5][210/391]\tTime  0.176 ( 0.175)\tLoss 2.6772e+00 (2.7847e+00)\tAcc@1  32.81 ( 28.59)\tAcc@5  65.62 ( 61.23)\n","Epoch: [5][240/391]\tTime  0.178 ( 0.175)\tLoss 2.9283e+00 (2.7781e+00)\tAcc@1  27.34 ( 28.77)\tAcc@5  50.78 ( 61.24)\n","Epoch: [5][270/391]\tTime  0.174 ( 0.175)\tLoss 2.6245e+00 (2.7701e+00)\tAcc@1  36.72 ( 29.08)\tAcc@5  66.41 ( 61.51)\n","Epoch: [5][300/391]\tTime  0.180 ( 0.175)\tLoss 2.5073e+00 (2.7629e+00)\tAcc@1  38.28 ( 29.31)\tAcc@5  66.41 ( 61.72)\n","Epoch: [5][330/391]\tTime  0.176 ( 0.175)\tLoss 2.7054e+00 (2.7560e+00)\tAcc@1  21.09 ( 29.36)\tAcc@5  69.53 ( 61.84)\n","Epoch: [5][360/391]\tTime  0.175 ( 0.175)\tLoss 2.8575e+00 (2.7534e+00)\tAcc@1  21.09 ( 29.40)\tAcc@5  59.38 ( 61.87)\n","Epoch: [5][390/391]\tTime  0.158 ( 0.175)\tLoss 2.8138e+00 (2.7503e+00)\tAcc@1  32.50 ( 29.48)\tAcc@5  60.00 ( 61.92)\n","==> Train Accuracy: Acc@1 29.484 || Acc@5 61.920\n","==> Test Accuracy:  Acc@1 30.650 || Acc@5 61.320\n","==> 72.66 seconds to train this epoch\n","\n","\n","----- epoch: 6, lr: 0.1 -----\n","Epoch: [6][  0/391]\tTime  0.255 ( 0.255)\tLoss 2.2860e+00 (2.2860e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  72.66 ( 72.66)\n","Epoch: [6][ 30/391]\tTime  0.173 ( 0.177)\tLoss 2.6833e+00 (2.5972e+00)\tAcc@1  31.25 ( 31.96)\tAcc@5  60.94 ( 65.83)\n","Epoch: [6][ 60/391]\tTime  0.174 ( 0.176)\tLoss 2.3434e+00 (2.5944e+00)\tAcc@1  35.94 ( 32.24)\tAcc@5  71.09 ( 65.65)\n","Epoch: [6][ 90/391]\tTime  0.176 ( 0.175)\tLoss 2.5708e+00 (2.5906e+00)\tAcc@1  39.84 ( 32.19)\tAcc@5  67.19 ( 65.77)\n","Epoch: [6][120/391]\tTime  0.174 ( 0.175)\tLoss 2.5066e+00 (2.5860e+00)\tAcc@1  29.69 ( 32.15)\tAcc@5  64.84 ( 66.03)\n","Epoch: [6][150/391]\tTime  0.175 ( 0.175)\tLoss 2.6697e+00 (2.5845e+00)\tAcc@1  34.38 ( 32.17)\tAcc@5  59.38 ( 65.87)\n","Epoch: [6][180/391]\tTime  0.178 ( 0.175)\tLoss 2.5116e+00 (2.5864e+00)\tAcc@1  33.59 ( 32.33)\tAcc@5  67.97 ( 65.76)\n","Epoch: [6][210/391]\tTime  0.178 ( 0.175)\tLoss 2.7077e+00 (2.5741e+00)\tAcc@1  27.34 ( 32.67)\tAcc@5  61.72 ( 65.97)\n","Epoch: [6][240/391]\tTime  0.172 ( 0.175)\tLoss 2.3547e+00 (2.5685e+00)\tAcc@1  40.62 ( 32.79)\tAcc@5  68.75 ( 66.03)\n","Epoch: [6][270/391]\tTime  0.175 ( 0.175)\tLoss 2.4673e+00 (2.5661e+00)\tAcc@1  38.28 ( 32.98)\tAcc@5  68.75 ( 65.98)\n","Epoch: [6][300/391]\tTime  0.175 ( 0.175)\tLoss 2.5113e+00 (2.5667e+00)\tAcc@1  29.69 ( 32.95)\tAcc@5  71.09 ( 65.91)\n","Epoch: [6][330/391]\tTime  0.174 ( 0.175)\tLoss 2.7234e+00 (2.5632e+00)\tAcc@1  33.59 ( 33.03)\tAcc@5  64.06 ( 65.99)\n","Epoch: [6][360/391]\tTime  0.175 ( 0.175)\tLoss 2.1733e+00 (2.5592e+00)\tAcc@1  35.94 ( 33.17)\tAcc@5  73.44 ( 66.12)\n","Epoch: [6][390/391]\tTime  0.157 ( 0.175)\tLoss 2.7329e+00 (2.5588e+00)\tAcc@1  30.00 ( 33.23)\tAcc@5  62.50 ( 66.11)\n","==> Train Accuracy: Acc@1 33.228 || Acc@5 66.110\n","==> Test Accuracy:  Acc@1 24.880 || Acc@5 55.780\n","==> 72.72 seconds to train this epoch\n","\n","\n","----- epoch: 7, lr: 0.1 -----\n","Epoch: [7][  0/391]\tTime  0.277 ( 0.277)\tLoss 2.7962e+00 (2.7962e+00)\tAcc@1  27.34 ( 27.34)\tAcc@5  62.50 ( 62.50)\n","Epoch: [7][ 30/391]\tTime  0.177 ( 0.178)\tLoss 2.5083e+00 (2.4822e+00)\tAcc@1  34.38 ( 34.35)\tAcc@5  66.41 ( 67.16)\n","Epoch: [7][ 60/391]\tTime  0.177 ( 0.176)\tLoss 2.4293e+00 (2.4499e+00)\tAcc@1  32.81 ( 35.14)\tAcc@5  70.31 ( 68.21)\n","Epoch: [7][ 90/391]\tTime  0.173 ( 0.176)\tLoss 2.2774e+00 (2.4439e+00)\tAcc@1  40.62 ( 35.43)\tAcc@5  72.66 ( 68.42)\n","Epoch: [7][120/391]\tTime  0.179 ( 0.176)\tLoss 2.3871e+00 (2.4442e+00)\tAcc@1  42.19 ( 35.70)\tAcc@5  72.66 ( 68.44)\n","Epoch: [7][150/391]\tTime  0.174 ( 0.176)\tLoss 2.2380e+00 (2.4388e+00)\tAcc@1  40.62 ( 35.73)\tAcc@5  78.91 ( 68.77)\n","Epoch: [7][180/391]\tTime  0.177 ( 0.175)\tLoss 2.3381e+00 (2.4311e+00)\tAcc@1  39.84 ( 36.00)\tAcc@5  71.88 ( 68.88)\n","Epoch: [7][210/391]\tTime  0.176 ( 0.175)\tLoss 2.7150e+00 (2.4297e+00)\tAcc@1  33.59 ( 35.91)\tAcc@5  63.28 ( 68.94)\n","Epoch: [7][240/391]\tTime  0.175 ( 0.175)\tLoss 2.2144e+00 (2.4284e+00)\tAcc@1  40.62 ( 35.91)\tAcc@5  70.31 ( 68.89)\n","Epoch: [7][270/391]\tTime  0.175 ( 0.175)\tLoss 2.6920e+00 (2.4290e+00)\tAcc@1  32.81 ( 35.89)\tAcc@5  60.16 ( 68.95)\n","Epoch: [7][300/391]\tTime  0.177 ( 0.175)\tLoss 2.3751e+00 (2.4278e+00)\tAcc@1  44.53 ( 35.92)\tAcc@5  66.41 ( 68.96)\n","Epoch: [7][330/391]\tTime  0.177 ( 0.175)\tLoss 2.3892e+00 (2.4268e+00)\tAcc@1  38.28 ( 36.02)\tAcc@5  66.41 ( 68.96)\n","Epoch: [7][360/391]\tTime  0.177 ( 0.175)\tLoss 2.5489e+00 (2.4212e+00)\tAcc@1  32.81 ( 36.06)\tAcc@5  65.62 ( 69.15)\n","Epoch: [7][390/391]\tTime  0.160 ( 0.175)\tLoss 2.4338e+00 (2.4111e+00)\tAcc@1  41.25 ( 36.32)\tAcc@5  66.25 ( 69.36)\n","==> Train Accuracy: Acc@1 36.322 || Acc@5 69.362\n","==> Test Accuracy:  Acc@1 37.810 || Acc@5 69.660\n","==> 72.86 seconds to train this epoch\n","\n","\n","----- epoch: 8, lr: 0.1 -----\n","Epoch: [8][  0/391]\tTime  0.271 ( 0.271)\tLoss 2.1868e+00 (2.1868e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  72.66 ( 72.66)\n","Epoch: [8][ 30/391]\tTime  0.175 ( 0.178)\tLoss 2.0258e+00 (2.2854e+00)\tAcc@1  43.75 ( 40.10)\tAcc@5  75.00 ( 72.28)\n","Epoch: [8][ 60/391]\tTime  0.176 ( 0.177)\tLoss 1.9904e+00 (2.2562e+00)\tAcc@1  45.31 ( 40.62)\tAcc@5  80.47 ( 72.68)\n","Epoch: [8][ 90/391]\tTime  0.176 ( 0.176)\tLoss 2.2969e+00 (2.2636e+00)\tAcc@1  34.38 ( 40.14)\tAcc@5  71.88 ( 72.47)\n","Epoch: [8][120/391]\tTime  0.178 ( 0.176)\tLoss 2.6158e+00 (2.2666e+00)\tAcc@1  33.59 ( 40.09)\tAcc@5  64.06 ( 72.28)\n","Epoch: [8][150/391]\tTime  0.175 ( 0.176)\tLoss 2.2554e+00 (2.2735e+00)\tAcc@1  34.38 ( 39.80)\tAcc@5  73.44 ( 72.06)\n","Epoch: [8][180/391]\tTime  0.174 ( 0.176)\tLoss 2.5437e+00 (2.2783e+00)\tAcc@1  34.38 ( 39.63)\tAcc@5  67.97 ( 72.12)\n","Epoch: [8][210/391]\tTime  0.177 ( 0.176)\tLoss 2.1047e+00 (2.2820e+00)\tAcc@1  45.31 ( 39.53)\tAcc@5  74.22 ( 72.03)\n","Epoch: [8][240/391]\tTime  0.176 ( 0.176)\tLoss 2.2018e+00 (2.2789e+00)\tAcc@1  39.84 ( 39.61)\tAcc@5  77.34 ( 72.07)\n","Epoch: [8][270/391]\tTime  0.173 ( 0.176)\tLoss 2.2449e+00 (2.2849e+00)\tAcc@1  34.38 ( 39.57)\tAcc@5  72.66 ( 71.91)\n","Epoch: [8][300/391]\tTime  0.176 ( 0.176)\tLoss 2.0956e+00 (2.2878e+00)\tAcc@1  40.62 ( 39.55)\tAcc@5  72.66 ( 71.89)\n","Epoch: [8][330/391]\tTime  0.174 ( 0.176)\tLoss 2.2869e+00 (2.2859e+00)\tAcc@1  39.06 ( 39.59)\tAcc@5  76.56 ( 72.05)\n","Epoch: [8][360/391]\tTime  0.174 ( 0.176)\tLoss 2.0380e+00 (2.2832e+00)\tAcc@1  44.53 ( 39.65)\tAcc@5  76.56 ( 72.07)\n","Epoch: [8][390/391]\tTime  0.157 ( 0.175)\tLoss 2.0935e+00 (2.2794e+00)\tAcc@1  43.75 ( 39.71)\tAcc@5  75.00 ( 72.14)\n","==> Train Accuracy: Acc@1 39.706 || Acc@5 72.138\n","==> Test Accuracy:  Acc@1 40.740 || Acc@5 72.750\n","==> 72.97 seconds to train this epoch\n","\n","\n","----- epoch: 9, lr: 0.1 -----\n","Epoch: [9][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.9621e+00 (1.9621e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  78.91 ( 78.91)\n","Epoch: [9][ 30/391]\tTime  0.177 ( 0.178)\tLoss 2.0723e+00 (2.1107e+00)\tAcc@1  39.84 ( 43.75)\tAcc@5  78.91 ( 76.01)\n","Epoch: [9][ 60/391]\tTime  0.175 ( 0.177)\tLoss 2.1112e+00 (2.1429e+00)\tAcc@1  36.72 ( 42.70)\tAcc@5  75.00 ( 75.20)\n","Epoch: [9][ 90/391]\tTime  0.173 ( 0.176)\tLoss 2.2148e+00 (2.1603e+00)\tAcc@1  36.72 ( 42.10)\tAcc@5  75.00 ( 75.01)\n","Epoch: [9][120/391]\tTime  0.176 ( 0.176)\tLoss 1.9526e+00 (2.1665e+00)\tAcc@1  48.44 ( 41.98)\tAcc@5  79.69 ( 74.70)\n","Epoch: [9][150/391]\tTime  0.176 ( 0.176)\tLoss 2.1586e+00 (2.1756e+00)\tAcc@1  40.62 ( 41.73)\tAcc@5  73.44 ( 74.43)\n","Epoch: [9][180/391]\tTime  0.174 ( 0.176)\tLoss 2.3211e+00 (2.1842e+00)\tAcc@1  33.59 ( 41.69)\tAcc@5  73.44 ( 74.36)\n","Epoch: [9][210/391]\tTime  0.171 ( 0.176)\tLoss 2.4587e+00 (2.1837e+00)\tAcc@1  35.94 ( 41.69)\tAcc@5  68.75 ( 74.42)\n","Epoch: [9][240/391]\tTime  0.174 ( 0.176)\tLoss 2.1628e+00 (2.1767e+00)\tAcc@1  37.50 ( 41.81)\tAcc@5  77.34 ( 74.57)\n","Epoch: [9][270/391]\tTime  0.175 ( 0.176)\tLoss 2.2053e+00 (2.1755e+00)\tAcc@1  42.97 ( 41.92)\tAcc@5  69.53 ( 74.56)\n","Epoch: [9][300/391]\tTime  0.173 ( 0.176)\tLoss 2.1601e+00 (2.1760e+00)\tAcc@1  46.09 ( 41.74)\tAcc@5  72.66 ( 74.58)\n","Epoch: [9][330/391]\tTime  0.173 ( 0.176)\tLoss 2.0804e+00 (2.1748e+00)\tAcc@1  42.97 ( 41.75)\tAcc@5  75.78 ( 74.54)\n","Epoch: [9][360/391]\tTime  0.176 ( 0.176)\tLoss 2.1578e+00 (2.1793e+00)\tAcc@1  44.53 ( 41.65)\tAcc@5  75.78 ( 74.43)\n","Epoch: [9][390/391]\tTime  0.159 ( 0.176)\tLoss 2.1862e+00 (2.1804e+00)\tAcc@1  45.00 ( 41.69)\tAcc@5  75.00 ( 74.38)\n","==> Train Accuracy: Acc@1 41.694 || Acc@5 74.382\n","==> Test Accuracy:  Acc@1 37.350 || Acc@5 68.780\n","==> 73.05 seconds to train this epoch\n","\n","\n","----- epoch: 10, lr: 0.1 -----\n","Epoch: [10][  0/391]\tTime  0.279 ( 0.279)\tLoss 2.3566e+00 (2.3566e+00)\tAcc@1  36.72 ( 36.72)\tAcc@5  72.66 ( 72.66)\n","Epoch: [10][ 30/391]\tTime  0.176 ( 0.178)\tLoss 1.8390e+00 (2.0796e+00)\tAcc@1  46.09 ( 43.04)\tAcc@5  78.12 ( 76.29)\n","Epoch: [10][ 60/391]\tTime  0.178 ( 0.177)\tLoss 1.9748e+00 (2.0675e+00)\tAcc@1  46.09 ( 44.03)\tAcc@5  78.91 ( 76.47)\n","Epoch: [10][ 90/391]\tTime  0.176 ( 0.176)\tLoss 2.1631e+00 (2.0547e+00)\tAcc@1  37.50 ( 44.62)\tAcc@5  73.44 ( 76.57)\n","Epoch: [10][120/391]\tTime  0.174 ( 0.176)\tLoss 2.4065e+00 (2.0753e+00)\tAcc@1  37.50 ( 44.03)\tAcc@5  68.75 ( 76.23)\n","Epoch: [10][150/391]\tTime  0.175 ( 0.176)\tLoss 1.9443e+00 (2.0737e+00)\tAcc@1  49.22 ( 44.12)\tAcc@5  79.69 ( 76.39)\n","Epoch: [10][180/391]\tTime  0.176 ( 0.176)\tLoss 2.2113e+00 (2.0875e+00)\tAcc@1  42.19 ( 43.73)\tAcc@5  74.22 ( 76.01)\n","Epoch: [10][210/391]\tTime  0.175 ( 0.176)\tLoss 2.0331e+00 (2.0816e+00)\tAcc@1  42.19 ( 43.82)\tAcc@5  78.91 ( 76.12)\n","Epoch: [10][240/391]\tTime  0.177 ( 0.176)\tLoss 2.0766e+00 (2.0817e+00)\tAcc@1  46.09 ( 43.93)\tAcc@5  74.22 ( 76.08)\n","Epoch: [10][270/391]\tTime  0.176 ( 0.176)\tLoss 2.0540e+00 (2.0786e+00)\tAcc@1  47.66 ( 44.09)\tAcc@5  77.34 ( 76.06)\n","Epoch: [10][300/391]\tTime  0.178 ( 0.175)\tLoss 2.3708e+00 (2.0821e+00)\tAcc@1  43.75 ( 44.03)\tAcc@5  68.75 ( 75.94)\n","Epoch: [10][330/391]\tTime  0.175 ( 0.175)\tLoss 2.2171e+00 (2.0890e+00)\tAcc@1  40.62 ( 43.88)\tAcc@5  73.44 ( 75.69)\n","Epoch: [10][360/391]\tTime  0.176 ( 0.175)\tLoss 2.0141e+00 (2.0875e+00)\tAcc@1  46.09 ( 43.92)\tAcc@5  78.12 ( 75.76)\n","Epoch: [10][390/391]\tTime  0.158 ( 0.175)\tLoss 2.0039e+00 (2.0886e+00)\tAcc@1  46.25 ( 43.91)\tAcc@5  77.50 ( 75.68)\n","==> Train Accuracy: Acc@1 43.910 || Acc@5 75.682\n","==> Test Accuracy:  Acc@1 47.530 || Acc@5 78.550\n","==> 72.89 seconds to train this epoch\n","\n","\n","----- epoch: 11, lr: 0.1 -----\n","Epoch: [11][  0/391]\tTime  0.271 ( 0.271)\tLoss 2.1782e+00 (2.1782e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  73.44 ( 73.44)\n","Epoch: [11][ 30/391]\tTime  0.179 ( 0.178)\tLoss 2.1042e+00 (2.0003e+00)\tAcc@1  40.62 ( 45.29)\tAcc@5  75.00 ( 77.75)\n","Epoch: [11][ 60/391]\tTime  0.174 ( 0.176)\tLoss 2.0993e+00 (2.0053e+00)\tAcc@1  41.41 ( 45.72)\tAcc@5  71.09 ( 77.28)\n","Epoch: [11][ 90/391]\tTime  0.174 ( 0.176)\tLoss 1.8039e+00 (1.9984e+00)\tAcc@1  50.00 ( 45.89)\tAcc@5  79.69 ( 77.53)\n","Epoch: [11][120/391]\tTime  0.178 ( 0.176)\tLoss 1.8732e+00 (1.9963e+00)\tAcc@1  50.00 ( 45.79)\tAcc@5  78.91 ( 77.67)\n","Epoch: [11][150/391]\tTime  0.176 ( 0.176)\tLoss 2.2333e+00 (2.0113e+00)\tAcc@1  39.06 ( 45.49)\tAcc@5  73.44 ( 77.45)\n","Epoch: [11][180/391]\tTime  0.175 ( 0.175)\tLoss 2.1388e+00 (2.0072e+00)\tAcc@1  39.84 ( 45.71)\tAcc@5  72.66 ( 77.42)\n","Epoch: [11][210/391]\tTime  0.175 ( 0.175)\tLoss 2.1902e+00 (2.0105e+00)\tAcc@1  47.66 ( 45.59)\tAcc@5  71.88 ( 77.33)\n","Epoch: [11][240/391]\tTime  0.174 ( 0.175)\tLoss 1.9187e+00 (2.0138e+00)\tAcc@1  39.84 ( 45.42)\tAcc@5  80.47 ( 77.34)\n","Epoch: [11][270/391]\tTime  0.175 ( 0.175)\tLoss 1.9489e+00 (2.0138e+00)\tAcc@1  47.66 ( 45.50)\tAcc@5  72.66 ( 77.37)\n","Epoch: [11][300/391]\tTime  0.174 ( 0.175)\tLoss 2.0833e+00 (2.0141e+00)\tAcc@1  42.19 ( 45.50)\tAcc@5  76.56 ( 77.42)\n","Epoch: [11][330/391]\tTime  0.173 ( 0.175)\tLoss 1.8543e+00 (2.0159e+00)\tAcc@1  50.78 ( 45.49)\tAcc@5  81.25 ( 77.41)\n","Epoch: [11][360/391]\tTime  0.176 ( 0.175)\tLoss 1.9343e+00 (2.0146e+00)\tAcc@1  50.78 ( 45.52)\tAcc@5  77.34 ( 77.46)\n","Epoch: [11][390/391]\tTime  0.155 ( 0.175)\tLoss 1.9064e+00 (2.0123e+00)\tAcc@1  53.75 ( 45.56)\tAcc@5  73.75 ( 77.39)\n","==> Train Accuracy: Acc@1 45.564 || Acc@5 77.390\n","==> Test Accuracy:  Acc@1 44.800 || Acc@5 75.610\n","==> 72.91 seconds to train this epoch\n","\n","\n","----- epoch: 12, lr: 0.1 -----\n","Epoch: [12][  0/391]\tTime  0.258 ( 0.258)\tLoss 2.0413e+00 (2.0413e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  77.34 ( 77.34)\n","Epoch: [12][ 30/391]\tTime  0.177 ( 0.177)\tLoss 2.0704e+00 (1.9300e+00)\tAcc@1  46.09 ( 47.66)\tAcc@5  79.69 ( 78.96)\n","Epoch: [12][ 60/391]\tTime  0.175 ( 0.177)\tLoss 1.9665e+00 (1.9505e+00)\tAcc@1  42.19 ( 46.84)\tAcc@5  80.47 ( 78.71)\n","Epoch: [12][ 90/391]\tTime  0.175 ( 0.176)\tLoss 1.9492e+00 (1.9366e+00)\tAcc@1  46.88 ( 47.33)\tAcc@5  82.03 ( 79.07)\n","Epoch: [12][120/391]\tTime  0.177 ( 0.176)\tLoss 1.7372e+00 (1.9244e+00)\tAcc@1  57.03 ( 47.74)\tAcc@5  82.03 ( 79.17)\n","Epoch: [12][150/391]\tTime  0.177 ( 0.176)\tLoss 1.9532e+00 (1.9261e+00)\tAcc@1  53.91 ( 47.67)\tAcc@5  78.91 ( 79.21)\n","Epoch: [12][180/391]\tTime  0.175 ( 0.176)\tLoss 1.8580e+00 (1.9271e+00)\tAcc@1  49.22 ( 47.71)\tAcc@5  83.59 ( 79.16)\n","Epoch: [12][210/391]\tTime  0.173 ( 0.176)\tLoss 2.1271e+00 (1.9282e+00)\tAcc@1  42.97 ( 47.66)\tAcc@5  75.78 ( 78.99)\n","Epoch: [12][240/391]\tTime  0.175 ( 0.176)\tLoss 1.8285e+00 (1.9290e+00)\tAcc@1  47.66 ( 47.54)\tAcc@5  83.59 ( 79.06)\n","Epoch: [12][270/391]\tTime  0.174 ( 0.176)\tLoss 1.8820e+00 (1.9236e+00)\tAcc@1  41.41 ( 47.60)\tAcc@5  81.25 ( 79.08)\n","Epoch: [12][300/391]\tTime  0.176 ( 0.176)\tLoss 2.0159e+00 (1.9314e+00)\tAcc@1  46.88 ( 47.51)\tAcc@5  75.78 ( 78.95)\n","Epoch: [12][330/391]\tTime  0.175 ( 0.176)\tLoss 1.6919e+00 (1.9299e+00)\tAcc@1  46.09 ( 47.63)\tAcc@5  87.50 ( 78.90)\n","Epoch: [12][360/391]\tTime  0.174 ( 0.176)\tLoss 1.8031e+00 (1.9294e+00)\tAcc@1  54.69 ( 47.54)\tAcc@5  82.03 ( 78.93)\n","Epoch: [12][390/391]\tTime  0.159 ( 0.176)\tLoss 1.9143e+00 (1.9295e+00)\tAcc@1  47.50 ( 47.53)\tAcc@5  77.50 ( 78.97)\n","==> Train Accuracy: Acc@1 47.530 || Acc@5 78.966\n","==> Test Accuracy:  Acc@1 49.230 || Acc@5 80.250\n","==> 73.00 seconds to train this epoch\n","\n","\n","----- epoch: 13, lr: 0.1 -----\n","Epoch: [13][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.8176e+00 (1.8176e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5  79.69 ( 79.69)\n","Epoch: [13][ 30/391]\tTime  0.178 ( 0.178)\tLoss 1.6840e+00 (1.8561e+00)\tAcc@1  53.12 ( 48.77)\tAcc@5  85.16 ( 80.44)\n","Epoch: [13][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.8030e+00 (1.8686e+00)\tAcc@1  51.56 ( 48.53)\tAcc@5  79.69 ( 79.94)\n","Epoch: [13][ 90/391]\tTime  0.170 ( 0.176)\tLoss 1.8399e+00 (1.8450e+00)\tAcc@1  45.31 ( 49.11)\tAcc@5  78.91 ( 80.28)\n","Epoch: [13][120/391]\tTime  0.176 ( 0.175)\tLoss 1.9864e+00 (1.8491e+00)\tAcc@1  49.22 ( 48.97)\tAcc@5  78.12 ( 80.36)\n","Epoch: [13][150/391]\tTime  0.174 ( 0.175)\tLoss 1.6206e+00 (1.8515e+00)\tAcc@1  55.47 ( 49.24)\tAcc@5  85.16 ( 80.34)\n","Epoch: [13][180/391]\tTime  0.174 ( 0.175)\tLoss 1.8042e+00 (1.8553e+00)\tAcc@1  53.12 ( 49.26)\tAcc@5  78.91 ( 80.27)\n","Epoch: [13][210/391]\tTime  0.175 ( 0.175)\tLoss 1.4358e+00 (1.8506e+00)\tAcc@1  58.59 ( 49.27)\tAcc@5  88.28 ( 80.44)\n","Epoch: [13][240/391]\tTime  0.177 ( 0.175)\tLoss 1.9138e+00 (1.8574e+00)\tAcc@1  43.75 ( 49.14)\tAcc@5  80.47 ( 80.34)\n","Epoch: [13][270/391]\tTime  0.175 ( 0.175)\tLoss 1.9969e+00 (1.8590e+00)\tAcc@1  52.34 ( 49.22)\tAcc@5  74.22 ( 80.32)\n","Epoch: [13][300/391]\tTime  0.174 ( 0.175)\tLoss 1.7408e+00 (1.8625e+00)\tAcc@1  54.69 ( 49.18)\tAcc@5  80.47 ( 80.25)\n","Epoch: [13][330/391]\tTime  0.172 ( 0.175)\tLoss 1.8216e+00 (1.8628e+00)\tAcc@1  49.22 ( 49.18)\tAcc@5  81.25 ( 80.23)\n","Epoch: [13][360/391]\tTime  0.173 ( 0.175)\tLoss 1.9773e+00 (1.8628e+00)\tAcc@1  48.44 ( 49.16)\tAcc@5  75.00 ( 80.24)\n","Epoch: [13][390/391]\tTime  0.159 ( 0.175)\tLoss 1.6220e+00 (1.8647e+00)\tAcc@1  56.25 ( 49.11)\tAcc@5  83.75 ( 80.19)\n","==> Train Accuracy: Acc@1 49.112 || Acc@5 80.192\n","==> Test Accuracy:  Acc@1 50.960 || Acc@5 80.810\n","==> 72.72 seconds to train this epoch\n","\n","\n","----- epoch: 14, lr: 0.1 -----\n","Epoch: [14][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.9552e+00 (1.9552e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  77.34 ( 77.34)\n","Epoch: [14][ 30/391]\tTime  0.176 ( 0.178)\tLoss 1.7438e+00 (1.7926e+00)\tAcc@1  53.12 ( 50.33)\tAcc@5  78.12 ( 81.75)\n","Epoch: [14][ 60/391]\tTime  0.173 ( 0.177)\tLoss 2.0704e+00 (1.8085e+00)\tAcc@1  51.56 ( 50.22)\tAcc@5  74.22 ( 81.11)\n","Epoch: [14][ 90/391]\tTime  0.176 ( 0.176)\tLoss 1.7984e+00 (1.7899e+00)\tAcc@1  55.47 ( 50.69)\tAcc@5  80.47 ( 81.36)\n","Epoch: [14][120/391]\tTime  0.178 ( 0.176)\tLoss 2.0011e+00 (1.7906e+00)\tAcc@1  49.22 ( 50.54)\tAcc@5  75.00 ( 81.26)\n","Epoch: [14][150/391]\tTime  0.179 ( 0.176)\tLoss 1.8406e+00 (1.8124e+00)\tAcc@1  51.56 ( 50.01)\tAcc@5  79.69 ( 80.97)\n","Epoch: [14][180/391]\tTime  0.174 ( 0.176)\tLoss 1.4450e+00 (1.8092e+00)\tAcc@1  60.94 ( 50.09)\tAcc@5  85.94 ( 81.05)\n","Epoch: [14][210/391]\tTime  0.176 ( 0.176)\tLoss 1.8684e+00 (1.8102e+00)\tAcc@1  49.22 ( 50.04)\tAcc@5  82.81 ( 81.16)\n","Epoch: [14][240/391]\tTime  0.175 ( 0.176)\tLoss 1.6896e+00 (1.8163e+00)\tAcc@1  52.34 ( 49.96)\tAcc@5  82.03 ( 81.07)\n","Epoch: [14][270/391]\tTime  0.177 ( 0.176)\tLoss 1.6835e+00 (1.8110e+00)\tAcc@1  53.91 ( 50.07)\tAcc@5  80.47 ( 81.17)\n","Epoch: [14][300/391]\tTime  0.177 ( 0.176)\tLoss 1.8092e+00 (1.8099e+00)\tAcc@1  47.66 ( 50.04)\tAcc@5  82.03 ( 81.17)\n","Epoch: [14][330/391]\tTime  0.176 ( 0.176)\tLoss 1.9260e+00 (1.8107e+00)\tAcc@1  50.00 ( 50.02)\tAcc@5  78.12 ( 81.17)\n","Epoch: [14][360/391]\tTime  0.175 ( 0.176)\tLoss 1.9111e+00 (1.8164e+00)\tAcc@1  46.09 ( 49.93)\tAcc@5  82.03 ( 81.08)\n","Epoch: [14][390/391]\tTime  0.159 ( 0.176)\tLoss 1.7924e+00 (1.8202e+00)\tAcc@1  47.50 ( 49.91)\tAcc@5  85.00 ( 80.99)\n","==> Train Accuracy: Acc@1 49.906 || Acc@5 80.990\n","==> Test Accuracy:  Acc@1 44.590 || Acc@5 75.260\n","==> 72.98 seconds to train this epoch\n","\n","\n","----- epoch: 15, lr: 0.1 -----\n","Epoch: [15][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.8527e+00 (1.8527e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  82.03 ( 82.03)\n","Epoch: [15][ 30/391]\tTime  0.174 ( 0.178)\tLoss 1.7372e+00 (1.7609e+00)\tAcc@1  54.69 ( 51.51)\tAcc@5  80.47 ( 82.21)\n","Epoch: [15][ 60/391]\tTime  0.178 ( 0.177)\tLoss 1.8208e+00 (1.7387e+00)\tAcc@1  46.09 ( 51.97)\tAcc@5  81.25 ( 82.68)\n","Epoch: [15][ 90/391]\tTime  0.176 ( 0.176)\tLoss 1.8024e+00 (1.7451e+00)\tAcc@1  50.78 ( 52.00)\tAcc@5  81.25 ( 82.35)\n","Epoch: [15][120/391]\tTime  0.173 ( 0.176)\tLoss 1.7352e+00 (1.7484e+00)\tAcc@1  50.78 ( 51.78)\tAcc@5  81.25 ( 82.20)\n","Epoch: [15][150/391]\tTime  0.175 ( 0.176)\tLoss 1.8334e+00 (1.7520e+00)\tAcc@1  50.78 ( 51.71)\tAcc@5  82.03 ( 82.16)\n","Epoch: [15][180/391]\tTime  0.171 ( 0.175)\tLoss 1.8183e+00 (1.7534e+00)\tAcc@1  47.66 ( 51.63)\tAcc@5  82.81 ( 82.19)\n","Epoch: [15][210/391]\tTime  0.174 ( 0.175)\tLoss 1.7982e+00 (1.7549e+00)\tAcc@1  50.00 ( 51.65)\tAcc@5  78.91 ( 82.07)\n","Epoch: [15][240/391]\tTime  0.176 ( 0.175)\tLoss 1.6296e+00 (1.7555e+00)\tAcc@1  53.12 ( 51.68)\tAcc@5  86.72 ( 82.04)\n","Epoch: [15][270/391]\tTime  0.174 ( 0.175)\tLoss 2.0416e+00 (1.7594e+00)\tAcc@1  42.19 ( 51.54)\tAcc@5  73.44 ( 81.96)\n","Epoch: [15][300/391]\tTime  0.173 ( 0.175)\tLoss 1.6817e+00 (1.7608e+00)\tAcc@1  53.12 ( 51.41)\tAcc@5  78.91 ( 81.95)\n","Epoch: [15][330/391]\tTime  0.173 ( 0.175)\tLoss 1.8329e+00 (1.7650e+00)\tAcc@1  52.34 ( 51.37)\tAcc@5  81.25 ( 81.82)\n","Epoch: [15][360/391]\tTime  0.174 ( 0.175)\tLoss 1.6117e+00 (1.7662e+00)\tAcc@1  50.78 ( 51.34)\tAcc@5  85.16 ( 81.78)\n","Epoch: [15][390/391]\tTime  0.161 ( 0.175)\tLoss 2.0977e+00 (1.7718e+00)\tAcc@1  45.00 ( 51.21)\tAcc@5  78.75 ( 81.68)\n","==> Train Accuracy: Acc@1 51.214 || Acc@5 81.682\n","==> Test Accuracy:  Acc@1 51.640 || Acc@5 81.180\n","==> 72.71 seconds to train this epoch\n","\n","\n","----- epoch: 16, lr: 0.1 -----\n","Epoch: [16][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.7807e+00 (1.7807e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  82.03 ( 82.03)\n","Epoch: [16][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.6298e+00 (1.6972e+00)\tAcc@1  55.47 ( 52.72)\tAcc@5  84.38 ( 83.32)\n","Epoch: [16][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.6460e+00 (1.7049e+00)\tAcc@1  57.03 ( 52.78)\tAcc@5  87.50 ( 83.08)\n","Epoch: [16][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.7645e+00 (1.7075e+00)\tAcc@1  50.00 ( 52.46)\tAcc@5  82.03 ( 83.22)\n","Epoch: [16][120/391]\tTime  0.175 ( 0.175)\tLoss 1.5958e+00 (1.7038e+00)\tAcc@1  60.16 ( 52.57)\tAcc@5  84.38 ( 83.19)\n","Epoch: [16][150/391]\tTime  0.172 ( 0.175)\tLoss 1.7346e+00 (1.7108e+00)\tAcc@1  58.59 ( 52.52)\tAcc@5  81.25 ( 83.02)\n","Epoch: [16][180/391]\tTime  0.174 ( 0.175)\tLoss 2.0077e+00 (1.7214e+00)\tAcc@1  50.78 ( 52.36)\tAcc@5  78.91 ( 82.92)\n","Epoch: [16][210/391]\tTime  0.174 ( 0.175)\tLoss 1.6218e+00 (1.7147e+00)\tAcc@1  54.69 ( 52.60)\tAcc@5  82.03 ( 82.95)\n","Epoch: [16][240/391]\tTime  0.174 ( 0.175)\tLoss 1.7926e+00 (1.7223e+00)\tAcc@1  48.44 ( 52.45)\tAcc@5  83.59 ( 82.79)\n","Epoch: [16][270/391]\tTime  0.175 ( 0.175)\tLoss 1.5792e+00 (1.7297e+00)\tAcc@1  53.91 ( 52.27)\tAcc@5  82.81 ( 82.67)\n","Epoch: [16][300/391]\tTime  0.175 ( 0.175)\tLoss 1.5652e+00 (1.7269e+00)\tAcc@1  56.25 ( 52.31)\tAcc@5  87.50 ( 82.72)\n","Epoch: [16][330/391]\tTime  0.176 ( 0.175)\tLoss 1.6206e+00 (1.7252e+00)\tAcc@1  57.81 ( 52.33)\tAcc@5  84.38 ( 82.73)\n","Epoch: [16][360/391]\tTime  0.175 ( 0.175)\tLoss 1.7086e+00 (1.7300e+00)\tAcc@1  54.69 ( 52.21)\tAcc@5  82.81 ( 82.62)\n","Epoch: [16][390/391]\tTime  0.157 ( 0.175)\tLoss 1.5149e+00 (1.7274e+00)\tAcc@1  55.00 ( 52.31)\tAcc@5  86.25 ( 82.65)\n","==> Train Accuracy: Acc@1 52.306 || Acc@5 82.646\n","==> Test Accuracy:  Acc@1 51.050 || Acc@5 81.240\n","==> 72.60 seconds to train this epoch\n","\n","\n","----- epoch: 17, lr: 0.1 -----\n","Epoch: [17][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.5611e+00 (1.5611e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  87.50 ( 87.50)\n","Epoch: [17][ 30/391]\tTime  0.170 ( 0.177)\tLoss 1.4000e+00 (1.6434e+00)\tAcc@1  60.16 ( 54.51)\tAcc@5  89.06 ( 84.32)\n","Epoch: [17][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.5190e+00 (1.6686e+00)\tAcc@1  53.12 ( 53.87)\tAcc@5  83.59 ( 84.00)\n","Epoch: [17][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.7547e+00 (1.6715e+00)\tAcc@1  50.78 ( 53.37)\tAcc@5  79.69 ( 83.83)\n","Epoch: [17][120/391]\tTime  0.173 ( 0.175)\tLoss 1.5330e+00 (1.6652e+00)\tAcc@1  58.59 ( 53.55)\tAcc@5  84.38 ( 83.73)\n","Epoch: [17][150/391]\tTime  0.173 ( 0.175)\tLoss 1.8484e+00 (1.6713e+00)\tAcc@1  53.91 ( 53.41)\tAcc@5  82.81 ( 83.67)\n","Epoch: [17][180/391]\tTime  0.171 ( 0.175)\tLoss 1.6232e+00 (1.6771e+00)\tAcc@1  59.38 ( 53.43)\tAcc@5  79.69 ( 83.52)\n","Epoch: [17][210/391]\tTime  0.175 ( 0.175)\tLoss 1.6342e+00 (1.6762e+00)\tAcc@1  58.59 ( 53.45)\tAcc@5  84.38 ( 83.57)\n","Epoch: [17][240/391]\tTime  0.174 ( 0.175)\tLoss 1.5187e+00 (1.6851e+00)\tAcc@1  56.25 ( 53.24)\tAcc@5  83.59 ( 83.39)\n","Epoch: [17][270/391]\tTime  0.174 ( 0.175)\tLoss 1.5628e+00 (1.6886e+00)\tAcc@1  50.78 ( 53.13)\tAcc@5  85.94 ( 83.35)\n","Epoch: [17][300/391]\tTime  0.175 ( 0.175)\tLoss 1.8235e+00 (1.6879e+00)\tAcc@1  50.00 ( 53.25)\tAcc@5  82.81 ( 83.30)\n","Epoch: [17][330/391]\tTime  0.176 ( 0.175)\tLoss 1.5356e+00 (1.6867e+00)\tAcc@1  55.47 ( 53.43)\tAcc@5  89.84 ( 83.32)\n","Epoch: [17][360/391]\tTime  0.176 ( 0.175)\tLoss 1.8244e+00 (1.6899e+00)\tAcc@1  50.00 ( 53.32)\tAcc@5  78.12 ( 83.25)\n","Epoch: [17][390/391]\tTime  0.159 ( 0.175)\tLoss 1.7806e+00 (1.6910e+00)\tAcc@1  51.25 ( 53.27)\tAcc@5  82.50 ( 83.25)\n","==> Train Accuracy: Acc@1 53.274 || Acc@5 83.252\n","==> Test Accuracy:  Acc@1 51.080 || Acc@5 79.280\n","==> 72.59 seconds to train this epoch\n","\n","\n","----- epoch: 18, lr: 0.1 -----\n","Epoch: [18][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.8024e+00 (1.8024e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5  85.16 ( 85.16)\n","Epoch: [18][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.7585e+00 (1.6419e+00)\tAcc@1  51.56 ( 54.26)\tAcc@5  84.38 ( 84.00)\n","Epoch: [18][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.7405e+00 (1.6432e+00)\tAcc@1  43.75 ( 54.00)\tAcc@5  89.06 ( 84.12)\n","Epoch: [18][ 90/391]\tTime  0.175 ( 0.176)\tLoss 1.6698e+00 (1.6488e+00)\tAcc@1  56.25 ( 54.19)\tAcc@5  80.47 ( 84.03)\n","Epoch: [18][120/391]\tTime  0.175 ( 0.175)\tLoss 1.6874e+00 (1.6367e+00)\tAcc@1  51.56 ( 54.38)\tAcc@5  83.59 ( 84.09)\n","Epoch: [18][150/391]\tTime  0.175 ( 0.175)\tLoss 1.5676e+00 (1.6343e+00)\tAcc@1  57.03 ( 54.54)\tAcc@5  86.72 ( 84.20)\n","Epoch: [18][180/391]\tTime  0.173 ( 0.175)\tLoss 1.6716e+00 (1.6358e+00)\tAcc@1  52.34 ( 54.60)\tAcc@5  83.59 ( 84.18)\n","Epoch: [18][210/391]\tTime  0.175 ( 0.175)\tLoss 1.5289e+00 (1.6432e+00)\tAcc@1  57.81 ( 54.42)\tAcc@5  83.59 ( 84.12)\n","Epoch: [18][240/391]\tTime  0.176 ( 0.175)\tLoss 1.6262e+00 (1.6447e+00)\tAcc@1  55.47 ( 54.32)\tAcc@5  89.06 ( 84.10)\n","Epoch: [18][270/391]\tTime  0.176 ( 0.175)\tLoss 1.5707e+00 (1.6409e+00)\tAcc@1  59.38 ( 54.40)\tAcc@5  84.38 ( 84.28)\n","Epoch: [18][300/391]\tTime  0.175 ( 0.175)\tLoss 1.6812e+00 (1.6477e+00)\tAcc@1  53.12 ( 54.21)\tAcc@5  75.78 ( 84.12)\n","Epoch: [18][330/391]\tTime  0.174 ( 0.175)\tLoss 1.4780e+00 (1.6538e+00)\tAcc@1  60.16 ( 54.07)\tAcc@5  85.16 ( 84.05)\n","Epoch: [18][360/391]\tTime  0.174 ( 0.175)\tLoss 1.5531e+00 (1.6553e+00)\tAcc@1  57.03 ( 54.01)\tAcc@5  88.28 ( 84.01)\n","Epoch: [18][390/391]\tTime  0.159 ( 0.175)\tLoss 1.8064e+00 (1.6555e+00)\tAcc@1  50.00 ( 53.98)\tAcc@5  82.50 ( 84.03)\n","==> Train Accuracy: Acc@1 53.978 || Acc@5 84.034\n","==> Test Accuracy:  Acc@1 54.600 || Acc@5 83.460\n","==> 72.64 seconds to train this epoch\n","\n","\n","----- epoch: 19, lr: 0.1 -----\n","Epoch: [19][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.5521e+00 (1.5521e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  84.38 ( 84.38)\n","Epoch: [19][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.3163e+00 (1.5828e+00)\tAcc@1  59.38 ( 55.75)\tAcc@5  92.19 ( 84.83)\n","Epoch: [19][ 60/391]\tTime  0.172 ( 0.176)\tLoss 1.6465e+00 (1.5956e+00)\tAcc@1  50.78 ( 55.17)\tAcc@5  83.59 ( 85.00)\n","Epoch: [19][ 90/391]\tTime  0.176 ( 0.176)\tLoss 1.8606e+00 (1.5958e+00)\tAcc@1  48.44 ( 55.21)\tAcc@5  82.03 ( 84.99)\n","Epoch: [19][120/391]\tTime  0.175 ( 0.175)\tLoss 1.6707e+00 (1.5948e+00)\tAcc@1  55.47 ( 55.29)\tAcc@5  82.81 ( 84.86)\n","Epoch: [19][150/391]\tTime  0.181 ( 0.175)\tLoss 1.6641e+00 (1.6077e+00)\tAcc@1  53.12 ( 55.10)\tAcc@5  82.03 ( 84.54)\n","Epoch: [19][180/391]\tTime  0.174 ( 0.175)\tLoss 1.6320e+00 (1.6105e+00)\tAcc@1  52.34 ( 54.97)\tAcc@5  84.38 ( 84.54)\n","Epoch: [19][210/391]\tTime  0.175 ( 0.175)\tLoss 1.2515e+00 (1.6134e+00)\tAcc@1  61.72 ( 54.86)\tAcc@5  89.06 ( 84.46)\n","Epoch: [19][240/391]\tTime  0.173 ( 0.175)\tLoss 1.5406e+00 (1.6165e+00)\tAcc@1  60.16 ( 54.78)\tAcc@5  86.72 ( 84.39)\n","Epoch: [19][270/391]\tTime  0.177 ( 0.175)\tLoss 1.5339e+00 (1.6227e+00)\tAcc@1  54.69 ( 54.66)\tAcc@5  88.28 ( 84.27)\n","Epoch: [19][300/391]\tTime  0.175 ( 0.175)\tLoss 1.5592e+00 (1.6231e+00)\tAcc@1  51.56 ( 54.74)\tAcc@5  85.16 ( 84.19)\n","Epoch: [19][330/391]\tTime  0.177 ( 0.175)\tLoss 1.4880e+00 (1.6251e+00)\tAcc@1  64.06 ( 54.71)\tAcc@5  81.25 ( 84.19)\n","Epoch: [19][360/391]\tTime  0.177 ( 0.175)\tLoss 1.7866e+00 (1.6289e+00)\tAcc@1  52.34 ( 54.63)\tAcc@5  78.91 ( 84.14)\n","Epoch: [19][390/391]\tTime  0.159 ( 0.175)\tLoss 1.2872e+00 (1.6303e+00)\tAcc@1  60.00 ( 54.57)\tAcc@5  90.00 ( 84.10)\n","==> Train Accuracy: Acc@1 54.570 || Acc@5 84.100\n","==> Test Accuracy:  Acc@1 51.750 || Acc@5 82.170\n","==> 72.87 seconds to train this epoch\n","\n","\n","----- epoch: 20, lr: 0.1 -----\n","Epoch: [20][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.4675e+00 (1.4675e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  85.94 ( 85.94)\n","Epoch: [20][ 30/391]\tTime  0.177 ( 0.178)\tLoss 1.6555e+00 (1.5687e+00)\tAcc@1  57.81 ( 55.92)\tAcc@5  82.81 ( 85.36)\n","Epoch: [20][ 60/391]\tTime  0.173 ( 0.177)\tLoss 1.3589e+00 (1.5596e+00)\tAcc@1  65.62 ( 56.42)\tAcc@5  87.50 ( 85.22)\n","Epoch: [20][ 90/391]\tTime  0.174 ( 0.176)\tLoss 1.5656e+00 (1.5758e+00)\tAcc@1  60.16 ( 55.95)\tAcc@5  84.38 ( 84.98)\n","Epoch: [20][120/391]\tTime  0.178 ( 0.176)\tLoss 1.6443e+00 (1.5860e+00)\tAcc@1  49.22 ( 55.77)\tAcc@5  83.59 ( 84.76)\n","Epoch: [20][150/391]\tTime  0.173 ( 0.176)\tLoss 1.5838e+00 (1.5861e+00)\tAcc@1  53.12 ( 55.74)\tAcc@5  85.94 ( 84.80)\n","Epoch: [20][180/391]\tTime  0.177 ( 0.176)\tLoss 1.3935e+00 (1.5861e+00)\tAcc@1  58.59 ( 55.79)\tAcc@5  92.97 ( 84.96)\n","Epoch: [20][210/391]\tTime  0.175 ( 0.176)\tLoss 1.5032e+00 (1.5865e+00)\tAcc@1  57.81 ( 55.72)\tAcc@5  85.16 ( 84.97)\n","Epoch: [20][240/391]\tTime  0.171 ( 0.175)\tLoss 1.7493e+00 (1.5966e+00)\tAcc@1  47.66 ( 55.53)\tAcc@5  82.81 ( 84.76)\n","Epoch: [20][270/391]\tTime  0.176 ( 0.175)\tLoss 1.5866e+00 (1.5951e+00)\tAcc@1  53.91 ( 55.58)\tAcc@5  86.72 ( 84.80)\n","Epoch: [20][300/391]\tTime  0.176 ( 0.175)\tLoss 1.3804e+00 (1.6011e+00)\tAcc@1  62.50 ( 55.41)\tAcc@5  87.50 ( 84.74)\n","Epoch: [20][330/391]\tTime  0.174 ( 0.175)\tLoss 1.4974e+00 (1.6040e+00)\tAcc@1  54.69 ( 55.24)\tAcc@5  88.28 ( 84.70)\n","Epoch: [20][360/391]\tTime  0.174 ( 0.175)\tLoss 1.8441e+00 (1.6075e+00)\tAcc@1  50.78 ( 55.14)\tAcc@5  82.81 ( 84.64)\n","Epoch: [20][390/391]\tTime  0.158 ( 0.175)\tLoss 1.6555e+00 (1.6101e+00)\tAcc@1  53.75 ( 55.08)\tAcc@5  85.00 ( 84.60)\n","==> Train Accuracy: Acc@1 55.084 || Acc@5 84.596\n","==> Test Accuracy:  Acc@1 53.790 || Acc@5 82.670\n","==> 72.80 seconds to train this epoch\n","\n","\n","----- epoch: 21, lr: 0.1 -----\n","Epoch: [21][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.3894e+00 (1.3894e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  87.50 ( 87.50)\n","Epoch: [21][ 30/391]\tTime  0.175 ( 0.178)\tLoss 1.5735e+00 (1.5612e+00)\tAcc@1  59.38 ( 56.88)\tAcc@5  84.38 ( 85.51)\n","Epoch: [21][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.4592e+00 (1.5701e+00)\tAcc@1  61.72 ( 56.34)\tAcc@5  88.28 ( 85.51)\n","Epoch: [21][ 90/391]\tTime  0.177 ( 0.176)\tLoss 1.4586e+00 (1.5572e+00)\tAcc@1  59.38 ( 56.43)\tAcc@5  85.94 ( 85.84)\n","Epoch: [21][120/391]\tTime  0.178 ( 0.175)\tLoss 1.6792e+00 (1.5513e+00)\tAcc@1  50.00 ( 56.40)\tAcc@5  84.38 ( 85.87)\n","Epoch: [21][150/391]\tTime  0.176 ( 0.175)\tLoss 1.8468e+00 (1.5536e+00)\tAcc@1  53.12 ( 56.62)\tAcc@5  79.69 ( 85.76)\n","Epoch: [21][180/391]\tTime  0.174 ( 0.175)\tLoss 1.5738e+00 (1.5611e+00)\tAcc@1  58.59 ( 56.47)\tAcc@5  83.59 ( 85.53)\n","Epoch: [21][210/391]\tTime  0.176 ( 0.175)\tLoss 1.8041e+00 (1.5701e+00)\tAcc@1  44.53 ( 56.18)\tAcc@5  81.25 ( 85.29)\n","Epoch: [21][240/391]\tTime  0.177 ( 0.175)\tLoss 1.3513e+00 (1.5723e+00)\tAcc@1  59.38 ( 56.02)\tAcc@5  86.72 ( 85.23)\n","Epoch: [21][270/391]\tTime  0.174 ( 0.175)\tLoss 1.6721e+00 (1.5727e+00)\tAcc@1  53.91 ( 55.98)\tAcc@5  81.25 ( 85.23)\n","Epoch: [21][300/391]\tTime  0.172 ( 0.175)\tLoss 1.6519e+00 (1.5738e+00)\tAcc@1  56.25 ( 55.92)\tAcc@5  83.59 ( 85.18)\n","Epoch: [21][330/391]\tTime  0.171 ( 0.175)\tLoss 1.7723e+00 (1.5786e+00)\tAcc@1  53.91 ( 55.86)\tAcc@5  78.91 ( 85.09)\n","Epoch: [21][360/391]\tTime  0.175 ( 0.175)\tLoss 1.4485e+00 (1.5822e+00)\tAcc@1  60.94 ( 55.68)\tAcc@5  88.28 ( 85.06)\n","Epoch: [21][390/391]\tTime  0.157 ( 0.175)\tLoss 1.8082e+00 (1.5842e+00)\tAcc@1  45.00 ( 55.61)\tAcc@5  83.75 ( 85.02)\n","==> Train Accuracy: Acc@1 55.608 || Acc@5 85.016\n","==> Test Accuracy:  Acc@1 52.180 || Acc@5 82.460\n","==> 72.69 seconds to train this epoch\n","\n","\n","----- epoch: 22, lr: 0.1 -----\n","Epoch: [22][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.2292e+00 (1.2292e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  92.19 ( 92.19)\n","Epoch: [22][ 30/391]\tTime  0.173 ( 0.178)\tLoss 1.7072e+00 (1.4877e+00)\tAcc@1  56.25 ( 59.17)\tAcc@5  82.81 ( 86.06)\n","Epoch: [22][ 60/391]\tTime  0.174 ( 0.176)\tLoss 1.3906e+00 (1.5054e+00)\tAcc@1  57.03 ( 58.04)\tAcc@5  89.06 ( 86.14)\n","Epoch: [22][ 90/391]\tTime  0.173 ( 0.176)\tLoss 1.4572e+00 (1.5187e+00)\tAcc@1  59.38 ( 57.59)\tAcc@5  83.59 ( 85.68)\n","Epoch: [22][120/391]\tTime  0.173 ( 0.175)\tLoss 1.4680e+00 (1.5177e+00)\tAcc@1  59.38 ( 57.51)\tAcc@5  85.94 ( 85.79)\n","Epoch: [22][150/391]\tTime  0.176 ( 0.175)\tLoss 1.5454e+00 (1.5292e+00)\tAcc@1  52.34 ( 57.23)\tAcc@5  82.81 ( 85.66)\n","Epoch: [22][180/391]\tTime  0.174 ( 0.175)\tLoss 1.4433e+00 (1.5382e+00)\tAcc@1  60.94 ( 57.00)\tAcc@5  87.50 ( 85.51)\n","Epoch: [22][210/391]\tTime  0.173 ( 0.175)\tLoss 1.5636e+00 (1.5377e+00)\tAcc@1  57.81 ( 56.99)\tAcc@5  82.81 ( 85.50)\n","Epoch: [22][240/391]\tTime  0.176 ( 0.175)\tLoss 1.5319e+00 (1.5465e+00)\tAcc@1  57.03 ( 56.71)\tAcc@5  88.28 ( 85.48)\n","Epoch: [22][270/391]\tTime  0.176 ( 0.175)\tLoss 1.6906e+00 (1.5486e+00)\tAcc@1  58.59 ( 56.64)\tAcc@5  82.03 ( 85.45)\n","Epoch: [22][300/391]\tTime  0.176 ( 0.175)\tLoss 1.7861e+00 (1.5527e+00)\tAcc@1  54.69 ( 56.55)\tAcc@5  76.56 ( 85.43)\n","Epoch: [22][330/391]\tTime  0.173 ( 0.175)\tLoss 1.6489e+00 (1.5527e+00)\tAcc@1  53.91 ( 56.57)\tAcc@5  82.81 ( 85.47)\n","Epoch: [22][360/391]\tTime  0.174 ( 0.175)\tLoss 1.5463e+00 (1.5529e+00)\tAcc@1  57.81 ( 56.51)\tAcc@5  87.50 ( 85.49)\n","Epoch: [22][390/391]\tTime  0.157 ( 0.175)\tLoss 1.6136e+00 (1.5585e+00)\tAcc@1  53.75 ( 56.41)\tAcc@5  88.75 ( 85.31)\n","==> Train Accuracy: Acc@1 56.408 || Acc@5 85.312\n","==> Test Accuracy:  Acc@1 55.600 || Acc@5 83.490\n","==> 72.66 seconds to train this epoch\n","\n","\n","----- epoch: 23, lr: 0.1 -----\n","Epoch: [23][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.5520e+00 (1.5520e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  86.72 ( 86.72)\n","Epoch: [23][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.4370e+00 (1.4808e+00)\tAcc@1  54.69 ( 58.52)\tAcc@5  86.72 ( 86.47)\n","Epoch: [23][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.6379e+00 (1.4742e+00)\tAcc@1  52.34 ( 58.79)\tAcc@5  83.59 ( 86.45)\n","Epoch: [23][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.4501e+00 (1.5061e+00)\tAcc@1  60.16 ( 57.80)\tAcc@5  84.38 ( 86.02)\n","Epoch: [23][120/391]\tTime  0.176 ( 0.175)\tLoss 1.7545e+00 (1.5132e+00)\tAcc@1  53.12 ( 57.61)\tAcc@5  80.47 ( 85.82)\n","Epoch: [23][150/391]\tTime  0.176 ( 0.175)\tLoss 1.6813e+00 (1.5121e+00)\tAcc@1  51.56 ( 57.59)\tAcc@5  78.91 ( 85.87)\n","Epoch: [23][180/391]\tTime  0.175 ( 0.175)\tLoss 1.3891e+00 (1.5223e+00)\tAcc@1  60.16 ( 57.31)\tAcc@5  85.94 ( 85.74)\n","Epoch: [23][210/391]\tTime  0.175 ( 0.175)\tLoss 1.5025e+00 (1.5211e+00)\tAcc@1  56.25 ( 57.21)\tAcc@5  82.81 ( 85.76)\n","Epoch: [23][240/391]\tTime  0.172 ( 0.175)\tLoss 1.5590e+00 (1.5231e+00)\tAcc@1  57.03 ( 57.24)\tAcc@5  82.81 ( 85.66)\n","Epoch: [23][270/391]\tTime  0.174 ( 0.175)\tLoss 1.3575e+00 (1.5275e+00)\tAcc@1  57.03 ( 57.15)\tAcc@5  90.62 ( 85.62)\n","Epoch: [23][300/391]\tTime  0.176 ( 0.175)\tLoss 1.6769e+00 (1.5348e+00)\tAcc@1  56.25 ( 56.96)\tAcc@5  80.47 ( 85.56)\n","Epoch: [23][330/391]\tTime  0.173 ( 0.175)\tLoss 1.2755e+00 (1.5398e+00)\tAcc@1  62.50 ( 56.85)\tAcc@5  86.72 ( 85.46)\n","Epoch: [23][360/391]\tTime  0.174 ( 0.175)\tLoss 1.5038e+00 (1.5455e+00)\tAcc@1  57.03 ( 56.63)\tAcc@5  85.16 ( 85.46)\n","Epoch: [23][390/391]\tTime  0.159 ( 0.175)\tLoss 1.6774e+00 (1.5493e+00)\tAcc@1  53.75 ( 56.53)\tAcc@5  83.75 ( 85.39)\n","==> Train Accuracy: Acc@1 56.530 || Acc@5 85.392\n","==> Test Accuracy:  Acc@1 53.350 || Acc@5 82.400\n","==> 72.54 seconds to train this epoch\n","\n","\n","----- epoch: 24, lr: 0.1 -----\n","Epoch: [24][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.3396e+00 (1.3396e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  92.97 ( 92.97)\n","Epoch: [24][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.2029e+00 (1.4917e+00)\tAcc@1  67.97 ( 57.76)\tAcc@5  88.28 ( 85.71)\n","Epoch: [24][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.4414e+00 (1.4958e+00)\tAcc@1  60.94 ( 57.74)\tAcc@5  87.50 ( 85.98)\n","Epoch: [24][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.5367e+00 (1.4939e+00)\tAcc@1  59.38 ( 58.08)\tAcc@5  85.94 ( 86.12)\n","Epoch: [24][120/391]\tTime  0.175 ( 0.175)\tLoss 1.6268e+00 (1.4980e+00)\tAcc@1  55.47 ( 57.53)\tAcc@5  82.81 ( 86.18)\n","Epoch: [24][150/391]\tTime  0.174 ( 0.175)\tLoss 1.4792e+00 (1.5070e+00)\tAcc@1  56.25 ( 57.60)\tAcc@5  86.72 ( 86.04)\n","Epoch: [24][180/391]\tTime  0.175 ( 0.175)\tLoss 1.5479e+00 (1.5107e+00)\tAcc@1  54.69 ( 57.57)\tAcc@5  86.72 ( 86.04)\n","Epoch: [24][210/391]\tTime  0.172 ( 0.174)\tLoss 1.7177e+00 (1.5118e+00)\tAcc@1  50.00 ( 57.51)\tAcc@5  80.47 ( 86.06)\n","Epoch: [24][240/391]\tTime  0.174 ( 0.175)\tLoss 1.4761e+00 (1.5124e+00)\tAcc@1  58.59 ( 57.52)\tAcc@5  86.72 ( 85.95)\n","Epoch: [24][270/391]\tTime  0.176 ( 0.174)\tLoss 1.4876e+00 (1.5136e+00)\tAcc@1  56.25 ( 57.49)\tAcc@5  84.38 ( 86.03)\n","Epoch: [24][300/391]\tTime  0.175 ( 0.174)\tLoss 1.6405e+00 (1.5199e+00)\tAcc@1  54.69 ( 57.29)\tAcc@5  86.72 ( 86.01)\n","Epoch: [24][330/391]\tTime  0.177 ( 0.175)\tLoss 1.3745e+00 (1.5204e+00)\tAcc@1  54.69 ( 57.23)\tAcc@5  90.62 ( 86.06)\n","Epoch: [24][360/391]\tTime  0.175 ( 0.175)\tLoss 1.3649e+00 (1.5242e+00)\tAcc@1  57.81 ( 57.17)\tAcc@5  89.06 ( 85.96)\n","Epoch: [24][390/391]\tTime  0.157 ( 0.174)\tLoss 1.5868e+00 (1.5308e+00)\tAcc@1  55.00 ( 57.05)\tAcc@5  86.25 ( 85.85)\n","==> Train Accuracy: Acc@1 57.050 || Acc@5 85.850\n","==> Test Accuracy:  Acc@1 54.950 || Acc@5 84.720\n","==> 72.52 seconds to train this epoch\n","\n","\n","----- epoch: 25, lr: 0.1 -----\n","Epoch: [25][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.7390e+00 (1.7390e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  84.38 ( 84.38)\n","Epoch: [25][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.3078e+00 (1.4695e+00)\tAcc@1  63.28 ( 58.29)\tAcc@5  92.97 ( 87.25)\n","Epoch: [25][ 60/391]\tTime  0.172 ( 0.176)\tLoss 1.4564e+00 (1.4690e+00)\tAcc@1  62.50 ( 58.38)\tAcc@5  83.59 ( 87.15)\n","Epoch: [25][ 90/391]\tTime  0.179 ( 0.175)\tLoss 1.5600e+00 (1.4770e+00)\tAcc@1  53.12 ( 58.14)\tAcc@5  85.16 ( 87.01)\n","Epoch: [25][120/391]\tTime  0.175 ( 0.175)\tLoss 1.5135e+00 (1.4833e+00)\tAcc@1  53.91 ( 58.01)\tAcc@5  89.06 ( 86.85)\n","Epoch: [25][150/391]\tTime  0.173 ( 0.175)\tLoss 1.5164e+00 (1.4815e+00)\tAcc@1  60.16 ( 58.12)\tAcc@5  84.38 ( 86.88)\n","Epoch: [25][180/391]\tTime  0.173 ( 0.175)\tLoss 1.4986e+00 (1.4871e+00)\tAcc@1  57.81 ( 58.10)\tAcc@5  84.38 ( 86.76)\n","Epoch: [25][210/391]\tTime  0.176 ( 0.175)\tLoss 1.4333e+00 (1.4938e+00)\tAcc@1  56.25 ( 57.91)\tAcc@5  88.28 ( 86.71)\n","Epoch: [25][240/391]\tTime  0.176 ( 0.175)\tLoss 1.2597e+00 (1.5012e+00)\tAcc@1  61.72 ( 57.75)\tAcc@5  89.84 ( 86.53)\n","Epoch: [25][270/391]\tTime  0.174 ( 0.175)\tLoss 1.4591e+00 (1.5103e+00)\tAcc@1  58.59 ( 57.54)\tAcc@5  89.84 ( 86.41)\n","Epoch: [25][300/391]\tTime  0.174 ( 0.175)\tLoss 1.6477e+00 (1.5140e+00)\tAcc@1  47.66 ( 57.50)\tAcc@5  88.28 ( 86.38)\n","Epoch: [25][330/391]\tTime  0.174 ( 0.175)\tLoss 1.6068e+00 (1.5163e+00)\tAcc@1  49.22 ( 57.44)\tAcc@5  84.38 ( 86.31)\n","Epoch: [25][360/391]\tTime  0.176 ( 0.175)\tLoss 1.3700e+00 (1.5159e+00)\tAcc@1  63.28 ( 57.50)\tAcc@5  85.94 ( 86.29)\n","Epoch: [25][390/391]\tTime  0.155 ( 0.175)\tLoss 1.1900e+00 (1.5172e+00)\tAcc@1  68.75 ( 57.49)\tAcc@5  92.50 ( 86.21)\n","==> Train Accuracy: Acc@1 57.488 || Acc@5 86.206\n","==> Test Accuracy:  Acc@1 54.080 || Acc@5 83.440\n","==> 72.70 seconds to train this epoch\n","\n","\n","----- epoch: 26, lr: 0.1 -----\n","Epoch: [26][  0/391]\tTime  0.244 ( 0.244)\tLoss 1.3464e+00 (1.3464e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  92.19 ( 92.19)\n","Epoch: [26][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.6262e+00 (1.4344e+00)\tAcc@1  55.47 ( 59.83)\tAcc@5  84.38 ( 87.63)\n","Epoch: [26][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.6420e+00 (1.4459e+00)\tAcc@1  49.22 ( 59.44)\tAcc@5  87.50 ( 87.38)\n","Epoch: [26][ 90/391]\tTime  0.175 ( 0.176)\tLoss 1.7209e+00 (1.4697e+00)\tAcc@1  54.69 ( 58.76)\tAcc@5  80.47 ( 86.83)\n","Epoch: [26][120/391]\tTime  0.176 ( 0.175)\tLoss 1.4158e+00 (1.4700e+00)\tAcc@1  59.38 ( 58.66)\tAcc@5  85.16 ( 86.88)\n","Epoch: [26][150/391]\tTime  0.175 ( 0.175)\tLoss 1.4339e+00 (1.4809e+00)\tAcc@1  55.47 ( 58.52)\tAcc@5  87.50 ( 86.66)\n","Epoch: [26][180/391]\tTime  0.172 ( 0.175)\tLoss 1.5381e+00 (1.4854e+00)\tAcc@1  58.59 ( 58.37)\tAcc@5  82.81 ( 86.52)\n","Epoch: [26][210/391]\tTime  0.176 ( 0.175)\tLoss 1.4645e+00 (1.4945e+00)\tAcc@1  61.72 ( 58.16)\tAcc@5  89.06 ( 86.31)\n","Epoch: [26][240/391]\tTime  0.175 ( 0.175)\tLoss 1.3520e+00 (1.4972e+00)\tAcc@1  60.16 ( 57.98)\tAcc@5  92.97 ( 86.37)\n","Epoch: [26][270/391]\tTime  0.175 ( 0.175)\tLoss 1.6290e+00 (1.5020e+00)\tAcc@1  53.12 ( 57.84)\tAcc@5  85.16 ( 86.30)\n","Epoch: [26][300/391]\tTime  0.173 ( 0.175)\tLoss 1.4240e+00 (1.5076e+00)\tAcc@1  58.59 ( 57.68)\tAcc@5  85.16 ( 86.15)\n","Epoch: [26][330/391]\tTime  0.176 ( 0.175)\tLoss 1.1723e+00 (1.5076e+00)\tAcc@1  65.62 ( 57.66)\tAcc@5  89.84 ( 86.17)\n","Epoch: [26][360/391]\tTime  0.175 ( 0.175)\tLoss 1.4950e+00 (1.5064e+00)\tAcc@1  57.81 ( 57.72)\tAcc@5  90.62 ( 86.17)\n","Epoch: [26][390/391]\tTime  0.159 ( 0.175)\tLoss 1.5047e+00 (1.5042e+00)\tAcc@1  57.50 ( 57.79)\tAcc@5  90.00 ( 86.18)\n","==> Train Accuracy: Acc@1 57.794 || Acc@5 86.184\n","==> Test Accuracy:  Acc@1 56.490 || Acc@5 85.280\n","==> 72.70 seconds to train this epoch\n","\n","\n","----- epoch: 27, lr: 0.1 -----\n","Epoch: [27][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.3745e+00 (1.3745e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  86.72 ( 86.72)\n","Epoch: [27][ 30/391]\tTime  0.174 ( 0.178)\tLoss 1.1572e+00 (1.4777e+00)\tAcc@1  65.62 ( 57.64)\tAcc@5  92.19 ( 86.84)\n","Epoch: [27][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.3523e+00 (1.4623e+00)\tAcc@1  60.16 ( 58.34)\tAcc@5  87.50 ( 87.04)\n","Epoch: [27][ 90/391]\tTime  0.176 ( 0.176)\tLoss 1.3438e+00 (1.4639e+00)\tAcc@1  57.03 ( 58.68)\tAcc@5  89.84 ( 86.80)\n","Epoch: [27][120/391]\tTime  0.172 ( 0.176)\tLoss 1.5105e+00 (1.4846e+00)\tAcc@1  58.59 ( 58.23)\tAcc@5  88.28 ( 86.53)\n","Epoch: [27][150/391]\tTime  0.176 ( 0.175)\tLoss 1.5269e+00 (1.4793e+00)\tAcc@1  53.12 ( 58.26)\tAcc@5  90.62 ( 86.53)\n","Epoch: [27][180/391]\tTime  0.176 ( 0.175)\tLoss 1.5443e+00 (1.4911e+00)\tAcc@1  53.12 ( 57.89)\tAcc@5  86.72 ( 86.46)\n","Epoch: [27][210/391]\tTime  0.176 ( 0.175)\tLoss 1.2231e+00 (1.4834e+00)\tAcc@1  64.06 ( 58.14)\tAcc@5  90.62 ( 86.59)\n","Epoch: [27][240/391]\tTime  0.174 ( 0.175)\tLoss 1.5300e+00 (1.4885e+00)\tAcc@1  56.25 ( 58.06)\tAcc@5  86.72 ( 86.46)\n","Epoch: [27][270/391]\tTime  0.175 ( 0.175)\tLoss 1.5663e+00 (1.4960e+00)\tAcc@1  53.12 ( 57.86)\tAcc@5  85.94 ( 86.39)\n","Epoch: [27][300/391]\tTime  0.173 ( 0.175)\tLoss 1.4417e+00 (1.4988e+00)\tAcc@1  57.81 ( 57.78)\tAcc@5  85.94 ( 86.34)\n","Epoch: [27][330/391]\tTime  0.175 ( 0.175)\tLoss 1.5158e+00 (1.4983e+00)\tAcc@1  57.81 ( 57.80)\tAcc@5  89.06 ( 86.35)\n","Epoch: [27][360/391]\tTime  0.176 ( 0.175)\tLoss 1.6088e+00 (1.4986e+00)\tAcc@1  56.25 ( 57.82)\tAcc@5  82.81 ( 86.34)\n","Epoch: [27][390/391]\tTime  0.159 ( 0.175)\tLoss 1.4648e+00 (1.5004e+00)\tAcc@1  61.25 ( 57.84)\tAcc@5  85.00 ( 86.26)\n","==> Train Accuracy: Acc@1 57.842 || Acc@5 86.262\n","==> Test Accuracy:  Acc@1 57.150 || Acc@5 85.210\n","==> 72.74 seconds to train this epoch\n","\n","\n","----- epoch: 28, lr: 0.1 -----\n","Epoch: [28][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.5784e+00 (1.5784e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  83.59 ( 83.59)\n","Epoch: [28][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.5902e+00 (1.4501e+00)\tAcc@1  54.69 ( 58.95)\tAcc@5  85.16 ( 86.67)\n","Epoch: [28][ 60/391]\tTime  0.174 ( 0.176)\tLoss 1.2292e+00 (1.4628e+00)\tAcc@1  63.28 ( 58.56)\tAcc@5  87.50 ( 86.60)\n","Epoch: [28][ 90/391]\tTime  0.175 ( 0.176)\tLoss 1.3205e+00 (1.4563e+00)\tAcc@1  64.84 ( 58.87)\tAcc@5  89.06 ( 86.93)\n","Epoch: [28][120/391]\tTime  0.174 ( 0.175)\tLoss 1.4614e+00 (1.4606e+00)\tAcc@1  58.59 ( 58.86)\tAcc@5  89.06 ( 86.80)\n","Epoch: [28][150/391]\tTime  0.176 ( 0.175)\tLoss 1.5147e+00 (1.4585e+00)\tAcc@1  53.91 ( 58.76)\tAcc@5  87.50 ( 86.89)\n","Epoch: [28][180/391]\tTime  0.176 ( 0.175)\tLoss 1.6493e+00 (1.4655e+00)\tAcc@1  53.12 ( 58.33)\tAcc@5  83.59 ( 86.74)\n","Epoch: [28][210/391]\tTime  0.174 ( 0.175)\tLoss 1.5663e+00 (1.4684e+00)\tAcc@1  56.25 ( 58.33)\tAcc@5  83.59 ( 86.63)\n","Epoch: [28][240/391]\tTime  0.175 ( 0.175)\tLoss 1.4560e+00 (1.4692e+00)\tAcc@1  57.03 ( 58.26)\tAcc@5  89.84 ( 86.68)\n","Epoch: [28][270/391]\tTime  0.176 ( 0.175)\tLoss 1.5778e+00 (1.4719e+00)\tAcc@1  56.25 ( 58.21)\tAcc@5  82.81 ( 86.60)\n","Epoch: [28][300/391]\tTime  0.175 ( 0.175)\tLoss 1.4358e+00 (1.4754e+00)\tAcc@1  61.72 ( 58.15)\tAcc@5  86.72 ( 86.57)\n","Epoch: [28][330/391]\tTime  0.176 ( 0.175)\tLoss 1.3331e+00 (1.4714e+00)\tAcc@1  64.06 ( 58.28)\tAcc@5  85.16 ( 86.60)\n","Epoch: [28][360/391]\tTime  0.176 ( 0.175)\tLoss 1.6659e+00 (1.4782e+00)\tAcc@1  53.12 ( 58.22)\tAcc@5  81.25 ( 86.49)\n","Epoch: [28][390/391]\tTime  0.155 ( 0.175)\tLoss 1.4746e+00 (1.4844e+00)\tAcc@1  50.00 ( 58.12)\tAcc@5  90.00 ( 86.45)\n","==> Train Accuracy: Acc@1 58.116 || Acc@5 86.448\n","==> Test Accuracy:  Acc@1 57.160 || Acc@5 85.160\n","==> 72.69 seconds to train this epoch\n","\n","\n","----- epoch: 29, lr: 0.1 -----\n","Epoch: [29][  0/391]\tTime  0.259 ( 0.259)\tLoss 1.3749e+00 (1.3749e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  89.06 ( 89.06)\n","Epoch: [29][ 30/391]\tTime  0.172 ( 0.177)\tLoss 1.3488e+00 (1.4036e+00)\tAcc@1  62.50 ( 60.41)\tAcc@5  87.50 ( 87.83)\n","Epoch: [29][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.5549e+00 (1.4029e+00)\tAcc@1  54.69 ( 60.17)\tAcc@5  85.16 ( 87.64)\n","Epoch: [29][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.6425e+00 (1.4102e+00)\tAcc@1  49.22 ( 59.74)\tAcc@5  88.28 ( 87.70)\n","Epoch: [29][120/391]\tTime  0.175 ( 0.175)\tLoss 1.4493e+00 (1.4187e+00)\tAcc@1  55.47 ( 59.72)\tAcc@5  86.72 ( 87.56)\n","Epoch: [29][150/391]\tTime  0.174 ( 0.175)\tLoss 1.3445e+00 (1.4279e+00)\tAcc@1  63.28 ( 59.64)\tAcc@5  89.84 ( 87.38)\n","Epoch: [29][180/391]\tTime  0.174 ( 0.175)\tLoss 1.5079e+00 (1.4331e+00)\tAcc@1  54.69 ( 59.47)\tAcc@5  85.16 ( 87.42)\n","Epoch: [29][210/391]\tTime  0.175 ( 0.175)\tLoss 1.4281e+00 (1.4371e+00)\tAcc@1  64.84 ( 59.49)\tAcc@5  84.38 ( 87.31)\n","Epoch: [29][240/391]\tTime  0.175 ( 0.175)\tLoss 1.3557e+00 (1.4460e+00)\tAcc@1  63.28 ( 59.29)\tAcc@5  85.16 ( 87.06)\n","Epoch: [29][270/391]\tTime  0.173 ( 0.175)\tLoss 1.3017e+00 (1.4505e+00)\tAcc@1  60.16 ( 59.27)\tAcc@5  89.84 ( 87.00)\n","Epoch: [29][300/391]\tTime  0.173 ( 0.175)\tLoss 1.3301e+00 (1.4538e+00)\tAcc@1  62.50 ( 59.17)\tAcc@5  85.16 ( 86.93)\n","Epoch: [29][330/391]\tTime  0.176 ( 0.175)\tLoss 1.4554e+00 (1.4520e+00)\tAcc@1  60.94 ( 59.17)\tAcc@5  86.72 ( 87.00)\n","Epoch: [29][360/391]\tTime  0.173 ( 0.175)\tLoss 1.3004e+00 (1.4553e+00)\tAcc@1  64.06 ( 59.07)\tAcc@5  89.06 ( 86.94)\n","Epoch: [29][390/391]\tTime  0.164 ( 0.175)\tLoss 1.4260e+00 (1.4577e+00)\tAcc@1  60.00 ( 59.04)\tAcc@5  86.25 ( 86.85)\n","==> Train Accuracy: Acc@1 59.042 || Acc@5 86.848\n","==> Test Accuracy:  Acc@1 53.020 || Acc@5 81.570\n","==> 72.62 seconds to train this epoch\n","\n","\n","----- epoch: 30, lr: 0.1 -----\n","Epoch: [30][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.5474e+00 (1.5474e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  85.94 ( 85.94)\n","Epoch: [30][ 30/391]\tTime  0.172 ( 0.177)\tLoss 1.3390e+00 (1.4003e+00)\tAcc@1  61.72 ( 60.48)\tAcc@5  89.06 ( 87.40)\n","Epoch: [30][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.4165e+00 (1.3998e+00)\tAcc@1  61.72 ( 60.53)\tAcc@5  89.84 ( 87.59)\n","Epoch: [30][ 90/391]\tTime  0.180 ( 0.175)\tLoss 1.5056e+00 (1.4078e+00)\tAcc@1  57.03 ( 60.27)\tAcc@5  86.72 ( 87.54)\n","Epoch: [30][120/391]\tTime  0.175 ( 0.175)\tLoss 1.1939e+00 (1.4099e+00)\tAcc@1  63.28 ( 60.46)\tAcc@5  95.31 ( 87.55)\n","Epoch: [30][150/391]\tTime  0.176 ( 0.175)\tLoss 1.4691e+00 (1.4115e+00)\tAcc@1  60.16 ( 60.39)\tAcc@5  89.84 ( 87.52)\n","Epoch: [30][180/391]\tTime  0.175 ( 0.175)\tLoss 1.5699e+00 (1.4221e+00)\tAcc@1  56.25 ( 60.18)\tAcc@5  81.25 ( 87.37)\n","Epoch: [30][210/391]\tTime  0.175 ( 0.175)\tLoss 1.5302e+00 (1.4327e+00)\tAcc@1  52.34 ( 59.86)\tAcc@5  86.72 ( 87.27)\n","Epoch: [30][240/391]\tTime  0.172 ( 0.175)\tLoss 1.6190e+00 (1.4457e+00)\tAcc@1  55.47 ( 59.63)\tAcc@5  84.38 ( 87.10)\n","Epoch: [30][270/391]\tTime  0.179 ( 0.175)\tLoss 1.5469e+00 (1.4545e+00)\tAcc@1  59.38 ( 59.42)\tAcc@5  85.94 ( 86.97)\n","Epoch: [30][300/391]\tTime  0.172 ( 0.175)\tLoss 1.3114e+00 (1.4560e+00)\tAcc@1  59.38 ( 59.27)\tAcc@5  89.84 ( 86.94)\n","Epoch: [30][330/391]\tTime  0.174 ( 0.175)\tLoss 1.3985e+00 (1.4627e+00)\tAcc@1  58.59 ( 59.04)\tAcc@5  89.84 ( 86.84)\n","Epoch: [30][360/391]\tTime  0.173 ( 0.175)\tLoss 1.4450e+00 (1.4631e+00)\tAcc@1  61.72 ( 58.97)\tAcc@5  87.50 ( 86.81)\n","Epoch: [30][390/391]\tTime  0.156 ( 0.175)\tLoss 1.6338e+00 (1.4658e+00)\tAcc@1  46.25 ( 58.88)\tAcc@5  83.75 ( 86.75)\n","==> Train Accuracy: Acc@1 58.878 || Acc@5 86.754\n","==> Test Accuracy:  Acc@1 58.180 || Acc@5 85.500\n","==> 72.64 seconds to train this epoch\n","\n","\n","----- epoch: 31, lr: 0.1 -----\n","Epoch: [31][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.2391e+00 (1.2391e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  90.62 ( 90.62)\n","Epoch: [31][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.2364e+00 (1.3842e+00)\tAcc@1  68.75 ( 61.06)\tAcc@5  89.06 ( 87.98)\n","Epoch: [31][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.4878e+00 (1.4000e+00)\tAcc@1  61.72 ( 60.66)\tAcc@5  83.59 ( 87.65)\n","Epoch: [31][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.5940e+00 (1.4119e+00)\tAcc@1  53.91 ( 60.16)\tAcc@5  79.69 ( 87.46)\n","Epoch: [31][120/391]\tTime  0.178 ( 0.175)\tLoss 1.5523e+00 (1.4141e+00)\tAcc@1  57.81 ( 60.08)\tAcc@5  82.81 ( 87.40)\n","Epoch: [31][150/391]\tTime  0.176 ( 0.175)\tLoss 1.2561e+00 (1.4240e+00)\tAcc@1  69.53 ( 59.75)\tAcc@5  90.62 ( 87.23)\n","Epoch: [31][180/391]\tTime  0.173 ( 0.175)\tLoss 1.4991e+00 (1.4308e+00)\tAcc@1  61.72 ( 59.53)\tAcc@5  85.16 ( 87.19)\n","Epoch: [31][210/391]\tTime  0.175 ( 0.175)\tLoss 1.4576e+00 (1.4303e+00)\tAcc@1  57.81 ( 59.54)\tAcc@5  85.16 ( 87.12)\n","Epoch: [31][240/391]\tTime  0.174 ( 0.175)\tLoss 1.4695e+00 (1.4324e+00)\tAcc@1  60.94 ( 59.47)\tAcc@5  84.38 ( 87.07)\n","Epoch: [31][270/391]\tTime  0.174 ( 0.175)\tLoss 1.5754e+00 (1.4385e+00)\tAcc@1  57.03 ( 59.26)\tAcc@5  86.72 ( 87.05)\n","Epoch: [31][300/391]\tTime  0.176 ( 0.175)\tLoss 1.5407e+00 (1.4392e+00)\tAcc@1  54.69 ( 59.27)\tAcc@5  89.06 ( 87.07)\n","Epoch: [31][330/391]\tTime  0.176 ( 0.175)\tLoss 1.6023e+00 (1.4461e+00)\tAcc@1  52.34 ( 58.99)\tAcc@5  86.72 ( 87.06)\n","Epoch: [31][360/391]\tTime  0.173 ( 0.175)\tLoss 1.4338e+00 (1.4488e+00)\tAcc@1  59.38 ( 58.93)\tAcc@5  85.94 ( 87.02)\n","Epoch: [31][390/391]\tTime  0.156 ( 0.175)\tLoss 1.6522e+00 (1.4547e+00)\tAcc@1  55.00 ( 58.82)\tAcc@5  83.75 ( 86.92)\n","==> Train Accuracy: Acc@1 58.820 || Acc@5 86.920\n","==> Test Accuracy:  Acc@1 58.820 || Acc@5 85.520\n","==> 72.62 seconds to train this epoch\n","\n","\n","----- epoch: 32, lr: 0.1 -----\n","Epoch: [32][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.4056e+00 (1.4056e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.06 ( 89.06)\n","Epoch: [32][ 30/391]\tTime  0.173 ( 0.178)\tLoss 1.3314e+00 (1.3549e+00)\tAcc@1  62.50 ( 62.75)\tAcc@5  86.72 ( 88.41)\n","Epoch: [32][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.5013e+00 (1.3715e+00)\tAcc@1  60.16 ( 61.81)\tAcc@5  85.94 ( 88.18)\n","Epoch: [32][ 90/391]\tTime  0.174 ( 0.176)\tLoss 1.2943e+00 (1.3765e+00)\tAcc@1  62.50 ( 61.40)\tAcc@5  89.06 ( 88.19)\n","Epoch: [32][120/391]\tTime  0.175 ( 0.175)\tLoss 1.3267e+00 (1.3799e+00)\tAcc@1  63.28 ( 61.43)\tAcc@5  89.06 ( 88.06)\n","Epoch: [32][150/391]\tTime  0.172 ( 0.175)\tLoss 1.4613e+00 (1.3863e+00)\tAcc@1  55.47 ( 61.10)\tAcc@5  90.62 ( 88.07)\n","Epoch: [32][180/391]\tTime  0.178 ( 0.175)\tLoss 1.3343e+00 (1.3956e+00)\tAcc@1  60.16 ( 60.73)\tAcc@5  91.41 ( 87.98)\n","Epoch: [32][210/391]\tTime  0.175 ( 0.175)\tLoss 1.3426e+00 (1.3982e+00)\tAcc@1  61.72 ( 60.61)\tAcc@5  89.06 ( 87.93)\n","Epoch: [32][240/391]\tTime  0.173 ( 0.175)\tLoss 1.4682e+00 (1.4051e+00)\tAcc@1  53.91 ( 60.47)\tAcc@5  86.72 ( 87.85)\n","Epoch: [32][270/391]\tTime  0.174 ( 0.175)\tLoss 1.3551e+00 (1.4126e+00)\tAcc@1  65.62 ( 60.29)\tAcc@5  85.16 ( 87.71)\n","Epoch: [32][300/391]\tTime  0.177 ( 0.175)\tLoss 1.2803e+00 (1.4147e+00)\tAcc@1  62.50 ( 60.15)\tAcc@5  87.50 ( 87.72)\n","Epoch: [32][330/391]\tTime  0.173 ( 0.175)\tLoss 1.6758e+00 (1.4242e+00)\tAcc@1  53.12 ( 59.91)\tAcc@5  82.03 ( 87.50)\n","Epoch: [32][360/391]\tTime  0.175 ( 0.175)\tLoss 1.2550e+00 (1.4321e+00)\tAcc@1  64.84 ( 59.72)\tAcc@5  90.62 ( 87.38)\n","Epoch: [32][390/391]\tTime  0.159 ( 0.175)\tLoss 1.6905e+00 (1.4353e+00)\tAcc@1  56.25 ( 59.63)\tAcc@5  85.00 ( 87.33)\n","==> Train Accuracy: Acc@1 59.634 || Acc@5 87.332\n","==> Test Accuracy:  Acc@1 53.300 || Acc@5 82.550\n","==> 72.65 seconds to train this epoch\n","\n","\n","----- epoch: 33, lr: 0.1 -----\n","Epoch: [33][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.2642e+00 (1.2642e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.84 ( 89.84)\n","Epoch: [33][ 30/391]\tTime  0.178 ( 0.176)\tLoss 1.6372e+00 (1.3937e+00)\tAcc@1  55.47 ( 61.09)\tAcc@5  81.25 ( 87.68)\n","Epoch: [33][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.3093e+00 (1.4035e+00)\tAcc@1  64.84 ( 60.35)\tAcc@5  85.94 ( 87.51)\n","Epoch: [33][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.3748e+00 (1.3975e+00)\tAcc@1  64.84 ( 60.76)\tAcc@5  85.94 ( 87.86)\n","Epoch: [33][120/391]\tTime  0.174 ( 0.175)\tLoss 1.4745e+00 (1.4068e+00)\tAcc@1  61.72 ( 60.50)\tAcc@5  84.38 ( 87.69)\n","Epoch: [33][150/391]\tTime  0.173 ( 0.175)\tLoss 1.5213e+00 (1.4060e+00)\tAcc@1  57.81 ( 60.41)\tAcc@5  85.16 ( 87.75)\n","Epoch: [33][180/391]\tTime  0.177 ( 0.175)\tLoss 1.5119e+00 (1.4215e+00)\tAcc@1  53.12 ( 60.06)\tAcc@5  87.50 ( 87.52)\n","Epoch: [33][210/391]\tTime  0.172 ( 0.175)\tLoss 1.2930e+00 (1.4252e+00)\tAcc@1  60.94 ( 59.87)\tAcc@5  90.62 ( 87.41)\n","Epoch: [33][240/391]\tTime  0.175 ( 0.175)\tLoss 1.3486e+00 (1.4237e+00)\tAcc@1  58.59 ( 59.85)\tAcc@5  87.50 ( 87.38)\n","Epoch: [33][270/391]\tTime  0.175 ( 0.175)\tLoss 1.5358e+00 (1.4233e+00)\tAcc@1  54.69 ( 59.86)\tAcc@5  87.50 ( 87.41)\n","Epoch: [33][300/391]\tTime  0.173 ( 0.175)\tLoss 1.2230e+00 (1.4291e+00)\tAcc@1  64.06 ( 59.71)\tAcc@5  92.19 ( 87.35)\n","Epoch: [33][330/391]\tTime  0.172 ( 0.175)\tLoss 1.4869e+00 (1.4305e+00)\tAcc@1  64.06 ( 59.68)\tAcc@5  85.16 ( 87.26)\n","Epoch: [33][360/391]\tTime  0.177 ( 0.175)\tLoss 1.4286e+00 (1.4282e+00)\tAcc@1  65.62 ( 59.78)\tAcc@5  90.62 ( 87.31)\n","Epoch: [33][390/391]\tTime  0.157 ( 0.175)\tLoss 1.5275e+00 (1.4343e+00)\tAcc@1  56.25 ( 59.59)\tAcc@5  82.50 ( 87.19)\n","==> Train Accuracy: Acc@1 59.588 || Acc@5 87.188\n","==> Test Accuracy:  Acc@1 56.900 || Acc@5 85.360\n","==> 72.64 seconds to train this epoch\n","\n","\n","----- epoch: 34, lr: 0.1 -----\n","Epoch: [34][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.0852e+00 (1.0852e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  93.75 ( 93.75)\n","Epoch: [34][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.5295e+00 (1.3724e+00)\tAcc@1  56.25 ( 61.24)\tAcc@5  85.94 ( 88.03)\n","Epoch: [34][ 60/391]\tTime  0.173 ( 0.176)\tLoss 1.3151e+00 (1.3655e+00)\tAcc@1  63.28 ( 61.32)\tAcc@5  89.06 ( 88.36)\n","Epoch: [34][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.5046e+00 (1.3871e+00)\tAcc@1  63.28 ( 60.64)\tAcc@5  85.16 ( 88.08)\n","Epoch: [34][120/391]\tTime  0.174 ( 0.175)\tLoss 1.3444e+00 (1.3887e+00)\tAcc@1  65.62 ( 60.63)\tAcc@5  85.94 ( 88.02)\n","Epoch: [34][150/391]\tTime  0.172 ( 0.175)\tLoss 1.6065e+00 (1.3997e+00)\tAcc@1  50.78 ( 60.13)\tAcc@5  83.59 ( 87.89)\n","Epoch: [34][180/391]\tTime  0.175 ( 0.175)\tLoss 1.4035e+00 (1.4082e+00)\tAcc@1  67.19 ( 60.09)\tAcc@5  84.38 ( 87.68)\n","Epoch: [34][210/391]\tTime  0.175 ( 0.175)\tLoss 1.3853e+00 (1.4052e+00)\tAcc@1  58.59 ( 60.29)\tAcc@5  88.28 ( 87.64)\n","Epoch: [34][240/391]\tTime  0.176 ( 0.174)\tLoss 1.3041e+00 (1.4050e+00)\tAcc@1  61.72 ( 60.39)\tAcc@5  89.06 ( 87.68)\n","Epoch: [34][270/391]\tTime  0.173 ( 0.174)\tLoss 1.3634e+00 (1.4132e+00)\tAcc@1  64.06 ( 60.22)\tAcc@5  85.94 ( 87.49)\n","Epoch: [34][300/391]\tTime  0.175 ( 0.174)\tLoss 1.4815e+00 (1.4149e+00)\tAcc@1  54.69 ( 60.23)\tAcc@5  86.72 ( 87.43)\n","Epoch: [34][330/391]\tTime  0.175 ( 0.174)\tLoss 1.5103e+00 (1.4181e+00)\tAcc@1  57.81 ( 60.15)\tAcc@5  89.84 ( 87.40)\n","Epoch: [34][360/391]\tTime  0.174 ( 0.174)\tLoss 1.4171e+00 (1.4207e+00)\tAcc@1  61.72 ( 60.11)\tAcc@5  87.50 ( 87.34)\n","Epoch: [34][390/391]\tTime  0.158 ( 0.174)\tLoss 1.3717e+00 (1.4219e+00)\tAcc@1  63.75 ( 60.07)\tAcc@5  87.50 ( 87.33)\n","==> Train Accuracy: Acc@1 60.074 || Acc@5 87.330\n","==> Test Accuracy:  Acc@1 58.170 || Acc@5 85.850\n","==> 72.47 seconds to train this epoch\n","\n","\n","----- epoch: 35, lr: 0.1 -----\n","Epoch: [35][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.3138e+00 (1.3138e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  89.06 ( 89.06)\n","Epoch: [35][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.3474e+00 (1.3746e+00)\tAcc@1  58.59 ( 61.39)\tAcc@5  90.62 ( 88.71)\n","Epoch: [35][ 60/391]\tTime  0.171 ( 0.175)\tLoss 1.3527e+00 (1.3669e+00)\tAcc@1  63.28 ( 61.58)\tAcc@5  85.94 ( 88.58)\n","Epoch: [35][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.4706e+00 (1.3718e+00)\tAcc@1  60.16 ( 61.25)\tAcc@5  84.38 ( 88.46)\n","Epoch: [35][120/391]\tTime  0.175 ( 0.175)\tLoss 1.3514e+00 (1.3819e+00)\tAcc@1  61.72 ( 61.14)\tAcc@5  92.19 ( 88.34)\n","Epoch: [35][150/391]\tTime  0.173 ( 0.174)\tLoss 1.6512e+00 (1.3899e+00)\tAcc@1  58.59 ( 60.99)\tAcc@5  84.38 ( 88.12)\n","Epoch: [35][180/391]\tTime  0.172 ( 0.174)\tLoss 1.3119e+00 (1.3936e+00)\tAcc@1  61.72 ( 60.91)\tAcc@5  87.50 ( 88.03)\n","Epoch: [35][210/391]\tTime  0.176 ( 0.174)\tLoss 1.7770e+00 (1.4023e+00)\tAcc@1  48.44 ( 60.68)\tAcc@5  84.38 ( 87.86)\n","Epoch: [35][240/391]\tTime  0.174 ( 0.174)\tLoss 1.2576e+00 (1.4113e+00)\tAcc@1  67.97 ( 60.31)\tAcc@5  89.84 ( 87.68)\n","Epoch: [35][270/391]\tTime  0.172 ( 0.174)\tLoss 1.4391e+00 (1.4153e+00)\tAcc@1  64.84 ( 60.13)\tAcc@5  84.38 ( 87.60)\n","Epoch: [35][300/391]\tTime  0.176 ( 0.174)\tLoss 1.7861e+00 (1.4203e+00)\tAcc@1  55.47 ( 60.03)\tAcc@5  80.47 ( 87.50)\n","Epoch: [35][330/391]\tTime  0.174 ( 0.174)\tLoss 1.3552e+00 (1.4205e+00)\tAcc@1  59.38 ( 60.09)\tAcc@5  89.84 ( 87.47)\n","Epoch: [35][360/391]\tTime  0.173 ( 0.174)\tLoss 1.4269e+00 (1.4235e+00)\tAcc@1  54.69 ( 59.96)\tAcc@5  85.94 ( 87.45)\n","Epoch: [35][390/391]\tTime  0.155 ( 0.174)\tLoss 1.4688e+00 (1.4275e+00)\tAcc@1  58.75 ( 59.93)\tAcc@5  83.75 ( 87.37)\n","==> Train Accuracy: Acc@1 59.928 || Acc@5 87.368\n","==> Test Accuracy:  Acc@1 55.580 || Acc@5 83.160\n","==> 72.38 seconds to train this epoch\n","\n","\n","----- epoch: 36, lr: 0.1 -----\n","Epoch: [36][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.4680e+00 (1.4680e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  87.50 ( 87.50)\n","Epoch: [36][ 30/391]\tTime  0.172 ( 0.177)\tLoss 1.2283e+00 (1.3795e+00)\tAcc@1  66.41 ( 61.06)\tAcc@5  92.19 ( 88.13)\n","Epoch: [36][ 60/391]\tTime  0.176 ( 0.175)\tLoss 1.1244e+00 (1.3602e+00)\tAcc@1  67.97 ( 61.31)\tAcc@5  92.97 ( 88.37)\n","Epoch: [36][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.2536e+00 (1.3697e+00)\tAcc@1  60.94 ( 60.85)\tAcc@5  94.53 ( 88.22)\n","Epoch: [36][120/391]\tTime  0.174 ( 0.175)\tLoss 1.2850e+00 (1.3762e+00)\tAcc@1  63.28 ( 60.79)\tAcc@5  89.06 ( 88.17)\n","Epoch: [36][150/391]\tTime  0.175 ( 0.175)\tLoss 1.6778e+00 (1.4045e+00)\tAcc@1  53.91 ( 60.10)\tAcc@5  85.94 ( 87.89)\n","Epoch: [36][180/391]\tTime  0.174 ( 0.174)\tLoss 1.3562e+00 (1.4079e+00)\tAcc@1  61.72 ( 60.07)\tAcc@5  88.28 ( 87.83)\n","Epoch: [36][210/391]\tTime  0.175 ( 0.174)\tLoss 1.3302e+00 (1.4069e+00)\tAcc@1  62.50 ( 60.15)\tAcc@5  88.28 ( 87.86)\n","Epoch: [36][240/391]\tTime  0.176 ( 0.174)\tLoss 1.3652e+00 (1.4119e+00)\tAcc@1  64.06 ( 60.12)\tAcc@5  85.94 ( 87.67)\n","Epoch: [36][270/391]\tTime  0.177 ( 0.174)\tLoss 1.3293e+00 (1.4125e+00)\tAcc@1  64.84 ( 60.29)\tAcc@5  87.50 ( 87.65)\n","Epoch: [36][300/391]\tTime  0.172 ( 0.174)\tLoss 1.2462e+00 (1.4147e+00)\tAcc@1  64.84 ( 60.20)\tAcc@5  89.84 ( 87.58)\n","Epoch: [36][330/391]\tTime  0.174 ( 0.174)\tLoss 1.3117e+00 (1.4169e+00)\tAcc@1  70.31 ( 60.23)\tAcc@5  92.97 ( 87.53)\n","Epoch: [36][360/391]\tTime  0.175 ( 0.174)\tLoss 1.4508e+00 (1.4163e+00)\tAcc@1  57.03 ( 60.19)\tAcc@5  88.28 ( 87.55)\n","Epoch: [36][390/391]\tTime  0.155 ( 0.174)\tLoss 1.3797e+00 (1.4209e+00)\tAcc@1  62.50 ( 60.04)\tAcc@5  87.50 ( 87.46)\n","==> Train Accuracy: Acc@1 60.040 || Acc@5 87.462\n","==> Test Accuracy:  Acc@1 57.670 || Acc@5 85.970\n","==> 72.33 seconds to train this epoch\n","\n","\n","----- epoch: 37, lr: 0.1 -----\n","Epoch: [37][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.6420e+00 (1.6420e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  88.28 ( 88.28)\n","Epoch: [37][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.2326e+00 (1.3259e+00)\tAcc@1  60.16 ( 62.32)\tAcc@5  89.84 ( 89.04)\n","Epoch: [37][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.1403e+00 (1.3671e+00)\tAcc@1  64.84 ( 60.94)\tAcc@5  89.84 ( 88.50)\n","Epoch: [37][ 90/391]\tTime  0.177 ( 0.175)\tLoss 1.4550e+00 (1.3738e+00)\tAcc@1  56.25 ( 60.71)\tAcc@5  89.06 ( 88.42)\n","Epoch: [37][120/391]\tTime  0.172 ( 0.174)\tLoss 1.4505e+00 (1.3650e+00)\tAcc@1  57.81 ( 61.14)\tAcc@5  85.94 ( 88.51)\n","Epoch: [37][150/391]\tTime  0.177 ( 0.174)\tLoss 1.4623e+00 (1.3667e+00)\tAcc@1  58.59 ( 61.08)\tAcc@5  85.94 ( 88.45)\n","Epoch: [37][180/391]\tTime  0.174 ( 0.174)\tLoss 1.3230e+00 (1.3735e+00)\tAcc@1  59.38 ( 60.93)\tAcc@5  88.28 ( 88.30)\n","Epoch: [37][210/391]\tTime  0.175 ( 0.174)\tLoss 1.8129e+00 (1.3896e+00)\tAcc@1  47.66 ( 60.61)\tAcc@5  85.94 ( 88.04)\n","Epoch: [37][240/391]\tTime  0.173 ( 0.174)\tLoss 1.2877e+00 (1.3961e+00)\tAcc@1  64.84 ( 60.50)\tAcc@5  89.06 ( 87.86)\n","Epoch: [37][270/391]\tTime  0.174 ( 0.174)\tLoss 1.3537e+00 (1.3996e+00)\tAcc@1  65.62 ( 60.45)\tAcc@5  87.50 ( 87.76)\n","Epoch: [37][300/391]\tTime  0.174 ( 0.174)\tLoss 1.3824e+00 (1.4051e+00)\tAcc@1  58.59 ( 60.24)\tAcc@5  88.28 ( 87.75)\n","Epoch: [37][330/391]\tTime  0.174 ( 0.174)\tLoss 1.6019e+00 (1.4076e+00)\tAcc@1  58.59 ( 60.26)\tAcc@5  81.25 ( 87.64)\n","Epoch: [37][360/391]\tTime  0.174 ( 0.174)\tLoss 1.2572e+00 (1.4068e+00)\tAcc@1  63.28 ( 60.27)\tAcc@5  91.41 ( 87.71)\n","Epoch: [37][390/391]\tTime  0.155 ( 0.174)\tLoss 1.7526e+00 (1.4127e+00)\tAcc@1  53.75 ( 60.14)\tAcc@5  81.25 ( 87.62)\n","==> Train Accuracy: Acc@1 60.140 || Acc@5 87.624\n","==> Test Accuracy:  Acc@1 57.900 || Acc@5 85.450\n","==> 72.34 seconds to train this epoch\n","\n","\n","----- epoch: 38, lr: 0.1 -----\n","Epoch: [38][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.4114e+00 (1.4114e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  88.28 ( 88.28)\n","Epoch: [38][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.2843e+00 (1.3696e+00)\tAcc@1  59.38 ( 61.92)\tAcc@5  90.62 ( 88.58)\n","Epoch: [38][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.1296e+00 (1.3576e+00)\tAcc@1  65.62 ( 61.78)\tAcc@5  90.62 ( 88.59)\n","Epoch: [38][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.5114e+00 (1.3662e+00)\tAcc@1  59.38 ( 61.36)\tAcc@5  90.62 ( 88.43)\n","Epoch: [38][120/391]\tTime  0.174 ( 0.175)\tLoss 1.2286e+00 (1.3759e+00)\tAcc@1  62.50 ( 61.16)\tAcc@5  89.84 ( 88.35)\n","Epoch: [38][150/391]\tTime  0.175 ( 0.175)\tLoss 1.4409e+00 (1.3727e+00)\tAcc@1  60.94 ( 61.33)\tAcc@5  86.72 ( 88.43)\n","Epoch: [38][180/391]\tTime  0.173 ( 0.174)\tLoss 1.4163e+00 (1.3815e+00)\tAcc@1  64.06 ( 61.16)\tAcc@5  87.50 ( 88.28)\n","Epoch: [38][210/391]\tTime  0.174 ( 0.174)\tLoss 1.6018e+00 (1.3795e+00)\tAcc@1  52.34 ( 61.14)\tAcc@5  89.06 ( 88.26)\n","Epoch: [38][240/391]\tTime  0.173 ( 0.174)\tLoss 1.4023e+00 (1.3840e+00)\tAcc@1  54.69 ( 60.95)\tAcc@5  86.72 ( 88.12)\n","Epoch: [38][270/391]\tTime  0.175 ( 0.174)\tLoss 1.3375e+00 (1.3880e+00)\tAcc@1  63.28 ( 60.89)\tAcc@5  89.84 ( 87.99)\n","Epoch: [38][300/391]\tTime  0.176 ( 0.174)\tLoss 1.4354e+00 (1.3959e+00)\tAcc@1  59.38 ( 60.69)\tAcc@5  90.62 ( 87.90)\n","Epoch: [38][330/391]\tTime  0.175 ( 0.174)\tLoss 1.3538e+00 (1.3980e+00)\tAcc@1  59.38 ( 60.60)\tAcc@5  87.50 ( 87.85)\n","Epoch: [38][360/391]\tTime  0.176 ( 0.174)\tLoss 1.3111e+00 (1.3984e+00)\tAcc@1  65.62 ( 60.55)\tAcc@5  89.06 ( 87.89)\n","Epoch: [38][390/391]\tTime  0.158 ( 0.174)\tLoss 1.1670e+00 (1.4023e+00)\tAcc@1  65.00 ( 60.48)\tAcc@5  91.25 ( 87.82)\n","==> Train Accuracy: Acc@1 60.482 || Acc@5 87.824\n","==> Test Accuracy:  Acc@1 58.900 || Acc@5 86.630\n","==> 72.45 seconds to train this epoch\n","\n","\n","----- epoch: 39, lr: 0.1 -----\n","Epoch: [39][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.3583e+00 (1.3583e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  86.72 ( 86.72)\n","Epoch: [39][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.0717e+00 (1.3065e+00)\tAcc@1  66.41 ( 62.80)\tAcc@5  90.62 ( 88.41)\n","Epoch: [39][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.5905e+00 (1.3170e+00)\tAcc@1  53.91 ( 62.35)\tAcc@5  82.03 ( 88.99)\n","Epoch: [39][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.2881e+00 (1.3424e+00)\tAcc@1  64.06 ( 61.86)\tAcc@5  88.28 ( 88.56)\n","Epoch: [39][120/391]\tTime  0.171 ( 0.175)\tLoss 1.3343e+00 (1.3479e+00)\tAcc@1  57.81 ( 61.73)\tAcc@5  90.62 ( 88.59)\n","Epoch: [39][150/391]\tTime  0.173 ( 0.175)\tLoss 1.2857e+00 (1.3458e+00)\tAcc@1  71.09 ( 61.98)\tAcc@5  84.38 ( 88.56)\n","Epoch: [39][180/391]\tTime  0.175 ( 0.175)\tLoss 1.3758e+00 (1.3482e+00)\tAcc@1  61.72 ( 62.03)\tAcc@5  86.72 ( 88.51)\n","Epoch: [39][210/391]\tTime  0.174 ( 0.175)\tLoss 1.4029e+00 (1.3498e+00)\tAcc@1  61.72 ( 61.95)\tAcc@5  87.50 ( 88.57)\n","Epoch: [39][240/391]\tTime  0.173 ( 0.175)\tLoss 1.1086e+00 (1.3622e+00)\tAcc@1  67.19 ( 61.66)\tAcc@5  92.19 ( 88.42)\n","Epoch: [39][270/391]\tTime  0.176 ( 0.175)\tLoss 1.4648e+00 (1.3728e+00)\tAcc@1  57.81 ( 61.27)\tAcc@5  82.81 ( 88.28)\n","Epoch: [39][300/391]\tTime  0.172 ( 0.175)\tLoss 1.4624e+00 (1.3794e+00)\tAcc@1  57.03 ( 61.03)\tAcc@5  90.62 ( 88.23)\n","Epoch: [39][330/391]\tTime  0.174 ( 0.175)\tLoss 1.2623e+00 (1.3856e+00)\tAcc@1  68.75 ( 60.92)\tAcc@5  90.62 ( 88.11)\n","Epoch: [39][360/391]\tTime  0.175 ( 0.175)\tLoss 1.4749e+00 (1.3913e+00)\tAcc@1  57.81 ( 60.80)\tAcc@5  86.72 ( 88.03)\n","Epoch: [39][390/391]\tTime  0.157 ( 0.175)\tLoss 1.4654e+00 (1.3963e+00)\tAcc@1  61.25 ( 60.64)\tAcc@5  83.75 ( 87.92)\n","==> Train Accuracy: Acc@1 60.644 || Acc@5 87.924\n","==> Test Accuracy:  Acc@1 58.290 || Acc@5 86.150\n","==> 72.62 seconds to train this epoch\n","\n","\n","----- epoch: 40, lr: 0.1 -----\n","Epoch: [40][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.4407e+00 (1.4407e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  88.28 ( 88.28)\n","Epoch: [40][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.2563e+00 (1.3634e+00)\tAcc@1  61.72 ( 62.12)\tAcc@5  92.97 ( 88.10)\n","Epoch: [40][ 60/391]\tTime  0.172 ( 0.176)\tLoss 1.5635e+00 (1.3670e+00)\tAcc@1  57.03 ( 61.62)\tAcc@5  85.94 ( 88.11)\n","Epoch: [40][ 90/391]\tTime  0.178 ( 0.175)\tLoss 1.2990e+00 (1.3725e+00)\tAcc@1  62.50 ( 61.70)\tAcc@5  85.94 ( 87.90)\n","Epoch: [40][120/391]\tTime  0.175 ( 0.175)\tLoss 1.5650e+00 (1.3666e+00)\tAcc@1  60.16 ( 61.69)\tAcc@5  83.59 ( 88.12)\n","Epoch: [40][150/391]\tTime  0.174 ( 0.175)\tLoss 1.3754e+00 (1.3610e+00)\tAcc@1  60.94 ( 61.71)\tAcc@5  88.28 ( 88.24)\n","Epoch: [40][180/391]\tTime  0.176 ( 0.175)\tLoss 1.5197e+00 (1.3674e+00)\tAcc@1  63.28 ( 61.40)\tAcc@5  86.72 ( 88.18)\n","Epoch: [40][210/391]\tTime  0.172 ( 0.175)\tLoss 1.4309e+00 (1.3760e+00)\tAcc@1  61.72 ( 61.17)\tAcc@5  85.94 ( 88.10)\n","Epoch: [40][240/391]\tTime  0.174 ( 0.175)\tLoss 1.6226e+00 (1.3783e+00)\tAcc@1  58.59 ( 61.10)\tAcc@5  84.38 ( 88.08)\n","Epoch: [40][270/391]\tTime  0.176 ( 0.175)\tLoss 1.3592e+00 (1.3823e+00)\tAcc@1  59.38 ( 60.98)\tAcc@5  88.28 ( 88.05)\n","Epoch: [40][300/391]\tTime  0.176 ( 0.175)\tLoss 1.3870e+00 (1.3862e+00)\tAcc@1  58.59 ( 60.87)\tAcc@5  89.06 ( 87.97)\n","Epoch: [40][330/391]\tTime  0.174 ( 0.175)\tLoss 1.3564e+00 (1.3909e+00)\tAcc@1  59.38 ( 60.78)\tAcc@5  89.84 ( 87.92)\n","Epoch: [40][360/391]\tTime  0.178 ( 0.175)\tLoss 1.4069e+00 (1.3928e+00)\tAcc@1  58.59 ( 60.71)\tAcc@5  85.94 ( 87.88)\n","Epoch: [40][390/391]\tTime  0.150 ( 0.175)\tLoss 1.3309e+00 (1.3961e+00)\tAcc@1  62.50 ( 60.65)\tAcc@5  90.00 ( 87.83)\n","==> Train Accuracy: Acc@1 60.648 || Acc@5 87.830\n","==> Test Accuracy:  Acc@1 57.810 || Acc@5 85.530\n","==> 72.62 seconds to train this epoch\n","\n","\n","----- epoch: 41, lr: 0.1 -----\n","Epoch: [41][  0/391]\tTime  0.258 ( 0.258)\tLoss 1.4057e+00 (1.4057e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  87.50 ( 87.50)\n","Epoch: [41][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.2907e+00 (1.3199e+00)\tAcc@1  57.81 ( 61.69)\tAcc@5  88.28 ( 89.54)\n","Epoch: [41][ 60/391]\tTime  0.179 ( 0.176)\tLoss 1.4780e+00 (1.3426e+00)\tAcc@1  62.50 ( 61.54)\tAcc@5  85.16 ( 89.15)\n","Epoch: [41][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.3430e+00 (1.3479e+00)\tAcc@1  60.94 ( 61.51)\tAcc@5  87.50 ( 88.96)\n","Epoch: [41][120/391]\tTime  0.176 ( 0.175)\tLoss 1.3059e+00 (1.3513e+00)\tAcc@1  68.75 ( 61.77)\tAcc@5  86.72 ( 88.77)\n","Epoch: [41][150/391]\tTime  0.173 ( 0.175)\tLoss 1.5927e+00 (1.3612e+00)\tAcc@1  57.03 ( 61.70)\tAcc@5  81.25 ( 88.53)\n","Epoch: [41][180/391]\tTime  0.173 ( 0.175)\tLoss 1.4223e+00 (1.3708e+00)\tAcc@1  59.38 ( 61.41)\tAcc@5  89.06 ( 88.35)\n","Epoch: [41][210/391]\tTime  0.175 ( 0.175)\tLoss 1.3310e+00 (1.3754e+00)\tAcc@1  63.28 ( 61.29)\tAcc@5  89.06 ( 88.32)\n","Epoch: [41][240/391]\tTime  0.175 ( 0.175)\tLoss 1.3212e+00 (1.3762e+00)\tAcc@1  61.72 ( 61.22)\tAcc@5  89.06 ( 88.23)\n","Epoch: [41][270/391]\tTime  0.173 ( 0.175)\tLoss 1.3448e+00 (1.3788e+00)\tAcc@1  59.38 ( 61.14)\tAcc@5  90.62 ( 88.18)\n","Epoch: [41][300/391]\tTime  0.176 ( 0.175)\tLoss 1.2375e+00 (1.3869e+00)\tAcc@1  67.97 ( 61.06)\tAcc@5  91.41 ( 88.01)\n","Epoch: [41][330/391]\tTime  0.174 ( 0.175)\tLoss 1.2358e+00 (1.3890e+00)\tAcc@1  61.72 ( 60.99)\tAcc@5  90.62 ( 87.99)\n","Epoch: [41][360/391]\tTime  0.176 ( 0.175)\tLoss 1.2680e+00 (1.3921e+00)\tAcc@1  59.38 ( 60.76)\tAcc@5  92.19 ( 87.94)\n","Epoch: [41][390/391]\tTime  0.157 ( 0.175)\tLoss 1.4302e+00 (1.3975e+00)\tAcc@1  65.00 ( 60.57)\tAcc@5  87.50 ( 87.87)\n","==> Train Accuracy: Acc@1 60.572 || Acc@5 87.874\n","==> Test Accuracy:  Acc@1 51.250 || Acc@5 81.300\n","==> 72.59 seconds to train this epoch\n","\n","\n","----- epoch: 42, lr: 0.1 -----\n","Epoch: [42][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.4821e+00 (1.4821e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  88.28 ( 88.28)\n","Epoch: [42][ 30/391]\tTime  0.177 ( 0.177)\tLoss 1.4013e+00 (1.3339e+00)\tAcc@1  62.50 ( 62.35)\tAcc@5  87.50 ( 88.86)\n","Epoch: [42][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.3148e+00 (1.3245e+00)\tAcc@1  61.72 ( 62.12)\tAcc@5  91.41 ( 89.37)\n","Epoch: [42][ 90/391]\tTime  0.177 ( 0.175)\tLoss 1.3580e+00 (1.3385e+00)\tAcc@1  53.91 ( 61.62)\tAcc@5  92.19 ( 88.96)\n","Epoch: [42][120/391]\tTime  0.175 ( 0.175)\tLoss 1.1563e+00 (1.3465e+00)\tAcc@1  65.62 ( 61.53)\tAcc@5  93.75 ( 88.84)\n","Epoch: [42][150/391]\tTime  0.171 ( 0.175)\tLoss 1.3074e+00 (1.3482e+00)\tAcc@1  62.50 ( 61.50)\tAcc@5  92.97 ( 88.77)\n","Epoch: [42][180/391]\tTime  0.175 ( 0.175)\tLoss 1.3395e+00 (1.3575e+00)\tAcc@1  60.16 ( 61.35)\tAcc@5  89.84 ( 88.58)\n","Epoch: [42][210/391]\tTime  0.175 ( 0.175)\tLoss 1.4750e+00 (1.3635e+00)\tAcc@1  57.81 ( 61.25)\tAcc@5  85.16 ( 88.49)\n","Epoch: [42][240/391]\tTime  0.172 ( 0.175)\tLoss 1.2606e+00 (1.3727e+00)\tAcc@1  64.06 ( 60.88)\tAcc@5  92.19 ( 88.40)\n","Epoch: [42][270/391]\tTime  0.177 ( 0.175)\tLoss 1.4643e+00 (1.3763e+00)\tAcc@1  59.38 ( 60.87)\tAcc@5  85.16 ( 88.33)\n","Epoch: [42][300/391]\tTime  0.176 ( 0.175)\tLoss 1.4979e+00 (1.3780e+00)\tAcc@1  55.47 ( 60.84)\tAcc@5  86.72 ( 88.32)\n","Epoch: [42][330/391]\tTime  0.179 ( 0.175)\tLoss 1.2830e+00 (1.3843e+00)\tAcc@1  65.62 ( 60.76)\tAcc@5  89.06 ( 88.18)\n","Epoch: [42][360/391]\tTime  0.175 ( 0.175)\tLoss 1.2299e+00 (1.3875e+00)\tAcc@1  67.19 ( 60.60)\tAcc@5  90.62 ( 88.12)\n","Epoch: [42][390/391]\tTime  0.156 ( 0.175)\tLoss 1.1220e+00 (1.3923e+00)\tAcc@1  67.50 ( 60.43)\tAcc@5  92.50 ( 88.05)\n","==> Train Accuracy: Acc@1 60.430 || Acc@5 88.050\n","==> Test Accuracy:  Acc@1 55.550 || Acc@5 84.170\n","==> 72.59 seconds to train this epoch\n","\n","\n","----- epoch: 43, lr: 0.1 -----\n","Epoch: [43][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.4665e+00 (1.4665e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  86.72 ( 86.72)\n","Epoch: [43][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.3378e+00 (1.3981e+00)\tAcc@1  64.06 ( 60.31)\tAcc@5  89.84 ( 88.10)\n","Epoch: [43][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.3924e+00 (1.3475e+00)\tAcc@1  56.25 ( 61.69)\tAcc@5  88.28 ( 89.14)\n","Epoch: [43][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.3072e+00 (1.3394e+00)\tAcc@1  65.62 ( 61.79)\tAcc@5  89.06 ( 89.05)\n","Epoch: [43][120/391]\tTime  0.172 ( 0.175)\tLoss 1.4123e+00 (1.3530e+00)\tAcc@1  59.38 ( 61.48)\tAcc@5  88.28 ( 88.92)\n","Epoch: [43][150/391]\tTime  0.176 ( 0.175)\tLoss 1.1598e+00 (1.3639e+00)\tAcc@1  68.75 ( 61.25)\tAcc@5  91.41 ( 88.72)\n","Epoch: [43][180/391]\tTime  0.173 ( 0.175)\tLoss 1.4385e+00 (1.3685e+00)\tAcc@1  59.38 ( 61.17)\tAcc@5  90.62 ( 88.61)\n","Epoch: [43][210/391]\tTime  0.173 ( 0.175)\tLoss 1.3708e+00 (1.3659e+00)\tAcc@1  58.59 ( 61.19)\tAcc@5  92.97 ( 88.63)\n","Epoch: [43][240/391]\tTime  0.176 ( 0.175)\tLoss 1.3222e+00 (1.3690e+00)\tAcc@1  60.94 ( 61.20)\tAcc@5  89.84 ( 88.48)\n","Epoch: [43][270/391]\tTime  0.174 ( 0.175)\tLoss 1.3790e+00 (1.3721e+00)\tAcc@1  67.19 ( 61.11)\tAcc@5  85.16 ( 88.38)\n","Epoch: [43][300/391]\tTime  0.176 ( 0.174)\tLoss 1.3549e+00 (1.3765e+00)\tAcc@1  56.25 ( 61.00)\tAcc@5  90.62 ( 88.24)\n","Epoch: [43][330/391]\tTime  0.171 ( 0.174)\tLoss 1.3690e+00 (1.3777e+00)\tAcc@1  57.81 ( 60.97)\tAcc@5  90.62 ( 88.27)\n","Epoch: [43][360/391]\tTime  0.175 ( 0.174)\tLoss 1.2514e+00 (1.3788e+00)\tAcc@1  64.06 ( 61.01)\tAcc@5  92.97 ( 88.21)\n","Epoch: [43][390/391]\tTime  0.156 ( 0.174)\tLoss 1.5983e+00 (1.3820e+00)\tAcc@1  52.50 ( 60.93)\tAcc@5  87.50 ( 88.19)\n","==> Train Accuracy: Acc@1 60.928 || Acc@5 88.190\n","==> Test Accuracy:  Acc@1 54.870 || Acc@5 83.620\n","==> 72.50 seconds to train this epoch\n","\n","\n","----- epoch: 44, lr: 0.1 -----\n","Epoch: [44][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.1277e+00 (1.1277e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  92.97 ( 92.97)\n","Epoch: [44][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.6386e+00 (1.3129e+00)\tAcc@1  57.03 ( 62.60)\tAcc@5  84.38 ( 89.47)\n","Epoch: [44][ 60/391]\tTime  0.174 ( 0.176)\tLoss 1.2552e+00 (1.3090e+00)\tAcc@1  63.28 ( 63.05)\tAcc@5  89.84 ( 89.36)\n","Epoch: [44][ 90/391]\tTime  0.171 ( 0.175)\tLoss 1.0412e+00 (1.3142e+00)\tAcc@1  70.31 ( 62.73)\tAcc@5  90.62 ( 89.23)\n","Epoch: [44][120/391]\tTime  0.176 ( 0.175)\tLoss 1.4594e+00 (1.3274e+00)\tAcc@1  54.69 ( 62.38)\tAcc@5  86.72 ( 89.00)\n","Epoch: [44][150/391]\tTime  0.178 ( 0.175)\tLoss 1.3712e+00 (1.3333e+00)\tAcc@1  60.16 ( 62.30)\tAcc@5  89.84 ( 88.79)\n","Epoch: [44][180/391]\tTime  0.175 ( 0.175)\tLoss 1.3607e+00 (1.3434e+00)\tAcc@1  62.50 ( 62.12)\tAcc@5  85.16 ( 88.63)\n","Epoch: [44][210/391]\tTime  0.174 ( 0.175)\tLoss 1.3728e+00 (1.3431e+00)\tAcc@1  60.94 ( 62.06)\tAcc@5  89.06 ( 88.60)\n","Epoch: [44][240/391]\tTime  0.174 ( 0.175)\tLoss 1.5216e+00 (1.3502e+00)\tAcc@1  51.56 ( 61.84)\tAcc@5  91.41 ( 88.53)\n","Epoch: [44][270/391]\tTime  0.176 ( 0.175)\tLoss 1.5314e+00 (1.3609e+00)\tAcc@1  58.59 ( 61.54)\tAcc@5  85.94 ( 88.34)\n","Epoch: [44][300/391]\tTime  0.174 ( 0.175)\tLoss 1.4004e+00 (1.3674e+00)\tAcc@1  59.38 ( 61.32)\tAcc@5  87.50 ( 88.25)\n","Epoch: [44][330/391]\tTime  0.180 ( 0.174)\tLoss 1.2395e+00 (1.3647e+00)\tAcc@1  62.50 ( 61.31)\tAcc@5  90.62 ( 88.23)\n","Epoch: [44][360/391]\tTime  0.169 ( 0.174)\tLoss 1.4184e+00 (1.3705e+00)\tAcc@1  56.25 ( 61.11)\tAcc@5  85.94 ( 88.12)\n","Epoch: [44][390/391]\tTime  0.159 ( 0.174)\tLoss 1.1097e+00 (1.3739e+00)\tAcc@1  70.00 ( 61.07)\tAcc@5  92.50 ( 88.08)\n","==> Train Accuracy: Acc@1 61.066 || Acc@5 88.082\n","==> Test Accuracy:  Acc@1 56.070 || Acc@5 84.490\n","==> 72.51 seconds to train this epoch\n","\n","\n","----- epoch: 45, lr: 0.1 -----\n","Epoch: [45][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.3385e+00 (1.3385e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  92.19 ( 92.19)\n","Epoch: [45][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.1621e+00 (1.2924e+00)\tAcc@1  63.28 ( 63.23)\tAcc@5  90.62 ( 89.57)\n","Epoch: [45][ 60/391]\tTime  0.174 ( 0.176)\tLoss 1.1623e+00 (1.2946e+00)\tAcc@1  66.41 ( 63.33)\tAcc@5  92.97 ( 89.70)\n","Epoch: [45][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.2951e+00 (1.3296e+00)\tAcc@1  63.28 ( 62.59)\tAcc@5  85.94 ( 89.03)\n","Epoch: [45][120/391]\tTime  0.174 ( 0.175)\tLoss 1.4420e+00 (1.3371e+00)\tAcc@1  59.38 ( 62.41)\tAcc@5  85.94 ( 88.89)\n","Epoch: [45][150/391]\tTime  0.175 ( 0.175)\tLoss 1.1326e+00 (1.3349e+00)\tAcc@1  73.44 ( 62.30)\tAcc@5  90.62 ( 88.89)\n","Epoch: [45][180/391]\tTime  0.173 ( 0.175)\tLoss 1.5037e+00 (1.3422e+00)\tAcc@1  53.91 ( 62.09)\tAcc@5  88.28 ( 88.71)\n","Epoch: [45][210/391]\tTime  0.175 ( 0.175)\tLoss 1.4774e+00 (1.3496e+00)\tAcc@1  62.50 ( 61.89)\tAcc@5  89.06 ( 88.64)\n","Epoch: [45][240/391]\tTime  0.173 ( 0.175)\tLoss 1.2676e+00 (1.3567e+00)\tAcc@1  60.16 ( 61.72)\tAcc@5  91.41 ( 88.56)\n","Epoch: [45][270/391]\tTime  0.175 ( 0.175)\tLoss 1.4023e+00 (1.3597e+00)\tAcc@1  61.72 ( 61.62)\tAcc@5  84.38 ( 88.53)\n","Epoch: [45][300/391]\tTime  0.174 ( 0.175)\tLoss 1.3464e+00 (1.3637e+00)\tAcc@1  63.28 ( 61.51)\tAcc@5  87.50 ( 88.49)\n","Epoch: [45][330/391]\tTime  0.173 ( 0.175)\tLoss 1.4081e+00 (1.3652e+00)\tAcc@1  62.50 ( 61.45)\tAcc@5  86.72 ( 88.41)\n","Epoch: [45][360/391]\tTime  0.174 ( 0.175)\tLoss 1.3538e+00 (1.3674e+00)\tAcc@1  68.75 ( 61.34)\tAcc@5  89.06 ( 88.34)\n","Epoch: [45][390/391]\tTime  0.156 ( 0.175)\tLoss 1.4332e+00 (1.3689e+00)\tAcc@1  61.25 ( 61.25)\tAcc@5  88.75 ( 88.29)\n","==> Train Accuracy: Acc@1 61.252 || Acc@5 88.288\n","==> Test Accuracy:  Acc@1 56.220 || Acc@5 84.300\n","==> 72.55 seconds to train this epoch\n","\n","\n","----- epoch: 46, lr: 0.1 -----\n","Epoch: [46][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.2221e+00 (1.2221e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  92.97 ( 92.97)\n","Epoch: [46][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.3562e+00 (1.3309e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  85.16 ( 89.39)\n","Epoch: [46][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.0940e+00 (1.3392e+00)\tAcc@1  71.09 ( 61.30)\tAcc@5  91.41 ( 89.10)\n","Epoch: [46][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.3549e+00 (1.3378e+00)\tAcc@1  60.94 ( 61.54)\tAcc@5  89.06 ( 89.06)\n","Epoch: [46][120/391]\tTime  0.181 ( 0.175)\tLoss 1.4941e+00 (1.3521e+00)\tAcc@1  59.38 ( 61.49)\tAcc@5  82.81 ( 88.75)\n","Epoch: [46][150/391]\tTime  0.173 ( 0.175)\tLoss 1.4550e+00 (1.3462e+00)\tAcc@1  59.38 ( 61.83)\tAcc@5  89.84 ( 88.79)\n","Epoch: [46][180/391]\tTime  0.174 ( 0.175)\tLoss 1.4548e+00 (1.3485e+00)\tAcc@1  64.06 ( 61.79)\tAcc@5  84.38 ( 88.71)\n","Epoch: [46][210/391]\tTime  0.176 ( 0.175)\tLoss 1.2504e+00 (1.3452e+00)\tAcc@1  67.19 ( 61.85)\tAcc@5  91.41 ( 88.77)\n","Epoch: [46][240/391]\tTime  0.178 ( 0.175)\tLoss 1.3715e+00 (1.3510e+00)\tAcc@1  60.94 ( 61.74)\tAcc@5  87.50 ( 88.66)\n","Epoch: [46][270/391]\tTime  0.177 ( 0.175)\tLoss 1.5946e+00 (1.3519e+00)\tAcc@1  55.47 ( 61.76)\tAcc@5  84.38 ( 88.62)\n","Epoch: [46][300/391]\tTime  0.174 ( 0.175)\tLoss 1.1759e+00 (1.3549e+00)\tAcc@1  60.94 ( 61.57)\tAcc@5  89.84 ( 88.57)\n","Epoch: [46][330/391]\tTime  0.174 ( 0.175)\tLoss 1.2818e+00 (1.3565e+00)\tAcc@1  61.72 ( 61.58)\tAcc@5  91.41 ( 88.45)\n","Epoch: [46][360/391]\tTime  0.175 ( 0.175)\tLoss 1.3694e+00 (1.3591e+00)\tAcc@1  60.94 ( 61.57)\tAcc@5  89.06 ( 88.37)\n","Epoch: [46][390/391]\tTime  0.157 ( 0.174)\tLoss 1.6804e+00 (1.3626e+00)\tAcc@1  58.75 ( 61.50)\tAcc@5  80.00 ( 88.33)\n","==> Train Accuracy: Acc@1 61.504 || Acc@5 88.334\n","==> Test Accuracy:  Acc@1 57.560 || Acc@5 85.190\n","==> 72.54 seconds to train this epoch\n","\n","\n","----- epoch: 47, lr: 0.1 -----\n","Epoch: [47][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.3839e+00 (1.3839e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  90.62 ( 90.62)\n","Epoch: [47][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.4226e+00 (1.3385e+00)\tAcc@1  56.25 ( 61.42)\tAcc@5  88.28 ( 88.94)\n","Epoch: [47][ 60/391]\tTime  0.174 ( 0.176)\tLoss 1.2173e+00 (1.3009e+00)\tAcc@1  65.62 ( 62.72)\tAcc@5  89.06 ( 89.40)\n","Epoch: [47][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.2449e+00 (1.2968e+00)\tAcc@1  64.06 ( 63.08)\tAcc@5  92.19 ( 89.50)\n","Epoch: [47][120/391]\tTime  0.175 ( 0.175)\tLoss 1.2008e+00 (1.2926e+00)\tAcc@1  65.62 ( 63.22)\tAcc@5  89.84 ( 89.42)\n","Epoch: [47][150/391]\tTime  0.175 ( 0.175)\tLoss 1.4965e+00 (1.3112e+00)\tAcc@1  55.47 ( 62.69)\tAcc@5  89.06 ( 89.19)\n","Epoch: [47][180/391]\tTime  0.173 ( 0.175)\tLoss 1.6673e+00 (1.3229e+00)\tAcc@1  50.00 ( 62.37)\tAcc@5  82.81 ( 89.10)\n","Epoch: [47][210/391]\tTime  0.175 ( 0.175)\tLoss 1.3540e+00 (1.3342e+00)\tAcc@1  58.59 ( 62.12)\tAcc@5  89.06 ( 88.94)\n","Epoch: [47][240/391]\tTime  0.176 ( 0.175)\tLoss 1.3590e+00 (1.3404e+00)\tAcc@1  58.59 ( 62.06)\tAcc@5  91.41 ( 88.90)\n","Epoch: [47][270/391]\tTime  0.174 ( 0.175)\tLoss 1.3482e+00 (1.3474e+00)\tAcc@1  59.38 ( 61.89)\tAcc@5  89.84 ( 88.78)\n","Epoch: [47][300/391]\tTime  0.173 ( 0.175)\tLoss 1.3499e+00 (1.3476e+00)\tAcc@1  62.50 ( 61.90)\tAcc@5  87.50 ( 88.73)\n","Epoch: [47][330/391]\tTime  0.174 ( 0.175)\tLoss 1.6009e+00 (1.3564e+00)\tAcc@1  55.47 ( 61.72)\tAcc@5  86.72 ( 88.58)\n","Epoch: [47][360/391]\tTime  0.175 ( 0.175)\tLoss 1.3788e+00 (1.3609e+00)\tAcc@1  61.72 ( 61.62)\tAcc@5  89.06 ( 88.53)\n","Epoch: [47][390/391]\tTime  0.157 ( 0.175)\tLoss 1.3176e+00 (1.3644e+00)\tAcc@1  67.50 ( 61.58)\tAcc@5  90.00 ( 88.46)\n","==> Train Accuracy: Acc@1 61.580 || Acc@5 88.460\n","==> Test Accuracy:  Acc@1 60.650 || Acc@5 86.760\n","==> 72.61 seconds to train this epoch\n","\n","\n","----- epoch: 48, lr: 0.1 -----\n","Epoch: [48][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.1407e+00 (1.1407e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  92.97 ( 92.97)\n","Epoch: [48][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.3593e+00 (1.3125e+00)\tAcc@1  62.50 ( 62.55)\tAcc@5  87.50 ( 89.14)\n","Epoch: [48][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.2896e+00 (1.2939e+00)\tAcc@1  63.28 ( 63.45)\tAcc@5  90.62 ( 89.33)\n","Epoch: [48][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.3634e+00 (1.2995e+00)\tAcc@1  65.62 ( 63.12)\tAcc@5  86.72 ( 89.30)\n","Epoch: [48][120/391]\tTime  0.175 ( 0.175)\tLoss 1.3631e+00 (1.3196e+00)\tAcc@1  62.50 ( 62.59)\tAcc@5  89.06 ( 89.00)\n","Epoch: [48][150/391]\tTime  0.175 ( 0.175)\tLoss 1.3446e+00 (1.3266e+00)\tAcc@1  69.53 ( 62.72)\tAcc@5  87.50 ( 88.84)\n","Epoch: [48][180/391]\tTime  0.173 ( 0.175)\tLoss 1.0790e+00 (1.3279e+00)\tAcc@1  71.09 ( 62.56)\tAcc@5  90.62 ( 88.83)\n","Epoch: [48][210/391]\tTime  0.173 ( 0.175)\tLoss 1.3278e+00 (1.3343e+00)\tAcc@1  64.06 ( 62.34)\tAcc@5  88.28 ( 88.71)\n","Epoch: [48][240/391]\tTime  0.176 ( 0.175)\tLoss 1.2683e+00 (1.3393e+00)\tAcc@1  67.19 ( 62.10)\tAcc@5  87.50 ( 88.66)\n","Epoch: [48][270/391]\tTime  0.179 ( 0.175)\tLoss 1.4938e+00 (1.3486e+00)\tAcc@1  57.03 ( 61.75)\tAcc@5  84.38 ( 88.58)\n","Epoch: [48][300/391]\tTime  0.170 ( 0.175)\tLoss 1.3174e+00 (1.3569e+00)\tAcc@1  64.06 ( 61.53)\tAcc@5  89.06 ( 88.51)\n","Epoch: [48][330/391]\tTime  0.173 ( 0.175)\tLoss 1.1531e+00 (1.3581e+00)\tAcc@1  70.31 ( 61.50)\tAcc@5  90.62 ( 88.48)\n","Epoch: [48][360/391]\tTime  0.176 ( 0.175)\tLoss 1.3404e+00 (1.3553e+00)\tAcc@1  64.06 ( 61.52)\tAcc@5  89.06 ( 88.50)\n","Epoch: [48][390/391]\tTime  0.159 ( 0.175)\tLoss 1.2191e+00 (1.3613e+00)\tAcc@1  62.50 ( 61.35)\tAcc@5  90.00 ( 88.41)\n","==> Train Accuracy: Acc@1 61.348 || Acc@5 88.412\n","==> Test Accuracy:  Acc@1 56.790 || Acc@5 84.850\n","==> 72.61 seconds to train this epoch\n","\n","\n","----- epoch: 49, lr: 0.1 -----\n","Epoch: [49][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.4175e+00 (1.4175e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  85.94 ( 85.94)\n","Epoch: [49][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.3647e+00 (1.2985e+00)\tAcc@1  61.72 ( 62.65)\tAcc@5  87.50 ( 88.96)\n","Epoch: [49][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.2222e+00 (1.2885e+00)\tAcc@1  64.06 ( 63.22)\tAcc@5  90.62 ( 89.10)\n","Epoch: [49][ 90/391]\tTime  0.177 ( 0.175)\tLoss 1.3912e+00 (1.3016e+00)\tAcc@1  58.59 ( 62.89)\tAcc@5  88.28 ( 88.86)\n","Epoch: [49][120/391]\tTime  0.174 ( 0.175)\tLoss 1.4577e+00 (1.3200e+00)\tAcc@1  54.69 ( 62.42)\tAcc@5  89.84 ( 88.83)\n","Epoch: [49][150/391]\tTime  0.173 ( 0.175)\tLoss 1.4144e+00 (1.3185e+00)\tAcc@1  57.03 ( 62.46)\tAcc@5  87.50 ( 88.88)\n","Epoch: [49][180/391]\tTime  0.174 ( 0.175)\tLoss 1.2784e+00 (1.3267e+00)\tAcc@1  64.84 ( 62.19)\tAcc@5  89.84 ( 88.78)\n","Epoch: [49][210/391]\tTime  0.174 ( 0.175)\tLoss 1.6427e+00 (1.3338e+00)\tAcc@1  55.47 ( 62.07)\tAcc@5  83.59 ( 88.71)\n","Epoch: [49][240/391]\tTime  0.175 ( 0.175)\tLoss 1.5535e+00 (1.3374e+00)\tAcc@1  53.91 ( 61.94)\tAcc@5  85.94 ( 88.66)\n","Epoch: [49][270/391]\tTime  0.176 ( 0.175)\tLoss 1.5626e+00 (1.3454e+00)\tAcc@1  59.38 ( 61.81)\tAcc@5  86.72 ( 88.57)\n","Epoch: [49][300/391]\tTime  0.175 ( 0.175)\tLoss 1.2480e+00 (1.3523e+00)\tAcc@1  65.62 ( 61.69)\tAcc@5  89.84 ( 88.48)\n","Epoch: [49][330/391]\tTime  0.174 ( 0.174)\tLoss 1.4532e+00 (1.3548e+00)\tAcc@1  52.34 ( 61.65)\tAcc@5  86.72 ( 88.44)\n","Epoch: [49][360/391]\tTime  0.174 ( 0.174)\tLoss 1.2351e+00 (1.3607e+00)\tAcc@1  66.41 ( 61.49)\tAcc@5  90.62 ( 88.35)\n","Epoch: [49][390/391]\tTime  0.158 ( 0.174)\tLoss 1.6244e+00 (1.3620e+00)\tAcc@1  53.75 ( 61.41)\tAcc@5  81.25 ( 88.37)\n","==> Train Accuracy: Acc@1 61.414 || Acc@5 88.370\n","==> Test Accuracy:  Acc@1 57.370 || Acc@5 86.030\n","==> 72.52 seconds to train this epoch\n","\n","\n","----- epoch: 50, lr: 0.1 -----\n","Epoch: [50][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.3311e+00 (1.3311e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  87.50 ( 87.50)\n","Epoch: [50][ 30/391]\tTime  0.171 ( 0.177)\tLoss 1.4707e+00 (1.2692e+00)\tAcc@1  56.25 ( 63.38)\tAcc@5  88.28 ( 90.10)\n","Epoch: [50][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.3046e+00 (1.2920e+00)\tAcc@1  62.50 ( 63.15)\tAcc@5  89.06 ( 89.54)\n","Epoch: [50][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.2036e+00 (1.3014e+00)\tAcc@1  64.84 ( 63.05)\tAcc@5  89.06 ( 89.45)\n","Epoch: [50][120/391]\tTime  0.174 ( 0.175)\tLoss 1.3737e+00 (1.3121e+00)\tAcc@1  60.16 ( 62.71)\tAcc@5  89.06 ( 89.16)\n","Epoch: [50][150/391]\tTime  0.174 ( 0.174)\tLoss 1.3050e+00 (1.3262e+00)\tAcc@1  63.28 ( 62.38)\tAcc@5  89.84 ( 88.94)\n","Epoch: [50][180/391]\tTime  0.174 ( 0.174)\tLoss 1.0919e+00 (1.3291e+00)\tAcc@1  68.75 ( 62.18)\tAcc@5  92.19 ( 88.96)\n","Epoch: [50][210/391]\tTime  0.175 ( 0.174)\tLoss 1.4005e+00 (1.3307e+00)\tAcc@1  65.62 ( 62.16)\tAcc@5  86.72 ( 88.90)\n","Epoch: [50][240/391]\tTime  0.170 ( 0.174)\tLoss 1.4628e+00 (1.3315e+00)\tAcc@1  58.59 ( 62.17)\tAcc@5  87.50 ( 88.84)\n","Epoch: [50][270/391]\tTime  0.175 ( 0.174)\tLoss 1.3354e+00 (1.3366e+00)\tAcc@1  64.06 ( 62.03)\tAcc@5  88.28 ( 88.71)\n","Epoch: [50][300/391]\tTime  0.172 ( 0.174)\tLoss 1.4277e+00 (1.3453e+00)\tAcc@1  56.25 ( 61.79)\tAcc@5  88.28 ( 88.61)\n","Epoch: [50][330/391]\tTime  0.173 ( 0.174)\tLoss 1.0570e+00 (1.3467e+00)\tAcc@1  66.41 ( 61.75)\tAcc@5  94.53 ( 88.64)\n","Epoch: [50][360/391]\tTime  0.172 ( 0.174)\tLoss 1.3632e+00 (1.3511e+00)\tAcc@1  59.38 ( 61.63)\tAcc@5  87.50 ( 88.59)\n","Epoch: [50][390/391]\tTime  0.157 ( 0.174)\tLoss 1.4919e+00 (1.3507e+00)\tAcc@1  57.50 ( 61.62)\tAcc@5  83.75 ( 88.60)\n","==> Train Accuracy: Acc@1 61.616 || Acc@5 88.598\n","==> Test Accuracy:  Acc@1 55.220 || Acc@5 83.420\n","==> 72.30 seconds to train this epoch\n","\n","\n","----- epoch: 51, lr: 0.1 -----\n","Epoch: [51][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.4109e+00 (1.4109e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  86.72 ( 86.72)\n","Epoch: [51][ 30/391]\tTime  0.177 ( 0.176)\tLoss 1.4009e+00 (1.2877e+00)\tAcc@1  64.84 ( 64.11)\tAcc@5  87.50 ( 89.67)\n","Epoch: [51][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.4890e+00 (1.3016e+00)\tAcc@1  59.38 ( 63.26)\tAcc@5  86.72 ( 89.32)\n","Epoch: [51][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.3795e+00 (1.3213e+00)\tAcc@1  64.06 ( 62.59)\tAcc@5  87.50 ( 88.99)\n","Epoch: [51][120/391]\tTime  0.173 ( 0.174)\tLoss 1.3269e+00 (1.3228e+00)\tAcc@1  57.81 ( 62.63)\tAcc@5  89.84 ( 88.84)\n","Epoch: [51][150/391]\tTime  0.175 ( 0.174)\tLoss 1.4671e+00 (1.3420e+00)\tAcc@1  53.91 ( 62.15)\tAcc@5  86.72 ( 88.58)\n","Epoch: [51][180/391]\tTime  0.176 ( 0.174)\tLoss 1.3490e+00 (1.3441e+00)\tAcc@1  60.94 ( 62.02)\tAcc@5  88.28 ( 88.58)\n","Epoch: [51][210/391]\tTime  0.174 ( 0.174)\tLoss 1.4628e+00 (1.3417e+00)\tAcc@1  60.94 ( 62.06)\tAcc@5  84.38 ( 88.60)\n","Epoch: [51][240/391]\tTime  0.177 ( 0.174)\tLoss 1.2112e+00 (1.3434e+00)\tAcc@1  66.41 ( 61.97)\tAcc@5  89.06 ( 88.56)\n","Epoch: [51][270/391]\tTime  0.173 ( 0.174)\tLoss 1.4784e+00 (1.3475e+00)\tAcc@1  57.03 ( 61.87)\tAcc@5  92.97 ( 88.56)\n","Epoch: [51][300/391]\tTime  0.174 ( 0.174)\tLoss 1.4729e+00 (1.3499e+00)\tAcc@1  62.50 ( 61.86)\tAcc@5  85.94 ( 88.51)\n","Epoch: [51][330/391]\tTime  0.174 ( 0.174)\tLoss 1.2249e+00 (1.3574e+00)\tAcc@1  63.28 ( 61.68)\tAcc@5  90.62 ( 88.42)\n","Epoch: [51][360/391]\tTime  0.174 ( 0.174)\tLoss 1.4264e+00 (1.3610e+00)\tAcc@1  61.72 ( 61.53)\tAcc@5  86.72 ( 88.38)\n","Epoch: [51][390/391]\tTime  0.155 ( 0.174)\tLoss 1.3889e+00 (1.3617e+00)\tAcc@1  57.50 ( 61.53)\tAcc@5  83.75 ( 88.36)\n","==> Train Accuracy: Acc@1 61.526 || Acc@5 88.360\n","==> Test Accuracy:  Acc@1 60.520 || Acc@5 86.730\n","==> 72.46 seconds to train this epoch\n","\n","\n","----- epoch: 52, lr: 0.1 -----\n","Epoch: [52][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.3110e+00 (1.3110e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.06 ( 89.06)\n","Epoch: [52][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.2429e+00 (1.2956e+00)\tAcc@1  63.28 ( 64.09)\tAcc@5  89.84 ( 89.31)\n","Epoch: [52][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.3040e+00 (1.2901e+00)\tAcc@1  60.16 ( 63.79)\tAcc@5  88.28 ( 89.45)\n","Epoch: [52][ 90/391]\tTime  0.177 ( 0.176)\tLoss 1.5113e+00 (1.3009e+00)\tAcc@1  59.38 ( 63.21)\tAcc@5  85.94 ( 89.47)\n","Epoch: [52][120/391]\tTime  0.175 ( 0.175)\tLoss 1.2680e+00 (1.3015e+00)\tAcc@1  55.47 ( 62.82)\tAcc@5  91.41 ( 89.42)\n","Epoch: [52][150/391]\tTime  0.174 ( 0.175)\tLoss 1.5121e+00 (1.3050e+00)\tAcc@1  54.69 ( 62.71)\tAcc@5  88.28 ( 89.39)\n","Epoch: [52][180/391]\tTime  0.175 ( 0.175)\tLoss 1.4254e+00 (1.3189e+00)\tAcc@1  60.16 ( 62.43)\tAcc@5  84.38 ( 89.14)\n","Epoch: [52][210/391]\tTime  0.178 ( 0.175)\tLoss 1.1089e+00 (1.3232e+00)\tAcc@1  67.19 ( 62.37)\tAcc@5  92.19 ( 89.17)\n","Epoch: [52][240/391]\tTime  0.175 ( 0.175)\tLoss 1.3352e+00 (1.3247e+00)\tAcc@1  59.38 ( 62.29)\tAcc@5  88.28 ( 89.18)\n","Epoch: [52][270/391]\tTime  0.175 ( 0.175)\tLoss 1.7963e+00 (1.3342e+00)\tAcc@1  55.47 ( 62.05)\tAcc@5  78.12 ( 89.02)\n","Epoch: [52][300/391]\tTime  0.175 ( 0.175)\tLoss 1.3066e+00 (1.3392e+00)\tAcc@1  63.28 ( 61.93)\tAcc@5  86.72 ( 88.91)\n","Epoch: [52][330/391]\tTime  0.176 ( 0.175)\tLoss 1.1855e+00 (1.3416e+00)\tAcc@1  69.53 ( 61.90)\tAcc@5  88.28 ( 88.91)\n","Epoch: [52][360/391]\tTime  0.176 ( 0.175)\tLoss 1.2896e+00 (1.3422e+00)\tAcc@1  62.50 ( 61.86)\tAcc@5  91.41 ( 88.91)\n","Epoch: [52][390/391]\tTime  0.161 ( 0.175)\tLoss 1.3778e+00 (1.3459e+00)\tAcc@1  57.50 ( 61.74)\tAcc@5  88.75 ( 88.83)\n","==> Train Accuracy: Acc@1 61.740 || Acc@5 88.826\n","==> Test Accuracy:  Acc@1 58.210 || Acc@5 85.550\n","==> 72.67 seconds to train this epoch\n","\n","\n","----- epoch: 53, lr: 0.1 -----\n","Epoch: [53][  0/391]\tTime  0.240 ( 0.240)\tLoss 1.0932e+00 (1.0932e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  92.19 ( 92.19)\n","Epoch: [53][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.3270e+00 (1.2849e+00)\tAcc@1  61.72 ( 63.36)\tAcc@5  90.62 ( 89.36)\n","Epoch: [53][ 60/391]\tTime  0.176 ( 0.176)\tLoss 1.1363e+00 (1.2856e+00)\tAcc@1  67.19 ( 63.65)\tAcc@5  91.41 ( 89.38)\n","Epoch: [53][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.1772e+00 (1.2959e+00)\tAcc@1  68.75 ( 63.24)\tAcc@5  90.62 ( 89.32)\n","Epoch: [53][120/391]\tTime  0.175 ( 0.175)\tLoss 1.3531e+00 (1.3065e+00)\tAcc@1  64.06 ( 62.73)\tAcc@5  89.84 ( 89.32)\n","Epoch: [53][150/391]\tTime  0.176 ( 0.175)\tLoss 1.1872e+00 (1.3125e+00)\tAcc@1  60.94 ( 62.65)\tAcc@5  90.62 ( 89.20)\n","Epoch: [53][180/391]\tTime  0.172 ( 0.175)\tLoss 1.4386e+00 (1.3251e+00)\tAcc@1  62.50 ( 62.30)\tAcc@5  84.38 ( 89.03)\n","Epoch: [53][210/391]\tTime  0.169 ( 0.175)\tLoss 1.3832e+00 (1.3341e+00)\tAcc@1  60.94 ( 62.14)\tAcc@5  87.50 ( 88.90)\n","Epoch: [53][240/391]\tTime  0.174 ( 0.175)\tLoss 1.3991e+00 (1.3359e+00)\tAcc@1  62.50 ( 62.12)\tAcc@5  83.59 ( 88.85)\n","Epoch: [53][270/391]\tTime  0.175 ( 0.175)\tLoss 1.4292e+00 (1.3414e+00)\tAcc@1  58.59 ( 61.88)\tAcc@5  86.72 ( 88.79)\n","Epoch: [53][300/391]\tTime  0.173 ( 0.175)\tLoss 1.4336e+00 (1.3495e+00)\tAcc@1  60.94 ( 61.71)\tAcc@5  85.94 ( 88.71)\n","Epoch: [53][330/391]\tTime  0.177 ( 0.175)\tLoss 1.4640e+00 (1.3524e+00)\tAcc@1  59.38 ( 61.68)\tAcc@5  86.72 ( 88.64)\n","Epoch: [53][360/391]\tTime  0.175 ( 0.175)\tLoss 1.3859e+00 (1.3557e+00)\tAcc@1  62.50 ( 61.62)\tAcc@5  86.72 ( 88.60)\n","Epoch: [53][390/391]\tTime  0.158 ( 0.175)\tLoss 1.2594e+00 (1.3579e+00)\tAcc@1  66.25 ( 61.57)\tAcc@5  93.75 ( 88.57)\n","==> Train Accuracy: Acc@1 61.570 || Acc@5 88.574\n","==> Test Accuracy:  Acc@1 58.540 || Acc@5 86.040\n","==> 72.59 seconds to train this epoch\n","\n","\n","----- epoch: 54, lr: 0.1 -----\n","Epoch: [54][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.3230e+00 (1.3230e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  89.84 ( 89.84)\n","Epoch: [54][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.2561e+00 (1.3003e+00)\tAcc@1  66.41 ( 62.75)\tAcc@5  89.84 ( 89.26)\n","Epoch: [54][ 60/391]\tTime  0.175 ( 0.175)\tLoss 1.3646e+00 (1.2834e+00)\tAcc@1  61.72 ( 63.17)\tAcc@5  89.84 ( 89.89)\n","Epoch: [54][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.6392e+00 (1.2912e+00)\tAcc@1  59.38 ( 63.14)\tAcc@5  82.03 ( 89.70)\n","Epoch: [54][120/391]\tTime  0.176 ( 0.175)\tLoss 1.3801e+00 (1.3169e+00)\tAcc@1  60.94 ( 62.56)\tAcc@5  89.84 ( 89.19)\n","Epoch: [54][150/391]\tTime  0.173 ( 0.174)\tLoss 1.3702e+00 (1.3174e+00)\tAcc@1  66.41 ( 62.55)\tAcc@5  88.28 ( 89.15)\n","Epoch: [54][180/391]\tTime  0.173 ( 0.174)\tLoss 1.1236e+00 (1.3245e+00)\tAcc@1  67.19 ( 62.29)\tAcc@5  94.53 ( 89.14)\n","Epoch: [54][210/391]\tTime  0.175 ( 0.174)\tLoss 1.2636e+00 (1.3273e+00)\tAcc@1  66.41 ( 62.34)\tAcc@5  92.97 ( 89.14)\n","Epoch: [54][240/391]\tTime  0.172 ( 0.174)\tLoss 1.3269e+00 (1.3325e+00)\tAcc@1  60.16 ( 62.22)\tAcc@5  87.50 ( 89.04)\n","Epoch: [54][270/391]\tTime  0.175 ( 0.174)\tLoss 1.3346e+00 (1.3385e+00)\tAcc@1  63.28 ( 62.13)\tAcc@5  90.62 ( 88.90)\n","Epoch: [54][300/391]\tTime  0.172 ( 0.174)\tLoss 1.6383e+00 (1.3487e+00)\tAcc@1  55.47 ( 61.93)\tAcc@5  82.81 ( 88.76)\n","Epoch: [54][330/391]\tTime  0.173 ( 0.174)\tLoss 1.3457e+00 (1.3501e+00)\tAcc@1  61.72 ( 61.89)\tAcc@5  88.28 ( 88.69)\n","Epoch: [54][360/391]\tTime  0.174 ( 0.174)\tLoss 1.3607e+00 (1.3499e+00)\tAcc@1  64.84 ( 61.90)\tAcc@5  85.16 ( 88.66)\n","Epoch: [54][390/391]\tTime  0.156 ( 0.174)\tLoss 1.1955e+00 (1.3534e+00)\tAcc@1  60.00 ( 61.80)\tAcc@5  97.50 ( 88.61)\n","==> Train Accuracy: Acc@1 61.800 || Acc@5 88.608\n","==> Test Accuracy:  Acc@1 58.950 || Acc@5 87.050\n","==> 72.36 seconds to train this epoch\n","\n","\n","----- epoch: 55, lr: 0.1 -----\n","Epoch: [55][  0/391]\tTime  0.266 ( 0.266)\tLoss 1.3525e+00 (1.3525e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  86.72 ( 86.72)\n","Epoch: [55][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.4014e+00 (1.3113e+00)\tAcc@1  60.94 ( 63.21)\tAcc@5  87.50 ( 88.76)\n","Epoch: [55][ 60/391]\tTime  0.176 ( 0.175)\tLoss 1.2072e+00 (1.2808e+00)\tAcc@1  64.06 ( 63.45)\tAcc@5  92.19 ( 89.49)\n","Epoch: [55][ 90/391]\tTime  0.172 ( 0.174)\tLoss 1.5028e+00 (1.2823e+00)\tAcc@1  62.50 ( 63.37)\tAcc@5  83.59 ( 89.48)\n","Epoch: [55][120/391]\tTime  0.175 ( 0.174)\tLoss 1.3323e+00 (1.2912e+00)\tAcc@1  60.16 ( 63.11)\tAcc@5  92.97 ( 89.48)\n","Epoch: [55][150/391]\tTime  0.176 ( 0.174)\tLoss 1.1730e+00 (1.2960e+00)\tAcc@1  63.28 ( 63.05)\tAcc@5  92.97 ( 89.31)\n","Epoch: [55][180/391]\tTime  0.174 ( 0.174)\tLoss 1.2340e+00 (1.3124e+00)\tAcc@1  64.84 ( 62.69)\tAcc@5  90.62 ( 89.05)\n","Epoch: [55][210/391]\tTime  0.175 ( 0.174)\tLoss 1.4995e+00 (1.3230e+00)\tAcc@1  60.94 ( 62.46)\tAcc@5  84.38 ( 88.89)\n","Epoch: [55][240/391]\tTime  0.174 ( 0.174)\tLoss 1.1542e+00 (1.3302e+00)\tAcc@1  64.06 ( 62.21)\tAcc@5  94.53 ( 88.83)\n","Epoch: [55][270/391]\tTime  0.175 ( 0.174)\tLoss 1.3773e+00 (1.3270e+00)\tAcc@1  64.06 ( 62.38)\tAcc@5  88.28 ( 88.85)\n","Epoch: [55][300/391]\tTime  0.174 ( 0.174)\tLoss 1.2952e+00 (1.3282e+00)\tAcc@1  60.16 ( 62.32)\tAcc@5  89.84 ( 88.81)\n","Epoch: [55][330/391]\tTime  0.175 ( 0.174)\tLoss 1.5548e+00 (1.3339e+00)\tAcc@1  56.25 ( 62.29)\tAcc@5  82.81 ( 88.70)\n","Epoch: [55][360/391]\tTime  0.171 ( 0.174)\tLoss 1.3258e+00 (1.3358e+00)\tAcc@1  59.38 ( 62.27)\tAcc@5  89.84 ( 88.66)\n","Epoch: [55][390/391]\tTime  0.157 ( 0.174)\tLoss 1.1478e+00 (1.3407e+00)\tAcc@1  66.25 ( 62.05)\tAcc@5  93.75 ( 88.63)\n","==> Train Accuracy: Acc@1 62.054 || Acc@5 88.628\n","==> Test Accuracy:  Acc@1 59.580 || Acc@5 85.580\n","==> 72.43 seconds to train this epoch\n","\n","\n","----- epoch: 56, lr: 0.1 -----\n","Epoch: [56][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.2926e+00 (1.2926e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  89.84 ( 89.84)\n","Epoch: [56][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.0964e+00 (1.2398e+00)\tAcc@1  71.88 ( 64.24)\tAcc@5  88.28 ( 90.50)\n","Epoch: [56][ 60/391]\tTime  0.175 ( 0.176)\tLoss 1.4950e+00 (1.2679e+00)\tAcc@1  58.59 ( 63.81)\tAcc@5  83.59 ( 89.91)\n","Epoch: [56][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.2726e+00 (1.2747e+00)\tAcc@1  64.06 ( 64.08)\tAcc@5  92.19 ( 89.59)\n","Epoch: [56][120/391]\tTime  0.175 ( 0.175)\tLoss 1.1893e+00 (1.2789e+00)\tAcc@1  65.62 ( 63.91)\tAcc@5  89.84 ( 89.51)\n","Epoch: [56][150/391]\tTime  0.176 ( 0.175)\tLoss 1.3554e+00 (1.2912e+00)\tAcc@1  64.06 ( 63.53)\tAcc@5  89.06 ( 89.38)\n","Epoch: [56][180/391]\tTime  0.173 ( 0.175)\tLoss 1.5705e+00 (1.3059e+00)\tAcc@1  56.25 ( 63.10)\tAcc@5  82.81 ( 89.14)\n","Epoch: [56][210/391]\tTime  0.177 ( 0.175)\tLoss 1.3250e+00 (1.3112e+00)\tAcc@1  62.50 ( 62.93)\tAcc@5  89.84 ( 89.11)\n","Epoch: [56][240/391]\tTime  0.174 ( 0.175)\tLoss 1.3224e+00 (1.3196e+00)\tAcc@1  60.16 ( 62.68)\tAcc@5  92.19 ( 89.02)\n","Epoch: [56][270/391]\tTime  0.177 ( 0.175)\tLoss 1.2436e+00 (1.3252e+00)\tAcc@1  62.50 ( 62.49)\tAcc@5  90.62 ( 88.95)\n","Epoch: [56][300/391]\tTime  0.175 ( 0.175)\tLoss 1.5042e+00 (1.3304e+00)\tAcc@1  60.94 ( 62.36)\tAcc@5  85.94 ( 88.84)\n","Epoch: [56][330/391]\tTime  0.175 ( 0.175)\tLoss 1.3898e+00 (1.3319e+00)\tAcc@1  59.38 ( 62.32)\tAcc@5  89.06 ( 88.85)\n","Epoch: [56][360/391]\tTime  0.172 ( 0.175)\tLoss 1.3063e+00 (1.3329e+00)\tAcc@1  66.41 ( 62.32)\tAcc@5  92.97 ( 88.83)\n","Epoch: [56][390/391]\tTime  0.158 ( 0.175)\tLoss 1.5938e+00 (1.3375e+00)\tAcc@1  61.25 ( 62.23)\tAcc@5  82.50 ( 88.78)\n","==> Train Accuracy: Acc@1 62.226 || Acc@5 88.784\n","==> Test Accuracy:  Acc@1 59.540 || Acc@5 87.180\n","==> 72.51 seconds to train this epoch\n","\n","\n","----- epoch: 57, lr: 0.1 -----\n","Epoch: [57][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.1636e+00 (1.1636e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  91.41 ( 91.41)\n","Epoch: [57][ 30/391]\tTime  0.176 ( 0.176)\tLoss 1.1359e+00 (1.2431e+00)\tAcc@1  69.53 ( 64.54)\tAcc@5  92.19 ( 89.89)\n","Epoch: [57][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.1653e+00 (1.2541e+00)\tAcc@1  67.19 ( 64.14)\tAcc@5  90.62 ( 89.81)\n","Epoch: [57][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.2573e+00 (1.2742e+00)\tAcc@1  61.72 ( 63.76)\tAcc@5  89.84 ( 89.56)\n","Epoch: [57][120/391]\tTime  0.173 ( 0.174)\tLoss 1.1892e+00 (1.2855e+00)\tAcc@1  66.41 ( 63.48)\tAcc@5  90.62 ( 89.40)\n","Epoch: [57][150/391]\tTime  0.174 ( 0.174)\tLoss 1.1805e+00 (1.2858e+00)\tAcc@1  67.19 ( 63.35)\tAcc@5  87.50 ( 89.46)\n","Epoch: [57][180/391]\tTime  0.176 ( 0.174)\tLoss 1.1510e+00 (1.2941e+00)\tAcc@1  65.62 ( 63.18)\tAcc@5  90.62 ( 89.37)\n","Epoch: [57][210/391]\tTime  0.174 ( 0.174)\tLoss 1.2347e+00 (1.3059e+00)\tAcc@1  63.28 ( 62.86)\tAcc@5  91.41 ( 89.15)\n","Epoch: [57][240/391]\tTime  0.176 ( 0.174)\tLoss 1.3119e+00 (1.3166e+00)\tAcc@1  64.06 ( 62.63)\tAcc@5  89.84 ( 88.96)\n","Epoch: [57][270/391]\tTime  0.175 ( 0.174)\tLoss 1.3895e+00 (1.3241e+00)\tAcc@1  58.59 ( 62.45)\tAcc@5  91.41 ( 88.85)\n","Epoch: [57][300/391]\tTime  0.174 ( 0.174)\tLoss 1.3463e+00 (1.3324e+00)\tAcc@1  64.06 ( 62.24)\tAcc@5  92.19 ( 88.74)\n","Epoch: [57][330/391]\tTime  0.171 ( 0.174)\tLoss 1.4294e+00 (1.3359e+00)\tAcc@1  57.03 ( 62.11)\tAcc@5  85.16 ( 88.69)\n","Epoch: [57][360/391]\tTime  0.175 ( 0.174)\tLoss 1.3051e+00 (1.3350e+00)\tAcc@1  62.50 ( 62.11)\tAcc@5  90.62 ( 88.71)\n","Epoch: [57][390/391]\tTime  0.158 ( 0.174)\tLoss 1.4661e+00 (1.3353e+00)\tAcc@1  57.50 ( 62.18)\tAcc@5  88.75 ( 88.68)\n","==> Train Accuracy: Acc@1 62.176 || Acc@5 88.680\n","==> Test Accuracy:  Acc@1 54.280 || Acc@5 81.950\n","==> 72.31 seconds to train this epoch\n","\n","\n","----- epoch: 58, lr: 0.1 -----\n","Epoch: [58][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.2213e+00 (1.2213e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  88.28 ( 88.28)\n","Epoch: [58][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.4810e+00 (1.2494e+00)\tAcc@1  58.59 ( 64.01)\tAcc@5  88.28 ( 89.54)\n","Epoch: [58][ 60/391]\tTime  0.174 ( 0.176)\tLoss 1.2151e+00 (1.2713e+00)\tAcc@1  65.62 ( 63.49)\tAcc@5  87.50 ( 89.50)\n","Epoch: [58][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.2271e+00 (1.2998e+00)\tAcc@1  63.28 ( 62.86)\tAcc@5  90.62 ( 89.39)\n","Epoch: [58][120/391]\tTime  0.174 ( 0.175)\tLoss 1.1376e+00 (1.3077e+00)\tAcc@1  68.75 ( 62.61)\tAcc@5  91.41 ( 89.31)\n","Epoch: [58][150/391]\tTime  0.175 ( 0.175)\tLoss 1.3934e+00 (1.3050e+00)\tAcc@1  62.50 ( 62.87)\tAcc@5  85.16 ( 89.29)\n","Epoch: [58][180/391]\tTime  0.174 ( 0.175)\tLoss 1.2543e+00 (1.3039e+00)\tAcc@1  66.41 ( 62.76)\tAcc@5  88.28 ( 89.34)\n","Epoch: [58][210/391]\tTime  0.174 ( 0.175)\tLoss 1.3535e+00 (1.3126e+00)\tAcc@1  63.28 ( 62.48)\tAcc@5  89.06 ( 89.19)\n","Epoch: [58][240/391]\tTime  0.171 ( 0.175)\tLoss 1.2276e+00 (1.3158e+00)\tAcc@1  64.84 ( 62.41)\tAcc@5  89.84 ( 89.21)\n","Epoch: [58][270/391]\tTime  0.173 ( 0.175)\tLoss 1.3578e+00 (1.3180e+00)\tAcc@1  59.38 ( 62.35)\tAcc@5  89.06 ( 89.18)\n","Epoch: [58][300/391]\tTime  0.177 ( 0.175)\tLoss 1.5844e+00 (1.3223e+00)\tAcc@1  60.16 ( 62.26)\tAcc@5  79.69 ( 89.12)\n","Epoch: [58][330/391]\tTime  0.174 ( 0.175)\tLoss 1.2766e+00 (1.3242e+00)\tAcc@1  60.94 ( 62.22)\tAcc@5  90.62 ( 89.04)\n","Epoch: [58][360/391]\tTime  0.174 ( 0.175)\tLoss 1.2944e+00 (1.3313e+00)\tAcc@1  64.06 ( 62.09)\tAcc@5  89.06 ( 88.93)\n","Epoch: [58][390/391]\tTime  0.156 ( 0.175)\tLoss 1.4101e+00 (1.3386e+00)\tAcc@1  60.00 ( 61.95)\tAcc@5  87.50 ( 88.85)\n","==> Train Accuracy: Acc@1 61.954 || Acc@5 88.850\n","==> Test Accuracy:  Acc@1 52.550 || Acc@5 81.960\n","==> 72.57 seconds to train this epoch\n","\n","\n","----- epoch: 59, lr: 0.1 -----\n","Epoch: [59][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.2106e+00 (1.2106e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  90.62 ( 90.62)\n","Epoch: [59][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.2659e+00 (1.2438e+00)\tAcc@1  67.19 ( 65.42)\tAcc@5  89.06 ( 89.97)\n","Epoch: [59][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.3203e+00 (1.2780e+00)\tAcc@1  59.38 ( 64.04)\tAcc@5  89.06 ( 89.34)\n","Epoch: [59][ 90/391]\tTime  0.173 ( 0.174)\tLoss 1.1909e+00 (1.2769e+00)\tAcc@1  67.19 ( 64.08)\tAcc@5  89.84 ( 89.33)\n","Epoch: [59][120/391]\tTime  0.172 ( 0.174)\tLoss 1.5658e+00 (1.2949e+00)\tAcc@1  58.59 ( 63.39)\tAcc@5  85.16 ( 89.29)\n","Epoch: [59][150/391]\tTime  0.173 ( 0.174)\tLoss 1.4698e+00 (1.3004e+00)\tAcc@1  60.16 ( 63.15)\tAcc@5  85.94 ( 89.20)\n","Epoch: [59][180/391]\tTime  0.174 ( 0.174)\tLoss 1.3114e+00 (1.3063e+00)\tAcc@1  64.84 ( 63.03)\tAcc@5  89.06 ( 89.09)\n","Epoch: [59][210/391]\tTime  0.174 ( 0.174)\tLoss 1.3254e+00 (1.3078e+00)\tAcc@1  62.50 ( 63.02)\tAcc@5  85.94 ( 89.03)\n","Epoch: [59][240/391]\tTime  0.173 ( 0.174)\tLoss 1.3144e+00 (1.3078e+00)\tAcc@1  59.38 ( 62.98)\tAcc@5  90.62 ( 89.06)\n","Epoch: [59][270/391]\tTime  0.175 ( 0.174)\tLoss 1.1856e+00 (1.3090e+00)\tAcc@1  60.16 ( 62.95)\tAcc@5  92.19 ( 89.13)\n","Epoch: [59][300/391]\tTime  0.172 ( 0.174)\tLoss 1.2447e+00 (1.3115e+00)\tAcc@1  62.50 ( 62.96)\tAcc@5  86.72 ( 89.03)\n","Epoch: [59][330/391]\tTime  0.172 ( 0.174)\tLoss 1.5746e+00 (1.3159e+00)\tAcc@1  60.94 ( 62.87)\tAcc@5  85.94 ( 89.00)\n","Epoch: [59][360/391]\tTime  0.172 ( 0.174)\tLoss 1.2898e+00 (1.3220e+00)\tAcc@1  66.41 ( 62.73)\tAcc@5  91.41 ( 88.94)\n","Epoch: [59][390/391]\tTime  0.155 ( 0.174)\tLoss 1.3798e+00 (1.3270e+00)\tAcc@1  57.50 ( 62.61)\tAcc@5  86.25 ( 88.84)\n","==> Train Accuracy: Acc@1 62.610 || Acc@5 88.842\n","==> Test Accuracy:  Acc@1 54.940 || Acc@5 83.410\n","==> 72.30 seconds to train this epoch\n","\n","\n","----- epoch: 60, lr: 0.020000000000000004 -----\n","Epoch: [60][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.2056e+00 (1.2056e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  89.84 ( 89.84)\n","Epoch: [60][ 30/391]\tTime  0.176 ( 0.177)\tLoss 1.1193e+00 (1.1165e+00)\tAcc@1  67.19 ( 67.57)\tAcc@5  92.19 ( 91.83)\n","Epoch: [60][ 60/391]\tTime  0.175 ( 0.175)\tLoss 9.8817e-01 (1.0681e+00)\tAcc@1  69.53 ( 69.16)\tAcc@5  93.75 ( 92.47)\n","Epoch: [60][ 90/391]\tTime  0.172 ( 0.175)\tLoss 1.0228e+00 (1.0234e+00)\tAcc@1  69.53 ( 70.39)\tAcc@5  94.53 ( 93.04)\n","Epoch: [60][120/391]\tTime  0.173 ( 0.175)\tLoss 9.4916e-01 (1.0038e+00)\tAcc@1  69.53 ( 71.10)\tAcc@5  96.09 ( 93.18)\n","Epoch: [60][150/391]\tTime  0.175 ( 0.175)\tLoss 9.9063e-01 (9.8037e-01)\tAcc@1  70.31 ( 71.71)\tAcc@5  92.97 ( 93.37)\n","Epoch: [60][180/391]\tTime  0.174 ( 0.175)\tLoss 1.0632e+00 (9.6740e-01)\tAcc@1  70.31 ( 71.97)\tAcc@5  92.97 ( 93.53)\n","Epoch: [60][210/391]\tTime  0.175 ( 0.175)\tLoss 6.8158e-01 (9.5101e-01)\tAcc@1  81.25 ( 72.50)\tAcc@5  95.31 ( 93.70)\n","Epoch: [60][240/391]\tTime  0.173 ( 0.174)\tLoss 9.0069e-01 (9.3751e-01)\tAcc@1  71.88 ( 72.86)\tAcc@5  92.97 ( 93.85)\n","Epoch: [60][270/391]\tTime  0.173 ( 0.174)\tLoss 8.4466e-01 (9.2779e-01)\tAcc@1  73.44 ( 73.08)\tAcc@5  96.09 ( 93.97)\n","Epoch: [60][300/391]\tTime  0.171 ( 0.174)\tLoss 7.4445e-01 (9.1592e-01)\tAcc@1  78.12 ( 73.46)\tAcc@5  97.66 ( 94.09)\n","Epoch: [60][330/391]\tTime  0.176 ( 0.174)\tLoss 6.2968e-01 (9.0928e-01)\tAcc@1  78.91 ( 73.58)\tAcc@5  96.09 ( 94.12)\n","Epoch: [60][360/391]\tTime  0.176 ( 0.174)\tLoss 9.1998e-01 (9.0275e-01)\tAcc@1  75.78 ( 73.70)\tAcc@5  97.66 ( 94.20)\n","Epoch: [60][390/391]\tTime  0.156 ( 0.174)\tLoss 8.3303e-01 (8.9494e-01)\tAcc@1  73.75 ( 73.93)\tAcc@5  97.50 ( 94.28)\n","==> Train Accuracy: Acc@1 73.926 || Acc@5 94.284\n","==> Test Accuracy:  Acc@1 73.110 || Acc@5 93.800\n","==> 72.51 seconds to train this epoch\n","\n","\n","----- epoch: 61, lr: 0.020000000000000004 -----\n","Epoch: [61][  0/391]\tTime  0.279 ( 0.279)\tLoss 7.7594e-01 (7.7594e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.88 ( 96.88)\n","Epoch: [61][ 30/391]\tTime  0.174 ( 0.177)\tLoss 9.1159e-01 (7.5262e-01)\tAcc@1  74.22 ( 78.07)\tAcc@5  92.97 ( 95.54)\n","Epoch: [61][ 60/391]\tTime  0.172 ( 0.176)\tLoss 6.5583e-01 (7.5335e-01)\tAcc@1  78.91 ( 78.20)\tAcc@5  97.66 ( 95.68)\n","Epoch: [61][ 90/391]\tTime  0.173 ( 0.175)\tLoss 6.8505e-01 (7.5405e-01)\tAcc@1  78.91 ( 77.88)\tAcc@5  96.09 ( 95.70)\n","Epoch: [61][120/391]\tTime  0.172 ( 0.175)\tLoss 6.9058e-01 (7.5407e-01)\tAcc@1  78.12 ( 77.85)\tAcc@5  96.88 ( 95.69)\n","Epoch: [61][150/391]\tTime  0.174 ( 0.175)\tLoss 5.3060e-01 (7.4415e-01)\tAcc@1  83.59 ( 78.01)\tAcc@5  98.44 ( 95.81)\n","Epoch: [61][180/391]\tTime  0.176 ( 0.175)\tLoss 7.4870e-01 (7.4285e-01)\tAcc@1  78.12 ( 77.95)\tAcc@5  96.09 ( 95.85)\n","Epoch: [61][210/391]\tTime  0.173 ( 0.175)\tLoss 9.1394e-01 (7.4597e-01)\tAcc@1  75.00 ( 77.92)\tAcc@5  96.09 ( 95.83)\n","Epoch: [61][240/391]\tTime  0.171 ( 0.175)\tLoss 6.0923e-01 (7.4874e-01)\tAcc@1  82.03 ( 77.77)\tAcc@5  95.31 ( 95.82)\n","Epoch: [61][270/391]\tTime  0.174 ( 0.175)\tLoss 8.6450e-01 (7.4600e-01)\tAcc@1  76.56 ( 77.94)\tAcc@5  95.31 ( 95.77)\n","Epoch: [61][300/391]\tTime  0.178 ( 0.175)\tLoss 7.2221e-01 (7.4926e-01)\tAcc@1  78.91 ( 77.84)\tAcc@5  96.09 ( 95.69)\n","Epoch: [61][330/391]\tTime  0.173 ( 0.175)\tLoss 6.3076e-01 (7.4835e-01)\tAcc@1  83.59 ( 77.89)\tAcc@5  96.88 ( 95.70)\n","Epoch: [61][360/391]\tTime  0.172 ( 0.175)\tLoss 6.8058e-01 (7.4847e-01)\tAcc@1  76.56 ( 77.88)\tAcc@5  96.88 ( 95.67)\n","Epoch: [61][390/391]\tTime  0.160 ( 0.175)\tLoss 7.0748e-01 (7.4593e-01)\tAcc@1  78.75 ( 77.89)\tAcc@5  96.25 ( 95.69)\n","==> Train Accuracy: Acc@1 77.888 || Acc@5 95.692\n","==> Test Accuracy:  Acc@1 73.800 || Acc@5 93.750\n","==> 72.58 seconds to train this epoch\n","\n","\n","----- epoch: 62, lr: 0.020000000000000004 -----\n","Epoch: [62][  0/391]\tTime  0.263 ( 0.263)\tLoss 7.1062e-01 (7.1062e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  95.31 ( 95.31)\n","Epoch: [62][ 30/391]\tTime  0.174 ( 0.177)\tLoss 8.5595e-01 (6.6601e-01)\tAcc@1  74.22 ( 80.75)\tAcc@5  95.31 ( 96.55)\n","Epoch: [62][ 60/391]\tTime  0.174 ( 0.176)\tLoss 5.9255e-01 (6.6187e-01)\tAcc@1  84.38 ( 80.40)\tAcc@5  96.88 ( 96.55)\n","Epoch: [62][ 90/391]\tTime  0.172 ( 0.175)\tLoss 8.5423e-01 (6.6836e-01)\tAcc@1  67.19 ( 80.01)\tAcc@5  94.53 ( 96.42)\n","Epoch: [62][120/391]\tTime  0.175 ( 0.175)\tLoss 5.5749e-01 (6.7310e-01)\tAcc@1  81.25 ( 79.92)\tAcc@5  99.22 ( 96.38)\n","Epoch: [62][150/391]\tTime  0.176 ( 0.175)\tLoss 7.7583e-01 (6.7612e-01)\tAcc@1  70.31 ( 79.92)\tAcc@5  96.09 ( 96.33)\n","Epoch: [62][180/391]\tTime  0.172 ( 0.175)\tLoss 7.9012e-01 (6.7771e-01)\tAcc@1  79.69 ( 79.90)\tAcc@5  96.09 ( 96.40)\n","Epoch: [62][210/391]\tTime  0.177 ( 0.175)\tLoss 6.9347e-01 (6.8348e-01)\tAcc@1  81.25 ( 79.72)\tAcc@5  96.09 ( 96.35)\n","Epoch: [62][240/391]\tTime  0.176 ( 0.175)\tLoss 6.8347e-01 (6.8483e-01)\tAcc@1  78.12 ( 79.63)\tAcc@5  96.09 ( 96.33)\n","Epoch: [62][270/391]\tTime  0.176 ( 0.175)\tLoss 7.0199e-01 (6.8984e-01)\tAcc@1  75.78 ( 79.49)\tAcc@5  96.09 ( 96.26)\n","Epoch: [62][300/391]\tTime  0.175 ( 0.175)\tLoss 5.8129e-01 (6.8865e-01)\tAcc@1  83.59 ( 79.59)\tAcc@5  95.31 ( 96.27)\n","Epoch: [62][330/391]\tTime  0.177 ( 0.175)\tLoss 7.0563e-01 (6.9029e-01)\tAcc@1  78.12 ( 79.50)\tAcc@5  96.88 ( 96.25)\n","Epoch: [62][360/391]\tTime  0.174 ( 0.175)\tLoss 7.3335e-01 (6.9417e-01)\tAcc@1  75.78 ( 79.40)\tAcc@5  97.66 ( 96.19)\n","Epoch: [62][390/391]\tTime  0.159 ( 0.175)\tLoss 7.1335e-01 (6.9714e-01)\tAcc@1  76.25 ( 79.31)\tAcc@5  95.00 ( 96.15)\n","==> Train Accuracy: Acc@1 79.306 || Acc@5 96.152\n","==> Test Accuracy:  Acc@1 73.710 || Acc@5 93.620\n","==> 72.63 seconds to train this epoch\n","\n","\n","----- epoch: 63, lr: 0.020000000000000004 -----\n","Epoch: [63][  0/391]\tTime  0.275 ( 0.275)\tLoss 5.7922e-01 (5.7922e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.88 ( 96.88)\n","Epoch: [63][ 30/391]\tTime  0.176 ( 0.177)\tLoss 7.0712e-01 (6.1836e-01)\tAcc@1  78.91 ( 80.59)\tAcc@5  94.53 ( 96.85)\n","Epoch: [63][ 60/391]\tTime  0.175 ( 0.176)\tLoss 6.3084e-01 (6.2556e-01)\tAcc@1  79.69 ( 81.03)\tAcc@5  96.88 ( 96.80)\n","Epoch: [63][ 90/391]\tTime  0.172 ( 0.175)\tLoss 7.3040e-01 (6.2901e-01)\tAcc@1  77.34 ( 80.98)\tAcc@5  96.88 ( 96.80)\n","Epoch: [63][120/391]\tTime  0.173 ( 0.175)\tLoss 5.7638e-01 (6.3838e-01)\tAcc@1  84.38 ( 80.71)\tAcc@5  95.31 ( 96.77)\n","Epoch: [63][150/391]\tTime  0.175 ( 0.175)\tLoss 8.4096e-01 (6.4301e-01)\tAcc@1  72.66 ( 80.60)\tAcc@5  96.88 ( 96.70)\n","Epoch: [63][180/391]\tTime  0.171 ( 0.175)\tLoss 5.6527e-01 (6.4476e-01)\tAcc@1  84.38 ( 80.62)\tAcc@5  97.66 ( 96.63)\n","Epoch: [63][210/391]\tTime  0.172 ( 0.175)\tLoss 5.3218e-01 (6.4524e-01)\tAcc@1  82.81 ( 80.58)\tAcc@5  98.44 ( 96.62)\n","Epoch: [63][240/391]\tTime  0.177 ( 0.175)\tLoss 7.4300e-01 (6.4900e-01)\tAcc@1  78.12 ( 80.51)\tAcc@5  96.88 ( 96.55)\n","Epoch: [63][270/391]\tTime  0.175 ( 0.174)\tLoss 7.4261e-01 (6.5089e-01)\tAcc@1  77.34 ( 80.49)\tAcc@5  96.88 ( 96.56)\n","Epoch: [63][300/391]\tTime  0.172 ( 0.174)\tLoss 7.1738e-01 (6.5322e-01)\tAcc@1  77.34 ( 80.48)\tAcc@5  96.88 ( 96.56)\n","Epoch: [63][330/391]\tTime  0.173 ( 0.174)\tLoss 7.4994e-01 (6.5362e-01)\tAcc@1  78.12 ( 80.48)\tAcc@5  96.09 ( 96.58)\n","Epoch: [63][360/391]\tTime  0.175 ( 0.174)\tLoss 6.9195e-01 (6.5435e-01)\tAcc@1  78.91 ( 80.47)\tAcc@5  96.88 ( 96.56)\n","Epoch: [63][390/391]\tTime  0.160 ( 0.174)\tLoss 8.2732e-01 (6.5621e-01)\tAcc@1  75.00 ( 80.39)\tAcc@5  95.00 ( 96.57)\n","==> Train Accuracy: Acc@1 80.392 || Acc@5 96.570\n","==> Test Accuracy:  Acc@1 74.190 || Acc@5 93.910\n","==> 72.48 seconds to train this epoch\n","\n","\n","----- epoch: 64, lr: 0.020000000000000004 -----\n","Epoch: [64][  0/391]\tTime  0.278 ( 0.278)\tLoss 6.1784e-01 (6.1784e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.09 ( 96.09)\n","Epoch: [64][ 30/391]\tTime  0.173 ( 0.177)\tLoss 6.5958e-01 (6.4579e-01)\tAcc@1  78.12 ( 80.57)\tAcc@5  96.88 ( 96.22)\n","Epoch: [64][ 60/391]\tTime  0.171 ( 0.175)\tLoss 6.3224e-01 (6.0623e-01)\tAcc@1  78.91 ( 81.79)\tAcc@5  97.66 ( 96.99)\n","Epoch: [64][ 90/391]\tTime  0.174 ( 0.175)\tLoss 7.3232e-01 (6.0009e-01)\tAcc@1  75.78 ( 81.98)\tAcc@5  94.53 ( 97.04)\n","Epoch: [64][120/391]\tTime  0.176 ( 0.175)\tLoss 5.7826e-01 (6.0633e-01)\tAcc@1  83.59 ( 81.84)\tAcc@5  97.66 ( 96.97)\n","Epoch: [64][150/391]\tTime  0.172 ( 0.174)\tLoss 6.1061e-01 (6.0893e-01)\tAcc@1  85.94 ( 81.74)\tAcc@5  96.09 ( 97.01)\n","Epoch: [64][180/391]\tTime  0.174 ( 0.174)\tLoss 5.4885e-01 (6.0840e-01)\tAcc@1  81.25 ( 81.74)\tAcc@5  97.66 ( 97.05)\n","Epoch: [64][210/391]\tTime  0.172 ( 0.174)\tLoss 5.9336e-01 (6.0938e-01)\tAcc@1  80.47 ( 81.57)\tAcc@5  96.88 ( 97.03)\n","Epoch: [64][240/391]\tTime  0.175 ( 0.174)\tLoss 4.8079e-01 (6.1049e-01)\tAcc@1  83.59 ( 81.42)\tAcc@5 100.00 ( 97.04)\n","Epoch: [64][270/391]\tTime  0.177 ( 0.174)\tLoss 4.7539e-01 (6.1540e-01)\tAcc@1  85.16 ( 81.30)\tAcc@5  98.44 ( 96.98)\n","Epoch: [64][300/391]\tTime  0.177 ( 0.174)\tLoss 6.3870e-01 (6.1848e-01)\tAcc@1  80.47 ( 81.19)\tAcc@5  98.44 ( 96.94)\n","Epoch: [64][330/391]\tTime  0.172 ( 0.174)\tLoss 7.1925e-01 (6.2028e-01)\tAcc@1  78.12 ( 81.17)\tAcc@5  96.09 ( 96.92)\n","Epoch: [64][360/391]\tTime  0.171 ( 0.174)\tLoss 7.1904e-01 (6.2433e-01)\tAcc@1  78.12 ( 81.08)\tAcc@5  95.31 ( 96.87)\n","Epoch: [64][390/391]\tTime  0.157 ( 0.174)\tLoss 5.6186e-01 (6.2949e-01)\tAcc@1  82.50 ( 80.93)\tAcc@5  97.50 ( 96.83)\n","==> Train Accuracy: Acc@1 80.930 || Acc@5 96.832\n","==> Test Accuracy:  Acc@1 73.440 || Acc@5 93.550\n","==> 72.40 seconds to train this epoch\n","\n","\n","----- epoch: 65, lr: 0.020000000000000004 -----\n","Epoch: [65][  0/391]\tTime  0.253 ( 0.253)\tLoss 6.2693e-01 (6.2693e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.88 ( 96.88)\n","Epoch: [65][ 30/391]\tTime  0.174 ( 0.176)\tLoss 5.9975e-01 (5.9794e-01)\tAcc@1  83.59 ( 82.21)\tAcc@5  95.31 ( 96.93)\n","Epoch: [65][ 60/391]\tTime  0.175 ( 0.175)\tLoss 5.1820e-01 (5.8957e-01)\tAcc@1  81.25 ( 82.39)\tAcc@5  97.66 ( 97.25)\n","Epoch: [65][ 90/391]\tTime  0.172 ( 0.175)\tLoss 5.6448e-01 (5.8994e-01)\tAcc@1  83.59 ( 82.39)\tAcc@5  97.66 ( 97.19)\n","Epoch: [65][120/391]\tTime  0.174 ( 0.175)\tLoss 4.6715e-01 (5.8554e-01)\tAcc@1  85.16 ( 82.33)\tAcc@5  97.66 ( 97.32)\n","Epoch: [65][150/391]\tTime  0.174 ( 0.174)\tLoss 5.9166e-01 (5.8663e-01)\tAcc@1  81.25 ( 82.31)\tAcc@5  97.66 ( 97.32)\n","Epoch: [65][180/391]\tTime  0.172 ( 0.174)\tLoss 6.5858e-01 (5.8603e-01)\tAcc@1  80.47 ( 82.27)\tAcc@5  95.31 ( 97.30)\n","Epoch: [65][210/391]\tTime  0.174 ( 0.174)\tLoss 5.9305e-01 (5.8829e-01)\tAcc@1  82.81 ( 82.16)\tAcc@5  96.09 ( 97.30)\n","Epoch: [65][240/391]\tTime  0.174 ( 0.174)\tLoss 7.1876e-01 (5.9450e-01)\tAcc@1  78.12 ( 82.05)\tAcc@5  97.66 ( 97.24)\n","Epoch: [65][270/391]\tTime  0.179 ( 0.174)\tLoss 5.2290e-01 (5.9635e-01)\tAcc@1  85.16 ( 81.98)\tAcc@5  99.22 ( 97.24)\n","Epoch: [65][300/391]\tTime  0.174 ( 0.174)\tLoss 4.8388e-01 (6.0204e-01)\tAcc@1  87.50 ( 81.81)\tAcc@5  98.44 ( 97.20)\n","Epoch: [65][330/391]\tTime  0.172 ( 0.174)\tLoss 6.3245e-01 (6.0476e-01)\tAcc@1  78.91 ( 81.72)\tAcc@5  96.88 ( 97.15)\n","Epoch: [65][360/391]\tTime  0.175 ( 0.174)\tLoss 7.4649e-01 (6.0865e-01)\tAcc@1  77.34 ( 81.62)\tAcc@5  96.09 ( 97.09)\n","Epoch: [65][390/391]\tTime  0.158 ( 0.174)\tLoss 6.1741e-01 (6.1188e-01)\tAcc@1  80.00 ( 81.46)\tAcc@5  97.50 ( 97.05)\n","==> Train Accuracy: Acc@1 81.458 || Acc@5 97.048\n","==> Test Accuracy:  Acc@1 73.780 || Acc@5 93.210\n","==> 72.32 seconds to train this epoch\n","\n","\n","----- epoch: 66, lr: 0.020000000000000004 -----\n","Epoch: [66][  0/391]\tTime  0.279 ( 0.279)\tLoss 4.8218e-01 (4.8218e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  97.66 ( 97.66)\n","Epoch: [66][ 30/391]\tTime  0.173 ( 0.177)\tLoss 5.2292e-01 (5.6313e-01)\tAcc@1  82.81 ( 83.44)\tAcc@5  98.44 ( 97.20)\n","Epoch: [66][ 60/391]\tTime  0.170 ( 0.175)\tLoss 6.1179e-01 (5.7902e-01)\tAcc@1  78.91 ( 82.70)\tAcc@5  97.66 ( 97.16)\n","Epoch: [66][ 90/391]\tTime  0.175 ( 0.175)\tLoss 8.5186e-01 (5.7767e-01)\tAcc@1  75.00 ( 82.90)\tAcc@5  93.75 ( 97.18)\n","Epoch: [66][120/391]\tTime  0.174 ( 0.175)\tLoss 4.1190e-01 (5.7907e-01)\tAcc@1  87.50 ( 82.83)\tAcc@5 100.00 ( 97.21)\n","Epoch: [66][150/391]\tTime  0.178 ( 0.175)\tLoss 6.2077e-01 (5.8457e-01)\tAcc@1  79.69 ( 82.48)\tAcc@5  97.66 ( 97.20)\n","Epoch: [66][180/391]\tTime  0.176 ( 0.175)\tLoss 5.9578e-01 (5.8921e-01)\tAcc@1  81.25 ( 82.32)\tAcc@5  97.66 ( 97.16)\n","Epoch: [66][210/391]\tTime  0.172 ( 0.175)\tLoss 6.1668e-01 (5.9252e-01)\tAcc@1  79.69 ( 82.16)\tAcc@5  97.66 ( 97.16)\n","Epoch: [66][240/391]\tTime  0.177 ( 0.175)\tLoss 4.9884e-01 (5.9208e-01)\tAcc@1  83.59 ( 82.19)\tAcc@5  97.66 ( 97.11)\n","Epoch: [66][270/391]\tTime  0.176 ( 0.175)\tLoss 8.0996e-01 (5.9365e-01)\tAcc@1  75.78 ( 82.15)\tAcc@5  96.09 ( 97.09)\n","Epoch: [66][300/391]\tTime  0.175 ( 0.175)\tLoss 5.8069e-01 (5.9685e-01)\tAcc@1  81.25 ( 82.06)\tAcc@5  96.09 ( 97.07)\n","Epoch: [66][330/391]\tTime  0.175 ( 0.174)\tLoss 5.9195e-01 (6.0029e-01)\tAcc@1  84.38 ( 81.92)\tAcc@5  96.09 ( 97.08)\n","Epoch: [66][360/391]\tTime  0.174 ( 0.174)\tLoss 6.6332e-01 (6.0148e-01)\tAcc@1  80.47 ( 81.87)\tAcc@5  93.75 ( 97.06)\n","Epoch: [66][390/391]\tTime  0.158 ( 0.174)\tLoss 6.0477e-01 (6.0292e-01)\tAcc@1  82.50 ( 81.82)\tAcc@5  96.25 ( 97.04)\n","==> Train Accuracy: Acc@1 81.822 || Acc@5 97.038\n","==> Test Accuracy:  Acc@1 73.010 || Acc@5 93.070\n","==> 72.47 seconds to train this epoch\n","\n","\n","----- epoch: 67, lr: 0.020000000000000004 -----\n","Epoch: [67][  0/391]\tTime  0.256 ( 0.256)\tLoss 5.1120e-01 (5.1120e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n","Epoch: [67][ 30/391]\tTime  0.173 ( 0.176)\tLoss 5.6200e-01 (5.6272e-01)\tAcc@1  82.03 ( 82.76)\tAcc@5  96.09 ( 97.88)\n","Epoch: [67][ 60/391]\tTime  0.173 ( 0.175)\tLoss 4.6860e-01 (5.6022e-01)\tAcc@1  85.94 ( 83.08)\tAcc@5  97.66 ( 97.59)\n","Epoch: [67][ 90/391]\tTime  0.171 ( 0.174)\tLoss 7.2184e-01 (5.5629e-01)\tAcc@1  77.34 ( 83.10)\tAcc@5  97.66 ( 97.66)\n","Epoch: [67][120/391]\tTime  0.172 ( 0.174)\tLoss 5.5158e-01 (5.6075e-01)\tAcc@1  84.38 ( 82.86)\tAcc@5  97.66 ( 97.61)\n","Epoch: [67][150/391]\tTime  0.168 ( 0.174)\tLoss 3.3271e-01 (5.5866e-01)\tAcc@1  91.41 ( 82.97)\tAcc@5  99.22 ( 97.64)\n","Epoch: [67][180/391]\tTime  0.174 ( 0.174)\tLoss 5.5743e-01 (5.6453e-01)\tAcc@1  82.03 ( 82.86)\tAcc@5  97.66 ( 97.56)\n","Epoch: [67][210/391]\tTime  0.173 ( 0.174)\tLoss 5.6405e-01 (5.6336e-01)\tAcc@1  81.25 ( 82.88)\tAcc@5  98.44 ( 97.61)\n","Epoch: [67][240/391]\tTime  0.174 ( 0.174)\tLoss 4.7628e-01 (5.6863e-01)\tAcc@1  87.50 ( 82.75)\tAcc@5  94.53 ( 97.57)\n","Epoch: [67][270/391]\tTime  0.174 ( 0.174)\tLoss 5.7327e-01 (5.7302e-01)\tAcc@1  81.25 ( 82.61)\tAcc@5  96.09 ( 97.54)\n","Epoch: [67][300/391]\tTime  0.172 ( 0.174)\tLoss 6.5999e-01 (5.8184e-01)\tAcc@1  78.91 ( 82.35)\tAcc@5  96.09 ( 97.44)\n","Epoch: [67][330/391]\tTime  0.174 ( 0.174)\tLoss 4.9701e-01 (5.8513e-01)\tAcc@1  82.81 ( 82.28)\tAcc@5  99.22 ( 97.40)\n","Epoch: [67][360/391]\tTime  0.176 ( 0.174)\tLoss 4.3847e-01 (5.8984e-01)\tAcc@1  88.28 ( 82.15)\tAcc@5  97.66 ( 97.35)\n","Epoch: [67][390/391]\tTime  0.155 ( 0.174)\tLoss 7.1376e-01 (5.9419e-01)\tAcc@1  78.75 ( 82.08)\tAcc@5  96.25 ( 97.33)\n","==> Train Accuracy: Acc@1 82.078 || Acc@5 97.330\n","==> Test Accuracy:  Acc@1 72.760 || Acc@5 93.060\n","==> 72.24 seconds to train this epoch\n","\n","\n","----- epoch: 68, lr: 0.020000000000000004 -----\n","Epoch: [68][  0/391]\tTime  0.253 ( 0.253)\tLoss 4.4437e-01 (4.4437e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  97.66 ( 97.66)\n","Epoch: [68][ 30/391]\tTime  0.174 ( 0.176)\tLoss 5.3092e-01 (5.5650e-01)\tAcc@1  85.16 ( 82.71)\tAcc@5  96.88 ( 97.58)\n","Epoch: [68][ 60/391]\tTime  0.175 ( 0.175)\tLoss 4.9343e-01 (5.4559e-01)\tAcc@1  84.38 ( 83.29)\tAcc@5  98.44 ( 97.46)\n","Epoch: [68][ 90/391]\tTime  0.172 ( 0.175)\tLoss 5.7754e-01 (5.4581e-01)\tAcc@1  79.69 ( 83.31)\tAcc@5  97.66 ( 97.46)\n","Epoch: [68][120/391]\tTime  0.175 ( 0.175)\tLoss 5.7771e-01 (5.4794e-01)\tAcc@1  82.81 ( 83.29)\tAcc@5  97.66 ( 97.53)\n","Epoch: [68][150/391]\tTime  0.173 ( 0.175)\tLoss 5.5037e-01 (5.4342e-01)\tAcc@1  82.03 ( 83.49)\tAcc@5  97.66 ( 97.59)\n","Epoch: [68][180/391]\tTime  0.177 ( 0.175)\tLoss 6.0616e-01 (5.4593e-01)\tAcc@1  82.03 ( 83.49)\tAcc@5  96.09 ( 97.60)\n","Epoch: [68][210/391]\tTime  0.173 ( 0.175)\tLoss 4.3487e-01 (5.5377e-01)\tAcc@1  86.72 ( 83.22)\tAcc@5  98.44 ( 97.55)\n","Epoch: [68][240/391]\tTime  0.171 ( 0.174)\tLoss 7.0054e-01 (5.6278e-01)\tAcc@1  74.22 ( 82.87)\tAcc@5  97.66 ( 97.51)\n","Epoch: [68][270/391]\tTime  0.175 ( 0.174)\tLoss 6.1845e-01 (5.6721e-01)\tAcc@1  82.81 ( 82.75)\tAcc@5  98.44 ( 97.49)\n","Epoch: [68][300/391]\tTime  0.174 ( 0.174)\tLoss 5.2498e-01 (5.6899e-01)\tAcc@1  86.72 ( 82.69)\tAcc@5  97.66 ( 97.47)\n","Epoch: [68][330/391]\tTime  0.176 ( 0.174)\tLoss 5.4711e-01 (5.7289e-01)\tAcc@1  82.03 ( 82.58)\tAcc@5  97.66 ( 97.41)\n","Epoch: [68][360/391]\tTime  0.176 ( 0.174)\tLoss 7.1782e-01 (5.7940e-01)\tAcc@1  76.56 ( 82.39)\tAcc@5  99.22 ( 97.37)\n","Epoch: [68][390/391]\tTime  0.159 ( 0.174)\tLoss 6.3914e-01 (5.8463e-01)\tAcc@1  81.25 ( 82.22)\tAcc@5  97.50 ( 97.32)\n","==> Train Accuracy: Acc@1 82.218 || Acc@5 97.320\n","==> Test Accuracy:  Acc@1 72.960 || Acc@5 92.580\n","==> 72.46 seconds to train this epoch\n","\n","\n","----- epoch: 69, lr: 0.020000000000000004 -----\n","Epoch: [69][  0/391]\tTime  0.272 ( 0.272)\tLoss 5.0100e-01 (5.0100e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  99.22 ( 99.22)\n","Epoch: [69][ 30/391]\tTime  0.172 ( 0.177)\tLoss 5.7248e-01 (5.2173e-01)\tAcc@1  85.16 ( 83.95)\tAcc@5  98.44 ( 98.19)\n","Epoch: [69][ 60/391]\tTime  0.175 ( 0.175)\tLoss 4.9040e-01 (5.1814e-01)\tAcc@1  85.16 ( 84.50)\tAcc@5  97.66 ( 98.03)\n","Epoch: [69][ 90/391]\tTime  0.176 ( 0.175)\tLoss 5.7567e-01 (5.2036e-01)\tAcc@1  85.94 ( 84.29)\tAcc@5  96.88 ( 97.99)\n","Epoch: [69][120/391]\tTime  0.173 ( 0.175)\tLoss 4.5175e-01 (5.2641e-01)\tAcc@1  85.94 ( 84.04)\tAcc@5  99.22 ( 97.99)\n","Epoch: [69][150/391]\tTime  0.176 ( 0.175)\tLoss 4.4446e-01 (5.3033e-01)\tAcc@1  84.38 ( 84.03)\tAcc@5  98.44 ( 97.93)\n","Epoch: [69][180/391]\tTime  0.176 ( 0.175)\tLoss 3.8431e-01 (5.3922e-01)\tAcc@1  89.06 ( 83.66)\tAcc@5  98.44 ( 97.83)\n","Epoch: [69][210/391]\tTime  0.176 ( 0.175)\tLoss 4.8050e-01 (5.4347e-01)\tAcc@1  87.50 ( 83.51)\tAcc@5  99.22 ( 97.79)\n","Epoch: [69][240/391]\tTime  0.174 ( 0.175)\tLoss 5.7845e-01 (5.5052e-01)\tAcc@1  82.81 ( 83.30)\tAcc@5  98.44 ( 97.74)\n","Epoch: [69][270/391]\tTime  0.176 ( 0.175)\tLoss 5.4326e-01 (5.5568e-01)\tAcc@1  83.59 ( 83.15)\tAcc@5  99.22 ( 97.71)\n","Epoch: [69][300/391]\tTime  0.175 ( 0.175)\tLoss 6.7890e-01 (5.6264e-01)\tAcc@1  81.25 ( 83.04)\tAcc@5  96.88 ( 97.65)\n","Epoch: [69][330/391]\tTime  0.176 ( 0.175)\tLoss 8.4456e-01 (5.6644e-01)\tAcc@1  78.12 ( 82.91)\tAcc@5  94.53 ( 97.58)\n","Epoch: [69][360/391]\tTime  0.176 ( 0.175)\tLoss 6.0182e-01 (5.6767e-01)\tAcc@1  78.91 ( 82.87)\tAcc@5  97.66 ( 97.55)\n","Epoch: [69][390/391]\tTime  0.159 ( 0.175)\tLoss 5.7297e-01 (5.7288e-01)\tAcc@1  78.75 ( 82.72)\tAcc@5  97.50 ( 97.52)\n","==> Train Accuracy: Acc@1 82.722 || Acc@5 97.520\n","==> Test Accuracy:  Acc@1 72.540 || Acc@5 93.220\n","==> 72.58 seconds to train this epoch\n","\n","\n","----- epoch: 70, lr: 0.020000000000000004 -----\n","Epoch: [70][  0/391]\tTime  0.260 ( 0.260)\tLoss 5.5130e-01 (5.5130e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  99.22 ( 99.22)\n","Epoch: [70][ 30/391]\tTime  0.174 ( 0.177)\tLoss 4.5323e-01 (5.2544e-01)\tAcc@1  85.16 ( 84.05)\tAcc@5 100.00 ( 97.96)\n","Epoch: [70][ 60/391]\tTime  0.174 ( 0.176)\tLoss 4.2678e-01 (5.2690e-01)\tAcc@1  87.50 ( 83.94)\tAcc@5  98.44 ( 97.98)\n","Epoch: [70][ 90/391]\tTime  0.171 ( 0.175)\tLoss 5.8367e-01 (5.3477e-01)\tAcc@1  85.94 ( 83.71)\tAcc@5  96.88 ( 97.78)\n","Epoch: [70][120/391]\tTime  0.176 ( 0.175)\tLoss 5.7784e-01 (5.3846e-01)\tAcc@1  82.81 ( 83.60)\tAcc@5  96.09 ( 97.75)\n","Epoch: [70][150/391]\tTime  0.172 ( 0.175)\tLoss 5.7143e-01 (5.4381e-01)\tAcc@1  79.69 ( 83.36)\tAcc@5  97.66 ( 97.73)\n","Epoch: [70][180/391]\tTime  0.175 ( 0.175)\tLoss 5.9399e-01 (5.4661e-01)\tAcc@1  82.03 ( 83.27)\tAcc@5  97.66 ( 97.65)\n","Epoch: [70][210/391]\tTime  0.172 ( 0.175)\tLoss 6.1243e-01 (5.5341e-01)\tAcc@1  79.69 ( 83.09)\tAcc@5  96.88 ( 97.59)\n","Epoch: [70][240/391]\tTime  0.175 ( 0.175)\tLoss 7.3696e-01 (5.6021e-01)\tAcc@1  75.00 ( 82.87)\tAcc@5  96.88 ( 97.51)\n","Epoch: [70][270/391]\tTime  0.169 ( 0.175)\tLoss 7.1135e-01 (5.6546e-01)\tAcc@1  76.56 ( 82.76)\tAcc@5  95.31 ( 97.47)\n","Epoch: [70][300/391]\tTime  0.175 ( 0.175)\tLoss 5.2743e-01 (5.6680e-01)\tAcc@1  82.81 ( 82.71)\tAcc@5  96.88 ( 97.49)\n","Epoch: [70][330/391]\tTime  0.175 ( 0.175)\tLoss 6.2887e-01 (5.7004e-01)\tAcc@1  82.81 ( 82.63)\tAcc@5  96.09 ( 97.45)\n","Epoch: [70][360/391]\tTime  0.172 ( 0.175)\tLoss 5.2959e-01 (5.7132e-01)\tAcc@1  85.94 ( 82.60)\tAcc@5  98.44 ( 97.44)\n","Epoch: [70][390/391]\tTime  0.157 ( 0.174)\tLoss 6.2513e-01 (5.7586e-01)\tAcc@1  80.00 ( 82.44)\tAcc@5  97.50 ( 97.42)\n","==> Train Accuracy: Acc@1 82.438 || Acc@5 97.416\n","==> Test Accuracy:  Acc@1 72.080 || Acc@5 93.080\n","==> 72.52 seconds to train this epoch\n","\n","\n","----- epoch: 71, lr: 0.020000000000000004 -----\n","Epoch: [71][  0/391]\tTime  0.282 ( 0.282)\tLoss 5.6509e-01 (5.6509e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5 100.00 (100.00)\n","Epoch: [71][ 30/391]\tTime  0.172 ( 0.177)\tLoss 5.7757e-01 (5.4098e-01)\tAcc@1  79.69 ( 83.77)\tAcc@5  99.22 ( 97.86)\n","Epoch: [71][ 60/391]\tTime  0.174 ( 0.176)\tLoss 6.4649e-01 (5.3866e-01)\tAcc@1  85.16 ( 84.03)\tAcc@5  95.31 ( 97.82)\n","Epoch: [71][ 90/391]\tTime  0.176 ( 0.175)\tLoss 6.4999e-01 (5.4153e-01)\tAcc@1  80.47 ( 83.83)\tAcc@5  96.09 ( 97.84)\n","Epoch: [71][120/391]\tTime  0.174 ( 0.175)\tLoss 5.1616e-01 (5.5128e-01)\tAcc@1  85.16 ( 83.50)\tAcc@5  98.44 ( 97.79)\n","Epoch: [71][150/391]\tTime  0.175 ( 0.175)\tLoss 5.7854e-01 (5.5622e-01)\tAcc@1  81.25 ( 83.31)\tAcc@5  97.66 ( 97.69)\n","Epoch: [71][180/391]\tTime  0.175 ( 0.175)\tLoss 7.3222e-01 (5.6147e-01)\tAcc@1  75.00 ( 83.03)\tAcc@5  96.88 ( 97.62)\n","Epoch: [71][210/391]\tTime  0.175 ( 0.174)\tLoss 5.5893e-01 (5.6556e-01)\tAcc@1  84.38 ( 82.95)\tAcc@5  98.44 ( 97.58)\n","Epoch: [71][240/391]\tTime  0.171 ( 0.174)\tLoss 7.2187e-01 (5.6843e-01)\tAcc@1  81.25 ( 82.87)\tAcc@5  96.88 ( 97.57)\n","Epoch: [71][270/391]\tTime  0.174 ( 0.174)\tLoss 7.6448e-01 (5.7023e-01)\tAcc@1  76.56 ( 82.80)\tAcc@5  96.09 ( 97.54)\n","Epoch: [71][300/391]\tTime  0.173 ( 0.174)\tLoss 6.6173e-01 (5.7329e-01)\tAcc@1  77.34 ( 82.70)\tAcc@5  94.53 ( 97.50)\n","Epoch: [71][330/391]\tTime  0.172 ( 0.174)\tLoss 5.8047e-01 (5.7426e-01)\tAcc@1  82.03 ( 82.66)\tAcc@5  96.88 ( 97.51)\n","Epoch: [71][360/391]\tTime  0.174 ( 0.174)\tLoss 5.5497e-01 (5.7617e-01)\tAcc@1  85.94 ( 82.61)\tAcc@5  95.31 ( 97.46)\n","Epoch: [71][390/391]\tTime  0.158 ( 0.174)\tLoss 6.9486e-01 (5.7998e-01)\tAcc@1  72.50 ( 82.48)\tAcc@5  98.75 ( 97.46)\n","==> Train Accuracy: Acc@1 82.480 || Acc@5 97.460\n","==> Test Accuracy:  Acc@1 71.950 || Acc@5 92.690\n","==> 72.40 seconds to train this epoch\n","\n","\n","----- epoch: 72, lr: 0.020000000000000004 -----\n","Epoch: [72][  0/391]\tTime  0.255 ( 0.255)\tLoss 3.7435e-01 (3.7435e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n","Epoch: [72][ 30/391]\tTime  0.174 ( 0.176)\tLoss 5.8621e-01 (5.2220e-01)\tAcc@1  85.94 ( 84.35)\tAcc@5  96.88 ( 97.83)\n","Epoch: [72][ 60/391]\tTime  0.176 ( 0.175)\tLoss 4.5218e-01 (5.2297e-01)\tAcc@1  87.50 ( 84.34)\tAcc@5  98.44 ( 97.81)\n","Epoch: [72][ 90/391]\tTime  0.174 ( 0.175)\tLoss 6.0170e-01 (5.3122e-01)\tAcc@1  80.47 ( 83.95)\tAcc@5  96.09 ( 97.66)\n","Epoch: [72][120/391]\tTime  0.175 ( 0.174)\tLoss 4.6611e-01 (5.3754e-01)\tAcc@1  85.94 ( 83.71)\tAcc@5  97.66 ( 97.69)\n","Epoch: [72][150/391]\tTime  0.175 ( 0.174)\tLoss 4.7995e-01 (5.4154e-01)\tAcc@1  85.94 ( 83.47)\tAcc@5  96.88 ( 97.68)\n","Epoch: [72][180/391]\tTime  0.176 ( 0.174)\tLoss 5.6468e-01 (5.4396e-01)\tAcc@1  82.81 ( 83.37)\tAcc@5  98.44 ( 97.64)\n","Epoch: [72][210/391]\tTime  0.175 ( 0.174)\tLoss 5.9261e-01 (5.4770e-01)\tAcc@1  77.34 ( 83.20)\tAcc@5  97.66 ( 97.63)\n","Epoch: [72][240/391]\tTime  0.175 ( 0.174)\tLoss 5.3440e-01 (5.5112e-01)\tAcc@1  80.47 ( 83.11)\tAcc@5  97.66 ( 97.54)\n","Epoch: [72][270/391]\tTime  0.175 ( 0.174)\tLoss 6.5680e-01 (5.5731e-01)\tAcc@1  83.59 ( 82.99)\tAcc@5  96.88 ( 97.51)\n","Epoch: [72][300/391]\tTime  0.174 ( 0.174)\tLoss 4.2769e-01 (5.5969e-01)\tAcc@1  88.28 ( 82.91)\tAcc@5  99.22 ( 97.54)\n","Epoch: [72][330/391]\tTime  0.174 ( 0.174)\tLoss 5.6233e-01 (5.6207e-01)\tAcc@1  85.16 ( 82.85)\tAcc@5  96.88 ( 97.51)\n","Epoch: [72][360/391]\tTime  0.176 ( 0.174)\tLoss 5.3680e-01 (5.6695e-01)\tAcc@1  78.12 ( 82.63)\tAcc@5  98.44 ( 97.50)\n","Epoch: [72][390/391]\tTime  0.160 ( 0.174)\tLoss 6.2923e-01 (5.7147e-01)\tAcc@1  80.00 ( 82.48)\tAcc@5  95.00 ( 97.46)\n","==> Train Accuracy: Acc@1 82.480 || Acc@5 97.456\n","==> Test Accuracy:  Acc@1 72.200 || Acc@5 92.740\n","==> 72.41 seconds to train this epoch\n","\n","\n","----- epoch: 73, lr: 0.020000000000000004 -----\n","Epoch: [73][  0/391]\tTime  0.269 ( 0.269)\tLoss 4.9347e-01 (4.9347e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  99.22 ( 99.22)\n","Epoch: [73][ 30/391]\tTime  0.175 ( 0.177)\tLoss 4.1728e-01 (4.9338e-01)\tAcc@1  87.50 ( 85.31)\tAcc@5  99.22 ( 98.14)\n","Epoch: [73][ 60/391]\tTime  0.177 ( 0.176)\tLoss 5.3890e-01 (5.1615e-01)\tAcc@1  83.59 ( 84.22)\tAcc@5  98.44 ( 97.89)\n","Epoch: [73][ 90/391]\tTime  0.172 ( 0.175)\tLoss 5.4565e-01 (5.1151e-01)\tAcc@1  86.72 ( 84.39)\tAcc@5  97.66 ( 97.94)\n","Epoch: [73][120/391]\tTime  0.174 ( 0.175)\tLoss 6.7089e-01 (5.1651e-01)\tAcc@1  78.91 ( 84.32)\tAcc@5  96.88 ( 97.90)\n","Epoch: [73][150/391]\tTime  0.173 ( 0.175)\tLoss 4.1850e-01 (5.2260e-01)\tAcc@1  91.41 ( 84.24)\tAcc@5  97.66 ( 97.85)\n","Epoch: [73][180/391]\tTime  0.177 ( 0.175)\tLoss 6.8530e-01 (5.2391e-01)\tAcc@1  78.91 ( 84.20)\tAcc@5  97.66 ( 97.90)\n","Epoch: [73][210/391]\tTime  0.168 ( 0.175)\tLoss 4.9926e-01 (5.3005e-01)\tAcc@1  86.72 ( 84.05)\tAcc@5  97.66 ( 97.89)\n","Epoch: [73][240/391]\tTime  0.175 ( 0.175)\tLoss 6.5019e-01 (5.3708e-01)\tAcc@1  81.25 ( 83.79)\tAcc@5  97.66 ( 97.83)\n","Epoch: [73][270/391]\tTime  0.174 ( 0.175)\tLoss 7.2588e-01 (5.4630e-01)\tAcc@1  76.56 ( 83.60)\tAcc@5  94.53 ( 97.73)\n","Epoch: [73][300/391]\tTime  0.174 ( 0.175)\tLoss 5.3714e-01 (5.5152e-01)\tAcc@1  82.03 ( 83.46)\tAcc@5  98.44 ( 97.68)\n","Epoch: [73][330/391]\tTime  0.175 ( 0.175)\tLoss 5.2586e-01 (5.5696e-01)\tAcc@1  84.38 ( 83.28)\tAcc@5 100.00 ( 97.64)\n","Epoch: [73][360/391]\tTime  0.176 ( 0.175)\tLoss 6.0596e-01 (5.6049e-01)\tAcc@1  81.25 ( 83.15)\tAcc@5  97.66 ( 97.62)\n","Epoch: [73][390/391]\tTime  0.158 ( 0.175)\tLoss 7.3297e-01 (5.6629e-01)\tAcc@1  78.75 ( 82.94)\tAcc@5  96.25 ( 97.57)\n","==> Train Accuracy: Acc@1 82.938 || Acc@5 97.572\n","==> Test Accuracy:  Acc@1 70.730 || Acc@5 92.170\n","==> 72.54 seconds to train this epoch\n","\n","\n","----- epoch: 74, lr: 0.020000000000000004 -----\n","Epoch: [74][  0/391]\tTime  0.263 ( 0.263)\tLoss 5.7308e-01 (5.7308e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  96.09 ( 96.09)\n","Epoch: [74][ 30/391]\tTime  0.174 ( 0.177)\tLoss 5.4424e-01 (5.4052e-01)\tAcc@1  86.72 ( 83.82)\tAcc@5  96.09 ( 97.68)\n","Epoch: [74][ 60/391]\tTime  0.174 ( 0.175)\tLoss 5.9334e-01 (5.3775e-01)\tAcc@1  82.03 ( 84.12)\tAcc@5  95.31 ( 97.81)\n","Epoch: [74][ 90/391]\tTime  0.172 ( 0.175)\tLoss 5.6145e-01 (5.3389e-01)\tAcc@1  82.81 ( 84.06)\tAcc@5  97.66 ( 97.79)\n","Epoch: [74][120/391]\tTime  0.175 ( 0.175)\tLoss 5.0304e-01 (5.4279e-01)\tAcc@1  84.38 ( 83.77)\tAcc@5  97.66 ( 97.68)\n","Epoch: [74][150/391]\tTime  0.176 ( 0.175)\tLoss 4.3239e-01 (5.3789e-01)\tAcc@1  85.16 ( 83.88)\tAcc@5  98.44 ( 97.76)\n","Epoch: [74][180/391]\tTime  0.175 ( 0.174)\tLoss 7.0880e-01 (5.4899e-01)\tAcc@1  76.56 ( 83.52)\tAcc@5  95.31 ( 97.70)\n","Epoch: [74][210/391]\tTime  0.175 ( 0.174)\tLoss 5.8959e-01 (5.5140e-01)\tAcc@1  82.81 ( 83.46)\tAcc@5  95.31 ( 97.67)\n","Epoch: [74][240/391]\tTime  0.172 ( 0.174)\tLoss 6.1180e-01 (5.5952e-01)\tAcc@1  82.03 ( 83.25)\tAcc@5  99.22 ( 97.62)\n","Epoch: [74][270/391]\tTime  0.175 ( 0.174)\tLoss 5.3475e-01 (5.6027e-01)\tAcc@1  84.38 ( 83.21)\tAcc@5  96.88 ( 97.65)\n","Epoch: [74][300/391]\tTime  0.173 ( 0.174)\tLoss 6.3089e-01 (5.6714e-01)\tAcc@1  79.69 ( 82.98)\tAcc@5  97.66 ( 97.61)\n","Epoch: [74][330/391]\tTime  0.172 ( 0.174)\tLoss 6.4367e-01 (5.7108e-01)\tAcc@1  82.03 ( 82.82)\tAcc@5  96.09 ( 97.56)\n","Epoch: [74][360/391]\tTime  0.173 ( 0.174)\tLoss 6.0987e-01 (5.7445e-01)\tAcc@1  78.12 ( 82.69)\tAcc@5  97.66 ( 97.53)\n","Epoch: [74][390/391]\tTime  0.157 ( 0.174)\tLoss 5.8937e-01 (5.7631e-01)\tAcc@1  81.25 ( 82.66)\tAcc@5  97.50 ( 97.50)\n","==> Train Accuracy: Acc@1 82.660 || Acc@5 97.500\n","==> Test Accuracy:  Acc@1 70.970 || Acc@5 92.450\n","==> 72.39 seconds to train this epoch\n","\n","\n","----- epoch: 75, lr: 0.020000000000000004 -----\n","Epoch: [75][  0/391]\tTime  0.274 ( 0.274)\tLoss 4.8368e-01 (4.8368e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n","Epoch: [75][ 30/391]\tTime  0.173 ( 0.177)\tLoss 5.3497e-01 (5.1678e-01)\tAcc@1  84.38 ( 84.20)\tAcc@5  97.66 ( 97.96)\n","Epoch: [75][ 60/391]\tTime  0.172 ( 0.175)\tLoss 5.3739e-01 (5.2537e-01)\tAcc@1  82.03 ( 84.02)\tAcc@5  98.44 ( 97.86)\n","Epoch: [75][ 90/391]\tTime  0.175 ( 0.175)\tLoss 5.3699e-01 (5.2800e-01)\tAcc@1  83.59 ( 83.92)\tAcc@5  96.88 ( 97.85)\n","Epoch: [75][120/391]\tTime  0.175 ( 0.175)\tLoss 4.8237e-01 (5.4233e-01)\tAcc@1  88.28 ( 83.45)\tAcc@5  97.66 ( 97.76)\n","Epoch: [75][150/391]\tTime  0.176 ( 0.174)\tLoss 6.0912e-01 (5.4027e-01)\tAcc@1  82.03 ( 83.57)\tAcc@5  95.31 ( 97.77)\n","Epoch: [75][180/391]\tTime  0.175 ( 0.174)\tLoss 4.7715e-01 (5.4682e-01)\tAcc@1  83.59 ( 83.42)\tAcc@5  99.22 ( 97.76)\n","Epoch: [75][210/391]\tTime  0.174 ( 0.174)\tLoss 4.8534e-01 (5.4792e-01)\tAcc@1  84.38 ( 83.42)\tAcc@5  98.44 ( 97.71)\n","Epoch: [75][240/391]\tTime  0.175 ( 0.174)\tLoss 6.9932e-01 (5.5159e-01)\tAcc@1  77.34 ( 83.25)\tAcc@5  96.09 ( 97.70)\n","Epoch: [75][270/391]\tTime  0.172 ( 0.174)\tLoss 5.2324e-01 (5.5284e-01)\tAcc@1  84.38 ( 83.21)\tAcc@5 100.00 ( 97.72)\n","Epoch: [75][300/391]\tTime  0.175 ( 0.174)\tLoss 5.7871e-01 (5.5623e-01)\tAcc@1  81.25 ( 83.16)\tAcc@5  99.22 ( 97.69)\n","Epoch: [75][330/391]\tTime  0.173 ( 0.174)\tLoss 6.4517e-01 (5.5993e-01)\tAcc@1  81.25 ( 82.98)\tAcc@5  95.31 ( 97.68)\n","Epoch: [75][360/391]\tTime  0.175 ( 0.174)\tLoss 7.0112e-01 (5.6272e-01)\tAcc@1  76.56 ( 82.91)\tAcc@5  95.31 ( 97.65)\n","Epoch: [75][390/391]\tTime  0.158 ( 0.174)\tLoss 6.9773e-01 (5.6382e-01)\tAcc@1  77.50 ( 82.87)\tAcc@5 100.00 ( 97.65)\n","==> Train Accuracy: Acc@1 82.872 || Acc@5 97.646\n","==> Test Accuracy:  Acc@1 72.020 || Acc@5 92.790\n","==> 72.33 seconds to train this epoch\n","\n","\n","----- epoch: 76, lr: 0.020000000000000004 -----\n","Epoch: [76][  0/391]\tTime  0.286 ( 0.286)\tLoss 4.3514e-01 (4.3514e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  99.22 ( 99.22)\n","Epoch: [76][ 30/391]\tTime  0.177 ( 0.177)\tLoss 4.7098e-01 (5.0438e-01)\tAcc@1  83.59 ( 84.88)\tAcc@5  99.22 ( 98.16)\n","Epoch: [76][ 60/391]\tTime  0.175 ( 0.176)\tLoss 5.6271e-01 (4.8003e-01)\tAcc@1  88.28 ( 85.64)\tAcc@5  96.09 ( 98.34)\n","Epoch: [76][ 90/391]\tTime  0.174 ( 0.175)\tLoss 4.7870e-01 (4.8727e-01)\tAcc@1  81.25 ( 85.22)\tAcc@5  99.22 ( 98.24)\n","Epoch: [76][120/391]\tTime  0.172 ( 0.175)\tLoss 5.7290e-01 (5.1052e-01)\tAcc@1  82.81 ( 84.43)\tAcc@5  97.66 ( 97.97)\n","Epoch: [76][150/391]\tTime  0.174 ( 0.174)\tLoss 5.3538e-01 (5.1059e-01)\tAcc@1  83.59 ( 84.43)\tAcc@5  98.44 ( 98.01)\n","Epoch: [76][180/391]\tTime  0.173 ( 0.174)\tLoss 5.9954e-01 (5.1795e-01)\tAcc@1  81.25 ( 84.23)\tAcc@5  95.31 ( 97.92)\n","Epoch: [76][210/391]\tTime  0.176 ( 0.174)\tLoss 5.3288e-01 (5.2257e-01)\tAcc@1  83.59 ( 84.11)\tAcc@5  99.22 ( 97.92)\n","Epoch: [76][240/391]\tTime  0.172 ( 0.174)\tLoss 5.6149e-01 (5.2992e-01)\tAcc@1  82.03 ( 83.91)\tAcc@5  98.44 ( 97.88)\n","Epoch: [76][270/391]\tTime  0.173 ( 0.174)\tLoss 6.9701e-01 (5.3874e-01)\tAcc@1  79.69 ( 83.57)\tAcc@5  96.09 ( 97.85)\n","Epoch: [76][300/391]\tTime  0.172 ( 0.174)\tLoss 6.3018e-01 (5.4564e-01)\tAcc@1  82.81 ( 83.35)\tAcc@5  96.88 ( 97.77)\n","Epoch: [76][330/391]\tTime  0.174 ( 0.174)\tLoss 5.1031e-01 (5.5006e-01)\tAcc@1  84.38 ( 83.23)\tAcc@5  97.66 ( 97.71)\n","Epoch: [76][360/391]\tTime  0.174 ( 0.174)\tLoss 6.0682e-01 (5.5403e-01)\tAcc@1  79.69 ( 83.13)\tAcc@5  97.66 ( 97.69)\n","Epoch: [76][390/391]\tTime  0.158 ( 0.174)\tLoss 8.1137e-01 (5.5842e-01)\tAcc@1  81.25 ( 83.01)\tAcc@5  97.50 ( 97.69)\n","==> Train Accuracy: Acc@1 83.010 || Acc@5 97.692\n","==> Test Accuracy:  Acc@1 70.860 || Acc@5 92.210\n","==> 72.30 seconds to train this epoch\n","\n","\n","----- epoch: 77, lr: 0.020000000000000004 -----\n","Epoch: [77][  0/391]\tTime  0.254 ( 0.254)\tLoss 6.1374e-01 (6.1374e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  96.09 ( 96.09)\n","Epoch: [77][ 30/391]\tTime  0.172 ( 0.176)\tLoss 5.4754e-01 (5.3440e-01)\tAcc@1  82.81 ( 83.80)\tAcc@5  98.44 ( 97.71)\n","Epoch: [77][ 60/391]\tTime  0.174 ( 0.175)\tLoss 5.0719e-01 (5.2272e-01)\tAcc@1  84.38 ( 84.36)\tAcc@5  99.22 ( 97.86)\n","Epoch: [77][ 90/391]\tTime  0.175 ( 0.175)\tLoss 5.9485e-01 (5.1101e-01)\tAcc@1  82.03 ( 84.68)\tAcc@5  97.66 ( 98.05)\n","Epoch: [77][120/391]\tTime  0.171 ( 0.174)\tLoss 5.7470e-01 (5.2073e-01)\tAcc@1  82.03 ( 84.38)\tAcc@5  98.44 ( 98.02)\n","Epoch: [77][150/391]\tTime  0.176 ( 0.174)\tLoss 5.0602e-01 (5.2555e-01)\tAcc@1  82.03 ( 84.25)\tAcc@5  96.88 ( 97.97)\n","Epoch: [77][180/391]\tTime  0.174 ( 0.174)\tLoss 5.3903e-01 (5.2784e-01)\tAcc@1  78.91 ( 84.09)\tAcc@5  98.44 ( 97.92)\n","Epoch: [77][210/391]\tTime  0.175 ( 0.174)\tLoss 6.0720e-01 (5.3698e-01)\tAcc@1  78.91 ( 83.76)\tAcc@5  97.66 ( 97.87)\n","Epoch: [77][240/391]\tTime  0.175 ( 0.174)\tLoss 4.6134e-01 (5.4526e-01)\tAcc@1  86.72 ( 83.57)\tAcc@5  99.22 ( 97.76)\n","Epoch: [77][270/391]\tTime  0.176 ( 0.174)\tLoss 7.1312e-01 (5.4989e-01)\tAcc@1  78.12 ( 83.42)\tAcc@5  93.75 ( 97.71)\n","Epoch: [77][300/391]\tTime  0.173 ( 0.174)\tLoss 6.2957e-01 (5.5375e-01)\tAcc@1  82.81 ( 83.34)\tAcc@5  98.44 ( 97.66)\n","Epoch: [77][330/391]\tTime  0.174 ( 0.174)\tLoss 6.8928e-01 (5.5774e-01)\tAcc@1  77.34 ( 83.17)\tAcc@5  97.66 ( 97.65)\n","Epoch: [77][360/391]\tTime  0.174 ( 0.174)\tLoss 3.8406e-01 (5.5986e-01)\tAcc@1  87.50 ( 83.14)\tAcc@5  97.66 ( 97.62)\n","Epoch: [77][390/391]\tTime  0.158 ( 0.174)\tLoss 5.3311e-01 (5.6228e-01)\tAcc@1  85.00 ( 83.05)\tAcc@5  97.50 ( 97.61)\n","==> Train Accuracy: Acc@1 83.050 || Acc@5 97.612\n","==> Test Accuracy:  Acc@1 71.390 || Acc@5 91.890\n","==> 72.43 seconds to train this epoch\n","\n","\n","----- epoch: 78, lr: 0.020000000000000004 -----\n","Epoch: [78][  0/391]\tTime  0.264 ( 0.264)\tLoss 4.8218e-01 (4.8218e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n","Epoch: [78][ 30/391]\tTime  0.173 ( 0.177)\tLoss 4.7194e-01 (5.0332e-01)\tAcc@1  85.16 ( 84.70)\tAcc@5  97.66 ( 98.14)\n","Epoch: [78][ 60/391]\tTime  0.176 ( 0.176)\tLoss 3.7316e-01 (4.9542e-01)\tAcc@1  85.94 ( 85.27)\tAcc@5 100.00 ( 98.31)\n","Epoch: [78][ 90/391]\tTime  0.174 ( 0.175)\tLoss 5.7775e-01 (4.9637e-01)\tAcc@1  79.69 ( 85.06)\tAcc@5  96.88 ( 98.27)\n","Epoch: [78][120/391]\tTime  0.172 ( 0.175)\tLoss 4.2724e-01 (5.0695e-01)\tAcc@1  86.72 ( 84.69)\tAcc@5  99.22 ( 98.19)\n","Epoch: [78][150/391]\tTime  0.178 ( 0.175)\tLoss 4.9602e-01 (5.1644e-01)\tAcc@1  83.59 ( 84.49)\tAcc@5  98.44 ( 98.04)\n","Epoch: [78][180/391]\tTime  0.174 ( 0.175)\tLoss 4.2573e-01 (5.1909e-01)\tAcc@1  88.28 ( 84.34)\tAcc@5  98.44 ( 98.00)\n","Epoch: [78][210/391]\tTime  0.173 ( 0.175)\tLoss 4.8291e-01 (5.2580e-01)\tAcc@1  85.94 ( 84.20)\tAcc@5  98.44 ( 97.94)\n","Epoch: [78][240/391]\tTime  0.175 ( 0.175)\tLoss 4.8325e-01 (5.3075e-01)\tAcc@1  85.16 ( 84.09)\tAcc@5  99.22 ( 97.86)\n","Epoch: [78][270/391]\tTime  0.173 ( 0.175)\tLoss 6.1099e-01 (5.3369e-01)\tAcc@1  81.25 ( 83.89)\tAcc@5  98.44 ( 97.88)\n","Epoch: [78][300/391]\tTime  0.176 ( 0.175)\tLoss 5.9059e-01 (5.3991e-01)\tAcc@1  81.25 ( 83.69)\tAcc@5  97.66 ( 97.85)\n","Epoch: [78][330/391]\tTime  0.177 ( 0.175)\tLoss 6.3870e-01 (5.4473e-01)\tAcc@1  84.38 ( 83.60)\tAcc@5  96.09 ( 97.82)\n","Epoch: [78][360/391]\tTime  0.174 ( 0.174)\tLoss 5.1690e-01 (5.4834e-01)\tAcc@1  84.38 ( 83.49)\tAcc@5  99.22 ( 97.79)\n","Epoch: [78][390/391]\tTime  0.157 ( 0.174)\tLoss 8.0039e-01 (5.5065e-01)\tAcc@1  70.00 ( 83.36)\tAcc@5  96.25 ( 97.78)\n","==> Train Accuracy: Acc@1 83.364 || Acc@5 97.782\n","==> Test Accuracy:  Acc@1 70.980 || Acc@5 92.020\n","==> 72.49 seconds to train this epoch\n","\n","\n","----- epoch: 79, lr: 0.020000000000000004 -----\n","Epoch: [79][  0/391]\tTime  0.251 ( 0.251)\tLoss 5.7934e-01 (5.7934e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  96.88 ( 96.88)\n","Epoch: [79][ 30/391]\tTime  0.175 ( 0.177)\tLoss 6.2048e-01 (5.2185e-01)\tAcc@1  81.25 ( 84.45)\tAcc@5  96.88 ( 97.86)\n","Epoch: [79][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.1801e-01 (5.2857e-01)\tAcc@1  82.81 ( 84.20)\tAcc@5  98.44 ( 97.87)\n","Epoch: [79][ 90/391]\tTime  0.174 ( 0.175)\tLoss 4.6619e-01 (5.2485e-01)\tAcc@1  86.72 ( 84.18)\tAcc@5  97.66 ( 97.90)\n","Epoch: [79][120/391]\tTime  0.171 ( 0.175)\tLoss 4.8186e-01 (5.2696e-01)\tAcc@1  87.50 ( 84.13)\tAcc@5  99.22 ( 97.87)\n","Epoch: [79][150/391]\tTime  0.175 ( 0.174)\tLoss 4.7967e-01 (5.2378e-01)\tAcc@1  83.59 ( 84.23)\tAcc@5  96.88 ( 97.82)\n","Epoch: [79][180/391]\tTime  0.174 ( 0.174)\tLoss 4.4774e-01 (5.2612e-01)\tAcc@1  84.38 ( 84.15)\tAcc@5  99.22 ( 97.80)\n","Epoch: [79][210/391]\tTime  0.173 ( 0.174)\tLoss 5.6408e-01 (5.2963e-01)\tAcc@1  82.03 ( 84.00)\tAcc@5  98.44 ( 97.81)\n","Epoch: [79][240/391]\tTime  0.174 ( 0.174)\tLoss 6.3622e-01 (5.3126e-01)\tAcc@1  79.69 ( 83.96)\tAcc@5  96.88 ( 97.82)\n","Epoch: [79][270/391]\tTime  0.172 ( 0.174)\tLoss 6.0910e-01 (5.3912e-01)\tAcc@1  81.25 ( 83.71)\tAcc@5  97.66 ( 97.80)\n","Epoch: [79][300/391]\tTime  0.170 ( 0.174)\tLoss 7.0440e-01 (5.4684e-01)\tAcc@1  75.00 ( 83.44)\tAcc@5  97.66 ( 97.72)\n","Epoch: [79][330/391]\tTime  0.174 ( 0.174)\tLoss 5.4080e-01 (5.5005e-01)\tAcc@1  84.38 ( 83.35)\tAcc@5  96.88 ( 97.72)\n","Epoch: [79][360/391]\tTime  0.175 ( 0.174)\tLoss 4.6112e-01 (5.5290e-01)\tAcc@1  85.16 ( 83.18)\tAcc@5  98.44 ( 97.71)\n","Epoch: [79][390/391]\tTime  0.158 ( 0.174)\tLoss 5.6242e-01 (5.5593e-01)\tAcc@1  77.50 ( 83.10)\tAcc@5  98.75 ( 97.69)\n","==> Train Accuracy: Acc@1 83.104 || Acc@5 97.690\n","==> Test Accuracy:  Acc@1 70.670 || Acc@5 92.010\n","==> 72.34 seconds to train this epoch\n","\n","\n","----- epoch: 80, lr: 0.020000000000000004 -----\n","Epoch: [80][  0/391]\tTime  0.259 ( 0.259)\tLoss 3.1132e-01 (3.1132e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n","Epoch: [80][ 30/391]\tTime  0.175 ( 0.176)\tLoss 4.9301e-01 (4.7309e-01)\tAcc@1  83.59 ( 85.94)\tAcc@5  96.88 ( 98.06)\n","Epoch: [80][ 60/391]\tTime  0.173 ( 0.175)\tLoss 4.3905e-01 (4.8949e-01)\tAcc@1  86.72 ( 85.37)\tAcc@5  98.44 ( 98.03)\n","Epoch: [80][ 90/391]\tTime  0.173 ( 0.175)\tLoss 6.0283e-01 (4.9238e-01)\tAcc@1  83.59 ( 85.27)\tAcc@5  97.66 ( 98.04)\n","Epoch: [80][120/391]\tTime  0.174 ( 0.175)\tLoss 4.1702e-01 (4.9360e-01)\tAcc@1  86.72 ( 85.22)\tAcc@5  97.66 ( 98.02)\n","Epoch: [80][150/391]\tTime  0.175 ( 0.174)\tLoss 5.2570e-01 (5.0068e-01)\tAcc@1  78.12 ( 84.86)\tAcc@5 100.00 ( 98.03)\n","Epoch: [80][180/391]\tTime  0.175 ( 0.174)\tLoss 6.7860e-01 (5.0578e-01)\tAcc@1  79.69 ( 84.63)\tAcc@5  96.88 ( 98.04)\n","Epoch: [80][210/391]\tTime  0.174 ( 0.174)\tLoss 4.2736e-01 (5.1037e-01)\tAcc@1  89.06 ( 84.49)\tAcc@5  98.44 ( 98.02)\n","Epoch: [80][240/391]\tTime  0.174 ( 0.174)\tLoss 6.4319e-01 (5.1548e-01)\tAcc@1  82.03 ( 84.34)\tAcc@5  97.66 ( 98.03)\n","Epoch: [80][270/391]\tTime  0.172 ( 0.174)\tLoss 6.4873e-01 (5.2014e-01)\tAcc@1  81.25 ( 84.21)\tAcc@5  96.88 ( 98.01)\n","Epoch: [80][300/391]\tTime  0.175 ( 0.174)\tLoss 5.6750e-01 (5.2704e-01)\tAcc@1  79.69 ( 83.98)\tAcc@5  98.44 ( 97.94)\n","Epoch: [80][330/391]\tTime  0.176 ( 0.174)\tLoss 6.6949e-01 (5.3399e-01)\tAcc@1  80.47 ( 83.76)\tAcc@5  96.09 ( 97.88)\n","Epoch: [80][360/391]\tTime  0.174 ( 0.174)\tLoss 4.7841e-01 (5.3963e-01)\tAcc@1  88.28 ( 83.62)\tAcc@5  98.44 ( 97.80)\n","Epoch: [80][390/391]\tTime  0.158 ( 0.174)\tLoss 4.6512e-01 (5.4171e-01)\tAcc@1  85.00 ( 83.49)\tAcc@5  97.50 ( 97.80)\n","==> Train Accuracy: Acc@1 83.494 || Acc@5 97.802\n","==> Test Accuracy:  Acc@1 68.760 || Acc@5 91.070\n","==> 72.47 seconds to train this epoch\n","\n","\n","----- epoch: 81, lr: 0.020000000000000004 -----\n","Epoch: [81][  0/391]\tTime  0.273 ( 0.273)\tLoss 4.1558e-01 (4.1558e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  99.22 ( 99.22)\n","Epoch: [81][ 30/391]\tTime  0.172 ( 0.177)\tLoss 5.1031e-01 (4.5690e-01)\tAcc@1  83.59 ( 85.71)\tAcc@5  96.88 ( 98.26)\n","Epoch: [81][ 60/391]\tTime  0.172 ( 0.176)\tLoss 4.0905e-01 (4.6158e-01)\tAcc@1  85.94 ( 85.58)\tAcc@5 100.00 ( 98.41)\n","Epoch: [81][ 90/391]\tTime  0.174 ( 0.175)\tLoss 3.7777e-01 (4.7923e-01)\tAcc@1  89.84 ( 85.26)\tAcc@5  99.22 ( 98.34)\n","Epoch: [81][120/391]\tTime  0.174 ( 0.175)\tLoss 5.5590e-01 (4.8956e-01)\tAcc@1  82.03 ( 85.05)\tAcc@5  98.44 ( 98.29)\n","Epoch: [81][150/391]\tTime  0.175 ( 0.175)\tLoss 3.8032e-01 (4.9096e-01)\tAcc@1  89.84 ( 85.07)\tAcc@5  98.44 ( 98.23)\n","Epoch: [81][180/391]\tTime  0.175 ( 0.175)\tLoss 5.0628e-01 (5.0088e-01)\tAcc@1  89.84 ( 84.71)\tAcc@5  96.88 ( 98.15)\n","Epoch: [81][210/391]\tTime  0.175 ( 0.175)\tLoss 5.3261e-01 (5.0582e-01)\tAcc@1  82.03 ( 84.51)\tAcc@5  98.44 ( 98.09)\n","Epoch: [81][240/391]\tTime  0.173 ( 0.175)\tLoss 4.1307e-01 (5.1193e-01)\tAcc@1  89.06 ( 84.26)\tAcc@5  98.44 ( 98.04)\n","Epoch: [81][270/391]\tTime  0.174 ( 0.174)\tLoss 5.2150e-01 (5.1652e-01)\tAcc@1  85.16 ( 84.17)\tAcc@5  97.66 ( 97.96)\n","Epoch: [81][300/391]\tTime  0.174 ( 0.174)\tLoss 4.8060e-01 (5.2032e-01)\tAcc@1  82.81 ( 84.02)\tAcc@5 100.00 ( 97.95)\n","Epoch: [81][330/391]\tTime  0.178 ( 0.174)\tLoss 5.0684e-01 (5.2415e-01)\tAcc@1  87.50 ( 83.89)\tAcc@5  97.66 ( 97.92)\n","Epoch: [81][360/391]\tTime  0.174 ( 0.174)\tLoss 3.3601e-01 (5.2555e-01)\tAcc@1  90.62 ( 83.84)\tAcc@5 100.00 ( 97.95)\n","Epoch: [81][390/391]\tTime  0.159 ( 0.174)\tLoss 5.2222e-01 (5.3240e-01)\tAcc@1  80.00 ( 83.62)\tAcc@5 100.00 ( 97.91)\n","==> Train Accuracy: Acc@1 83.622 || Acc@5 97.910\n","==> Test Accuracy:  Acc@1 70.530 || Acc@5 92.000\n","==> 72.46 seconds to train this epoch\n","\n","\n","----- epoch: 82, lr: 0.020000000000000004 -----\n","Epoch: [82][  0/391]\tTime  0.276 ( 0.276)\tLoss 5.2671e-01 (5.2671e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n","Epoch: [82][ 30/391]\tTime  0.173 ( 0.177)\tLoss 5.9581e-01 (5.1569e-01)\tAcc@1  82.81 ( 84.68)\tAcc@5  99.22 ( 98.14)\n","Epoch: [82][ 60/391]\tTime  0.173 ( 0.175)\tLoss 5.9306e-01 (5.0239e-01)\tAcc@1  85.94 ( 85.18)\tAcc@5 100.00 ( 98.00)\n","Epoch: [82][ 90/391]\tTime  0.174 ( 0.175)\tLoss 5.1072e-01 (5.0195e-01)\tAcc@1  84.38 ( 85.16)\tAcc@5  96.88 ( 97.94)\n","Epoch: [82][120/391]\tTime  0.174 ( 0.175)\tLoss 4.0991e-01 (5.0847e-01)\tAcc@1  85.94 ( 84.90)\tAcc@5  99.22 ( 97.83)\n","Epoch: [82][150/391]\tTime  0.176 ( 0.175)\tLoss 4.3189e-01 (5.1110e-01)\tAcc@1  87.50 ( 84.88)\tAcc@5  98.44 ( 97.83)\n","Epoch: [82][180/391]\tTime  0.173 ( 0.174)\tLoss 5.7615e-01 (5.1586e-01)\tAcc@1  78.12 ( 84.69)\tAcc@5  96.88 ( 97.82)\n","Epoch: [82][210/391]\tTime  0.172 ( 0.174)\tLoss 4.4428e-01 (5.1487e-01)\tAcc@1  85.94 ( 84.70)\tAcc@5 100.00 ( 97.83)\n","Epoch: [82][240/391]\tTime  0.173 ( 0.174)\tLoss 7.0239e-01 (5.1715e-01)\tAcc@1  78.12 ( 84.57)\tAcc@5  96.88 ( 97.85)\n","Epoch: [82][270/391]\tTime  0.172 ( 0.174)\tLoss 7.1935e-01 (5.2417e-01)\tAcc@1  78.12 ( 84.32)\tAcc@5  95.31 ( 97.80)\n","Epoch: [82][300/391]\tTime  0.178 ( 0.174)\tLoss 4.4550e-01 (5.3018e-01)\tAcc@1  86.72 ( 84.07)\tAcc@5  98.44 ( 97.81)\n","Epoch: [82][330/391]\tTime  0.177 ( 0.174)\tLoss 6.7403e-01 (5.3580e-01)\tAcc@1  76.56 ( 83.91)\tAcc@5  96.09 ( 97.76)\n","Epoch: [82][360/391]\tTime  0.172 ( 0.174)\tLoss 6.4106e-01 (5.3737e-01)\tAcc@1  82.81 ( 83.84)\tAcc@5  97.66 ( 97.77)\n","Epoch: [82][390/391]\tTime  0.157 ( 0.174)\tLoss 5.7342e-01 (5.4251e-01)\tAcc@1  83.75 ( 83.70)\tAcc@5  96.25 ( 97.73)\n","==> Train Accuracy: Acc@1 83.700 || Acc@5 97.732\n","==> Test Accuracy:  Acc@1 69.380 || Acc@5 91.600\n","==> 72.36 seconds to train this epoch\n","\n","\n","----- epoch: 83, lr: 0.020000000000000004 -----\n","Epoch: [83][  0/391]\tTime  0.256 ( 0.256)\tLoss 5.3810e-01 (5.3810e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  97.66 ( 97.66)\n","Epoch: [83][ 30/391]\tTime  0.176 ( 0.176)\tLoss 4.4445e-01 (5.0916e-01)\tAcc@1  88.28 ( 84.53)\tAcc@5  99.22 ( 97.78)\n","Epoch: [83][ 60/391]\tTime  0.176 ( 0.175)\tLoss 4.8460e-01 (4.9897e-01)\tAcc@1  84.38 ( 84.99)\tAcc@5  98.44 ( 97.99)\n","Epoch: [83][ 90/391]\tTime  0.173 ( 0.174)\tLoss 4.8319e-01 (5.0373e-01)\tAcc@1  85.16 ( 84.59)\tAcc@5  97.66 ( 98.04)\n","Epoch: [83][120/391]\tTime  0.175 ( 0.174)\tLoss 3.5095e-01 (5.0543e-01)\tAcc@1  89.84 ( 84.66)\tAcc@5 100.00 ( 98.11)\n","Epoch: [83][150/391]\tTime  0.175 ( 0.174)\tLoss 6.3482e-01 (5.0987e-01)\tAcc@1  81.25 ( 84.51)\tAcc@5  96.09 ( 98.07)\n","Epoch: [83][180/391]\tTime  0.173 ( 0.174)\tLoss 5.3868e-01 (5.1213e-01)\tAcc@1  82.03 ( 84.39)\tAcc@5  97.66 ( 98.03)\n","Epoch: [83][210/391]\tTime  0.172 ( 0.174)\tLoss 6.3755e-01 (5.1607e-01)\tAcc@1  78.91 ( 84.30)\tAcc@5  96.88 ( 97.96)\n","Epoch: [83][240/391]\tTime  0.179 ( 0.174)\tLoss 4.4577e-01 (5.1946e-01)\tAcc@1  86.72 ( 84.24)\tAcc@5  98.44 ( 97.97)\n","Epoch: [83][270/391]\tTime  0.176 ( 0.174)\tLoss 4.1439e-01 (5.2259e-01)\tAcc@1  86.72 ( 84.17)\tAcc@5 100.00 ( 97.97)\n","Epoch: [83][300/391]\tTime  0.173 ( 0.174)\tLoss 4.4189e-01 (5.2820e-01)\tAcc@1  85.16 ( 84.01)\tAcc@5  98.44 ( 97.94)\n","Epoch: [83][330/391]\tTime  0.173 ( 0.174)\tLoss 7.3646e-01 (5.3097e-01)\tAcc@1  76.56 ( 83.86)\tAcc@5  95.31 ( 97.91)\n","Epoch: [83][360/391]\tTime  0.174 ( 0.174)\tLoss 7.0101e-01 (5.3591e-01)\tAcc@1  78.91 ( 83.70)\tAcc@5  95.31 ( 97.87)\n","Epoch: [83][390/391]\tTime  0.157 ( 0.174)\tLoss 5.2730e-01 (5.3789e-01)\tAcc@1  83.75 ( 83.67)\tAcc@5  98.75 ( 97.86)\n","==> Train Accuracy: Acc@1 83.670 || Acc@5 97.860\n","==> Test Accuracy:  Acc@1 70.900 || Acc@5 91.620\n","==> 72.27 seconds to train this epoch\n","\n","\n","----- epoch: 84, lr: 0.020000000000000004 -----\n","Epoch: [84][  0/391]\tTime  0.274 ( 0.274)\tLoss 5.2906e-01 (5.2906e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  96.88 ( 96.88)\n","Epoch: [84][ 30/391]\tTime  0.176 ( 0.176)\tLoss 4.1973e-01 (4.8917e-01)\tAcc@1  87.50 ( 85.41)\tAcc@5  99.22 ( 98.16)\n","Epoch: [84][ 60/391]\tTime  0.175 ( 0.175)\tLoss 5.7749e-01 (4.9817e-01)\tAcc@1  77.34 ( 84.86)\tAcc@5  98.44 ( 98.21)\n","Epoch: [84][ 90/391]\tTime  0.173 ( 0.175)\tLoss 4.3289e-01 (4.9417e-01)\tAcc@1  89.06 ( 84.85)\tAcc@5  99.22 ( 98.25)\n","Epoch: [84][120/391]\tTime  0.174 ( 0.174)\tLoss 5.4271e-01 (4.9789e-01)\tAcc@1  83.59 ( 84.93)\tAcc@5  97.66 ( 98.14)\n","Epoch: [84][150/391]\tTime  0.173 ( 0.174)\tLoss 4.6321e-01 (5.0191e-01)\tAcc@1  85.16 ( 84.69)\tAcc@5  98.44 ( 98.11)\n","Epoch: [84][180/391]\tTime  0.179 ( 0.174)\tLoss 4.6043e-01 (5.0283e-01)\tAcc@1  86.72 ( 84.66)\tAcc@5  99.22 ( 98.10)\n","Epoch: [84][210/391]\tTime  0.174 ( 0.174)\tLoss 4.7220e-01 (5.0764e-01)\tAcc@1  85.94 ( 84.55)\tAcc@5  98.44 ( 98.06)\n","Epoch: [84][240/391]\tTime  0.174 ( 0.174)\tLoss 5.0891e-01 (5.0809e-01)\tAcc@1  85.16 ( 84.48)\tAcc@5  96.88 ( 98.03)\n","Epoch: [84][270/391]\tTime  0.172 ( 0.174)\tLoss 5.3429e-01 (5.1235e-01)\tAcc@1  85.16 ( 84.27)\tAcc@5  98.44 ( 98.01)\n","Epoch: [84][300/391]\tTime  0.175 ( 0.174)\tLoss 4.1459e-01 (5.1516e-01)\tAcc@1  89.84 ( 84.19)\tAcc@5  98.44 ( 98.00)\n","Epoch: [84][330/391]\tTime  0.175 ( 0.174)\tLoss 6.9017e-01 (5.1928e-01)\tAcc@1  80.47 ( 84.13)\tAcc@5  99.22 ( 97.99)\n","Epoch: [84][360/391]\tTime  0.174 ( 0.174)\tLoss 3.6066e-01 (5.2185e-01)\tAcc@1  86.72 ( 84.05)\tAcc@5  99.22 ( 97.95)\n","Epoch: [84][390/391]\tTime  0.156 ( 0.174)\tLoss 6.3567e-01 (5.2595e-01)\tAcc@1  80.00 ( 83.89)\tAcc@5  97.50 ( 97.94)\n","==> Train Accuracy: Acc@1 83.890 || Acc@5 97.936\n","==> Test Accuracy:  Acc@1 70.270 || Acc@5 91.750\n","==> 72.41 seconds to train this epoch\n","\n","\n","----- epoch: 85, lr: 0.020000000000000004 -----\n","Epoch: [85][  0/391]\tTime  0.263 ( 0.263)\tLoss 5.4263e-01 (5.4263e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.88 ( 96.88)\n","Epoch: [85][ 30/391]\tTime  0.174 ( 0.177)\tLoss 5.0866e-01 (5.0540e-01)\tAcc@1  87.50 ( 84.80)\tAcc@5  97.66 ( 98.08)\n","Epoch: [85][ 60/391]\tTime  0.175 ( 0.176)\tLoss 3.7496e-01 (4.8520e-01)\tAcc@1  89.84 ( 85.04)\tAcc@5 100.00 ( 98.36)\n","Epoch: [85][ 90/391]\tTime  0.175 ( 0.175)\tLoss 4.5934e-01 (4.8038e-01)\tAcc@1  82.81 ( 85.34)\tAcc@5 100.00 ( 98.32)\n","Epoch: [85][120/391]\tTime  0.176 ( 0.175)\tLoss 4.6836e-01 (4.7599e-01)\tAcc@1  85.94 ( 85.59)\tAcc@5  97.66 ( 98.31)\n","Epoch: [85][150/391]\tTime  0.173 ( 0.175)\tLoss 5.6207e-01 (4.8062e-01)\tAcc@1  82.81 ( 85.51)\tAcc@5 100.00 ( 98.32)\n","Epoch: [85][180/391]\tTime  0.176 ( 0.175)\tLoss 5.2066e-01 (4.8342e-01)\tAcc@1  82.81 ( 85.50)\tAcc@5  99.22 ( 98.26)\n","Epoch: [85][210/391]\tTime  0.174 ( 0.175)\tLoss 2.9742e-01 (4.8539e-01)\tAcc@1  92.19 ( 85.41)\tAcc@5  97.66 ( 98.22)\n","Epoch: [85][240/391]\tTime  0.173 ( 0.175)\tLoss 4.6176e-01 (4.9292e-01)\tAcc@1  88.28 ( 85.18)\tAcc@5  97.66 ( 98.12)\n","Epoch: [85][270/391]\tTime  0.175 ( 0.175)\tLoss 4.4788e-01 (4.9740e-01)\tAcc@1  88.28 ( 85.00)\tAcc@5  98.44 ( 98.10)\n","Epoch: [85][300/391]\tTime  0.172 ( 0.175)\tLoss 5.6361e-01 (5.0265e-01)\tAcc@1  82.03 ( 84.76)\tAcc@5  99.22 ( 98.08)\n","Epoch: [85][330/391]\tTime  0.175 ( 0.175)\tLoss 6.9709e-01 (5.0823e-01)\tAcc@1  78.91 ( 84.57)\tAcc@5  95.31 ( 98.04)\n","Epoch: [85][360/391]\tTime  0.175 ( 0.175)\tLoss 4.7682e-01 (5.1319e-01)\tAcc@1  84.38 ( 84.43)\tAcc@5 100.00 ( 98.00)\n","Epoch: [85][390/391]\tTime  0.157 ( 0.175)\tLoss 4.6579e-01 (5.1762e-01)\tAcc@1  91.25 ( 84.32)\tAcc@5  96.25 ( 97.96)\n","==> Train Accuracy: Acc@1 84.322 || Acc@5 97.960\n","==> Test Accuracy:  Acc@1 70.280 || Acc@5 91.570\n","==> 72.58 seconds to train this epoch\n","\n","\n","----- epoch: 86, lr: 0.020000000000000004 -----\n","Epoch: [86][  0/391]\tTime  0.263 ( 0.263)\tLoss 4.5982e-01 (4.5982e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  99.22 ( 99.22)\n","Epoch: [86][ 30/391]\tTime  0.174 ( 0.177)\tLoss 5.9157e-01 (4.7463e-01)\tAcc@1  88.28 ( 86.24)\tAcc@5  97.66 ( 98.36)\n","Epoch: [86][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.5802e-01 (4.8423e-01)\tAcc@1  83.59 ( 85.67)\tAcc@5  99.22 ( 98.32)\n","Epoch: [86][ 90/391]\tTime  0.174 ( 0.175)\tLoss 6.2953e-01 (4.8815e-01)\tAcc@1  85.16 ( 85.49)\tAcc@5  96.88 ( 98.17)\n","Epoch: [86][120/391]\tTime  0.175 ( 0.175)\tLoss 5.5730e-01 (4.8234e-01)\tAcc@1  83.59 ( 85.61)\tAcc@5  96.09 ( 98.21)\n","Epoch: [86][150/391]\tTime  0.175 ( 0.175)\tLoss 5.2775e-01 (4.8311e-01)\tAcc@1  85.16 ( 85.47)\tAcc@5  96.09 ( 98.20)\n","Epoch: [86][180/391]\tTime  0.174 ( 0.174)\tLoss 5.9217e-01 (4.9193e-01)\tAcc@1  82.81 ( 85.18)\tAcc@5  95.31 ( 98.14)\n","Epoch: [86][210/391]\tTime  0.176 ( 0.174)\tLoss 5.7916e-01 (4.9855e-01)\tAcc@1  82.03 ( 84.94)\tAcc@5  99.22 ( 98.09)\n","Epoch: [86][240/391]\tTime  0.174 ( 0.174)\tLoss 4.5178e-01 (5.0370e-01)\tAcc@1  87.50 ( 84.90)\tAcc@5  99.22 ( 98.04)\n","Epoch: [86][270/391]\tTime  0.173 ( 0.174)\tLoss 6.0866e-01 (5.0892e-01)\tAcc@1  79.69 ( 84.68)\tAcc@5  99.22 ( 97.99)\n","Epoch: [86][300/391]\tTime  0.173 ( 0.174)\tLoss 4.8501e-01 (5.1383e-01)\tAcc@1  85.94 ( 84.41)\tAcc@5  96.09 ( 97.97)\n","Epoch: [86][330/391]\tTime  0.171 ( 0.174)\tLoss 5.7611e-01 (5.1577e-01)\tAcc@1  82.81 ( 84.37)\tAcc@5  95.31 ( 97.93)\n","Epoch: [86][360/391]\tTime  0.173 ( 0.174)\tLoss 4.7297e-01 (5.1847e-01)\tAcc@1  85.94 ( 84.27)\tAcc@5  98.44 ( 97.91)\n","Epoch: [86][390/391]\tTime  0.155 ( 0.174)\tLoss 5.5020e-01 (5.1937e-01)\tAcc@1  82.50 ( 84.27)\tAcc@5  97.50 ( 97.88)\n","==> Train Accuracy: Acc@1 84.272 || Acc@5 97.884\n","==> Test Accuracy:  Acc@1 70.410 || Acc@5 91.370\n","==> 72.35 seconds to train this epoch\n","\n","\n","----- epoch: 87, lr: 0.020000000000000004 -----\n","Epoch: [87][  0/391]\tTime  0.242 ( 0.242)\tLoss 5.8468e-01 (5.8468e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  96.88 ( 96.88)\n","Epoch: [87][ 30/391]\tTime  0.172 ( 0.176)\tLoss 2.9648e-01 (4.5851e-01)\tAcc@1  90.62 ( 86.37)\tAcc@5  99.22 ( 98.34)\n","Epoch: [87][ 60/391]\tTime  0.172 ( 0.175)\tLoss 5.6696e-01 (4.7062e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  96.09 ( 98.16)\n","Epoch: [87][ 90/391]\tTime  0.171 ( 0.174)\tLoss 5.5700e-01 (4.7075e-01)\tAcc@1  83.59 ( 85.69)\tAcc@5  98.44 ( 98.26)\n","Epoch: [87][120/391]\tTime  0.174 ( 0.174)\tLoss 4.7256e-01 (4.7920e-01)\tAcc@1  83.59 ( 85.30)\tAcc@5 100.00 ( 98.27)\n","Epoch: [87][150/391]\tTime  0.173 ( 0.174)\tLoss 6.2080e-01 (4.8248e-01)\tAcc@1  81.25 ( 85.24)\tAcc@5  97.66 ( 98.26)\n","Epoch: [87][180/391]\tTime  0.174 ( 0.174)\tLoss 7.1832e-01 (4.8634e-01)\tAcc@1  76.56 ( 85.02)\tAcc@5  96.88 ( 98.30)\n","Epoch: [87][210/391]\tTime  0.174 ( 0.174)\tLoss 4.3468e-01 (4.8580e-01)\tAcc@1  85.94 ( 85.09)\tAcc@5 100.00 ( 98.26)\n","Epoch: [87][240/391]\tTime  0.172 ( 0.174)\tLoss 4.3125e-01 (4.9026e-01)\tAcc@1  89.06 ( 84.98)\tAcc@5  99.22 ( 98.21)\n","Epoch: [87][270/391]\tTime  0.172 ( 0.174)\tLoss 4.9289e-01 (4.9572e-01)\tAcc@1  86.72 ( 84.88)\tAcc@5  98.44 ( 98.13)\n","Epoch: [87][300/391]\tTime  0.172 ( 0.174)\tLoss 6.2145e-01 (5.0092e-01)\tAcc@1  80.47 ( 84.76)\tAcc@5  97.66 ( 98.06)\n","Epoch: [87][330/391]\tTime  0.172 ( 0.174)\tLoss 5.0702e-01 (5.0532e-01)\tAcc@1  84.38 ( 84.65)\tAcc@5  99.22 ( 98.06)\n","Epoch: [87][360/391]\tTime  0.175 ( 0.174)\tLoss 6.2022e-01 (5.0758e-01)\tAcc@1  83.59 ( 84.54)\tAcc@5  96.88 ( 98.04)\n","Epoch: [87][390/391]\tTime  0.159 ( 0.174)\tLoss 7.0355e-01 (5.1294e-01)\tAcc@1  80.00 ( 84.34)\tAcc@5  96.25 ( 98.02)\n","==> Train Accuracy: Acc@1 84.340 || Acc@5 98.016\n","==> Test Accuracy:  Acc@1 69.100 || Acc@5 91.150\n","==> 72.22 seconds to train this epoch\n","\n","\n","----- epoch: 88, lr: 0.020000000000000004 -----\n","Epoch: [88][  0/391]\tTime  0.266 ( 0.266)\tLoss 5.5263e-01 (5.5263e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  98.44 ( 98.44)\n","Epoch: [88][ 30/391]\tTime  0.174 ( 0.176)\tLoss 5.6304e-01 (4.7608e-01)\tAcc@1  83.59 ( 85.31)\tAcc@5  98.44 ( 98.56)\n","Epoch: [88][ 60/391]\tTime  0.175 ( 0.175)\tLoss 4.8353e-01 (4.8238e-01)\tAcc@1  83.59 ( 85.22)\tAcc@5  99.22 ( 98.57)\n","Epoch: [88][ 90/391]\tTime  0.173 ( 0.175)\tLoss 4.4740e-01 (4.7475e-01)\tAcc@1  87.50 ( 85.55)\tAcc@5  98.44 ( 98.51)\n","Epoch: [88][120/391]\tTime  0.173 ( 0.174)\tLoss 5.7743e-01 (4.7909e-01)\tAcc@1  83.59 ( 85.39)\tAcc@5  99.22 ( 98.48)\n","Epoch: [88][150/391]\tTime  0.173 ( 0.174)\tLoss 5.3045e-01 (4.7988e-01)\tAcc@1  82.81 ( 85.26)\tAcc@5  98.44 ( 98.47)\n","Epoch: [88][180/391]\tTime  0.172 ( 0.174)\tLoss 5.4461e-01 (4.8236e-01)\tAcc@1  85.16 ( 85.15)\tAcc@5  98.44 ( 98.44)\n","Epoch: [88][210/391]\tTime  0.169 ( 0.174)\tLoss 4.8408e-01 (4.8966e-01)\tAcc@1  82.81 ( 84.92)\tAcc@5  98.44 ( 98.40)\n","Epoch: [88][240/391]\tTime  0.174 ( 0.174)\tLoss 6.0610e-01 (4.9668e-01)\tAcc@1  80.47 ( 84.66)\tAcc@5  97.66 ( 98.35)\n","Epoch: [88][270/391]\tTime  0.174 ( 0.174)\tLoss 5.0523e-01 (5.0197e-01)\tAcc@1  83.59 ( 84.50)\tAcc@5  97.66 ( 98.29)\n","Epoch: [88][300/391]\tTime  0.173 ( 0.174)\tLoss 7.8580e-01 (5.0676e-01)\tAcc@1  77.34 ( 84.38)\tAcc@5  96.88 ( 98.26)\n","Epoch: [88][330/391]\tTime  0.173 ( 0.174)\tLoss 5.6257e-01 (5.0631e-01)\tAcc@1  81.25 ( 84.35)\tAcc@5  98.44 ( 98.27)\n","Epoch: [88][360/391]\tTime  0.175 ( 0.174)\tLoss 6.6418e-01 (5.1075e-01)\tAcc@1  84.38 ( 84.23)\tAcc@5  96.88 ( 98.22)\n","Epoch: [88][390/391]\tTime  0.157 ( 0.174)\tLoss 6.6999e-01 (5.1523e-01)\tAcc@1  83.75 ( 84.17)\tAcc@5  96.25 ( 98.17)\n","==> Train Accuracy: Acc@1 84.166 || Acc@5 98.170\n","==> Test Accuracy:  Acc@1 70.480 || Acc@5 91.820\n","==> 72.20 seconds to train this epoch\n","\n","\n","----- epoch: 89, lr: 0.020000000000000004 -----\n","Epoch: [89][  0/391]\tTime  0.262 ( 0.262)\tLoss 3.7129e-01 (3.7129e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  99.22 ( 99.22)\n","Epoch: [89][ 30/391]\tTime  0.172 ( 0.176)\tLoss 4.6316e-01 (4.8416e-01)\tAcc@1  89.84 ( 85.58)\tAcc@5  99.22 ( 98.14)\n","Epoch: [89][ 60/391]\tTime  0.175 ( 0.175)\tLoss 4.1749e-01 (4.8524e-01)\tAcc@1  87.50 ( 85.49)\tAcc@5  98.44 ( 98.25)\n","Epoch: [89][ 90/391]\tTime  0.174 ( 0.174)\tLoss 6.1291e-01 (4.7544e-01)\tAcc@1  82.81 ( 85.84)\tAcc@5  97.66 ( 98.31)\n","Epoch: [89][120/391]\tTime  0.175 ( 0.174)\tLoss 4.2393e-01 (4.8783e-01)\tAcc@1  85.94 ( 85.44)\tAcc@5  99.22 ( 98.22)\n","Epoch: [89][150/391]\tTime  0.174 ( 0.174)\tLoss 5.6889e-01 (4.9133e-01)\tAcc@1  82.81 ( 85.22)\tAcc@5  98.44 ( 98.22)\n","Epoch: [89][180/391]\tTime  0.174 ( 0.174)\tLoss 5.9144e-01 (4.9322e-01)\tAcc@1  85.94 ( 85.08)\tAcc@5  98.44 ( 98.23)\n","Epoch: [89][210/391]\tTime  0.174 ( 0.174)\tLoss 5.1338e-01 (4.9442e-01)\tAcc@1  82.03 ( 85.02)\tAcc@5  99.22 ( 98.17)\n","Epoch: [89][240/391]\tTime  0.172 ( 0.174)\tLoss 5.0422e-01 (4.9733e-01)\tAcc@1  84.38 ( 84.93)\tAcc@5  97.66 ( 98.17)\n","Epoch: [89][270/391]\tTime  0.176 ( 0.174)\tLoss 5.8913e-01 (5.0055e-01)\tAcc@1  83.59 ( 84.80)\tAcc@5  99.22 ( 98.17)\n","Epoch: [89][300/391]\tTime  0.177 ( 0.174)\tLoss 6.2076e-01 (5.0272e-01)\tAcc@1  81.25 ( 84.77)\tAcc@5  98.44 ( 98.17)\n","Epoch: [89][330/391]\tTime  0.174 ( 0.174)\tLoss 5.7315e-01 (5.0701e-01)\tAcc@1  85.94 ( 84.67)\tAcc@5  96.09 ( 98.11)\n","Epoch: [89][360/391]\tTime  0.174 ( 0.174)\tLoss 6.1112e-01 (5.1104e-01)\tAcc@1  77.34 ( 84.49)\tAcc@5  98.44 ( 98.10)\n","Epoch: [89][390/391]\tTime  0.157 ( 0.174)\tLoss 3.4411e-01 (5.1345e-01)\tAcc@1  91.25 ( 84.40)\tAcc@5  98.75 ( 98.07)\n","==> Train Accuracy: Acc@1 84.400 || Acc@5 98.072\n","==> Test Accuracy:  Acc@1 70.370 || Acc@5 91.990\n","==> 72.38 seconds to train this epoch\n","\n","\n","----- epoch: 90, lr: 0.004000000000000001 -----\n","Epoch: [90][  0/391]\tTime  0.273 ( 0.273)\tLoss 4.9604e-01 (4.9604e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5  97.66 ( 97.66)\n","Epoch: [90][ 30/391]\tTime  0.176 ( 0.177)\tLoss 3.4490e-01 (4.3792e-01)\tAcc@1  89.84 ( 87.05)\tAcc@5  99.22 ( 98.56)\n","Epoch: [90][ 60/391]\tTime  0.176 ( 0.175)\tLoss 2.9862e-01 (4.0471e-01)\tAcc@1  92.97 ( 87.94)\tAcc@5  98.44 ( 98.76)\n","Epoch: [90][ 90/391]\tTime  0.174 ( 0.175)\tLoss 3.6496e-01 (3.7476e-01)\tAcc@1  87.50 ( 88.79)\tAcc@5  99.22 ( 98.85)\n","Epoch: [90][120/391]\tTime  0.174 ( 0.175)\tLoss 2.5103e-01 (3.5831e-01)\tAcc@1  93.75 ( 89.33)\tAcc@5 100.00 ( 98.93)\n","Epoch: [90][150/391]\tTime  0.175 ( 0.175)\tLoss 2.9326e-01 (3.4491e-01)\tAcc@1  92.97 ( 89.70)\tAcc@5  99.22 ( 98.98)\n","Epoch: [90][180/391]\tTime  0.175 ( 0.175)\tLoss 2.0872e-01 (3.3703e-01)\tAcc@1  94.53 ( 90.03)\tAcc@5  99.22 ( 98.99)\n","Epoch: [90][210/391]\tTime  0.175 ( 0.175)\tLoss 2.4407e-01 (3.2876e-01)\tAcc@1  92.19 ( 90.26)\tAcc@5  99.22 ( 99.01)\n","Epoch: [90][240/391]\tTime  0.175 ( 0.175)\tLoss 2.9370e-01 (3.2462e-01)\tAcc@1  90.62 ( 90.35)\tAcc@5  99.22 ( 99.05)\n","Epoch: [90][270/391]\tTime  0.173 ( 0.175)\tLoss 2.5348e-01 (3.2130e-01)\tAcc@1  93.75 ( 90.47)\tAcc@5 100.00 ( 99.07)\n","Epoch: [90][300/391]\tTime  0.173 ( 0.175)\tLoss 2.2285e-01 (3.1456e-01)\tAcc@1  93.75 ( 90.71)\tAcc@5 100.00 ( 99.10)\n","Epoch: [90][330/391]\tTime  0.175 ( 0.175)\tLoss 1.7383e-01 (3.0900e-01)\tAcc@1  97.66 ( 90.93)\tAcc@5 100.00 ( 99.12)\n","Epoch: [90][360/391]\tTime  0.172 ( 0.175)\tLoss 3.3200e-01 (3.0506e-01)\tAcc@1  88.28 ( 91.03)\tAcc@5  96.88 ( 99.14)\n","Epoch: [90][390/391]\tTime  0.159 ( 0.174)\tLoss 3.2424e-01 (3.0103e-01)\tAcc@1  93.75 ( 91.19)\tAcc@5  98.75 ( 99.17)\n","==> Train Accuracy: Acc@1 91.192 || Acc@5 99.172\n","==> Test Accuracy:  Acc@1 76.490 || Acc@5 94.320\n","==> 72.54 seconds to train this epoch\n","\n","\n","----- epoch: 91, lr: 0.004000000000000001 -----\n","Epoch: [91][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.5152e-01 (1.5152e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [91][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.9298e-01 (2.2368e-01)\tAcc@1  95.31 ( 93.42)\tAcc@5  99.22 ( 99.52)\n","Epoch: [91][ 60/391]\tTime  0.174 ( 0.175)\tLoss 2.3286e-01 (2.2382e-01)\tAcc@1  92.19 ( 93.38)\tAcc@5 100.00 ( 99.60)\n","Epoch: [91][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.6328e-01 (2.2494e-01)\tAcc@1  94.53 ( 93.43)\tAcc@5 100.00 ( 99.55)\n","Epoch: [91][120/391]\tTime  0.175 ( 0.175)\tLoss 2.1657e-01 (2.2567e-01)\tAcc@1  93.75 ( 93.41)\tAcc@5 100.00 ( 99.54)\n","Epoch: [91][150/391]\tTime  0.173 ( 0.174)\tLoss 1.0501e-01 (2.2417e-01)\tAcc@1  96.88 ( 93.53)\tAcc@5 100.00 ( 99.51)\n","Epoch: [91][180/391]\tTime  0.176 ( 0.174)\tLoss 3.1244e-01 (2.2562e-01)\tAcc@1  92.97 ( 93.49)\tAcc@5  98.44 ( 99.51)\n","Epoch: [91][210/391]\tTime  0.174 ( 0.174)\tLoss 2.8924e-01 (2.2594e-01)\tAcc@1  92.19 ( 93.45)\tAcc@5  99.22 ( 99.53)\n","Epoch: [91][240/391]\tTime  0.172 ( 0.174)\tLoss 1.7208e-01 (2.2607e-01)\tAcc@1  94.53 ( 93.47)\tAcc@5 100.00 ( 99.53)\n","Epoch: [91][270/391]\tTime  0.178 ( 0.174)\tLoss 2.5423e-01 (2.2515e-01)\tAcc@1  89.84 ( 93.51)\tAcc@5 100.00 ( 99.53)\n","Epoch: [91][300/391]\tTime  0.174 ( 0.174)\tLoss 2.3368e-01 (2.2414e-01)\tAcc@1  95.31 ( 93.57)\tAcc@5  99.22 ( 99.54)\n","Epoch: [91][330/391]\tTime  0.174 ( 0.174)\tLoss 1.9172e-01 (2.2439e-01)\tAcc@1  96.88 ( 93.55)\tAcc@5 100.00 ( 99.52)\n","Epoch: [91][360/391]\tTime  0.173 ( 0.174)\tLoss 1.5950e-01 (2.2491e-01)\tAcc@1  96.09 ( 93.54)\tAcc@5  99.22 ( 99.52)\n","Epoch: [91][390/391]\tTime  0.156 ( 0.174)\tLoss 1.3289e-01 (2.2363e-01)\tAcc@1  98.75 ( 93.58)\tAcc@5 100.00 ( 99.52)\n","==> Train Accuracy: Acc@1 93.576 || Acc@5 99.516\n","==> Test Accuracy:  Acc@1 76.800 || Acc@5 94.170\n","==> 72.32 seconds to train this epoch\n","\n","\n","----- epoch: 92, lr: 0.004000000000000001 -----\n","Epoch: [92][  0/391]\tTime  0.266 ( 0.266)\tLoss 2.6372e-01 (2.6372e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [92][ 30/391]\tTime  0.172 ( 0.177)\tLoss 2.8551e-01 (2.1000e-01)\tAcc@1  91.41 ( 93.93)\tAcc@5  99.22 ( 99.60)\n","Epoch: [92][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.9449e-01 (2.1539e-01)\tAcc@1  93.75 ( 93.74)\tAcc@5  99.22 ( 99.59)\n","Epoch: [92][ 90/391]\tTime  0.176 ( 0.175)\tLoss 2.2386e-01 (2.0897e-01)\tAcc@1  93.75 ( 93.97)\tAcc@5  99.22 ( 99.61)\n","Epoch: [92][120/391]\tTime  0.173 ( 0.174)\tLoss 2.5894e-01 (2.0862e-01)\tAcc@1  92.97 ( 94.05)\tAcc@5  99.22 ( 99.59)\n","Epoch: [92][150/391]\tTime  0.174 ( 0.174)\tLoss 2.0870e-01 (2.0721e-01)\tAcc@1  94.53 ( 94.08)\tAcc@5  98.44 ( 99.58)\n","Epoch: [92][180/391]\tTime  0.176 ( 0.174)\tLoss 1.8032e-01 (2.0529e-01)\tAcc@1  95.31 ( 94.17)\tAcc@5  99.22 ( 99.59)\n","Epoch: [92][210/391]\tTime  0.173 ( 0.174)\tLoss 2.4819e-01 (2.0404e-01)\tAcc@1  94.53 ( 94.25)\tAcc@5 100.00 ( 99.59)\n","Epoch: [92][240/391]\tTime  0.171 ( 0.174)\tLoss 1.6493e-01 (2.0290e-01)\tAcc@1  95.31 ( 94.31)\tAcc@5  99.22 ( 99.59)\n","Epoch: [92][270/391]\tTime  0.176 ( 0.174)\tLoss 1.4234e-01 (2.0168e-01)\tAcc@1  96.88 ( 94.32)\tAcc@5 100.00 ( 99.61)\n","Epoch: [92][300/391]\tTime  0.176 ( 0.174)\tLoss 1.3841e-01 (2.0006e-01)\tAcc@1  96.88 ( 94.42)\tAcc@5 100.00 ( 99.62)\n","Epoch: [92][330/391]\tTime  0.173 ( 0.174)\tLoss 1.9329e-01 (2.0006e-01)\tAcc@1  93.75 ( 94.43)\tAcc@5 100.00 ( 99.62)\n","Epoch: [92][360/391]\tTime  0.172 ( 0.174)\tLoss 1.6196e-01 (1.9989e-01)\tAcc@1  95.31 ( 94.42)\tAcc@5 100.00 ( 99.63)\n","Epoch: [92][390/391]\tTime  0.158 ( 0.174)\tLoss 1.6958e-01 (1.9939e-01)\tAcc@1  96.25 ( 94.43)\tAcc@5 100.00 ( 99.62)\n","==> Train Accuracy: Acc@1 94.428 || Acc@5 99.622\n","==> Test Accuracy:  Acc@1 76.730 || Acc@5 94.230\n","==> 72.24 seconds to train this epoch\n","\n","\n","----- epoch: 93, lr: 0.004000000000000001 -----\n","Epoch: [93][  0/391]\tTime  0.255 ( 0.255)\tLoss 2.0227e-01 (2.0227e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n","Epoch: [93][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.9116e-01 (1.8850e-01)\tAcc@1  93.75 ( 94.93)\tAcc@5  99.22 ( 99.50)\n","Epoch: [93][ 60/391]\tTime  0.175 ( 0.175)\tLoss 2.7026e-01 (1.8860e-01)\tAcc@1  94.53 ( 94.83)\tAcc@5  98.44 ( 99.59)\n","Epoch: [93][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.7587e-01 (1.8598e-01)\tAcc@1  94.53 ( 94.76)\tAcc@5 100.00 ( 99.62)\n","Epoch: [93][120/391]\tTime  0.173 ( 0.174)\tLoss 2.0114e-01 (1.8448e-01)\tAcc@1  95.31 ( 94.89)\tAcc@5  99.22 ( 99.64)\n","Epoch: [93][150/391]\tTime  0.175 ( 0.174)\tLoss 2.0455e-01 (1.8228e-01)\tAcc@1  95.31 ( 94.98)\tAcc@5  99.22 ( 99.64)\n","Epoch: [93][180/391]\tTime  0.174 ( 0.174)\tLoss 9.5776e-02 (1.8125e-01)\tAcc@1  97.66 ( 94.96)\tAcc@5 100.00 ( 99.65)\n","Epoch: [93][210/391]\tTime  0.173 ( 0.174)\tLoss 9.5540e-02 (1.8341e-01)\tAcc@1  99.22 ( 94.84)\tAcc@5 100.00 ( 99.65)\n","Epoch: [93][240/391]\tTime  0.174 ( 0.174)\tLoss 1.9618e-01 (1.8116e-01)\tAcc@1  94.53 ( 94.94)\tAcc@5  99.22 ( 99.66)\n","Epoch: [93][270/391]\tTime  0.173 ( 0.174)\tLoss 2.2332e-01 (1.8117e-01)\tAcc@1  93.75 ( 94.99)\tAcc@5 100.00 ( 99.66)\n","Epoch: [93][300/391]\tTime  0.176 ( 0.174)\tLoss 1.8127e-01 (1.8157e-01)\tAcc@1  93.75 ( 94.98)\tAcc@5 100.00 ( 99.65)\n","Epoch: [93][330/391]\tTime  0.173 ( 0.174)\tLoss 2.0280e-01 (1.8219e-01)\tAcc@1  91.41 ( 94.93)\tAcc@5 100.00 ( 99.67)\n","Epoch: [93][360/391]\tTime  0.175 ( 0.174)\tLoss 1.3527e-01 (1.8207e-01)\tAcc@1  96.88 ( 94.94)\tAcc@5 100.00 ( 99.68)\n","Epoch: [93][390/391]\tTime  0.157 ( 0.174)\tLoss 2.3776e-01 (1.8189e-01)\tAcc@1  91.25 ( 94.97)\tAcc@5  98.75 ( 99.67)\n","==> Train Accuracy: Acc@1 94.970 || Acc@5 99.672\n","==> Test Accuracy:  Acc@1 76.710 || Acc@5 94.330\n","==> 72.36 seconds to train this epoch\n","\n","\n","----- epoch: 94, lr: 0.004000000000000001 -----\n","Epoch: [94][  0/391]\tTime  0.247 ( 0.247)\tLoss 1.8586e-01 (1.8586e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [94][ 30/391]\tTime  0.175 ( 0.177)\tLoss 2.4695e-01 (1.7559e-01)\tAcc@1  92.19 ( 95.31)\tAcc@5  99.22 ( 99.62)\n","Epoch: [94][ 60/391]\tTime  0.174 ( 0.176)\tLoss 8.3395e-02 (1.7135e-01)\tAcc@1  99.22 ( 95.52)\tAcc@5 100.00 ( 99.69)\n","Epoch: [94][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.9913e-01 (1.6763e-01)\tAcc@1  94.53 ( 95.57)\tAcc@5 100.00 ( 99.68)\n","Epoch: [94][120/391]\tTime  0.175 ( 0.175)\tLoss 1.2649e-01 (1.6671e-01)\tAcc@1  96.88 ( 95.56)\tAcc@5 100.00 ( 99.68)\n","Epoch: [94][150/391]\tTime  0.172 ( 0.175)\tLoss 2.6419e-01 (1.6583e-01)\tAcc@1  93.75 ( 95.54)\tAcc@5  99.22 ( 99.68)\n","Epoch: [94][180/391]\tTime  0.176 ( 0.175)\tLoss 1.9504e-01 (1.6827e-01)\tAcc@1  94.53 ( 95.49)\tAcc@5  99.22 ( 99.67)\n","Epoch: [94][210/391]\tTime  0.173 ( 0.175)\tLoss 1.9073e-01 (1.6774e-01)\tAcc@1  95.31 ( 95.52)\tAcc@5  99.22 ( 99.68)\n","Epoch: [94][240/391]\tTime  0.175 ( 0.175)\tLoss 1.4784e-01 (1.6682e-01)\tAcc@1  97.66 ( 95.54)\tAcc@5  98.44 ( 99.67)\n","Epoch: [94][270/391]\tTime  0.173 ( 0.175)\tLoss 2.1586e-01 (1.6689e-01)\tAcc@1  92.97 ( 95.49)\tAcc@5 100.00 ( 99.67)\n","Epoch: [94][300/391]\tTime  0.172 ( 0.174)\tLoss 1.9616e-01 (1.6726e-01)\tAcc@1  97.66 ( 95.46)\tAcc@5  99.22 ( 99.67)\n","Epoch: [94][330/391]\tTime  0.174 ( 0.174)\tLoss 1.7256e-01 (1.6679e-01)\tAcc@1  95.31 ( 95.49)\tAcc@5 100.00 ( 99.67)\n","Epoch: [94][360/391]\tTime  0.172 ( 0.174)\tLoss 9.8899e-02 (1.6687e-01)\tAcc@1 100.00 ( 95.48)\tAcc@5 100.00 ( 99.66)\n","Epoch: [94][390/391]\tTime  0.158 ( 0.174)\tLoss 2.5231e-01 (1.6755e-01)\tAcc@1  92.50 ( 95.46)\tAcc@5  98.75 ( 99.66)\n","==> Train Accuracy: Acc@1 95.458 || Acc@5 99.658\n","==> Test Accuracy:  Acc@1 76.570 || Acc@5 94.330\n","==> 72.46 seconds to train this epoch\n","\n","\n","----- epoch: 95, lr: 0.004000000000000001 -----\n","Epoch: [95][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.3242e-01 (1.3242e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [95][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.0999e-01 (1.5505e-01)\tAcc@1  98.44 ( 95.72)\tAcc@5 100.00 ( 99.72)\n","Epoch: [95][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.1010e-01 (1.5968e-01)\tAcc@1  93.75 ( 95.54)\tAcc@5  99.22 ( 99.71)\n","Epoch: [95][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.5791e-01 (1.5796e-01)\tAcc@1  95.31 ( 95.60)\tAcc@5  99.22 ( 99.72)\n","Epoch: [95][120/391]\tTime  0.176 ( 0.174)\tLoss 2.5528e-01 (1.5867e-01)\tAcc@1  92.19 ( 95.77)\tAcc@5 100.00 ( 99.67)\n","Epoch: [95][150/391]\tTime  0.174 ( 0.174)\tLoss 1.7540e-01 (1.5850e-01)\tAcc@1  96.88 ( 95.81)\tAcc@5 100.00 ( 99.65)\n","Epoch: [95][180/391]\tTime  0.178 ( 0.174)\tLoss 1.5670e-01 (1.6050e-01)\tAcc@1  95.31 ( 95.82)\tAcc@5 100.00 ( 99.66)\n","Epoch: [95][210/391]\tTime  0.174 ( 0.174)\tLoss 1.3669e-01 (1.6097e-01)\tAcc@1  95.31 ( 95.81)\tAcc@5  99.22 ( 99.65)\n","Epoch: [95][240/391]\tTime  0.174 ( 0.174)\tLoss 1.2978e-01 (1.6063e-01)\tAcc@1  96.88 ( 95.77)\tAcc@5 100.00 ( 99.67)\n","Epoch: [95][270/391]\tTime  0.173 ( 0.174)\tLoss 1.5273e-01 (1.6084e-01)\tAcc@1  97.66 ( 95.77)\tAcc@5  99.22 ( 99.67)\n","Epoch: [95][300/391]\tTime  0.175 ( 0.174)\tLoss 1.2226e-01 (1.6107e-01)\tAcc@1  96.88 ( 95.76)\tAcc@5 100.00 ( 99.68)\n","Epoch: [95][330/391]\tTime  0.174 ( 0.174)\tLoss 1.1351e-01 (1.6125e-01)\tAcc@1  97.66 ( 95.75)\tAcc@5 100.00 ( 99.67)\n","Epoch: [95][360/391]\tTime  0.173 ( 0.174)\tLoss 1.6043e-01 (1.6131e-01)\tAcc@1  96.88 ( 95.77)\tAcc@5 100.00 ( 99.68)\n","Epoch: [95][390/391]\tTime  0.158 ( 0.174)\tLoss 1.6373e-01 (1.6232e-01)\tAcc@1  95.00 ( 95.72)\tAcc@5 100.00 ( 99.68)\n","==> Train Accuracy: Acc@1 95.716 || Acc@5 99.676\n","==> Test Accuracy:  Acc@1 76.230 || Acc@5 94.000\n","==> 72.25 seconds to train this epoch\n","\n","\n","----- epoch: 96, lr: 0.004000000000000001 -----\n","Epoch: [96][  0/391]\tTime  0.258 ( 0.258)\tLoss 1.5690e-01 (1.5690e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [96][ 30/391]\tTime  0.172 ( 0.176)\tLoss 1.8696e-01 (1.5286e-01)\tAcc@1  92.97 ( 95.59)\tAcc@5 100.00 ( 99.82)\n","Epoch: [96][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.0521e-01 (1.4817e-01)\tAcc@1  98.44 ( 95.90)\tAcc@5 100.00 ( 99.81)\n","Epoch: [96][ 90/391]\tTime  0.172 ( 0.174)\tLoss 1.8691e-01 (1.4875e-01)\tAcc@1  94.53 ( 95.98)\tAcc@5  99.22 ( 99.78)\n","Epoch: [96][120/391]\tTime  0.174 ( 0.174)\tLoss 1.8822e-01 (1.5241e-01)\tAcc@1  94.53 ( 95.85)\tAcc@5 100.00 ( 99.76)\n","Epoch: [96][150/391]\tTime  0.173 ( 0.174)\tLoss 1.6508e-01 (1.4976e-01)\tAcc@1  96.09 ( 95.90)\tAcc@5 100.00 ( 99.76)\n","Epoch: [96][180/391]\tTime  0.172 ( 0.174)\tLoss 1.4093e-01 (1.4966e-01)\tAcc@1  96.88 ( 95.86)\tAcc@5 100.00 ( 99.76)\n","Epoch: [96][210/391]\tTime  0.174 ( 0.174)\tLoss 1.5702e-01 (1.4889e-01)\tAcc@1  96.09 ( 95.95)\tAcc@5 100.00 ( 99.76)\n","Epoch: [96][240/391]\tTime  0.174 ( 0.174)\tLoss 1.1235e-01 (1.4797e-01)\tAcc@1  96.88 ( 95.96)\tAcc@5 100.00 ( 99.76)\n","Epoch: [96][270/391]\tTime  0.174 ( 0.174)\tLoss 1.8761e-01 (1.4839e-01)\tAcc@1  92.97 ( 95.99)\tAcc@5 100.00 ( 99.77)\n","Epoch: [96][300/391]\tTime  0.173 ( 0.174)\tLoss 1.7149e-01 (1.4798e-01)\tAcc@1  96.88 ( 96.00)\tAcc@5 100.00 ( 99.77)\n","Epoch: [96][330/391]\tTime  0.173 ( 0.174)\tLoss 1.6615e-01 (1.4788e-01)\tAcc@1  94.53 ( 96.00)\tAcc@5  99.22 ( 99.76)\n","Epoch: [96][360/391]\tTime  0.174 ( 0.174)\tLoss 1.4998e-01 (1.4798e-01)\tAcc@1  95.31 ( 96.01)\tAcc@5 100.00 ( 99.76)\n","Epoch: [96][390/391]\tTime  0.156 ( 0.174)\tLoss 1.4454e-01 (1.4739e-01)\tAcc@1  96.25 ( 96.03)\tAcc@5 100.00 ( 99.76)\n","==> Train Accuracy: Acc@1 96.032 || Acc@5 99.762\n","==> Test Accuracy:  Acc@1 76.880 || Acc@5 94.400\n","==> 72.28 seconds to train this epoch\n","\n","\n","----- epoch: 97, lr: 0.004000000000000001 -----\n","Epoch: [97][  0/391]\tTime  0.247 ( 0.247)\tLoss 1.2507e-01 (1.2507e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [97][ 30/391]\tTime  0.175 ( 0.176)\tLoss 1.4466e-01 (1.3729e-01)\tAcc@1  96.88 ( 96.14)\tAcc@5 100.00 ( 99.85)\n","Epoch: [97][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.2487e-01 (1.3527e-01)\tAcc@1  96.88 ( 96.13)\tAcc@5 100.00 ( 99.83)\n","Epoch: [97][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.4292e-01 (1.3493e-01)\tAcc@1  96.88 ( 96.30)\tAcc@5 100.00 ( 99.80)\n","Epoch: [97][120/391]\tTime  0.175 ( 0.174)\tLoss 8.9732e-02 (1.3719e-01)\tAcc@1  98.44 ( 96.27)\tAcc@5 100.00 ( 99.82)\n","Epoch: [97][150/391]\tTime  0.175 ( 0.174)\tLoss 1.9292e-01 (1.3754e-01)\tAcc@1  96.09 ( 96.27)\tAcc@5  99.22 ( 99.79)\n","Epoch: [97][180/391]\tTime  0.174 ( 0.174)\tLoss 1.2953e-01 (1.3885e-01)\tAcc@1  96.88 ( 96.24)\tAcc@5  99.22 ( 99.77)\n","Epoch: [97][210/391]\tTime  0.174 ( 0.174)\tLoss 1.3561e-01 (1.3835e-01)\tAcc@1  96.09 ( 96.27)\tAcc@5 100.00 ( 99.77)\n","Epoch: [97][240/391]\tTime  0.173 ( 0.174)\tLoss 1.1788e-01 (1.3927e-01)\tAcc@1  96.88 ( 96.23)\tAcc@5 100.00 ( 99.76)\n","Epoch: [97][270/391]\tTime  0.175 ( 0.174)\tLoss 1.2487e-01 (1.4096e-01)\tAcc@1  96.88 ( 96.17)\tAcc@5 100.00 ( 99.75)\n","Epoch: [97][300/391]\tTime  0.174 ( 0.174)\tLoss 1.1929e-01 (1.4179e-01)\tAcc@1  95.31 ( 96.11)\tAcc@5 100.00 ( 99.75)\n","Epoch: [97][330/391]\tTime  0.174 ( 0.174)\tLoss 1.6931e-01 (1.4294e-01)\tAcc@1  94.53 ( 96.08)\tAcc@5  98.44 ( 99.74)\n","Epoch: [97][360/391]\tTime  0.175 ( 0.174)\tLoss 2.1471e-01 (1.4303e-01)\tAcc@1  94.53 ( 96.08)\tAcc@5  99.22 ( 99.74)\n","Epoch: [97][390/391]\tTime  0.158 ( 0.174)\tLoss 1.1296e-01 (1.4376e-01)\tAcc@1  98.75 ( 96.06)\tAcc@5 100.00 ( 99.72)\n","==> Train Accuracy: Acc@1 96.060 || Acc@5 99.722\n","==> Test Accuracy:  Acc@1 76.370 || Acc@5 94.050\n","==> 72.40 seconds to train this epoch\n","\n","\n","----- epoch: 98, lr: 0.004000000000000001 -----\n","Epoch: [98][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.9071e-01 (1.9071e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n","Epoch: [98][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.6590e-01 (1.3484e-01)\tAcc@1  93.75 ( 96.32)\tAcc@5 100.00 ( 99.75)\n","Epoch: [98][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.5652e-01 (1.3561e-01)\tAcc@1  95.31 ( 96.41)\tAcc@5 100.00 ( 99.77)\n","Epoch: [98][ 90/391]\tTime  0.174 ( 0.175)\tLoss 8.9277e-02 (1.3108e-01)\tAcc@1  98.44 ( 96.60)\tAcc@5  99.22 ( 99.79)\n","Epoch: [98][120/391]\tTime  0.174 ( 0.175)\tLoss 1.2358e-01 (1.2925e-01)\tAcc@1  96.88 ( 96.66)\tAcc@5 100.00 ( 99.79)\n","Epoch: [98][150/391]\tTime  0.172 ( 0.175)\tLoss 1.1034e-01 (1.2904e-01)\tAcc@1  96.88 ( 96.64)\tAcc@5 100.00 ( 99.80)\n","Epoch: [98][180/391]\tTime  0.174 ( 0.175)\tLoss 1.4800e-01 (1.3084e-01)\tAcc@1  96.09 ( 96.53)\tAcc@5 100.00 ( 99.80)\n","Epoch: [98][210/391]\tTime  0.174 ( 0.174)\tLoss 1.0062e-01 (1.3144e-01)\tAcc@1  96.09 ( 96.56)\tAcc@5 100.00 ( 99.80)\n","Epoch: [98][240/391]\tTime  0.175 ( 0.174)\tLoss 9.2470e-02 (1.3135e-01)\tAcc@1  98.44 ( 96.55)\tAcc@5 100.00 ( 99.80)\n","Epoch: [98][270/391]\tTime  0.176 ( 0.174)\tLoss 1.3698e-01 (1.3211e-01)\tAcc@1  96.88 ( 96.52)\tAcc@5 100.00 ( 99.80)\n","Epoch: [98][300/391]\tTime  0.175 ( 0.174)\tLoss 1.8465e-01 (1.3410e-01)\tAcc@1  95.31 ( 96.42)\tAcc@5  99.22 ( 99.79)\n","Epoch: [98][330/391]\tTime  0.175 ( 0.174)\tLoss 1.4469e-01 (1.3412e-01)\tAcc@1  96.09 ( 96.42)\tAcc@5  99.22 ( 99.79)\n","Epoch: [98][360/391]\tTime  0.175 ( 0.174)\tLoss 1.8383e-01 (1.3562e-01)\tAcc@1  96.09 ( 96.38)\tAcc@5  98.44 ( 99.77)\n","Epoch: [98][390/391]\tTime  0.158 ( 0.174)\tLoss 1.2651e-01 (1.3575e-01)\tAcc@1  96.25 ( 96.38)\tAcc@5 100.00 ( 99.77)\n","==> Train Accuracy: Acc@1 96.384 || Acc@5 99.766\n","==> Test Accuracy:  Acc@1 76.420 || Acc@5 94.220\n","==> 72.44 seconds to train this epoch\n","\n","\n","----- epoch: 99, lr: 0.004000000000000001 -----\n","Epoch: [99][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.1368e-01 (1.1368e-01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [99][ 30/391]\tTime  0.174 ( 0.176)\tLoss 7.7011e-02 (1.3007e-01)\tAcc@1  97.66 ( 96.62)\tAcc@5 100.00 ( 99.85)\n","Epoch: [99][ 60/391]\tTime  0.172 ( 0.175)\tLoss 8.6125e-02 (1.3094e-01)\tAcc@1  99.22 ( 96.50)\tAcc@5 100.00 ( 99.78)\n","Epoch: [99][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.5601e-01 (1.3059e-01)\tAcc@1  95.31 ( 96.56)\tAcc@5  99.22 ( 99.76)\n","Epoch: [99][120/391]\tTime  0.178 ( 0.174)\tLoss 1.0524e-01 (1.3099e-01)\tAcc@1  96.88 ( 96.49)\tAcc@5 100.00 ( 99.76)\n","Epoch: [99][150/391]\tTime  0.172 ( 0.174)\tLoss 7.5232e-02 (1.2876e-01)\tAcc@1  98.44 ( 96.59)\tAcc@5 100.00 ( 99.78)\n","Epoch: [99][180/391]\tTime  0.173 ( 0.174)\tLoss 1.4169e-01 (1.2779e-01)\tAcc@1  96.09 ( 96.60)\tAcc@5 100.00 ( 99.78)\n","Epoch: [99][210/391]\tTime  0.174 ( 0.174)\tLoss 1.3214e-01 (1.2894e-01)\tAcc@1  93.75 ( 96.55)\tAcc@5 100.00 ( 99.79)\n","Epoch: [99][240/391]\tTime  0.171 ( 0.174)\tLoss 1.2447e-01 (1.2910e-01)\tAcc@1  96.09 ( 96.56)\tAcc@5 100.00 ( 99.78)\n","Epoch: [99][270/391]\tTime  0.176 ( 0.174)\tLoss 1.2341e-01 (1.2907e-01)\tAcc@1  95.31 ( 96.56)\tAcc@5  99.22 ( 99.78)\n","Epoch: [99][300/391]\tTime  0.177 ( 0.174)\tLoss 6.7760e-02 (1.3062e-01)\tAcc@1  99.22 ( 96.50)\tAcc@5 100.00 ( 99.77)\n","Epoch: [99][330/391]\tTime  0.175 ( 0.174)\tLoss 1.4353e-01 (1.3111e-01)\tAcc@1  97.66 ( 96.49)\tAcc@5 100.00 ( 99.77)\n","Epoch: [99][360/391]\tTime  0.175 ( 0.174)\tLoss 1.1104e-01 (1.3084e-01)\tAcc@1  97.66 ( 96.47)\tAcc@5 100.00 ( 99.77)\n","Epoch: [99][390/391]\tTime  0.156 ( 0.174)\tLoss 1.3322e-01 (1.3103e-01)\tAcc@1  96.25 ( 96.45)\tAcc@5 100.00 ( 99.77)\n","==> Train Accuracy: Acc@1 96.452 || Acc@5 99.770\n","==> Test Accuracy:  Acc@1 77.060 || Acc@5 94.390\n","==> 72.34 seconds to train this epoch\n","\n","\n","----- epoch: 100, lr: 0.004000000000000001 -----\n","Epoch: [100][  0/391]\tTime  0.299 ( 0.299)\tLoss 8.8873e-02 (8.8873e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [100][ 30/391]\tTime  0.177 ( 0.178)\tLoss 6.9088e-02 (1.2231e-01)\tAcc@1  99.22 ( 96.85)\tAcc@5 100.00 ( 99.70)\n","Epoch: [100][ 60/391]\tTime  0.173 ( 0.176)\tLoss 1.1668e-01 (1.2255e-01)\tAcc@1  97.66 ( 96.75)\tAcc@5 100.00 ( 99.73)\n","Epoch: [100][ 90/391]\tTime  0.174 ( 0.175)\tLoss 1.0503e-01 (1.2282e-01)\tAcc@1  96.09 ( 96.73)\tAcc@5  99.22 ( 99.74)\n","Epoch: [100][120/391]\tTime  0.175 ( 0.175)\tLoss 1.4762e-01 (1.2188e-01)\tAcc@1  96.09 ( 96.81)\tAcc@5  99.22 ( 99.79)\n","Epoch: [100][150/391]\tTime  0.173 ( 0.175)\tLoss 9.0497e-02 (1.2095e-01)\tAcc@1  97.66 ( 96.86)\tAcc@5 100.00 ( 99.78)\n","Epoch: [100][180/391]\tTime  0.174 ( 0.174)\tLoss 8.4691e-02 (1.2429e-01)\tAcc@1  98.44 ( 96.75)\tAcc@5 100.00 ( 99.79)\n","Epoch: [100][210/391]\tTime  0.177 ( 0.174)\tLoss 1.0896e-01 (1.2547e-01)\tAcc@1  96.09 ( 96.68)\tAcc@5 100.00 ( 99.78)\n","Epoch: [100][240/391]\tTime  0.173 ( 0.174)\tLoss 6.6991e-02 (1.2527e-01)\tAcc@1  99.22 ( 96.69)\tAcc@5 100.00 ( 99.79)\n","Epoch: [100][270/391]\tTime  0.177 ( 0.174)\tLoss 1.5993e-01 (1.2613e-01)\tAcc@1  92.97 ( 96.68)\tAcc@5 100.00 ( 99.78)\n","Epoch: [100][300/391]\tTime  0.175 ( 0.174)\tLoss 1.2144e-01 (1.2694e-01)\tAcc@1  96.88 ( 96.66)\tAcc@5 100.00 ( 99.78)\n","Epoch: [100][330/391]\tTime  0.175 ( 0.174)\tLoss 1.5861e-01 (1.2626e-01)\tAcc@1  96.88 ( 96.68)\tAcc@5 100.00 ( 99.79)\n","Epoch: [100][360/391]\tTime  0.173 ( 0.174)\tLoss 1.6657e-01 (1.2667e-01)\tAcc@1  93.75 ( 96.68)\tAcc@5 100.00 ( 99.79)\n","Epoch: [100][390/391]\tTime  0.158 ( 0.174)\tLoss 1.0141e-01 (1.2614e-01)\tAcc@1  96.25 ( 96.70)\tAcc@5 100.00 ( 99.79)\n","==> Train Accuracy: Acc@1 96.696 || Acc@5 99.788\n","==> Test Accuracy:  Acc@1 77.220 || Acc@5 94.270\n","==> 72.41 seconds to train this epoch\n","\n","\n","----- epoch: 101, lr: 0.004000000000000001 -----\n","Epoch: [101][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.8700e-01 (1.8700e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [101][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.6589e-01 (1.2073e-01)\tAcc@1  96.88 ( 96.80)\tAcc@5  99.22 ( 99.75)\n","Epoch: [101][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.2283e-01 (1.2426e-01)\tAcc@1  95.31 ( 96.84)\tAcc@5 100.00 ( 99.69)\n","Epoch: [101][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.1770e-01 (1.2408e-01)\tAcc@1  95.31 ( 96.69)\tAcc@5 100.00 ( 99.72)\n","Epoch: [101][120/391]\tTime  0.175 ( 0.175)\tLoss 8.9084e-02 (1.2153e-01)\tAcc@1  97.66 ( 96.73)\tAcc@5 100.00 ( 99.75)\n","Epoch: [101][150/391]\tTime  0.174 ( 0.174)\tLoss 1.3943e-01 (1.2382e-01)\tAcc@1  96.88 ( 96.69)\tAcc@5 100.00 ( 99.72)\n","Epoch: [101][180/391]\tTime  0.174 ( 0.174)\tLoss 1.5573e-01 (1.2485e-01)\tAcc@1  96.88 ( 96.70)\tAcc@5  98.44 ( 99.70)\n","Epoch: [101][210/391]\tTime  0.173 ( 0.174)\tLoss 1.2372e-01 (1.2521e-01)\tAcc@1  96.88 ( 96.68)\tAcc@5 100.00 ( 99.72)\n","Epoch: [101][240/391]\tTime  0.175 ( 0.174)\tLoss 1.9201e-01 (1.2464e-01)\tAcc@1  95.31 ( 96.73)\tAcc@5  99.22 ( 99.73)\n","Epoch: [101][270/391]\tTime  0.173 ( 0.174)\tLoss 1.5935e-01 (1.2544e-01)\tAcc@1  96.09 ( 96.70)\tAcc@5 100.00 ( 99.73)\n","Epoch: [101][300/391]\tTime  0.172 ( 0.174)\tLoss 1.0347e-01 (1.2584e-01)\tAcc@1  96.88 ( 96.68)\tAcc@5 100.00 ( 99.74)\n","Epoch: [101][330/391]\tTime  0.172 ( 0.174)\tLoss 9.6427e-02 (1.2554e-01)\tAcc@1  97.66 ( 96.69)\tAcc@5 100.00 ( 99.75)\n","Epoch: [101][360/391]\tTime  0.175 ( 0.174)\tLoss 9.1154e-02 (1.2515e-01)\tAcc@1  97.66 ( 96.71)\tAcc@5 100.00 ( 99.76)\n","Epoch: [101][390/391]\tTime  0.156 ( 0.174)\tLoss 6.7271e-02 (1.2539e-01)\tAcc@1 100.00 ( 96.71)\tAcc@5 100.00 ( 99.76)\n","==> Train Accuracy: Acc@1 96.714 || Acc@5 99.758\n","==> Test Accuracy:  Acc@1 76.720 || Acc@5 94.210\n","==> 72.38 seconds to train this epoch\n","\n","\n","----- epoch: 102, lr: 0.004000000000000001 -----\n","Epoch: [102][  0/391]\tTime  0.276 ( 0.276)\tLoss 7.5688e-02 (7.5688e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [102][ 30/391]\tTime  0.177 ( 0.177)\tLoss 1.5922e-01 (1.1306e-01)\tAcc@1  97.66 ( 97.05)\tAcc@5 100.00 ( 99.85)\n","Epoch: [102][ 60/391]\tTime  0.174 ( 0.175)\tLoss 9.7349e-02 (1.1610e-01)\tAcc@1  95.31 ( 96.76)\tAcc@5 100.00 ( 99.81)\n","Epoch: [102][ 90/391]\tTime  0.173 ( 0.175)\tLoss 1.0227e-01 (1.1260e-01)\tAcc@1  97.66 ( 96.96)\tAcc@5 100.00 ( 99.84)\n","Epoch: [102][120/391]\tTime  0.174 ( 0.175)\tLoss 6.7951e-02 (1.1261e-01)\tAcc@1  97.66 ( 96.91)\tAcc@5 100.00 ( 99.85)\n","Epoch: [102][150/391]\tTime  0.174 ( 0.175)\tLoss 9.5493e-02 (1.1245e-01)\tAcc@1  97.66 ( 96.96)\tAcc@5 100.00 ( 99.84)\n","Epoch: [102][180/391]\tTime  0.173 ( 0.175)\tLoss 8.6178e-02 (1.1316e-01)\tAcc@1  96.88 ( 96.95)\tAcc@5 100.00 ( 99.85)\n","Epoch: [102][210/391]\tTime  0.173 ( 0.174)\tLoss 9.9418e-02 (1.1499e-01)\tAcc@1  98.44 ( 96.91)\tAcc@5 100.00 ( 99.84)\n","Epoch: [102][240/391]\tTime  0.174 ( 0.174)\tLoss 9.7018e-02 (1.1422e-01)\tAcc@1  98.44 ( 96.94)\tAcc@5 100.00 ( 99.86)\n","Epoch: [102][270/391]\tTime  0.175 ( 0.174)\tLoss 1.1103e-01 (1.1442e-01)\tAcc@1  96.88 ( 96.93)\tAcc@5 100.00 ( 99.87)\n","Epoch: [102][300/391]\tTime  0.174 ( 0.174)\tLoss 8.9314e-02 (1.1614e-01)\tAcc@1  99.22 ( 96.83)\tAcc@5  99.22 ( 99.87)\n","Epoch: [102][330/391]\tTime  0.176 ( 0.174)\tLoss 1.7961e-01 (1.1712e-01)\tAcc@1  93.75 ( 96.82)\tAcc@5 100.00 ( 99.87)\n","Epoch: [102][360/391]\tTime  0.175 ( 0.174)\tLoss 1.3293e-01 (1.1866e-01)\tAcc@1  96.88 ( 96.78)\tAcc@5 100.00 ( 99.87)\n","Epoch: [102][390/391]\tTime  0.157 ( 0.174)\tLoss 9.5238e-02 (1.1901e-01)\tAcc@1  97.50 ( 96.77)\tAcc@5 100.00 ( 99.87)\n","==> Train Accuracy: Acc@1 96.770 || Acc@5 99.870\n","==> Test Accuracy:  Acc@1 76.880 || Acc@5 94.240\n","==> 72.44 seconds to train this epoch\n","\n","\n","----- epoch: 103, lr: 0.004000000000000001 -----\n","Epoch: [103][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.0971e-01 (1.0971e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [103][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.3090e-01 (1.2784e-01)\tAcc@1  96.09 ( 96.40)\tAcc@5 100.00 ( 99.80)\n","Epoch: [103][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.4762e-01 (1.2469e-01)\tAcc@1  95.31 ( 96.62)\tAcc@5 100.00 ( 99.83)\n","Epoch: [103][ 90/391]\tTime  0.172 ( 0.175)\tLoss 9.4678e-02 (1.1737e-01)\tAcc@1  97.66 ( 96.83)\tAcc@5 100.00 ( 99.84)\n","Epoch: [103][120/391]\tTime  0.172 ( 0.175)\tLoss 7.1433e-02 (1.1826e-01)\tAcc@1  98.44 ( 96.87)\tAcc@5 100.00 ( 99.84)\n","Epoch: [103][150/391]\tTime  0.171 ( 0.175)\tLoss 1.4402e-01 (1.1870e-01)\tAcc@1  96.09 ( 96.82)\tAcc@5  99.22 ( 99.83)\n","Epoch: [103][180/391]\tTime  0.171 ( 0.174)\tLoss 6.4237e-02 (1.1809e-01)\tAcc@1  97.66 ( 96.85)\tAcc@5 100.00 ( 99.82)\n","Epoch: [103][210/391]\tTime  0.175 ( 0.174)\tLoss 1.2312e-01 (1.1661e-01)\tAcc@1  97.66 ( 96.93)\tAcc@5 100.00 ( 99.83)\n","Epoch: [103][240/391]\tTime  0.171 ( 0.174)\tLoss 1.1964e-01 (1.1574e-01)\tAcc@1  96.88 ( 96.95)\tAcc@5 100.00 ( 99.83)\n","Epoch: [103][270/391]\tTime  0.173 ( 0.174)\tLoss 1.1507e-01 (1.1587e-01)\tAcc@1  96.09 ( 96.94)\tAcc@5 100.00 ( 99.83)\n","Epoch: [103][300/391]\tTime  0.173 ( 0.174)\tLoss 1.5044e-01 (1.1653e-01)\tAcc@1  96.09 ( 96.91)\tAcc@5  99.22 ( 99.82)\n","Epoch: [103][330/391]\tTime  0.173 ( 0.174)\tLoss 1.0075e-01 (1.1599e-01)\tAcc@1  98.44 ( 96.94)\tAcc@5 100.00 ( 99.83)\n","Epoch: [103][360/391]\tTime  0.172 ( 0.174)\tLoss 1.0532e-01 (1.1709e-01)\tAcc@1  96.09 ( 96.90)\tAcc@5 100.00 ( 99.82)\n","Epoch: [103][390/391]\tTime  0.157 ( 0.174)\tLoss 1.0593e-01 (1.1680e-01)\tAcc@1  95.00 ( 96.89)\tAcc@5 100.00 ( 99.82)\n","==> Train Accuracy: Acc@1 96.894 || Acc@5 99.816\n","==> Test Accuracy:  Acc@1 76.870 || Acc@5 93.960\n","==> 72.42 seconds to train this epoch\n","\n","\n","----- epoch: 104, lr: 0.004000000000000001 -----\n","Epoch: [104][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.3617e-01 (1.3617e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n","Epoch: [104][ 30/391]\tTime  0.176 ( 0.177)\tLoss 9.1448e-02 (1.0907e-01)\tAcc@1  97.66 ( 97.23)\tAcc@5 100.00 ( 99.82)\n","Epoch: [104][ 60/391]\tTime  0.176 ( 0.175)\tLoss 1.5915e-01 (1.1630e-01)\tAcc@1  94.53 ( 97.00)\tAcc@5  99.22 ( 99.78)\n","Epoch: [104][ 90/391]\tTime  0.175 ( 0.175)\tLoss 1.0808e-01 (1.1382e-01)\tAcc@1  95.31 ( 96.94)\tAcc@5 100.00 ( 99.79)\n","Epoch: [104][120/391]\tTime  0.172 ( 0.175)\tLoss 8.8524e-02 (1.1260e-01)\tAcc@1  99.22 ( 97.04)\tAcc@5 100.00 ( 99.79)\n","Epoch: [104][150/391]\tTime  0.174 ( 0.174)\tLoss 1.5811e-01 (1.1262e-01)\tAcc@1  94.53 ( 97.02)\tAcc@5 100.00 ( 99.80)\n","Epoch: [104][180/391]\tTime  0.173 ( 0.174)\tLoss 1.5598e-01 (1.1186e-01)\tAcc@1  96.09 ( 97.04)\tAcc@5  98.44 ( 99.80)\n","Epoch: [104][210/391]\tTime  0.173 ( 0.174)\tLoss 1.0978e-01 (1.1079e-01)\tAcc@1  97.66 ( 97.06)\tAcc@5 100.00 ( 99.81)\n","Epoch: [104][240/391]\tTime  0.173 ( 0.174)\tLoss 7.1823e-02 (1.1073e-01)\tAcc@1  99.22 ( 97.06)\tAcc@5 100.00 ( 99.82)\n","Epoch: [104][270/391]\tTime  0.174 ( 0.174)\tLoss 1.3598e-01 (1.1073e-01)\tAcc@1  97.66 ( 97.06)\tAcc@5  99.22 ( 99.82)\n","Epoch: [104][300/391]\tTime  0.175 ( 0.174)\tLoss 1.7702e-01 (1.1136e-01)\tAcc@1  96.09 ( 97.04)\tAcc@5 100.00 ( 99.81)\n","Epoch: [104][330/391]\tTime  0.176 ( 0.174)\tLoss 8.1878e-02 (1.1105e-01)\tAcc@1  99.22 ( 97.05)\tAcc@5 100.00 ( 99.82)\n","Epoch: [104][360/391]\tTime  0.175 ( 0.174)\tLoss 1.2153e-01 (1.1201e-01)\tAcc@1  96.09 ( 97.06)\tAcc@5  99.22 ( 99.81)\n","Epoch: [104][390/391]\tTime  0.156 ( 0.174)\tLoss 1.5022e-01 (1.1244e-01)\tAcc@1  96.25 ( 97.04)\tAcc@5 100.00 ( 99.80)\n","==> Train Accuracy: Acc@1 97.038 || Acc@5 99.802\n","==> Test Accuracy:  Acc@1 76.770 || Acc@5 94.070\n","==> 72.39 seconds to train this epoch\n","\n","\n","----- epoch: 105, lr: 0.004000000000000001 -----\n","Epoch: [105][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.0056e-01 (1.0056e-01)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [105][ 30/391]\tTime  0.174 ( 0.176)\tLoss 8.6719e-02 (1.0809e-01)\tAcc@1  98.44 ( 97.05)\tAcc@5 100.00 ( 99.90)\n","Epoch: [105][ 60/391]\tTime  0.170 ( 0.175)\tLoss 7.3882e-02 (1.0778e-01)\tAcc@1  97.66 ( 97.04)\tAcc@5 100.00 ( 99.91)\n","Epoch: [105][ 90/391]\tTime  0.176 ( 0.174)\tLoss 5.8115e-02 (1.0456e-01)\tAcc@1  99.22 ( 97.21)\tAcc@5 100.00 ( 99.87)\n","Epoch: [105][120/391]\tTime  0.174 ( 0.174)\tLoss 7.1783e-02 (1.0642e-01)\tAcc@1  97.66 ( 97.17)\tAcc@5 100.00 ( 99.85)\n","Epoch: [105][150/391]\tTime  0.173 ( 0.174)\tLoss 1.6182e-01 (1.0599e-01)\tAcc@1  96.09 ( 97.21)\tAcc@5  99.22 ( 99.84)\n","Epoch: [105][180/391]\tTime  0.172 ( 0.174)\tLoss 1.3671e-01 (1.0868e-01)\tAcc@1  96.09 ( 97.16)\tAcc@5 100.00 ( 99.82)\n","Epoch: [105][210/391]\tTime  0.175 ( 0.174)\tLoss 1.2387e-01 (1.0850e-01)\tAcc@1  97.66 ( 97.17)\tAcc@5 100.00 ( 99.82)\n","Epoch: [105][240/391]\tTime  0.173 ( 0.174)\tLoss 1.2557e-01 (1.0931e-01)\tAcc@1  96.09 ( 97.12)\tAcc@5 100.00 ( 99.84)\n","Epoch: [105][270/391]\tTime  0.173 ( 0.174)\tLoss 9.3637e-02 (1.1015e-01)\tAcc@1  96.09 ( 97.09)\tAcc@5 100.00 ( 99.84)\n","Epoch: [105][300/391]\tTime  0.174 ( 0.174)\tLoss 1.3615e-01 (1.1011e-01)\tAcc@1  95.31 ( 97.10)\tAcc@5  99.22 ( 99.83)\n","Epoch: [105][330/391]\tTime  0.173 ( 0.174)\tLoss 1.3974e-01 (1.0935e-01)\tAcc@1  96.09 ( 97.13)\tAcc@5  99.22 ( 99.84)\n","Epoch: [105][360/391]\tTime  0.175 ( 0.174)\tLoss 1.0048e-01 (1.0941e-01)\tAcc@1  98.44 ( 97.12)\tAcc@5 100.00 ( 99.84)\n","Epoch: [105][390/391]\tTime  0.157 ( 0.174)\tLoss 7.4550e-02 (1.1017e-01)\tAcc@1  97.50 ( 97.11)\tAcc@5 100.00 ( 99.83)\n","==> Train Accuracy: Acc@1 97.110 || Acc@5 99.830\n","==> Test Accuracy:  Acc@1 76.940 || Acc@5 94.000\n","==> 72.25 seconds to train this epoch\n","\n","\n","----- epoch: 106, lr: 0.004000000000000001 -----\n","Epoch: [106][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.1669e-01 (1.1669e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [106][ 30/391]\tTime  0.174 ( 0.176)\tLoss 2.0466e-01 (1.0507e-01)\tAcc@1  93.75 ( 97.15)\tAcc@5 100.00 ( 99.87)\n","Epoch: [106][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.0443e-01 (1.0516e-01)\tAcc@1  96.88 ( 97.11)\tAcc@5 100.00 ( 99.88)\n","Epoch: [106][ 90/391]\tTime  0.175 ( 0.174)\tLoss 1.5474e-01 (1.0504e-01)\tAcc@1  96.88 ( 97.16)\tAcc@5  99.22 ( 99.85)\n","Epoch: [106][120/391]\tTime  0.172 ( 0.174)\tLoss 9.1444e-02 (1.0474e-01)\tAcc@1  96.88 ( 97.20)\tAcc@5 100.00 ( 99.85)\n","Epoch: [106][150/391]\tTime  0.175 ( 0.174)\tLoss 9.2192e-02 (1.0116e-01)\tAcc@1  96.88 ( 97.35)\tAcc@5 100.00 ( 99.87)\n","Epoch: [106][180/391]\tTime  0.176 ( 0.174)\tLoss 7.5565e-02 (1.0252e-01)\tAcc@1  96.88 ( 97.28)\tAcc@5 100.00 ( 99.87)\n","Epoch: [106][210/391]\tTime  0.174 ( 0.174)\tLoss 1.1589e-01 (1.0203e-01)\tAcc@1  96.09 ( 97.31)\tAcc@5 100.00 ( 99.87)\n","Epoch: [106][240/391]\tTime  0.172 ( 0.174)\tLoss 8.7699e-02 (1.0250e-01)\tAcc@1  98.44 ( 97.28)\tAcc@5 100.00 ( 99.86)\n","Epoch: [106][270/391]\tTime  0.174 ( 0.174)\tLoss 5.9759e-02 (1.0243e-01)\tAcc@1  98.44 ( 97.30)\tAcc@5 100.00 ( 99.86)\n","Epoch: [106][300/391]\tTime  0.174 ( 0.174)\tLoss 1.0836e-01 (1.0305e-01)\tAcc@1  96.09 ( 97.29)\tAcc@5 100.00 ( 99.85)\n","Epoch: [106][330/391]\tTime  0.173 ( 0.174)\tLoss 1.0031e-01 (1.0394e-01)\tAcc@1  96.88 ( 97.26)\tAcc@5 100.00 ( 99.86)\n","Epoch: [106][360/391]\tTime  0.178 ( 0.174)\tLoss 7.4906e-02 (1.0452e-01)\tAcc@1  99.22 ( 97.26)\tAcc@5 100.00 ( 99.86)\n","Epoch: [106][390/391]\tTime  0.158 ( 0.174)\tLoss 1.4165e-01 (1.0598e-01)\tAcc@1  97.50 ( 97.19)\tAcc@5 100.00 ( 99.86)\n","==> Train Accuracy: Acc@1 97.194 || Acc@5 99.856\n","==> Test Accuracy:  Acc@1 76.500 || Acc@5 94.020\n","==> 72.19 seconds to train this epoch\n","\n","\n","----- epoch: 107, lr: 0.004000000000000001 -----\n","Epoch: [107][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.0146e-01 (1.0146e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [107][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.1638e-01 (9.4692e-02)\tAcc@1  96.88 ( 97.66)\tAcc@5 100.00 ( 99.90)\n","Epoch: [107][ 60/391]\tTime  0.173 ( 0.175)\tLoss 8.0749e-02 (1.0045e-01)\tAcc@1  96.88 ( 97.35)\tAcc@5 100.00 ( 99.81)\n","Epoch: [107][ 90/391]\tTime  0.175 ( 0.175)\tLoss 6.0651e-02 (9.9311e-02)\tAcc@1  99.22 ( 97.48)\tAcc@5 100.00 ( 99.80)\n","Epoch: [107][120/391]\tTime  0.174 ( 0.174)\tLoss 3.9853e-02 (9.9578e-02)\tAcc@1 100.00 ( 97.51)\tAcc@5 100.00 ( 99.81)\n","Epoch: [107][150/391]\tTime  0.174 ( 0.174)\tLoss 5.6804e-02 (9.8465e-02)\tAcc@1  99.22 ( 97.57)\tAcc@5 100.00 ( 99.81)\n","Epoch: [107][180/391]\tTime  0.173 ( 0.174)\tLoss 1.1621e-01 (9.8825e-02)\tAcc@1  97.66 ( 97.51)\tAcc@5 100.00 ( 99.83)\n","Epoch: [107][210/391]\tTime  0.173 ( 0.174)\tLoss 1.4915e-01 (9.9342e-02)\tAcc@1  96.88 ( 97.47)\tAcc@5 100.00 ( 99.84)\n","Epoch: [107][240/391]\tTime  0.173 ( 0.174)\tLoss 1.0798e-01 (1.0057e-01)\tAcc@1  97.66 ( 97.42)\tAcc@5 100.00 ( 99.84)\n","Epoch: [107][270/391]\tTime  0.174 ( 0.174)\tLoss 1.1082e-01 (1.0246e-01)\tAcc@1  96.88 ( 97.38)\tAcc@5 100.00 ( 99.83)\n","Epoch: [107][300/391]\tTime  0.170 ( 0.174)\tLoss 5.5379e-02 (1.0319e-01)\tAcc@1  99.22 ( 97.35)\tAcc@5 100.00 ( 99.84)\n","Epoch: [107][330/391]\tTime  0.174 ( 0.174)\tLoss 6.4011e-02 (1.0379e-01)\tAcc@1  98.44 ( 97.34)\tAcc@5 100.00 ( 99.84)\n","Epoch: [107][360/391]\tTime  0.174 ( 0.174)\tLoss 8.3449e-02 (1.0433e-01)\tAcc@1  96.88 ( 97.32)\tAcc@5 100.00 ( 99.84)\n","Epoch: [107][390/391]\tTime  0.158 ( 0.174)\tLoss 1.1194e-01 (1.0441e-01)\tAcc@1  95.00 ( 97.29)\tAcc@5 100.00 ( 99.84)\n","==> Train Accuracy: Acc@1 97.294 || Acc@5 99.840\n","==> Test Accuracy:  Acc@1 77.220 || Acc@5 94.210\n","==> 72.22 seconds to train this epoch\n","\n","\n","----- epoch: 108, lr: 0.004000000000000001 -----\n","Epoch: [108][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.2054e-01 (1.2054e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [108][ 30/391]\tTime  0.172 ( 0.176)\tLoss 7.7082e-02 (1.1124e-01)\tAcc@1  99.22 ( 97.05)\tAcc@5 100.00 ( 99.85)\n","Epoch: [108][ 60/391]\tTime  0.171 ( 0.175)\tLoss 8.5879e-02 (1.0751e-01)\tAcc@1  97.66 ( 97.17)\tAcc@5  99.22 ( 99.80)\n","Epoch: [108][ 90/391]\tTime  0.172 ( 0.174)\tLoss 1.3580e-01 (1.0257e-01)\tAcc@1  96.88 ( 97.31)\tAcc@5 100.00 ( 99.83)\n","Epoch: [108][120/391]\tTime  0.174 ( 0.174)\tLoss 7.8141e-02 (1.0189e-01)\tAcc@1  98.44 ( 97.37)\tAcc@5 100.00 ( 99.81)\n","Epoch: [108][150/391]\tTime  0.172 ( 0.174)\tLoss 1.0578e-01 (9.8162e-02)\tAcc@1  96.88 ( 97.51)\tAcc@5 100.00 ( 99.84)\n","Epoch: [108][180/391]\tTime  0.175 ( 0.174)\tLoss 7.0979e-02 (9.8844e-02)\tAcc@1  97.66 ( 97.50)\tAcc@5 100.00 ( 99.84)\n","Epoch: [108][210/391]\tTime  0.173 ( 0.174)\tLoss 7.2738e-02 (9.8021e-02)\tAcc@1  98.44 ( 97.55)\tAcc@5 100.00 ( 99.84)\n","Epoch: [108][240/391]\tTime  0.174 ( 0.174)\tLoss 7.1857e-02 (9.9109e-02)\tAcc@1  98.44 ( 97.50)\tAcc@5 100.00 ( 99.85)\n","Epoch: [108][270/391]\tTime  0.173 ( 0.174)\tLoss 9.4614e-02 (9.8972e-02)\tAcc@1  96.88 ( 97.51)\tAcc@5 100.00 ( 99.84)\n","Epoch: [108][300/391]\tTime  0.174 ( 0.174)\tLoss 1.1595e-01 (9.9486e-02)\tAcc@1  96.88 ( 97.46)\tAcc@5 100.00 ( 99.85)\n","Epoch: [108][330/391]\tTime  0.175 ( 0.174)\tLoss 1.0507e-01 (1.0003e-01)\tAcc@1  97.66 ( 97.45)\tAcc@5 100.00 ( 99.85)\n","Epoch: [108][360/391]\tTime  0.174 ( 0.174)\tLoss 8.7440e-02 (1.0109e-01)\tAcc@1  96.88 ( 97.41)\tAcc@5 100.00 ( 99.84)\n","Epoch: [108][390/391]\tTime  0.155 ( 0.174)\tLoss 2.0358e-01 (1.0170e-01)\tAcc@1  93.75 ( 97.38)\tAcc@5  97.50 ( 99.83)\n","==> Train Accuracy: Acc@1 97.376 || Acc@5 99.832\n","==> Test Accuracy:  Acc@1 76.730 || Acc@5 93.840\n","==> 72.14 seconds to train this epoch\n","\n","\n","----- epoch: 109, lr: 0.004000000000000001 -----\n","Epoch: [109][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.1388e-01 (1.1388e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [109][ 30/391]\tTime  0.172 ( 0.176)\tLoss 8.0642e-02 (9.8694e-02)\tAcc@1  99.22 ( 97.56)\tAcc@5 100.00 ( 99.85)\n","Epoch: [109][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.4054e-01 (1.0228e-01)\tAcc@1  96.09 ( 97.39)\tAcc@5 100.00 ( 99.85)\n","Epoch: [109][ 90/391]\tTime  0.171 ( 0.174)\tLoss 1.3012e-01 (1.0132e-01)\tAcc@1  96.09 ( 97.42)\tAcc@5 100.00 ( 99.83)\n","Epoch: [109][120/391]\tTime  0.172 ( 0.174)\tLoss 8.6626e-02 (9.9461e-02)\tAcc@1  96.09 ( 97.48)\tAcc@5 100.00 ( 99.86)\n","Epoch: [109][150/391]\tTime  0.174 ( 0.174)\tLoss 7.5408e-02 (1.0018e-01)\tAcc@1  97.66 ( 97.44)\tAcc@5 100.00 ( 99.87)\n","Epoch: [109][180/391]\tTime  0.175 ( 0.174)\tLoss 8.5091e-02 (9.9982e-02)\tAcc@1  97.66 ( 97.47)\tAcc@5 100.00 ( 99.87)\n","Epoch: [109][210/391]\tTime  0.174 ( 0.174)\tLoss 9.1665e-02 (1.0109e-01)\tAcc@1  97.66 ( 97.41)\tAcc@5 100.00 ( 99.86)\n","Epoch: [109][240/391]\tTime  0.174 ( 0.174)\tLoss 1.6153e-01 (1.0159e-01)\tAcc@1  93.75 ( 97.40)\tAcc@5 100.00 ( 99.85)\n","Epoch: [109][270/391]\tTime  0.173 ( 0.174)\tLoss 4.1542e-02 (1.0170e-01)\tAcc@1  99.22 ( 97.41)\tAcc@5 100.00 ( 99.85)\n","Epoch: [109][300/391]\tTime  0.171 ( 0.174)\tLoss 1.1344e-01 (1.0230e-01)\tAcc@1  96.09 ( 97.38)\tAcc@5 100.00 ( 99.84)\n","Epoch: [109][330/391]\tTime  0.173 ( 0.174)\tLoss 7.4821e-02 (1.0231e-01)\tAcc@1  97.66 ( 97.37)\tAcc@5 100.00 ( 99.85)\n","Epoch: [109][360/391]\tTime  0.176 ( 0.174)\tLoss 5.7352e-02 (1.0339e-01)\tAcc@1  98.44 ( 97.34)\tAcc@5 100.00 ( 99.84)\n","Epoch: [109][390/391]\tTime  0.157 ( 0.174)\tLoss 1.3771e-01 (1.0344e-01)\tAcc@1  96.25 ( 97.35)\tAcc@5  98.75 ( 99.83)\n","==> Train Accuracy: Acc@1 97.346 || Acc@5 99.834\n","==> Test Accuracy:  Acc@1 77.000 || Acc@5 93.980\n","==> 72.15 seconds to train this epoch\n","\n","\n","----- epoch: 110, lr: 0.004000000000000001 -----\n","Epoch: [110][  0/391]\tTime  0.267 ( 0.267)\tLoss 7.6749e-02 (7.6749e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [110][ 30/391]\tTime  0.173 ( 0.176)\tLoss 1.0526e-01 (9.7218e-02)\tAcc@1  96.88 ( 97.63)\tAcc@5 100.00 ( 99.90)\n","Epoch: [110][ 60/391]\tTime  0.174 ( 0.175)\tLoss 7.9910e-02 (9.8005e-02)\tAcc@1  98.44 ( 97.49)\tAcc@5 100.00 ( 99.90)\n","Epoch: [110][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.2710e-01 (9.8239e-02)\tAcc@1  95.31 ( 97.49)\tAcc@5 100.00 ( 99.87)\n","Epoch: [110][120/391]\tTime  0.174 ( 0.174)\tLoss 9.6407e-02 (9.9470e-02)\tAcc@1  96.09 ( 97.41)\tAcc@5 100.00 ( 99.87)\n","Epoch: [110][150/391]\tTime  0.171 ( 0.174)\tLoss 9.2858e-02 (1.0098e-01)\tAcc@1  97.66 ( 97.36)\tAcc@5 100.00 ( 99.88)\n","Epoch: [110][180/391]\tTime  0.173 ( 0.174)\tLoss 7.9836e-02 (1.0021e-01)\tAcc@1  96.88 ( 97.41)\tAcc@5 100.00 ( 99.87)\n","Epoch: [110][210/391]\tTime  0.174 ( 0.174)\tLoss 9.1528e-02 (1.0197e-01)\tAcc@1  96.88 ( 97.30)\tAcc@5 100.00 ( 99.86)\n","Epoch: [110][240/391]\tTime  0.174 ( 0.174)\tLoss 8.7717e-02 (1.0222e-01)\tAcc@1  99.22 ( 97.33)\tAcc@5 100.00 ( 99.85)\n","Epoch: [110][270/391]\tTime  0.175 ( 0.174)\tLoss 1.6144e-01 (1.0329e-01)\tAcc@1  96.09 ( 97.30)\tAcc@5 100.00 ( 99.85)\n","Epoch: [110][300/391]\tTime  0.174 ( 0.174)\tLoss 9.3600e-02 (1.0281e-01)\tAcc@1  97.66 ( 97.33)\tAcc@5 100.00 ( 99.84)\n","Epoch: [110][330/391]\tTime  0.172 ( 0.174)\tLoss 1.7023e-01 (1.0345e-01)\tAcc@1  94.53 ( 97.30)\tAcc@5  99.22 ( 99.84)\n","Epoch: [110][360/391]\tTime  0.175 ( 0.174)\tLoss 6.5968e-02 (1.0349e-01)\tAcc@1  98.44 ( 97.31)\tAcc@5 100.00 ( 99.84)\n","Epoch: [110][390/391]\tTime  0.151 ( 0.174)\tLoss 1.0991e-01 (1.0284e-01)\tAcc@1  96.25 ( 97.32)\tAcc@5 100.00 ( 99.84)\n","==> Train Accuracy: Acc@1 97.320 || Acc@5 99.840\n","==> Test Accuracy:  Acc@1 76.670 || Acc@5 94.010\n","==> 72.18 seconds to train this epoch\n","\n","\n","----- epoch: 111, lr: 0.004000000000000001 -----\n","Epoch: [111][  0/391]\tTime  0.269 ( 0.269)\tLoss 8.8383e-02 (8.8383e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [111][ 30/391]\tTime  0.173 ( 0.176)\tLoss 5.6498e-02 (9.3963e-02)\tAcc@1  99.22 ( 97.33)\tAcc@5 100.00 ( 99.87)\n","Epoch: [111][ 60/391]\tTime  0.172 ( 0.175)\tLoss 6.0932e-02 (9.3698e-02)\tAcc@1  99.22 ( 97.52)\tAcc@5 100.00 ( 99.87)\n","Epoch: [111][ 90/391]\tTime  0.175 ( 0.174)\tLoss 7.3891e-02 (9.3559e-02)\tAcc@1  98.44 ( 97.55)\tAcc@5 100.00 ( 99.89)\n","Epoch: [111][120/391]\tTime  0.173 ( 0.174)\tLoss 4.9080e-02 (9.6260e-02)\tAcc@1 100.00 ( 97.54)\tAcc@5 100.00 ( 99.84)\n","Epoch: [111][150/391]\tTime  0.173 ( 0.174)\tLoss 1.1362e-01 (9.5757e-02)\tAcc@1  95.31 ( 97.52)\tAcc@5 100.00 ( 99.86)\n","Epoch: [111][180/391]\tTime  0.172 ( 0.174)\tLoss 3.9844e-02 (9.5707e-02)\tAcc@1 100.00 ( 97.55)\tAcc@5 100.00 ( 99.85)\n","Epoch: [111][210/391]\tTime  0.173 ( 0.174)\tLoss 1.0647e-01 (9.6853e-02)\tAcc@1  95.31 ( 97.49)\tAcc@5 100.00 ( 99.83)\n","Epoch: [111][240/391]\tTime  0.173 ( 0.174)\tLoss 1.1365e-01 (9.6631e-02)\tAcc@1  96.88 ( 97.48)\tAcc@5 100.00 ( 99.84)\n","Epoch: [111][270/391]\tTime  0.174 ( 0.174)\tLoss 1.1762e-01 (9.6833e-02)\tAcc@1  96.09 ( 97.50)\tAcc@5 100.00 ( 99.85)\n","Epoch: [111][300/391]\tTime  0.175 ( 0.174)\tLoss 9.6739e-02 (9.7901e-02)\tAcc@1  96.88 ( 97.47)\tAcc@5 100.00 ( 99.85)\n","Epoch: [111][330/391]\tTime  0.176 ( 0.174)\tLoss 8.0384e-02 (9.8327e-02)\tAcc@1  96.88 ( 97.45)\tAcc@5 100.00 ( 99.85)\n","Epoch: [111][360/391]\tTime  0.172 ( 0.174)\tLoss 7.9904e-02 (9.8841e-02)\tAcc@1  98.44 ( 97.43)\tAcc@5  99.22 ( 99.84)\n","Epoch: [111][390/391]\tTime  0.155 ( 0.174)\tLoss 1.2186e-01 (9.8908e-02)\tAcc@1  97.50 ( 97.43)\tAcc@5 100.00 ( 99.85)\n","==> Train Accuracy: Acc@1 97.434 || Acc@5 99.848\n","==> Test Accuracy:  Acc@1 76.720 || Acc@5 93.910\n","==> 72.16 seconds to train this epoch\n","\n","\n","----- epoch: 112, lr: 0.004000000000000001 -----\n","Epoch: [112][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.3512e-01 (1.3512e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [112][ 30/391]\tTime  0.172 ( 0.176)\tLoss 1.0933e-01 (1.0036e-01)\tAcc@1  98.44 ( 97.56)\tAcc@5 100.00 ( 99.82)\n","Epoch: [112][ 60/391]\tTime  0.174 ( 0.175)\tLoss 1.0820e-01 (9.9546e-02)\tAcc@1  95.31 ( 97.41)\tAcc@5 100.00 ( 99.82)\n","Epoch: [112][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.3306e-01 (9.7741e-02)\tAcc@1  96.88 ( 97.49)\tAcc@5 100.00 ( 99.81)\n","Epoch: [112][120/391]\tTime  0.172 ( 0.174)\tLoss 1.0591e-01 (9.6880e-02)\tAcc@1  97.66 ( 97.51)\tAcc@5 100.00 ( 99.83)\n","Epoch: [112][150/391]\tTime  0.173 ( 0.174)\tLoss 8.9991e-02 (9.7504e-02)\tAcc@1  96.88 ( 97.56)\tAcc@5 100.00 ( 99.83)\n","Epoch: [112][180/391]\tTime  0.173 ( 0.174)\tLoss 7.0491e-02 (9.8729e-02)\tAcc@1  98.44 ( 97.50)\tAcc@5 100.00 ( 99.82)\n","Epoch: [112][210/391]\tTime  0.172 ( 0.174)\tLoss 8.7224e-02 (9.8156e-02)\tAcc@1  97.66 ( 97.52)\tAcc@5 100.00 ( 99.84)\n","Epoch: [112][240/391]\tTime  0.175 ( 0.174)\tLoss 5.6722e-02 (9.7827e-02)\tAcc@1  98.44 ( 97.52)\tAcc@5 100.00 ( 99.85)\n","Epoch: [112][270/391]\tTime  0.171 ( 0.174)\tLoss 1.7946e-01 (9.9147e-02)\tAcc@1  94.53 ( 97.48)\tAcc@5  99.22 ( 99.85)\n","Epoch: [112][300/391]\tTime  0.175 ( 0.174)\tLoss 1.2951e-01 (1.0068e-01)\tAcc@1  95.31 ( 97.41)\tAcc@5 100.00 ( 99.85)\n","Epoch: [112][330/391]\tTime  0.173 ( 0.174)\tLoss 1.4568e-01 (1.0048e-01)\tAcc@1  95.31 ( 97.42)\tAcc@5  99.22 ( 99.85)\n","Epoch: [112][360/391]\tTime  0.171 ( 0.174)\tLoss 7.5126e-02 (1.0012e-01)\tAcc@1  97.66 ( 97.44)\tAcc@5 100.00 ( 99.84)\n","Epoch: [112][390/391]\tTime  0.157 ( 0.174)\tLoss 6.6209e-02 (1.0077e-01)\tAcc@1  97.50 ( 97.41)\tAcc@5 100.00 ( 99.85)\n","==> Train Accuracy: Acc@1 97.410 || Acc@5 99.848\n","==> Test Accuracy:  Acc@1 76.630 || Acc@5 93.930\n","==> 72.16 seconds to train this epoch\n","\n","\n","----- epoch: 113, lr: 0.004000000000000001 -----\n","Epoch: [113][  0/391]\tTime  0.251 ( 0.251)\tLoss 8.8385e-02 (8.8385e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [113][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.0412e-01 (1.1332e-01)\tAcc@1  96.09 ( 96.75)\tAcc@5 100.00 ( 99.92)\n","Epoch: [113][ 60/391]\tTime  0.174 ( 0.174)\tLoss 6.7607e-02 (1.0662e-01)\tAcc@1  99.22 ( 97.30)\tAcc@5 100.00 ( 99.92)\n","Epoch: [113][ 90/391]\tTime  0.170 ( 0.174)\tLoss 9.6810e-02 (1.0088e-01)\tAcc@1  98.44 ( 97.40)\tAcc@5 100.00 ( 99.93)\n","Epoch: [113][120/391]\tTime  0.174 ( 0.174)\tLoss 5.8495e-02 (9.8909e-02)\tAcc@1  99.22 ( 97.44)\tAcc@5 100.00 ( 99.93)\n","Epoch: [113][150/391]\tTime  0.172 ( 0.174)\tLoss 7.0941e-02 (9.7593e-02)\tAcc@1  99.22 ( 97.49)\tAcc@5 100.00 ( 99.91)\n","Epoch: [113][180/391]\tTime  0.175 ( 0.174)\tLoss 6.2388e-02 (9.7296e-02)\tAcc@1  99.22 ( 97.51)\tAcc@5 100.00 ( 99.89)\n","Epoch: [113][210/391]\tTime  0.174 ( 0.174)\tLoss 8.0661e-02 (9.7142e-02)\tAcc@1  99.22 ( 97.51)\tAcc@5 100.00 ( 99.90)\n","Epoch: [113][240/391]\tTime  0.175 ( 0.174)\tLoss 7.5535e-02 (9.7229e-02)\tAcc@1  97.66 ( 97.47)\tAcc@5 100.00 ( 99.90)\n","Epoch: [113][270/391]\tTime  0.174 ( 0.174)\tLoss 3.2586e-02 (9.7550e-02)\tAcc@1  99.22 ( 97.47)\tAcc@5 100.00 ( 99.89)\n","Epoch: [113][300/391]\tTime  0.176 ( 0.174)\tLoss 1.4293e-01 (9.7691e-02)\tAcc@1  96.09 ( 97.46)\tAcc@5 100.00 ( 99.88)\n","Epoch: [113][330/391]\tTime  0.171 ( 0.174)\tLoss 1.4119e-01 (9.8467e-02)\tAcc@1  96.88 ( 97.44)\tAcc@5 100.00 ( 99.88)\n","Epoch: [113][360/391]\tTime  0.175 ( 0.174)\tLoss 1.3570e-01 (9.8625e-02)\tAcc@1  95.31 ( 97.44)\tAcc@5  99.22 ( 99.88)\n","Epoch: [113][390/391]\tTime  0.157 ( 0.173)\tLoss 8.7541e-02 (9.8288e-02)\tAcc@1  97.50 ( 97.47)\tAcc@5  98.75 ( 99.88)\n","==> Train Accuracy: Acc@1 97.466 || Acc@5 99.876\n","==> Test Accuracy:  Acc@1 76.750 || Acc@5 93.850\n","==> 72.11 seconds to train this epoch\n","\n","\n","----- epoch: 114, lr: 0.004000000000000001 -----\n","Epoch: [114][  0/391]\tTime  0.268 ( 0.268)\tLoss 7.0354e-02 (7.0354e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [114][ 30/391]\tTime  0.175 ( 0.176)\tLoss 7.4754e-02 (9.5772e-02)\tAcc@1  99.22 ( 97.66)\tAcc@5  99.22 ( 99.87)\n","Epoch: [114][ 60/391]\tTime  0.172 ( 0.175)\tLoss 9.8487e-02 (9.8991e-02)\tAcc@1  96.09 ( 97.61)\tAcc@5 100.00 ( 99.86)\n","Epoch: [114][ 90/391]\tTime  0.173 ( 0.174)\tLoss 8.6723e-02 (9.8067e-02)\tAcc@1  98.44 ( 97.60)\tAcc@5 100.00 ( 99.87)\n","Epoch: [114][120/391]\tTime  0.173 ( 0.174)\tLoss 8.2438e-02 (9.6952e-02)\tAcc@1  97.66 ( 97.64)\tAcc@5 100.00 ( 99.88)\n","Epoch: [114][150/391]\tTime  0.176 ( 0.174)\tLoss 5.6934e-02 (9.5202e-02)\tAcc@1  98.44 ( 97.74)\tAcc@5 100.00 ( 99.88)\n","Epoch: [114][180/391]\tTime  0.177 ( 0.174)\tLoss 1.6683e-01 (9.6480e-02)\tAcc@1  94.53 ( 97.66)\tAcc@5 100.00 ( 99.87)\n","Epoch: [114][210/391]\tTime  0.172 ( 0.174)\tLoss 1.3764e-01 (9.5595e-02)\tAcc@1  96.09 ( 97.69)\tAcc@5 100.00 ( 99.87)\n","Epoch: [114][240/391]\tTime  0.175 ( 0.174)\tLoss 1.4127e-01 (9.5817e-02)\tAcc@1  96.88 ( 97.66)\tAcc@5  99.22 ( 99.88)\n","Epoch: [114][270/391]\tTime  0.174 ( 0.174)\tLoss 8.5639e-02 (9.4930e-02)\tAcc@1  97.66 ( 97.68)\tAcc@5 100.00 ( 99.88)\n","Epoch: [114][300/391]\tTime  0.172 ( 0.174)\tLoss 7.4728e-02 (9.4715e-02)\tAcc@1  98.44 ( 97.69)\tAcc@5 100.00 ( 99.88)\n","Epoch: [114][330/391]\tTime  0.172 ( 0.174)\tLoss 9.1869e-02 (9.5416e-02)\tAcc@1  96.88 ( 97.64)\tAcc@5 100.00 ( 99.88)\n","Epoch: [114][360/391]\tTime  0.174 ( 0.174)\tLoss 8.2057e-02 (9.5483e-02)\tAcc@1 100.00 ( 97.62)\tAcc@5 100.00 ( 99.88)\n","Epoch: [114][390/391]\tTime  0.158 ( 0.174)\tLoss 1.3423e-01 (9.5666e-02)\tAcc@1  96.25 ( 97.60)\tAcc@5 100.00 ( 99.89)\n","==> Train Accuracy: Acc@1 97.598 || Acc@5 99.886\n","==> Test Accuracy:  Acc@1 76.550 || Acc@5 93.910\n","==> 72.26 seconds to train this epoch\n","\n","\n","----- epoch: 115, lr: 0.004000000000000001 -----\n","Epoch: [115][  0/391]\tTime  0.249 ( 0.249)\tLoss 8.3959e-02 (8.3959e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [115][ 30/391]\tTime  0.172 ( 0.176)\tLoss 6.2281e-02 (9.7716e-02)\tAcc@1  99.22 ( 97.61)\tAcc@5 100.00 ( 99.80)\n","Epoch: [115][ 60/391]\tTime  0.174 ( 0.174)\tLoss 1.1549e-01 (9.7120e-02)\tAcc@1  96.88 ( 97.63)\tAcc@5  99.22 ( 99.85)\n","Epoch: [115][ 90/391]\tTime  0.174 ( 0.174)\tLoss 1.1497e-01 (9.4587e-02)\tAcc@1  96.88 ( 97.65)\tAcc@5  99.22 ( 99.85)\n","Epoch: [115][120/391]\tTime  0.172 ( 0.174)\tLoss 9.8781e-02 (9.6052e-02)\tAcc@1  97.66 ( 97.64)\tAcc@5 100.00 ( 99.83)\n","Epoch: [115][150/391]\tTime  0.174 ( 0.174)\tLoss 7.7833e-02 (9.6526e-02)\tAcc@1  98.44 ( 97.60)\tAcc@5 100.00 ( 99.82)\n","Epoch: [115][180/391]\tTime  0.174 ( 0.174)\tLoss 1.3593e-01 (9.7664e-02)\tAcc@1  95.31 ( 97.56)\tAcc@5  99.22 ( 99.82)\n","Epoch: [115][210/391]\tTime  0.175 ( 0.174)\tLoss 7.1951e-02 (9.7484e-02)\tAcc@1  97.66 ( 97.56)\tAcc@5 100.00 ( 99.82)\n","Epoch: [115][240/391]\tTime  0.175 ( 0.174)\tLoss 1.1841e-01 (9.8318e-02)\tAcc@1  97.66 ( 97.53)\tAcc@5  99.22 ( 99.82)\n","Epoch: [115][270/391]\tTime  0.171 ( 0.174)\tLoss 1.1989e-01 (9.7407e-02)\tAcc@1  95.31 ( 97.55)\tAcc@5 100.00 ( 99.83)\n","Epoch: [115][300/391]\tTime  0.175 ( 0.174)\tLoss 8.7223e-02 (9.6885e-02)\tAcc@1  97.66 ( 97.56)\tAcc@5 100.00 ( 99.84)\n","Epoch: [115][330/391]\tTime  0.173 ( 0.174)\tLoss 1.3268e-01 (9.7011e-02)\tAcc@1  96.09 ( 97.55)\tAcc@5 100.00 ( 99.85)\n","Epoch: [115][360/391]\tTime  0.175 ( 0.174)\tLoss 7.0065e-02 (9.6808e-02)\tAcc@1  98.44 ( 97.55)\tAcc@5 100.00 ( 99.86)\n","Epoch: [115][390/391]\tTime  0.158 ( 0.174)\tLoss 6.9679e-02 (9.6488e-02)\tAcc@1  98.75 ( 97.56)\tAcc@5 100.00 ( 99.85)\n","==> Train Accuracy: Acc@1 97.560 || Acc@5 99.848\n","==> Test Accuracy:  Acc@1 76.790 || Acc@5 94.160\n","==> 72.25 seconds to train this epoch\n","\n","\n","----- epoch: 116, lr: 0.004000000000000001 -----\n","Epoch: [116][  0/391]\tTime  0.255 ( 0.255)\tLoss 7.5049e-02 (7.5049e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [116][ 30/391]\tTime  0.174 ( 0.176)\tLoss 7.3713e-02 (8.9770e-02)\tAcc@1  98.44 ( 97.88)\tAcc@5 100.00 ( 99.87)\n","Epoch: [116][ 60/391]\tTime  0.174 ( 0.175)\tLoss 9.9672e-02 (9.1939e-02)\tAcc@1  97.66 ( 97.68)\tAcc@5  99.22 ( 99.88)\n","Epoch: [116][ 90/391]\tTime  0.174 ( 0.175)\tLoss 4.3709e-02 (8.8612e-02)\tAcc@1  99.22 ( 97.85)\tAcc@5 100.00 ( 99.88)\n","Epoch: [116][120/391]\tTime  0.174 ( 0.174)\tLoss 4.4671e-02 (8.9600e-02)\tAcc@1 100.00 ( 97.85)\tAcc@5 100.00 ( 99.88)\n","Epoch: [116][150/391]\tTime  0.174 ( 0.174)\tLoss 9.1092e-02 (8.9580e-02)\tAcc@1  96.88 ( 97.78)\tAcc@5 100.00 ( 99.88)\n","Epoch: [116][180/391]\tTime  0.173 ( 0.174)\tLoss 1.0666e-01 (9.0292e-02)\tAcc@1  96.88 ( 97.72)\tAcc@5  99.22 ( 99.87)\n","Epoch: [116][210/391]\tTime  0.171 ( 0.174)\tLoss 6.0129e-02 (8.9759e-02)\tAcc@1  98.44 ( 97.76)\tAcc@5 100.00 ( 99.87)\n","Epoch: [116][240/391]\tTime  0.174 ( 0.174)\tLoss 6.9217e-02 (8.9654e-02)\tAcc@1  97.66 ( 97.76)\tAcc@5 100.00 ( 99.88)\n","Epoch: [116][270/391]\tTime  0.174 ( 0.174)\tLoss 6.8064e-02 (9.1105e-02)\tAcc@1  98.44 ( 97.70)\tAcc@5 100.00 ( 99.88)\n","Epoch: [116][300/391]\tTime  0.176 ( 0.174)\tLoss 7.7028e-02 (9.2443e-02)\tAcc@1  96.88 ( 97.68)\tAcc@5 100.00 ( 99.88)\n","Epoch: [116][330/391]\tTime  0.174 ( 0.174)\tLoss 6.1893e-02 (9.2306e-02)\tAcc@1  98.44 ( 97.68)\tAcc@5 100.00 ( 99.88)\n","Epoch: [116][360/391]\tTime  0.173 ( 0.174)\tLoss 7.3079e-02 (9.2260e-02)\tAcc@1  97.66 ( 97.63)\tAcc@5 100.00 ( 99.89)\n","Epoch: [116][390/391]\tTime  0.156 ( 0.174)\tLoss 9.5923e-02 (9.2728e-02)\tAcc@1  95.00 ( 97.61)\tAcc@5 100.00 ( 99.88)\n","==> Train Accuracy: Acc@1 97.612 || Acc@5 99.880\n","==> Test Accuracy:  Acc@1 76.840 || Acc@5 93.900\n","==> 72.33 seconds to train this epoch\n","\n","\n","----- epoch: 117, lr: 0.004000000000000001 -----\n","Epoch: [117][  0/391]\tTime  0.258 ( 0.258)\tLoss 4.1081e-02 (4.1081e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [117][ 30/391]\tTime  0.174 ( 0.176)\tLoss 1.2158e-01 (8.9471e-02)\tAcc@1  95.31 ( 97.40)\tAcc@5 100.00 ( 99.90)\n","Epoch: [117][ 60/391]\tTime  0.174 ( 0.175)\tLoss 6.8514e-02 (8.7043e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 ( 99.90)\n","Epoch: [117][ 90/391]\tTime  0.174 ( 0.175)\tLoss 7.9471e-02 (8.6578e-02)\tAcc@1  96.88 ( 97.66)\tAcc@5 100.00 ( 99.89)\n","Epoch: [117][120/391]\tTime  0.175 ( 0.174)\tLoss 7.0565e-02 (8.6582e-02)\tAcc@1  99.22 ( 97.72)\tAcc@5 100.00 ( 99.90)\n","Epoch: [117][150/391]\tTime  0.173 ( 0.174)\tLoss 1.0537e-01 (8.6570e-02)\tAcc@1  97.66 ( 97.71)\tAcc@5  99.22 ( 99.90)\n","Epoch: [117][180/391]\tTime  0.174 ( 0.174)\tLoss 4.8575e-02 (8.8470e-02)\tAcc@1  98.44 ( 97.63)\tAcc@5 100.00 ( 99.88)\n","Epoch: [117][210/391]\tTime  0.175 ( 0.174)\tLoss 1.2521e-01 (9.0064e-02)\tAcc@1  96.88 ( 97.58)\tAcc@5 100.00 ( 99.88)\n","Epoch: [117][240/391]\tTime  0.175 ( 0.174)\tLoss 1.0685e-01 (9.0740e-02)\tAcc@1  96.88 ( 97.57)\tAcc@5  99.22 ( 99.88)\n","Epoch: [117][270/391]\tTime  0.174 ( 0.174)\tLoss 8.1086e-02 (9.0477e-02)\tAcc@1  98.44 ( 97.61)\tAcc@5 100.00 ( 99.88)\n","Epoch: [117][300/391]\tTime  0.171 ( 0.174)\tLoss 8.6025e-02 (9.0954e-02)\tAcc@1  98.44 ( 97.60)\tAcc@5 100.00 ( 99.88)\n","Epoch: [117][330/391]\tTime  0.176 ( 0.174)\tLoss 7.1350e-02 (9.0945e-02)\tAcc@1  97.66 ( 97.59)\tAcc@5 100.00 ( 99.88)\n","Epoch: [117][360/391]\tTime  0.170 ( 0.174)\tLoss 6.7138e-02 (9.0588e-02)\tAcc@1  99.22 ( 97.62)\tAcc@5 100.00 ( 99.88)\n","Epoch: [117][390/391]\tTime  0.157 ( 0.174)\tLoss 8.4355e-02 (9.0150e-02)\tAcc@1  97.50 ( 97.64)\tAcc@5 100.00 ( 99.88)\n","==> Train Accuracy: Acc@1 97.640 || Acc@5 99.884\n","==> Test Accuracy:  Acc@1 76.660 || Acc@5 93.980\n","==> 72.33 seconds to train this epoch\n","\n","\n","----- epoch: 118, lr: 0.004000000000000001 -----\n","Epoch: [118][  0/391]\tTime  0.243 ( 0.243)\tLoss 1.2074e-01 (1.2074e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [118][ 30/391]\tTime  0.175 ( 0.176)\tLoss 5.8217e-02 (9.2825e-02)\tAcc@1  98.44 ( 97.76)\tAcc@5 100.00 ( 99.77)\n","Epoch: [118][ 60/391]\tTime  0.177 ( 0.175)\tLoss 6.7482e-02 (9.0739e-02)\tAcc@1  99.22 ( 97.78)\tAcc@5 100.00 ( 99.85)\n","Epoch: [118][ 90/391]\tTime  0.174 ( 0.175)\tLoss 6.5717e-02 (8.8874e-02)\tAcc@1  97.66 ( 97.81)\tAcc@5 100.00 ( 99.87)\n","Epoch: [118][120/391]\tTime  0.173 ( 0.174)\tLoss 1.1097e-01 (9.1239e-02)\tAcc@1  96.09 ( 97.70)\tAcc@5  99.22 ( 99.87)\n","Epoch: [118][150/391]\tTime  0.175 ( 0.174)\tLoss 6.9074e-02 (8.9486e-02)\tAcc@1  97.66 ( 97.69)\tAcc@5 100.00 ( 99.87)\n","Epoch: [118][180/391]\tTime  0.173 ( 0.174)\tLoss 6.0568e-02 (9.0802e-02)\tAcc@1  98.44 ( 97.63)\tAcc@5 100.00 ( 99.85)\n","Epoch: [118][210/391]\tTime  0.173 ( 0.174)\tLoss 6.5472e-02 (9.0135e-02)\tAcc@1  98.44 ( 97.66)\tAcc@5 100.00 ( 99.86)\n","Epoch: [118][240/391]\tTime  0.176 ( 0.174)\tLoss 5.9091e-02 (9.0795e-02)\tAcc@1  99.22 ( 97.64)\tAcc@5 100.00 ( 99.86)\n","Epoch: [118][270/391]\tTime  0.175 ( 0.174)\tLoss 6.8361e-02 (9.1542e-02)\tAcc@1  96.88 ( 97.59)\tAcc@5 100.00 ( 99.87)\n","Epoch: [118][300/391]\tTime  0.172 ( 0.174)\tLoss 1.0845e-01 (9.1210e-02)\tAcc@1  96.09 ( 97.59)\tAcc@5 100.00 ( 99.87)\n","Epoch: [118][330/391]\tTime  0.175 ( 0.174)\tLoss 6.2452e-02 (9.0808e-02)\tAcc@1  99.22 ( 97.62)\tAcc@5 100.00 ( 99.86)\n","Epoch: [118][360/391]\tTime  0.175 ( 0.174)\tLoss 8.7425e-02 (9.1228e-02)\tAcc@1  97.66 ( 97.60)\tAcc@5 100.00 ( 99.87)\n","Epoch: [118][390/391]\tTime  0.157 ( 0.174)\tLoss 5.8806e-02 (9.1180e-02)\tAcc@1  98.75 ( 97.59)\tAcc@5 100.00 ( 99.88)\n","==> Train Accuracy: Acc@1 97.592 || Acc@5 99.876\n","==> Test Accuracy:  Acc@1 76.860 || Acc@5 93.840\n","==> 72.33 seconds to train this epoch\n","\n","\n","----- epoch: 119, lr: 0.004000000000000001 -----\n","Epoch: [119][  0/391]\tTime  0.265 ( 0.265)\tLoss 8.5458e-02 (8.5458e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [119][ 30/391]\tTime  0.172 ( 0.176)\tLoss 8.3728e-02 (9.2893e-02)\tAcc@1  97.66 ( 97.58)\tAcc@5 100.00 ( 99.77)\n","Epoch: [119][ 60/391]\tTime  0.171 ( 0.175)\tLoss 6.0825e-02 (9.2333e-02)\tAcc@1  99.22 ( 97.54)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][ 90/391]\tTime  0.172 ( 0.175)\tLoss 8.8802e-02 (9.1472e-02)\tAcc@1  98.44 ( 97.66)\tAcc@5 100.00 ( 99.86)\n","Epoch: [119][120/391]\tTime  0.175 ( 0.175)\tLoss 6.0227e-02 (9.6513e-02)\tAcc@1 100.00 ( 97.50)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][150/391]\tTime  0.175 ( 0.174)\tLoss 7.6079e-02 (9.5703e-02)\tAcc@1  97.66 ( 97.52)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][180/391]\tTime  0.172 ( 0.174)\tLoss 1.0693e-01 (9.6252e-02)\tAcc@1  96.09 ( 97.51)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][210/391]\tTime  0.173 ( 0.174)\tLoss 9.1887e-02 (9.6246e-02)\tAcc@1  96.88 ( 97.50)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][240/391]\tTime  0.174 ( 0.174)\tLoss 3.8984e-02 (9.6019e-02)\tAcc@1  99.22 ( 97.49)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][270/391]\tTime  0.172 ( 0.174)\tLoss 9.9588e-02 (9.6208e-02)\tAcc@1  97.66 ( 97.47)\tAcc@5 100.00 ( 99.86)\n","Epoch: [119][300/391]\tTime  0.174 ( 0.174)\tLoss 5.6388e-02 (9.6772e-02)\tAcc@1  99.22 ( 97.48)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][330/391]\tTime  0.173 ( 0.174)\tLoss 3.6507e-02 (9.6842e-02)\tAcc@1  99.22 ( 97.46)\tAcc@5 100.00 ( 99.85)\n","Epoch: [119][360/391]\tTime  0.174 ( 0.174)\tLoss 6.9248e-02 (9.6919e-02)\tAcc@1  99.22 ( 97.48)\tAcc@5 100.00 ( 99.84)\n","Epoch: [119][390/391]\tTime  0.157 ( 0.174)\tLoss 1.1986e-01 (9.7012e-02)\tAcc@1  98.75 ( 97.48)\tAcc@5  98.75 ( 99.84)\n","==> Train Accuracy: Acc@1 97.484 || Acc@5 99.842\n","==> Test Accuracy:  Acc@1 76.390 || Acc@5 93.720\n","==> 72.39 seconds to train this epoch\n","\n","\n","----- epoch: 120, lr: 0.0008000000000000003 -----\n","Epoch: [120][  0/391]\tTime  0.273 ( 0.273)\tLoss 4.5215e-02 (4.5215e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [120][ 30/391]\tTime  0.173 ( 0.176)\tLoss 9.4507e-02 (8.8113e-02)\tAcc@1  99.22 ( 97.86)\tAcc@5 100.00 ( 99.82)\n","Epoch: [120][ 60/391]\tTime  0.172 ( 0.175)\tLoss 1.4090e-01 (8.5005e-02)\tAcc@1  96.09 ( 97.89)\tAcc@5  99.22 ( 99.87)\n","Epoch: [120][ 90/391]\tTime  0.173 ( 0.174)\tLoss 7.7444e-02 (8.3954e-02)\tAcc@1  97.66 ( 97.89)\tAcc@5 100.00 ( 99.90)\n","Epoch: [120][120/391]\tTime  0.175 ( 0.174)\tLoss 5.9760e-02 (8.2291e-02)\tAcc@1  99.22 ( 97.95)\tAcc@5 100.00 ( 99.91)\n","Epoch: [120][150/391]\tTime  0.179 ( 0.174)\tLoss 7.1806e-02 (7.9466e-02)\tAcc@1  98.44 ( 98.04)\tAcc@5 100.00 ( 99.92)\n","Epoch: [120][180/391]\tTime  0.176 ( 0.174)\tLoss 5.2295e-02 (7.8595e-02)\tAcc@1  98.44 ( 98.08)\tAcc@5 100.00 ( 99.90)\n","Epoch: [120][210/391]\tTime  0.172 ( 0.174)\tLoss 7.0974e-02 (7.6361e-02)\tAcc@1  99.22 ( 98.13)\tAcc@5 100.00 ( 99.90)\n","Epoch: [120][240/391]\tTime  0.171 ( 0.174)\tLoss 7.1653e-02 (7.5576e-02)\tAcc@1  97.66 ( 98.17)\tAcc@5 100.00 ( 99.89)\n","Epoch: [120][270/391]\tTime  0.174 ( 0.174)\tLoss 3.1636e-02 (7.5608e-02)\tAcc@1 100.00 ( 98.17)\tAcc@5 100.00 ( 99.89)\n","Epoch: [120][300/391]\tTime  0.173 ( 0.174)\tLoss 7.3214e-02 (7.4931e-02)\tAcc@1  97.66 ( 98.22)\tAcc@5 100.00 ( 99.90)\n","Epoch: [120][330/391]\tTime  0.173 ( 0.174)\tLoss 8.9472e-02 (7.4156e-02)\tAcc@1  96.09 ( 98.22)\tAcc@5 100.00 ( 99.90)\n","Epoch: [120][360/391]\tTime  0.175 ( 0.174)\tLoss 8.6208e-02 (7.4066e-02)\tAcc@1  98.44 ( 98.25)\tAcc@5 100.00 ( 99.90)\n","Epoch: [120][390/391]\tTime  0.159 ( 0.173)\tLoss 1.9772e-01 (7.4009e-02)\tAcc@1  93.75 ( 98.24)\tAcc@5 100.00 ( 99.90)\n","==> Train Accuracy: Acc@1 98.242 || Acc@5 99.898\n","==> Test Accuracy:  Acc@1 77.240 || Acc@5 94.040\n","==> 72.12 seconds to train this epoch\n","\n","\n","----- epoch: 121, lr: 0.0008000000000000003 -----\n","Epoch: [121][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.1051e-01 (1.1051e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [121][ 30/391]\tTime  0.174 ( 0.176)\tLoss 9.8373e-02 (7.5512e-02)\tAcc@1  96.88 ( 98.01)\tAcc@5 100.00 ( 99.87)\n","Epoch: [121][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.4774e-02 (7.4343e-02)\tAcc@1 100.00 ( 98.09)\tAcc@5 100.00 ( 99.88)\n","Epoch: [121][ 90/391]\tTime  0.176 ( 0.174)\tLoss 9.7247e-02 (7.0758e-02)\tAcc@1  96.09 ( 98.22)\tAcc@5 100.00 ( 99.91)\n","Epoch: [121][120/391]\tTime  0.173 ( 0.174)\tLoss 9.1900e-02 (7.1680e-02)\tAcc@1  98.44 ( 98.17)\tAcc@5  99.22 ( 99.90)\n","Epoch: [121][150/391]\tTime  0.175 ( 0.174)\tLoss 2.6203e-02 (6.9226e-02)\tAcc@1  99.22 ( 98.24)\tAcc@5 100.00 ( 99.91)\n","Epoch: [121][180/391]\tTime  0.174 ( 0.174)\tLoss 8.8022e-02 (6.8318e-02)\tAcc@1  96.88 ( 98.28)\tAcc@5  99.22 ( 99.91)\n","Epoch: [121][210/391]\tTime  0.173 ( 0.174)\tLoss 6.9347e-02 (6.8527e-02)\tAcc@1  98.44 ( 98.31)\tAcc@5  99.22 ( 99.91)\n","Epoch: [121][240/391]\tTime  0.175 ( 0.174)\tLoss 1.6151e-01 (6.8641e-02)\tAcc@1  97.66 ( 98.35)\tAcc@5  98.44 ( 99.91)\n","Epoch: [121][270/391]\tTime  0.172 ( 0.174)\tLoss 7.1098e-02 (6.7935e-02)\tAcc@1  98.44 ( 98.39)\tAcc@5 100.00 ( 99.91)\n","Epoch: [121][300/391]\tTime  0.172 ( 0.174)\tLoss 3.4554e-02 (6.7410e-02)\tAcc@1  99.22 ( 98.41)\tAcc@5 100.00 ( 99.91)\n","Epoch: [121][330/391]\tTime  0.176 ( 0.174)\tLoss 4.4212e-02 (6.7131e-02)\tAcc@1  99.22 ( 98.41)\tAcc@5 100.00 ( 99.92)\n","Epoch: [121][360/391]\tTime  0.173 ( 0.174)\tLoss 3.5331e-02 (6.6590e-02)\tAcc@1  98.44 ( 98.39)\tAcc@5 100.00 ( 99.92)\n","Epoch: [121][390/391]\tTime  0.159 ( 0.174)\tLoss 9.7617e-02 (6.6956e-02)\tAcc@1  97.50 ( 98.39)\tAcc@5  98.75 ( 99.92)\n","==> Train Accuracy: Acc@1 98.392 || Acc@5 99.920\n","==> Test Accuracy:  Acc@1 77.470 || Acc@5 94.200\n","==> 72.20 seconds to train this epoch\n","\n","\n","----- epoch: 122, lr: 0.0008000000000000003 -----\n","Epoch: [122][  0/391]\tTime  0.267 ( 0.267)\tLoss 5.9688e-02 (5.9688e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [122][ 30/391]\tTime  0.175 ( 0.177)\tLoss 1.2171e-01 (6.3420e-02)\tAcc@1  97.66 ( 98.64)\tAcc@5  99.22 ( 99.95)\n","Epoch: [122][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.0596e-01 (6.3546e-02)\tAcc@1  96.09 ( 98.53)\tAcc@5 100.00 ( 99.96)\n","Epoch: [122][ 90/391]\tTime  0.172 ( 0.175)\tLoss 4.2056e-02 (6.3432e-02)\tAcc@1 100.00 ( 98.51)\tAcc@5 100.00 ( 99.95)\n","Epoch: [122][120/391]\tTime  0.173 ( 0.175)\tLoss 6.4571e-02 (6.3243e-02)\tAcc@1  98.44 ( 98.51)\tAcc@5 100.00 ( 99.95)\n","Epoch: [122][150/391]\tTime  0.174 ( 0.174)\tLoss 6.8577e-02 (6.4241e-02)\tAcc@1  97.66 ( 98.44)\tAcc@5 100.00 ( 99.95)\n","Epoch: [122][180/391]\tTime  0.176 ( 0.174)\tLoss 4.3509e-02 (6.4641e-02)\tAcc@1  99.22 ( 98.42)\tAcc@5 100.00 ( 99.95)\n","Epoch: [122][210/391]\tTime  0.174 ( 0.174)\tLoss 4.5115e-02 (6.3523e-02)\tAcc@1  99.22 ( 98.43)\tAcc@5 100.00 ( 99.94)\n","Epoch: [122][240/391]\tTime  0.174 ( 0.174)\tLoss 6.5653e-02 (6.3603e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 ( 99.94)\n","Epoch: [122][270/391]\tTime  0.170 ( 0.174)\tLoss 6.0341e-02 (6.4594e-02)\tAcc@1  99.22 ( 98.42)\tAcc@5 100.00 ( 99.93)\n","Epoch: [122][300/391]\tTime  0.175 ( 0.174)\tLoss 8.1606e-02 (6.4552e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 ( 99.94)\n","Epoch: [122][330/391]\tTime  0.174 ( 0.174)\tLoss 7.5329e-02 (6.4341e-02)\tAcc@1  97.66 ( 98.44)\tAcc@5 100.00 ( 99.93)\n","Epoch: [122][360/391]\tTime  0.174 ( 0.174)\tLoss 9.6739e-02 (6.4087e-02)\tAcc@1  98.44 ( 98.47)\tAcc@5  99.22 ( 99.93)\n","Epoch: [122][390/391]\tTime  0.155 ( 0.174)\tLoss 1.1819e-01 (6.4164e-02)\tAcc@1  96.25 ( 98.47)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 98.472 || Acc@5 99.930\n","==> Test Accuracy:  Acc@1 77.420 || Acc@5 94.040\n","==> 72.38 seconds to train this epoch\n","\n","\n","----- epoch: 123, lr: 0.0008000000000000003 -----\n","Epoch: [123][  0/391]\tTime  0.269 ( 0.269)\tLoss 9.2678e-02 (9.2678e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [123][ 30/391]\tTime  0.177 ( 0.177)\tLoss 7.6723e-02 (7.6053e-02)\tAcc@1  99.22 ( 98.26)\tAcc@5  99.22 ( 99.85)\n","Epoch: [123][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.6814e-02 (6.8239e-02)\tAcc@1  99.22 ( 98.45)\tAcc@5 100.00 ( 99.88)\n","Epoch: [123][ 90/391]\tTime  0.176 ( 0.175)\tLoss 1.0098e-01 (6.4769e-02)\tAcc@1  97.66 ( 98.56)\tAcc@5 100.00 ( 99.89)\n","Epoch: [123][120/391]\tTime  0.173 ( 0.175)\tLoss 3.6147e-02 (6.3923e-02)\tAcc@1  99.22 ( 98.53)\tAcc@5 100.00 ( 99.91)\n","Epoch: [123][150/391]\tTime  0.173 ( 0.174)\tLoss 4.6331e-02 (6.4391e-02)\tAcc@1  99.22 ( 98.52)\tAcc@5 100.00 ( 99.92)\n","Epoch: [123][180/391]\tTime  0.176 ( 0.174)\tLoss 6.7205e-02 (6.6014e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 ( 99.90)\n","Epoch: [123][210/391]\tTime  0.173 ( 0.174)\tLoss 3.0021e-02 (6.3879e-02)\tAcc@1 100.00 ( 98.48)\tAcc@5 100.00 ( 99.91)\n","Epoch: [123][240/391]\tTime  0.172 ( 0.174)\tLoss 4.3577e-02 (6.3898e-02)\tAcc@1  99.22 ( 98.47)\tAcc@5 100.00 ( 99.91)\n","Epoch: [123][270/391]\tTime  0.176 ( 0.174)\tLoss 3.6438e-02 (6.3878e-02)\tAcc@1 100.00 ( 98.47)\tAcc@5 100.00 ( 99.90)\n","Epoch: [123][300/391]\tTime  0.173 ( 0.174)\tLoss 2.1515e-02 (6.3592e-02)\tAcc@1 100.00 ( 98.46)\tAcc@5 100.00 ( 99.91)\n","Epoch: [123][330/391]\tTime  0.173 ( 0.174)\tLoss 8.4110e-02 (6.4062e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 ( 99.90)\n","Epoch: [123][360/391]\tTime  0.173 ( 0.174)\tLoss 2.0973e-02 (6.3314e-02)\tAcc@1 100.00 ( 98.47)\tAcc@5 100.00 ( 99.91)\n","Epoch: [123][390/391]\tTime  0.157 ( 0.174)\tLoss 6.5735e-02 (6.3102e-02)\tAcc@1  98.75 ( 98.47)\tAcc@5 100.00 ( 99.92)\n","==> Train Accuracy: Acc@1 98.470 || Acc@5 99.916\n","==> Test Accuracy:  Acc@1 77.560 || Acc@5 94.200\n","==> 72.40 seconds to train this epoch\n","\n","\n","----- epoch: 124, lr: 0.0008000000000000003 -----\n","Epoch: [124][  0/391]\tTime  0.274 ( 0.274)\tLoss 5.7905e-02 (5.7905e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [124][ 30/391]\tTime  0.174 ( 0.177)\tLoss 3.0520e-02 (5.9610e-02)\tAcc@1 100.00 ( 98.56)\tAcc@5 100.00 ( 99.90)\n","Epoch: [124][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.1501e-01 (6.1558e-02)\tAcc@1  96.88 ( 98.67)\tAcc@5  99.22 ( 99.86)\n","Epoch: [124][ 90/391]\tTime  0.174 ( 0.175)\tLoss 4.5374e-02 (5.9977e-02)\tAcc@1  99.22 ( 98.70)\tAcc@5 100.00 ( 99.86)\n","Epoch: [124][120/391]\tTime  0.174 ( 0.175)\tLoss 3.1912e-02 (6.0344e-02)\tAcc@1  99.22 ( 98.69)\tAcc@5 100.00 ( 99.87)\n","Epoch: [124][150/391]\tTime  0.175 ( 0.175)\tLoss 2.4768e-02 (6.0155e-02)\tAcc@1 100.00 ( 98.64)\tAcc@5 100.00 ( 99.88)\n","Epoch: [124][180/391]\tTime  0.176 ( 0.174)\tLoss 3.2764e-02 (5.8538e-02)\tAcc@1  99.22 ( 98.69)\tAcc@5 100.00 ( 99.90)\n","Epoch: [124][210/391]\tTime  0.170 ( 0.174)\tLoss 4.9116e-02 (5.8329e-02)\tAcc@1  98.44 ( 98.67)\tAcc@5 100.00 ( 99.90)\n","Epoch: [124][240/391]\tTime  0.173 ( 0.174)\tLoss 1.3644e-01 (5.8226e-02)\tAcc@1  97.66 ( 98.68)\tAcc@5  99.22 ( 99.90)\n","Epoch: [124][270/391]\tTime  0.174 ( 0.174)\tLoss 3.0903e-02 (5.9143e-02)\tAcc@1 100.00 ( 98.67)\tAcc@5 100.00 ( 99.90)\n","Epoch: [124][300/391]\tTime  0.173 ( 0.174)\tLoss 5.6541e-02 (5.8805e-02)\tAcc@1  97.66 ( 98.67)\tAcc@5 100.00 ( 99.91)\n","Epoch: [124][330/391]\tTime  0.175 ( 0.174)\tLoss 9.6527e-02 (5.8414e-02)\tAcc@1  96.88 ( 98.68)\tAcc@5 100.00 ( 99.91)\n","Epoch: [124][360/391]\tTime  0.175 ( 0.174)\tLoss 3.0859e-02 (5.9523e-02)\tAcc@1  99.22 ( 98.62)\tAcc@5 100.00 ( 99.90)\n","Epoch: [124][390/391]\tTime  0.160 ( 0.174)\tLoss 5.6874e-02 (5.9318e-02)\tAcc@1 100.00 ( 98.64)\tAcc@5 100.00 ( 99.91)\n","==> Train Accuracy: Acc@1 98.640 || Acc@5 99.908\n","==> Test Accuracy:  Acc@1 77.670 || Acc@5 94.230\n","==> 72.38 seconds to train this epoch\n","\n","\n","----- epoch: 125, lr: 0.0008000000000000003 -----\n","Epoch: [125][  0/391]\tTime  0.264 ( 0.264)\tLoss 4.6749e-02 (4.6749e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [125][ 30/391]\tTime  0.173 ( 0.176)\tLoss 5.6647e-02 (6.2133e-02)\tAcc@1  97.66 ( 98.46)\tAcc@5 100.00 ( 99.97)\n","Epoch: [125][ 60/391]\tTime  0.170 ( 0.175)\tLoss 4.4936e-02 (5.7889e-02)\tAcc@1  98.44 ( 98.64)\tAcc@5 100.00 ( 99.95)\n","Epoch: [125][ 90/391]\tTime  0.175 ( 0.175)\tLoss 4.5415e-02 (5.5579e-02)\tAcc@1  99.22 ( 98.76)\tAcc@5 100.00 ( 99.94)\n","Epoch: [125][120/391]\tTime  0.173 ( 0.175)\tLoss 5.0929e-02 (5.5770e-02)\tAcc@1  99.22 ( 98.72)\tAcc@5 100.00 ( 99.93)\n","Epoch: [125][150/391]\tTime  0.174 ( 0.174)\tLoss 4.0854e-02 (5.5232e-02)\tAcc@1  99.22 ( 98.75)\tAcc@5 100.00 ( 99.94)\n","Epoch: [125][180/391]\tTime  0.180 ( 0.174)\tLoss 2.9859e-02 (5.5096e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 ( 99.94)\n","Epoch: [125][210/391]\tTime  0.175 ( 0.174)\tLoss 5.0872e-02 (5.4923e-02)\tAcc@1  98.44 ( 98.77)\tAcc@5 100.00 ( 99.93)\n","Epoch: [125][240/391]\tTime  0.174 ( 0.174)\tLoss 4.4766e-02 (5.4387e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 ( 99.94)\n","Epoch: [125][270/391]\tTime  0.173 ( 0.174)\tLoss 6.1985e-02 (5.4098e-02)\tAcc@1  98.44 ( 98.77)\tAcc@5 100.00 ( 99.94)\n","Epoch: [125][300/391]\tTime  0.176 ( 0.174)\tLoss 8.1761e-02 (5.4563e-02)\tAcc@1  97.66 ( 98.75)\tAcc@5 100.00 ( 99.93)\n","Epoch: [125][330/391]\tTime  0.173 ( 0.174)\tLoss 8.6726e-02 (5.5196e-02)\tAcc@1  97.66 ( 98.73)\tAcc@5 100.00 ( 99.93)\n","Epoch: [125][360/391]\tTime  0.173 ( 0.174)\tLoss 3.9712e-02 (5.5165e-02)\tAcc@1  99.22 ( 98.74)\tAcc@5 100.00 ( 99.93)\n","Epoch: [125][390/391]\tTime  0.155 ( 0.174)\tLoss 1.1597e-01 (5.5942e-02)\tAcc@1  96.25 ( 98.72)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 98.720 || Acc@5 99.930\n","==> Test Accuracy:  Acc@1 77.550 || Acc@5 94.150\n","==> 72.36 seconds to train this epoch\n","\n","\n","----- epoch: 126, lr: 0.0008000000000000003 -----\n","Epoch: [126][  0/391]\tTime  0.266 ( 0.266)\tLoss 7.4319e-02 (7.4319e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [126][ 30/391]\tTime  0.174 ( 0.177)\tLoss 6.6873e-02 (6.4332e-02)\tAcc@1  97.66 ( 98.54)\tAcc@5 100.00 ( 99.82)\n","Epoch: [126][ 60/391]\tTime  0.174 ( 0.175)\tLoss 8.1643e-02 (6.0440e-02)\tAcc@1  97.66 ( 98.67)\tAcc@5 100.00 ( 99.90)\n","Epoch: [126][ 90/391]\tTime  0.174 ( 0.175)\tLoss 4.0999e-02 (5.6714e-02)\tAcc@1  99.22 ( 98.70)\tAcc@5 100.00 ( 99.92)\n","Epoch: [126][120/391]\tTime  0.174 ( 0.175)\tLoss 1.8082e-02 (5.5499e-02)\tAcc@1 100.00 ( 98.69)\tAcc@5 100.00 ( 99.94)\n","Epoch: [126][150/391]\tTime  0.172 ( 0.174)\tLoss 2.7193e-02 (5.5728e-02)\tAcc@1  99.22 ( 98.70)\tAcc@5 100.00 ( 99.92)\n","Epoch: [126][180/391]\tTime  0.174 ( 0.174)\tLoss 4.8545e-02 (5.6289e-02)\tAcc@1 100.00 ( 98.67)\tAcc@5 100.00 ( 99.93)\n","Epoch: [126][210/391]\tTime  0.172 ( 0.174)\tLoss 2.9252e-02 (5.6304e-02)\tAcc@1 100.00 ( 98.67)\tAcc@5 100.00 ( 99.93)\n","Epoch: [126][240/391]\tTime  0.173 ( 0.174)\tLoss 3.5752e-02 (5.6045e-02)\tAcc@1  99.22 ( 98.68)\tAcc@5 100.00 ( 99.94)\n","Epoch: [126][270/391]\tTime  0.172 ( 0.174)\tLoss 6.7689e-02 (5.6430e-02)\tAcc@1  98.44 ( 98.67)\tAcc@5 100.00 ( 99.93)\n","Epoch: [126][300/391]\tTime  0.174 ( 0.174)\tLoss 4.0046e-02 (5.6303e-02)\tAcc@1  98.44 ( 98.68)\tAcc@5 100.00 ( 99.93)\n","Epoch: [126][330/391]\tTime  0.172 ( 0.174)\tLoss 8.2449e-02 (5.6792e-02)\tAcc@1  96.88 ( 98.65)\tAcc@5 100.00 ( 99.93)\n","Epoch: [126][360/391]\tTime  0.175 ( 0.174)\tLoss 3.7600e-02 (5.6752e-02)\tAcc@1  98.44 ( 98.65)\tAcc@5 100.00 ( 99.94)\n","Epoch: [126][390/391]\tTime  0.155 ( 0.174)\tLoss 3.9028e-02 (5.6771e-02)\tAcc@1 100.00 ( 98.65)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 98.646 || Acc@5 99.932\n","==> Test Accuracy:  Acc@1 77.640 || Acc@5 94.130\n","==> 72.39 seconds to train this epoch\n","\n","\n","----- epoch: 127, lr: 0.0008000000000000003 -----\n","Epoch: [127][  0/391]\tTime  0.275 ( 0.275)\tLoss 2.8437e-02 (2.8437e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [127][ 30/391]\tTime  0.174 ( 0.177)\tLoss 7.4246e-02 (5.3557e-02)\tAcc@1  99.22 ( 98.71)\tAcc@5 100.00 ( 99.95)\n","Epoch: [127][ 60/391]\tTime  0.180 ( 0.176)\tLoss 5.4399e-02 (5.2572e-02)\tAcc@1  97.66 ( 98.82)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][ 90/391]\tTime  0.174 ( 0.175)\tLoss 2.8918e-02 (5.2695e-02)\tAcc@1 100.00 ( 98.83)\tAcc@5 100.00 ( 99.93)\n","Epoch: [127][120/391]\tTime  0.174 ( 0.175)\tLoss 5.5802e-02 (5.4491e-02)\tAcc@1  97.66 ( 98.75)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][150/391]\tTime  0.174 ( 0.174)\tLoss 2.3785e-02 (5.4678e-02)\tAcc@1 100.00 ( 98.72)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][180/391]\tTime  0.173 ( 0.174)\tLoss 5.1416e-02 (5.4365e-02)\tAcc@1  98.44 ( 98.74)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][210/391]\tTime  0.173 ( 0.174)\tLoss 3.6956e-02 (5.3808e-02)\tAcc@1  98.44 ( 98.76)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][240/391]\tTime  0.174 ( 0.174)\tLoss 3.0833e-02 (5.4040e-02)\tAcc@1  99.22 ( 98.75)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][270/391]\tTime  0.174 ( 0.174)\tLoss 4.8884e-02 (5.3637e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 ( 99.95)\n","Epoch: [127][300/391]\tTime  0.174 ( 0.174)\tLoss 4.5614e-02 (5.4884e-02)\tAcc@1  98.44 ( 98.75)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][330/391]\tTime  0.176 ( 0.174)\tLoss 3.5060e-02 (5.4439e-02)\tAcc@1  99.22 ( 98.75)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][360/391]\tTime  0.174 ( 0.174)\tLoss 7.4289e-02 (5.4881e-02)\tAcc@1  98.44 ( 98.74)\tAcc@5 100.00 ( 99.94)\n","Epoch: [127][390/391]\tTime  0.157 ( 0.174)\tLoss 2.5214e-02 (5.5036e-02)\tAcc@1 100.00 ( 98.75)\tAcc@5 100.00 ( 99.94)\n","==> Train Accuracy: Acc@1 98.752 || Acc@5 99.942\n","==> Test Accuracy:  Acc@1 77.770 || Acc@5 94.070\n","==> 72.35 seconds to train this epoch\n","\n","\n","----- epoch: 128, lr: 0.0008000000000000003 -----\n","Epoch: [128][  0/391]\tTime  0.264 ( 0.264)\tLoss 6.1786e-02 (6.1786e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [128][ 30/391]\tTime  0.174 ( 0.176)\tLoss 7.0710e-02 (5.6107e-02)\tAcc@1  97.66 ( 98.82)\tAcc@5 100.00 ( 99.95)\n","Epoch: [128][ 60/391]\tTime  0.171 ( 0.175)\tLoss 8.0221e-02 (5.4282e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5  99.22 ( 99.94)\n","Epoch: [128][ 90/391]\tTime  0.173 ( 0.175)\tLoss 7.5032e-02 (5.4646e-02)\tAcc@1  98.44 ( 98.85)\tAcc@5 100.00 ( 99.91)\n","Epoch: [128][120/391]\tTime  0.172 ( 0.174)\tLoss 4.4128e-02 (5.3368e-02)\tAcc@1  99.22 ( 98.87)\tAcc@5 100.00 ( 99.92)\n","Epoch: [128][150/391]\tTime  0.175 ( 0.174)\tLoss 4.5977e-02 (5.5051e-02)\tAcc@1  99.22 ( 98.80)\tAcc@5 100.00 ( 99.91)\n","Epoch: [128][180/391]\tTime  0.177 ( 0.174)\tLoss 4.5931e-02 (5.4932e-02)\tAcc@1  98.44 ( 98.79)\tAcc@5 100.00 ( 99.91)\n","Epoch: [128][210/391]\tTime  0.172 ( 0.174)\tLoss 6.2643e-02 (5.5106e-02)\tAcc@1  97.66 ( 98.79)\tAcc@5 100.00 ( 99.91)\n","Epoch: [128][240/391]\tTime  0.173 ( 0.174)\tLoss 3.9487e-02 (5.4831e-02)\tAcc@1  99.22 ( 98.80)\tAcc@5 100.00 ( 99.92)\n","Epoch: [128][270/391]\tTime  0.173 ( 0.174)\tLoss 4.9729e-02 (5.5188e-02)\tAcc@1  99.22 ( 98.79)\tAcc@5 100.00 ( 99.93)\n","Epoch: [128][300/391]\tTime  0.173 ( 0.174)\tLoss 5.7035e-02 (5.5287e-02)\tAcc@1  99.22 ( 98.78)\tAcc@5 100.00 ( 99.92)\n","Epoch: [128][330/391]\tTime  0.174 ( 0.174)\tLoss 5.5279e-02 (5.5703e-02)\tAcc@1  98.44 ( 98.75)\tAcc@5 100.00 ( 99.93)\n","Epoch: [128][360/391]\tTime  0.176 ( 0.174)\tLoss 4.7627e-02 (5.5351e-02)\tAcc@1  98.44 ( 98.76)\tAcc@5 100.00 ( 99.93)\n","Epoch: [128][390/391]\tTime  0.155 ( 0.174)\tLoss 4.9537e-02 (5.4860e-02)\tAcc@1 100.00 ( 98.78)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 98.776 || Acc@5 99.934\n","==> Test Accuracy:  Acc@1 77.750 || Acc@5 94.420\n","==> 72.33 seconds to train this epoch\n","\n","\n","----- epoch: 129, lr: 0.0008000000000000003 -----\n","Epoch: [129][  0/391]\tTime  0.245 ( 0.245)\tLoss 6.6327e-02 (6.6327e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [129][ 30/391]\tTime  0.177 ( 0.176)\tLoss 4.7259e-02 (5.7831e-02)\tAcc@1  99.22 ( 98.49)\tAcc@5 100.00 ( 99.97)\n","Epoch: [129][ 60/391]\tTime  0.172 ( 0.175)\tLoss 4.1996e-02 (5.8330e-02)\tAcc@1  99.22 ( 98.64)\tAcc@5 100.00 ( 99.92)\n","Epoch: [129][ 90/391]\tTime  0.173 ( 0.174)\tLoss 6.5244e-02 (5.6628e-02)\tAcc@1  97.66 ( 98.69)\tAcc@5 100.00 ( 99.91)\n","Epoch: [129][120/391]\tTime  0.174 ( 0.174)\tLoss 4.3742e-02 (5.4744e-02)\tAcc@1  99.22 ( 98.72)\tAcc@5 100.00 ( 99.93)\n","Epoch: [129][150/391]\tTime  0.175 ( 0.174)\tLoss 7.2090e-02 (5.5693e-02)\tAcc@1  98.44 ( 98.69)\tAcc@5 100.00 ( 99.92)\n","Epoch: [129][180/391]\tTime  0.172 ( 0.174)\tLoss 4.5735e-02 (5.5790e-02)\tAcc@1  99.22 ( 98.65)\tAcc@5 100.00 ( 99.93)\n","Epoch: [129][210/391]\tTime  0.172 ( 0.174)\tLoss 9.1186e-02 (5.5632e-02)\tAcc@1  97.66 ( 98.66)\tAcc@5 100.00 ( 99.91)\n","Epoch: [129][240/391]\tTime  0.174 ( 0.174)\tLoss 7.6576e-02 (5.5376e-02)\tAcc@1  97.66 ( 98.67)\tAcc@5 100.00 ( 99.91)\n","Epoch: [129][270/391]\tTime  0.179 ( 0.174)\tLoss 3.2462e-02 (5.4510e-02)\tAcc@1 100.00 ( 98.69)\tAcc@5 100.00 ( 99.92)\n","Epoch: [129][300/391]\tTime  0.174 ( 0.174)\tLoss 3.9945e-02 (5.4739e-02)\tAcc@1 100.00 ( 98.68)\tAcc@5 100.00 ( 99.92)\n","Epoch: [129][330/391]\tTime  0.172 ( 0.174)\tLoss 6.3275e-02 (5.4797e-02)\tAcc@1  96.88 ( 98.69)\tAcc@5 100.00 ( 99.93)\n","Epoch: [129][360/391]\tTime  0.173 ( 0.174)\tLoss 4.4387e-02 (5.4182e-02)\tAcc@1  99.22 ( 98.73)\tAcc@5 100.00 ( 99.93)\n","Epoch: [129][390/391]\tTime  0.158 ( 0.174)\tLoss 4.0198e-02 (5.4609e-02)\tAcc@1 100.00 ( 98.74)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 98.742 || Acc@5 99.928\n","==> Test Accuracy:  Acc@1 77.640 || Acc@5 94.150\n","==> 72.28 seconds to train this epoch\n","\n","\n","----- epoch: 130, lr: 0.0008000000000000003 -----\n","Epoch: [130][  0/391]\tTime  0.270 ( 0.270)\tLoss 6.4584e-02 (6.4584e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [130][ 30/391]\tTime  0.176 ( 0.177)\tLoss 7.4677e-02 (5.9108e-02)\tAcc@1  98.44 ( 98.49)\tAcc@5  99.22 ( 99.92)\n","Epoch: [130][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.4844e-02 (5.8005e-02)\tAcc@1 100.00 ( 98.60)\tAcc@5 100.00 ( 99.91)\n","Epoch: [130][ 90/391]\tTime  0.172 ( 0.175)\tLoss 4.9182e-02 (5.4269e-02)\tAcc@1  98.44 ( 98.77)\tAcc@5 100.00 ( 99.94)\n","Epoch: [130][120/391]\tTime  0.168 ( 0.174)\tLoss 2.5010e-02 (5.4745e-02)\tAcc@1  99.22 ( 98.79)\tAcc@5 100.00 ( 99.92)\n","Epoch: [130][150/391]\tTime  0.176 ( 0.174)\tLoss 3.4662e-02 (5.4229e-02)\tAcc@1 100.00 ( 98.79)\tAcc@5 100.00 ( 99.92)\n","Epoch: [130][180/391]\tTime  0.175 ( 0.174)\tLoss 6.5102e-02 (5.5189e-02)\tAcc@1  98.44 ( 98.76)\tAcc@5 100.00 ( 99.94)\n","Epoch: [130][210/391]\tTime  0.174 ( 0.174)\tLoss 4.0825e-02 (5.5309e-02)\tAcc@1  98.44 ( 98.76)\tAcc@5 100.00 ( 99.93)\n","Epoch: [130][240/391]\tTime  0.173 ( 0.174)\tLoss 2.3726e-02 (5.4013e-02)\tAcc@1 100.00 ( 98.80)\tAcc@5 100.00 ( 99.93)\n","Epoch: [130][270/391]\tTime  0.174 ( 0.174)\tLoss 2.8020e-02 (5.3832e-02)\tAcc@1  99.22 ( 98.80)\tAcc@5 100.00 ( 99.94)\n","Epoch: [130][300/391]\tTime  0.172 ( 0.174)\tLoss 1.9179e-02 (5.4655e-02)\tAcc@1 100.00 ( 98.77)\tAcc@5 100.00 ( 99.94)\n","Epoch: [130][330/391]\tTime  0.175 ( 0.174)\tLoss 1.2200e-01 (5.4951e-02)\tAcc@1  97.66 ( 98.75)\tAcc@5  98.44 ( 99.93)\n","Epoch: [130][360/391]\tTime  0.174 ( 0.174)\tLoss 6.2617e-02 (5.4922e-02)\tAcc@1  99.22 ( 98.75)\tAcc@5 100.00 ( 99.94)\n","Epoch: [130][390/391]\tTime  0.157 ( 0.174)\tLoss 8.9003e-02 (5.4690e-02)\tAcc@1  97.50 ( 98.76)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 98.756 || Acc@5 99.934\n","==> Test Accuracy:  Acc@1 77.640 || Acc@5 94.310\n","==> 72.31 seconds to train this epoch\n","\n","\n","----- epoch: 131, lr: 0.0008000000000000003 -----\n","Epoch: [131][  0/391]\tTime  0.285 ( 0.285)\tLoss 6.8855e-02 (6.8855e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [131][ 30/391]\tTime  0.174 ( 0.177)\tLoss 9.3265e-02 (5.7939e-02)\tAcc@1  96.09 ( 98.51)\tAcc@5 100.00 ( 99.95)\n","Epoch: [131][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.7697e-02 (5.5270e-02)\tAcc@1  98.44 ( 98.67)\tAcc@5 100.00 ( 99.95)\n","Epoch: [131][ 90/391]\tTime  0.174 ( 0.175)\tLoss 4.4765e-02 (5.1894e-02)\tAcc@1 100.00 ( 98.79)\tAcc@5 100.00 ( 99.97)\n","Epoch: [131][120/391]\tTime  0.175 ( 0.175)\tLoss 6.4079e-02 (5.1074e-02)\tAcc@1  98.44 ( 98.88)\tAcc@5  99.22 ( 99.94)\n","Epoch: [131][150/391]\tTime  0.174 ( 0.174)\tLoss 2.8811e-02 (5.1015e-02)\tAcc@1 100.00 ( 98.87)\tAcc@5 100.00 ( 99.93)\n","Epoch: [131][180/391]\tTime  0.172 ( 0.174)\tLoss 3.2779e-02 (5.2755e-02)\tAcc@1  99.22 ( 98.84)\tAcc@5 100.00 ( 99.92)\n","Epoch: [131][210/391]\tTime  0.174 ( 0.174)\tLoss 8.5074e-02 (5.2184e-02)\tAcc@1  98.44 ( 98.86)\tAcc@5 100.00 ( 99.92)\n","Epoch: [131][240/391]\tTime  0.174 ( 0.174)\tLoss 6.1868e-02 (5.1810e-02)\tAcc@1  98.44 ( 98.87)\tAcc@5 100.00 ( 99.92)\n","Epoch: [131][270/391]\tTime  0.176 ( 0.174)\tLoss 4.8052e-02 (5.1906e-02)\tAcc@1  98.44 ( 98.87)\tAcc@5 100.00 ( 99.92)\n","Epoch: [131][300/391]\tTime  0.172 ( 0.174)\tLoss 3.0198e-02 (5.2318e-02)\tAcc@1  99.22 ( 98.86)\tAcc@5 100.00 ( 99.92)\n","Epoch: [131][330/391]\tTime  0.173 ( 0.174)\tLoss 3.3278e-02 (5.2927e-02)\tAcc@1  99.22 ( 98.86)\tAcc@5 100.00 ( 99.92)\n","Epoch: [131][360/391]\tTime  0.176 ( 0.174)\tLoss 7.3829e-02 (5.2729e-02)\tAcc@1  96.09 ( 98.85)\tAcc@5 100.00 ( 99.93)\n","Epoch: [131][390/391]\tTime  0.158 ( 0.174)\tLoss 5.9244e-02 (5.2351e-02)\tAcc@1  98.75 ( 98.87)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 98.868 || Acc@5 99.928\n","==> Test Accuracy:  Acc@1 77.780 || Acc@5 94.180\n","==> 72.30 seconds to train this epoch\n","\n","\n","----- epoch: 132, lr: 0.0008000000000000003 -----\n","Epoch: [132][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.0441e-01 (1.0441e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [132][ 30/391]\tTime  0.173 ( 0.177)\tLoss 6.8305e-02 (5.4356e-02)\tAcc@1  98.44 ( 98.74)\tAcc@5 100.00 ( 99.92)\n","Epoch: [132][ 60/391]\tTime  0.173 ( 0.175)\tLoss 5.0531e-02 (5.0493e-02)\tAcc@1  99.22 ( 98.86)\tAcc@5 100.00 ( 99.95)\n","Epoch: [132][ 90/391]\tTime  0.173 ( 0.175)\tLoss 6.8061e-02 (5.0066e-02)\tAcc@1  98.44 ( 98.89)\tAcc@5 100.00 ( 99.95)\n","Epoch: [132][120/391]\tTime  0.173 ( 0.175)\tLoss 4.9423e-02 (4.9355e-02)\tAcc@1  98.44 ( 98.92)\tAcc@5 100.00 ( 99.96)\n","Epoch: [132][150/391]\tTime  0.176 ( 0.174)\tLoss 3.3788e-02 (4.8939e-02)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 ( 99.96)\n","Epoch: [132][180/391]\tTime  0.175 ( 0.174)\tLoss 4.3653e-02 (4.8805e-02)\tAcc@1  99.22 ( 98.95)\tAcc@5 100.00 ( 99.97)\n","Epoch: [132][210/391]\tTime  0.172 ( 0.174)\tLoss 5.1166e-02 (5.0003e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.96)\n","Epoch: [132][240/391]\tTime  0.173 ( 0.174)\tLoss 4.0214e-02 (5.0253e-02)\tAcc@1  98.44 ( 98.93)\tAcc@5 100.00 ( 99.96)\n","Epoch: [132][270/391]\tTime  0.172 ( 0.174)\tLoss 2.4948e-02 (5.0316e-02)\tAcc@1 100.00 ( 98.92)\tAcc@5 100.00 ( 99.95)\n","Epoch: [132][300/391]\tTime  0.177 ( 0.174)\tLoss 4.4783e-02 (5.0509e-02)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [132][330/391]\tTime  0.173 ( 0.174)\tLoss 4.0910e-02 (5.1018e-02)\tAcc@1 100.00 ( 98.88)\tAcc@5 100.00 ( 99.94)\n","Epoch: [132][360/391]\tTime  0.175 ( 0.174)\tLoss 7.2600e-02 (5.0941e-02)\tAcc@1  96.88 ( 98.88)\tAcc@5  99.22 ( 99.94)\n","Epoch: [132][390/391]\tTime  0.157 ( 0.174)\tLoss 4.8006e-02 (5.0907e-02)\tAcc@1  97.50 ( 98.87)\tAcc@5 100.00 ( 99.94)\n","==> Train Accuracy: Acc@1 98.866 || Acc@5 99.944\n","==> Test Accuracy:  Acc@1 77.850 || Acc@5 94.310\n","==> 72.38 seconds to train this epoch\n","\n","\n","----- epoch: 133, lr: 0.0008000000000000003 -----\n","Epoch: [133][  0/391]\tTime  0.258 ( 0.258)\tLoss 5.5071e-02 (5.5071e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [133][ 30/391]\tTime  0.174 ( 0.177)\tLoss 1.0818e-01 (5.4365e-02)\tAcc@1  97.66 ( 98.79)\tAcc@5 100.00 ( 99.92)\n","Epoch: [133][ 60/391]\tTime  0.173 ( 0.175)\tLoss 4.1808e-02 (5.3317e-02)\tAcc@1  99.22 ( 98.78)\tAcc@5 100.00 ( 99.95)\n","Epoch: [133][ 90/391]\tTime  0.174 ( 0.175)\tLoss 6.9385e-02 (5.3628e-02)\tAcc@1  99.22 ( 98.79)\tAcc@5 100.00 ( 99.95)\n","Epoch: [133][120/391]\tTime  0.176 ( 0.175)\tLoss 2.8662e-02 (5.3957e-02)\tAcc@1  99.22 ( 98.82)\tAcc@5 100.00 ( 99.93)\n","Epoch: [133][150/391]\tTime  0.175 ( 0.174)\tLoss 3.3930e-02 (5.2487e-02)\tAcc@1 100.00 ( 98.88)\tAcc@5 100.00 ( 99.94)\n","Epoch: [133][180/391]\tTime  0.174 ( 0.174)\tLoss 6.0019e-02 (5.1558e-02)\tAcc@1  99.22 ( 98.91)\tAcc@5 100.00 ( 99.94)\n","Epoch: [133][210/391]\tTime  0.171 ( 0.174)\tLoss 9.4573e-02 (5.1845e-02)\tAcc@1  97.66 ( 98.89)\tAcc@5  99.22 ( 99.93)\n","Epoch: [133][240/391]\tTime  0.174 ( 0.174)\tLoss 3.8622e-02 (5.1569e-02)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 ( 99.93)\n","Epoch: [133][270/391]\tTime  0.175 ( 0.174)\tLoss 4.6148e-02 (5.1495e-02)\tAcc@1  99.22 ( 98.89)\tAcc@5 100.00 ( 99.93)\n","Epoch: [133][300/391]\tTime  0.172 ( 0.174)\tLoss 4.6495e-02 (5.1609e-02)\tAcc@1  99.22 ( 98.88)\tAcc@5  99.22 ( 99.94)\n","Epoch: [133][330/391]\tTime  0.175 ( 0.174)\tLoss 3.3149e-02 (5.1714e-02)\tAcc@1  99.22 ( 98.86)\tAcc@5 100.00 ( 99.94)\n","Epoch: [133][360/391]\tTime  0.174 ( 0.174)\tLoss 6.6777e-02 (5.1761e-02)\tAcc@1  98.44 ( 98.85)\tAcc@5  99.22 ( 99.94)\n","Epoch: [133][390/391]\tTime  0.158 ( 0.174)\tLoss 4.5636e-02 (5.1616e-02)\tAcc@1 100.00 ( 98.86)\tAcc@5 100.00 ( 99.94)\n","==> Train Accuracy: Acc@1 98.856 || Acc@5 99.944\n","==> Test Accuracy:  Acc@1 77.720 || Acc@5 94.200\n","==> 72.40 seconds to train this epoch\n","\n","\n","----- epoch: 134, lr: 0.0008000000000000003 -----\n","Epoch: [134][  0/391]\tTime  0.263 ( 0.263)\tLoss 7.5433e-02 (7.5433e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5  99.22 ( 99.22)\n","Epoch: [134][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.6298e-02 (5.3446e-02)\tAcc@1 100.00 ( 98.99)\tAcc@5 100.00 ( 99.92)\n","Epoch: [134][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.0574e-02 (5.2352e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.92)\n","Epoch: [134][ 90/391]\tTime  0.174 ( 0.175)\tLoss 6.8404e-02 (5.1887e-02)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 ( 99.92)\n","Epoch: [134][120/391]\tTime  0.173 ( 0.175)\tLoss 7.5607e-02 (5.1962e-02)\tAcc@1  98.44 ( 98.89)\tAcc@5 100.00 ( 99.94)\n","Epoch: [134][150/391]\tTime  0.174 ( 0.175)\tLoss 4.9350e-02 (5.2805e-02)\tAcc@1  99.22 ( 98.82)\tAcc@5 100.00 ( 99.93)\n","Epoch: [134][180/391]\tTime  0.175 ( 0.174)\tLoss 2.1633e-02 (5.1854e-02)\tAcc@1 100.00 ( 98.85)\tAcc@5 100.00 ( 99.94)\n","Epoch: [134][210/391]\tTime  0.177 ( 0.174)\tLoss 4.7206e-02 (5.2250e-02)\tAcc@1  98.44 ( 98.82)\tAcc@5 100.00 ( 99.94)\n","Epoch: [134][240/391]\tTime  0.174 ( 0.174)\tLoss 4.1610e-02 (5.2068e-02)\tAcc@1  98.44 ( 98.81)\tAcc@5 100.00 ( 99.95)\n","Epoch: [134][270/391]\tTime  0.174 ( 0.174)\tLoss 6.0605e-02 (5.2194e-02)\tAcc@1  99.22 ( 98.81)\tAcc@5 100.00 ( 99.96)\n","Epoch: [134][300/391]\tTime  0.173 ( 0.174)\tLoss 5.2529e-02 (5.2114e-02)\tAcc@1  98.44 ( 98.83)\tAcc@5 100.00 ( 99.95)\n","Epoch: [134][330/391]\tTime  0.174 ( 0.174)\tLoss 3.2529e-02 (5.1192e-02)\tAcc@1  99.22 ( 98.85)\tAcc@5 100.00 ( 99.96)\n","Epoch: [134][360/391]\tTime  0.174 ( 0.174)\tLoss 7.1600e-02 (5.1132e-02)\tAcc@1  97.66 ( 98.85)\tAcc@5 100.00 ( 99.95)\n","Epoch: [134][390/391]\tTime  0.159 ( 0.174)\tLoss 9.3923e-02 (5.1812e-02)\tAcc@1  97.50 ( 98.83)\tAcc@5 100.00 ( 99.95)\n","==> Train Accuracy: Acc@1 98.828 || Acc@5 99.950\n","==> Test Accuracy:  Acc@1 77.630 || Acc@5 93.970\n","==> 72.42 seconds to train this epoch\n","\n","\n","----- epoch: 135, lr: 0.0008000000000000003 -----\n","Epoch: [135][  0/391]\tTime  0.294 ( 0.294)\tLoss 5.4769e-02 (5.4769e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [135][ 30/391]\tTime  0.176 ( 0.178)\tLoss 5.4423e-02 (4.9174e-02)\tAcc@1  97.66 ( 98.87)\tAcc@5 100.00 ( 99.97)\n","Epoch: [135][ 60/391]\tTime  0.171 ( 0.176)\tLoss 3.2615e-02 (5.0967e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.94)\n","Epoch: [135][ 90/391]\tTime  0.171 ( 0.175)\tLoss 6.1520e-02 (4.9871e-02)\tAcc@1  98.44 ( 98.98)\tAcc@5 100.00 ( 99.95)\n","Epoch: [135][120/391]\tTime  0.173 ( 0.175)\tLoss 5.9079e-02 (5.0416e-02)\tAcc@1  98.44 ( 98.97)\tAcc@5 100.00 ( 99.94)\n","Epoch: [135][150/391]\tTime  0.174 ( 0.175)\tLoss 3.2646e-02 (5.0819e-02)\tAcc@1 100.00 ( 98.95)\tAcc@5 100.00 ( 99.94)\n","Epoch: [135][180/391]\tTime  0.173 ( 0.175)\tLoss 3.8070e-02 (4.9508e-02)\tAcc@1 100.00 ( 99.00)\tAcc@5 100.00 ( 99.95)\n","Epoch: [135][210/391]\tTime  0.176 ( 0.174)\tLoss 3.5532e-02 (5.0061e-02)\tAcc@1  99.22 ( 98.93)\tAcc@5 100.00 ( 99.95)\n","Epoch: [135][240/391]\tTime  0.173 ( 0.174)\tLoss 2.7699e-02 (5.0780e-02)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.94)\n","Epoch: [135][270/391]\tTime  0.176 ( 0.174)\tLoss 6.2613e-02 (5.1491e-02)\tAcc@1  99.22 ( 98.88)\tAcc@5  99.22 ( 99.93)\n","Epoch: [135][300/391]\tTime  0.175 ( 0.174)\tLoss 3.4129e-02 (5.1119e-02)\tAcc@1  99.22 ( 98.89)\tAcc@5 100.00 ( 99.94)\n","Epoch: [135][330/391]\tTime  0.173 ( 0.174)\tLoss 4.2827e-02 (5.0755e-02)\tAcc@1  98.44 ( 98.89)\tAcc@5 100.00 ( 99.94)\n","Epoch: [135][360/391]\tTime  0.174 ( 0.174)\tLoss 3.6537e-02 (5.0377e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.95)\n","Epoch: [135][390/391]\tTime  0.154 ( 0.174)\tLoss 2.3029e-02 (5.0517e-02)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.94)\n","==> Train Accuracy: Acc@1 98.906 || Acc@5 99.942\n","==> Test Accuracy:  Acc@1 77.920 || Acc@5 94.070\n","==> 72.44 seconds to train this epoch\n","\n","\n","----- epoch: 136, lr: 0.0008000000000000003 -----\n","Epoch: [136][  0/391]\tTime  0.257 ( 0.257)\tLoss 3.7784e-02 (3.7784e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [136][ 30/391]\tTime  0.174 ( 0.176)\tLoss 5.2057e-02 (4.2273e-02)\tAcc@1  98.44 ( 99.22)\tAcc@5 100.00 ( 99.95)\n","Epoch: [136][ 60/391]\tTime  0.175 ( 0.175)\tLoss 4.5729e-02 (4.9287e-02)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [136][ 90/391]\tTime  0.175 ( 0.175)\tLoss 5.6315e-02 (5.0845e-02)\tAcc@1  99.22 ( 98.91)\tAcc@5 100.00 ( 99.96)\n","Epoch: [136][120/391]\tTime  0.176 ( 0.175)\tLoss 5.4422e-02 (5.2090e-02)\tAcc@1  97.66 ( 98.87)\tAcc@5 100.00 ( 99.94)\n","Epoch: [136][150/391]\tTime  0.174 ( 0.174)\tLoss 4.3935e-02 (5.1552e-02)\tAcc@1  98.44 ( 98.89)\tAcc@5 100.00 ( 99.94)\n","Epoch: [136][180/391]\tTime  0.173 ( 0.174)\tLoss 4.5018e-02 (5.0744e-02)\tAcc@1  99.22 ( 98.90)\tAcc@5  99.22 ( 99.94)\n","Epoch: [136][210/391]\tTime  0.174 ( 0.174)\tLoss 4.1139e-02 (4.9947e-02)\tAcc@1  99.22 ( 98.95)\tAcc@5 100.00 ( 99.95)\n","Epoch: [136][240/391]\tTime  0.173 ( 0.174)\tLoss 5.0817e-02 (5.0224e-02)\tAcc@1  96.88 ( 98.92)\tAcc@5 100.00 ( 99.94)\n","Epoch: [136][270/391]\tTime  0.177 ( 0.174)\tLoss 5.9990e-02 (4.9979e-02)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 ( 99.94)\n","Epoch: [136][300/391]\tTime  0.172 ( 0.174)\tLoss 2.7739e-02 (4.9597e-02)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.94)\n","Epoch: [136][330/391]\tTime  0.174 ( 0.174)\tLoss 4.3391e-02 (5.0549e-02)\tAcc@1  98.44 ( 98.88)\tAcc@5 100.00 ( 99.94)\n","Epoch: [136][360/391]\tTime  0.176 ( 0.174)\tLoss 6.1916e-02 (5.0771e-02)\tAcc@1  98.44 ( 98.85)\tAcc@5 100.00 ( 99.94)\n","Epoch: [136][390/391]\tTime  0.156 ( 0.174)\tLoss 5.9896e-02 (5.0670e-02)\tAcc@1  97.50 ( 98.84)\tAcc@5 100.00 ( 99.94)\n","==> Train Accuracy: Acc@1 98.842 || Acc@5 99.938\n","==> Test Accuracy:  Acc@1 77.630 || Acc@5 94.190\n","==> 72.38 seconds to train this epoch\n","\n","\n","----- epoch: 137, lr: 0.0008000000000000003 -----\n","Epoch: [137][  0/391]\tTime  0.289 ( 0.289)\tLoss 5.1558e-02 (5.1558e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [137][ 30/391]\tTime  0.173 ( 0.177)\tLoss 1.2546e-01 (4.7109e-02)\tAcc@1  96.88 ( 98.94)\tAcc@5 100.00 ( 99.90)\n","Epoch: [137][ 60/391]\tTime  0.172 ( 0.175)\tLoss 6.7902e-02 (4.8830e-02)\tAcc@1  99.22 ( 98.91)\tAcc@5 100.00 ( 99.90)\n","Epoch: [137][ 90/391]\tTime  0.175 ( 0.175)\tLoss 4.0695e-02 (4.7234e-02)\tAcc@1  99.22 ( 98.99)\tAcc@5 100.00 ( 99.91)\n","Epoch: [137][120/391]\tTime  0.175 ( 0.175)\tLoss 2.1263e-02 (4.5922e-02)\tAcc@1  99.22 ( 99.04)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][150/391]\tTime  0.172 ( 0.175)\tLoss 4.9665e-02 (4.5710e-02)\tAcc@1  99.22 ( 99.04)\tAcc@5  99.22 ( 99.93)\n","Epoch: [137][180/391]\tTime  0.171 ( 0.174)\tLoss 1.4749e-02 (4.6172e-02)\tAcc@1 100.00 ( 99.03)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][210/391]\tTime  0.174 ( 0.174)\tLoss 4.1991e-02 (4.5812e-02)\tAcc@1  98.44 ( 99.02)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][240/391]\tTime  0.176 ( 0.174)\tLoss 1.4991e-02 (4.6127e-02)\tAcc@1 100.00 ( 99.03)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][270/391]\tTime  0.174 ( 0.174)\tLoss 3.4981e-02 (4.7075e-02)\tAcc@1  99.22 ( 99.01)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][300/391]\tTime  0.175 ( 0.174)\tLoss 4.6593e-02 (4.6824e-02)\tAcc@1  99.22 ( 99.01)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][330/391]\tTime  0.173 ( 0.174)\tLoss 4.8697e-02 (4.6703e-02)\tAcc@1  98.44 ( 99.01)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][360/391]\tTime  0.173 ( 0.174)\tLoss 4.2370e-02 (4.6733e-02)\tAcc@1  99.22 ( 99.02)\tAcc@5 100.00 ( 99.94)\n","Epoch: [137][390/391]\tTime  0.156 ( 0.174)\tLoss 6.7177e-02 (4.6780e-02)\tAcc@1  97.50 ( 98.99)\tAcc@5 100.00 ( 99.95)\n","==> Train Accuracy: Acc@1 98.990 || Acc@5 99.946\n","==> Test Accuracy:  Acc@1 77.920 || Acc@5 94.150\n","==> 72.37 seconds to train this epoch\n","\n","\n","----- epoch: 138, lr: 0.0008000000000000003 -----\n","Epoch: [138][  0/391]\tTime  0.247 ( 0.247)\tLoss 3.6294e-02 (3.6294e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [138][ 30/391]\tTime  0.172 ( 0.176)\tLoss 3.6191e-02 (4.9381e-02)\tAcc@1  99.22 ( 98.99)\tAcc@5 100.00 ( 99.95)\n","Epoch: [138][ 60/391]\tTime  0.175 ( 0.175)\tLoss 2.5825e-02 (4.8308e-02)\tAcc@1 100.00 ( 99.05)\tAcc@5 100.00 ( 99.95)\n","Epoch: [138][ 90/391]\tTime  0.173 ( 0.175)\tLoss 5.5883e-02 (4.7044e-02)\tAcc@1  97.66 ( 99.04)\tAcc@5 100.00 ( 99.95)\n","Epoch: [138][120/391]\tTime  0.171 ( 0.174)\tLoss 2.9722e-02 (4.8856e-02)\tAcc@1 100.00 ( 98.97)\tAcc@5 100.00 ( 99.95)\n","Epoch: [138][150/391]\tTime  0.173 ( 0.174)\tLoss 5.1519e-02 (4.7745e-02)\tAcc@1  97.66 ( 99.01)\tAcc@5 100.00 ( 99.95)\n","Epoch: [138][180/391]\tTime  0.174 ( 0.174)\tLoss 4.9560e-02 (4.8453e-02)\tAcc@1  99.22 ( 98.99)\tAcc@5 100.00 ( 99.94)\n","Epoch: [138][210/391]\tTime  0.175 ( 0.174)\tLoss 1.9869e-02 (4.8735e-02)\tAcc@1 100.00 ( 98.98)\tAcc@5 100.00 ( 99.94)\n","Epoch: [138][240/391]\tTime  0.173 ( 0.174)\tLoss 5.6277e-02 (4.8842e-02)\tAcc@1  98.44 ( 98.96)\tAcc@5 100.00 ( 99.94)\n","Epoch: [138][270/391]\tTime  0.175 ( 0.174)\tLoss 4.5711e-02 (4.8651e-02)\tAcc@1 100.00 ( 98.96)\tAcc@5 100.00 ( 99.94)\n","Epoch: [138][300/391]\tTime  0.175 ( 0.174)\tLoss 8.4423e-02 (4.8877e-02)\tAcc@1  97.66 ( 98.95)\tAcc@5  99.22 ( 99.94)\n","Epoch: [138][330/391]\tTime  0.172 ( 0.174)\tLoss 2.4581e-02 (4.9168e-02)\tAcc@1  99.22 ( 98.94)\tAcc@5 100.00 ( 99.94)\n","Epoch: [138][360/391]\tTime  0.173 ( 0.174)\tLoss 7.6087e-02 (4.9184e-02)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 ( 99.94)\n","Epoch: [138][390/391]\tTime  0.156 ( 0.174)\tLoss 4.7127e-02 (4.9369e-02)\tAcc@1 100.00 ( 98.95)\tAcc@5 100.00 ( 99.94)\n","==> Train Accuracy: Acc@1 98.946 || Acc@5 99.944\n","==> Test Accuracy:  Acc@1 77.710 || Acc@5 94.150\n","==> 72.28 seconds to train this epoch\n","\n","\n","----- epoch: 139, lr: 0.0008000000000000003 -----\n","Epoch: [139][  0/391]\tTime  0.262 ( 0.262)\tLoss 6.3095e-02 (6.3095e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [139][ 30/391]\tTime  0.175 ( 0.176)\tLoss 3.7400e-02 (5.5670e-02)\tAcc@1  99.22 ( 98.46)\tAcc@5 100.00 ( 99.97)\n","Epoch: [139][ 60/391]\tTime  0.171 ( 0.175)\tLoss 2.3003e-02 (5.4768e-02)\tAcc@1 100.00 ( 98.69)\tAcc@5 100.00 ( 99.96)\n","Epoch: [139][ 90/391]\tTime  0.174 ( 0.175)\tLoss 3.2401e-02 (5.0815e-02)\tAcc@1  99.22 ( 98.82)\tAcc@5 100.00 ( 99.97)\n","Epoch: [139][120/391]\tTime  0.174 ( 0.174)\tLoss 6.1313e-02 (5.1663e-02)\tAcc@1  97.66 ( 98.79)\tAcc@5 100.00 ( 99.97)\n","Epoch: [139][150/391]\tTime  0.174 ( 0.174)\tLoss 7.6943e-02 (5.0470e-02)\tAcc@1  97.66 ( 98.79)\tAcc@5  99.22 ( 99.96)\n","Epoch: [139][180/391]\tTime  0.175 ( 0.174)\tLoss 3.3976e-02 (4.9828e-02)\tAcc@1  99.22 ( 98.83)\tAcc@5 100.00 ( 99.97)\n","Epoch: [139][210/391]\tTime  0.172 ( 0.174)\tLoss 3.1958e-02 (4.8228e-02)\tAcc@1  99.22 ( 98.87)\tAcc@5 100.00 ( 99.97)\n","Epoch: [139][240/391]\tTime  0.175 ( 0.174)\tLoss 3.3765e-02 (4.8019e-02)\tAcc@1  98.44 ( 98.89)\tAcc@5 100.00 ( 99.97)\n","Epoch: [139][270/391]\tTime  0.172 ( 0.174)\tLoss 4.6919e-02 (4.7717e-02)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.97)\n","Epoch: [139][300/391]\tTime  0.172 ( 0.174)\tLoss 5.6962e-02 (4.8199e-02)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 ( 99.96)\n","Epoch: [139][330/391]\tTime  0.175 ( 0.174)\tLoss 5.8294e-02 (4.8386e-02)\tAcc@1  98.44 ( 98.89)\tAcc@5 100.00 ( 99.96)\n","Epoch: [139][360/391]\tTime  0.175 ( 0.174)\tLoss 3.5747e-02 (4.8465e-02)\tAcc@1  99.22 ( 98.88)\tAcc@5 100.00 ( 99.96)\n","Epoch: [139][390/391]\tTime  0.159 ( 0.174)\tLoss 6.1125e-02 (4.8481e-02)\tAcc@1  98.75 ( 98.89)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 98.888 || Acc@5 99.960\n","==> Test Accuracy:  Acc@1 77.770 || Acc@5 94.110\n","==> 72.28 seconds to train this epoch\n","\n","\n","----- epoch: 140, lr: 0.0008000000000000003 -----\n","Epoch: [140][  0/391]\tTime  0.262 ( 0.262)\tLoss 2.5178e-02 (2.5178e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [140][ 30/391]\tTime  0.172 ( 0.176)\tLoss 1.7317e-02 (4.3108e-02)\tAcc@1 100.00 ( 99.09)\tAcc@5 100.00 ( 99.95)\n","Epoch: [140][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.9395e-02 (4.4226e-02)\tAcc@1  99.22 ( 99.01)\tAcc@5 100.00 ( 99.94)\n","Epoch: [140][ 90/391]\tTime  0.175 ( 0.175)\tLoss 4.6178e-02 (4.7176e-02)\tAcc@1  97.66 ( 98.93)\tAcc@5 100.00 ( 99.93)\n","Epoch: [140][120/391]\tTime  0.174 ( 0.174)\tLoss 6.3769e-02 (4.7835e-02)\tAcc@1  97.66 ( 98.93)\tAcc@5 100.00 ( 99.94)\n","Epoch: [140][150/391]\tTime  0.175 ( 0.174)\tLoss 3.3085e-02 (4.7737e-02)\tAcc@1  99.22 ( 98.93)\tAcc@5 100.00 ( 99.94)\n","Epoch: [140][180/391]\tTime  0.172 ( 0.174)\tLoss 1.7859e-02 (4.7911e-02)\tAcc@1 100.00 ( 98.92)\tAcc@5 100.00 ( 99.94)\n","Epoch: [140][210/391]\tTime  0.173 ( 0.174)\tLoss 4.0663e-02 (4.7663e-02)\tAcc@1  99.22 ( 98.94)\tAcc@5 100.00 ( 99.94)\n","Epoch: [140][240/391]\tTime  0.173 ( 0.174)\tLoss 5.8814e-02 (4.7438e-02)\tAcc@1  98.44 ( 98.96)\tAcc@5 100.00 ( 99.94)\n","Epoch: [140][270/391]\tTime  0.171 ( 0.174)\tLoss 7.8365e-02 (4.6944e-02)\tAcc@1  98.44 ( 98.96)\tAcc@5 100.00 ( 99.95)\n","Epoch: [140][300/391]\tTime  0.175 ( 0.174)\tLoss 5.5445e-02 (4.7647e-02)\tAcc@1  98.44 ( 98.93)\tAcc@5 100.00 ( 99.95)\n","Epoch: [140][330/391]\tTime  0.173 ( 0.174)\tLoss 3.1556e-02 (4.7204e-02)\tAcc@1  99.22 ( 98.95)\tAcc@5 100.00 ( 99.95)\n","Epoch: [140][360/391]\tTime  0.172 ( 0.174)\tLoss 2.6435e-02 (4.7327e-02)\tAcc@1  99.22 ( 98.95)\tAcc@5 100.00 ( 99.95)\n","Epoch: [140][390/391]\tTime  0.158 ( 0.174)\tLoss 4.6454e-02 (4.7791e-02)\tAcc@1 100.00 ( 98.93)\tAcc@5 100.00 ( 99.95)\n","==> Train Accuracy: Acc@1 98.930 || Acc@5 99.946\n","==> Test Accuracy:  Acc@1 77.690 || Acc@5 94.290\n","==> 72.26 seconds to train this epoch\n","\n","\n","----- epoch: 141, lr: 0.0008000000000000003 -----\n","Epoch: [141][  0/391]\tTime  0.261 ( 0.261)\tLoss 8.7891e-02 (8.7891e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [141][ 30/391]\tTime  0.169 ( 0.176)\tLoss 7.0528e-02 (4.0257e-02)\tAcc@1  98.44 ( 99.14)\tAcc@5 100.00 (100.00)\n","Epoch: [141][ 60/391]\tTime  0.173 ( 0.175)\tLoss 4.8618e-02 (4.4410e-02)\tAcc@1  98.44 ( 98.99)\tAcc@5 100.00 ( 99.97)\n","Epoch: [141][ 90/391]\tTime  0.175 ( 0.175)\tLoss 3.5704e-02 (4.5890e-02)\tAcc@1  99.22 ( 98.98)\tAcc@5 100.00 ( 99.97)\n","Epoch: [141][120/391]\tTime  0.174 ( 0.174)\tLoss 3.2897e-02 (4.5644e-02)\tAcc@1  99.22 ( 99.01)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][150/391]\tTime  0.174 ( 0.174)\tLoss 5.5705e-02 (4.5619e-02)\tAcc@1  98.44 ( 99.03)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][180/391]\tTime  0.175 ( 0.174)\tLoss 3.7018e-02 (4.6159e-02)\tAcc@1  99.22 ( 99.02)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][210/391]\tTime  0.174 ( 0.174)\tLoss 4.4744e-02 (4.6192e-02)\tAcc@1  99.22 ( 99.00)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][240/391]\tTime  0.174 ( 0.174)\tLoss 4.8739e-02 (4.6719e-02)\tAcc@1  98.44 ( 98.99)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][270/391]\tTime  0.173 ( 0.174)\tLoss 2.6721e-02 (4.6417e-02)\tAcc@1  99.22 ( 99.01)\tAcc@5 100.00 ( 99.97)\n","Epoch: [141][300/391]\tTime  0.175 ( 0.174)\tLoss 7.4812e-02 (4.6705e-02)\tAcc@1  96.88 ( 99.01)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][330/391]\tTime  0.174 ( 0.174)\tLoss 5.7561e-02 (4.6827e-02)\tAcc@1  99.22 ( 99.03)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][360/391]\tTime  0.176 ( 0.174)\tLoss 4.1250e-02 (4.7094e-02)\tAcc@1  99.22 ( 99.02)\tAcc@5 100.00 ( 99.96)\n","Epoch: [141][390/391]\tTime  0.156 ( 0.174)\tLoss 2.7836e-02 (4.7187e-02)\tAcc@1 100.00 ( 99.02)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 99.016 || Acc@5 99.960\n","==> Test Accuracy:  Acc@1 77.660 || Acc@5 94.250\n","==> 72.34 seconds to train this epoch\n","\n","\n","----- epoch: 142, lr: 0.0008000000000000003 -----\n","Epoch: [142][  0/391]\tTime  0.256 ( 0.256)\tLoss 4.1700e-02 (4.1700e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [142][ 30/391]\tTime  0.176 ( 0.176)\tLoss 3.7384e-02 (4.5103e-02)\tAcc@1 100.00 ( 99.04)\tAcc@5 100.00 (100.00)\n","Epoch: [142][ 60/391]\tTime  0.173 ( 0.175)\tLoss 1.7908e-02 (4.7999e-02)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][ 90/391]\tTime  0.173 ( 0.174)\tLoss 4.4010e-02 (4.7587e-02)\tAcc@1  99.22 ( 98.95)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][120/391]\tTime  0.172 ( 0.174)\tLoss 1.4663e-02 (4.6840e-02)\tAcc@1 100.00 ( 98.97)\tAcc@5 100.00 ( 99.98)\n","Epoch: [142][150/391]\tTime  0.172 ( 0.174)\tLoss 2.7778e-02 (4.7049e-02)\tAcc@1  98.44 ( 98.93)\tAcc@5 100.00 ( 99.98)\n","Epoch: [142][180/391]\tTime  0.175 ( 0.174)\tLoss 4.3197e-02 (4.7036e-02)\tAcc@1  99.22 ( 98.93)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][210/391]\tTime  0.177 ( 0.174)\tLoss 3.4376e-02 (4.6225e-02)\tAcc@1  99.22 ( 98.98)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][240/391]\tTime  0.173 ( 0.174)\tLoss 9.7144e-02 (4.6123e-02)\tAcc@1  97.66 ( 98.98)\tAcc@5 100.00 ( 99.96)\n","Epoch: [142][270/391]\tTime  0.173 ( 0.174)\tLoss 5.0326e-02 (4.5769e-02)\tAcc@1  98.44 ( 99.00)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][300/391]\tTime  0.174 ( 0.174)\tLoss 2.2240e-02 (4.5040e-02)\tAcc@1 100.00 ( 99.03)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][330/391]\tTime  0.175 ( 0.174)\tLoss 6.3531e-02 (4.5918e-02)\tAcc@1  98.44 ( 99.00)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][360/391]\tTime  0.174 ( 0.174)\tLoss 2.9737e-02 (4.6022e-02)\tAcc@1  99.22 ( 99.00)\tAcc@5 100.00 ( 99.97)\n","Epoch: [142][390/391]\tTime  0.162 ( 0.174)\tLoss 3.2744e-02 (4.6155e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.97)\n","==> Train Accuracy: Acc@1 99.014 || Acc@5 99.966\n","==> Test Accuracy:  Acc@1 77.630 || Acc@5 94.130\n","==> 72.25 seconds to train this epoch\n","\n","\n","----- epoch: 143, lr: 0.0008000000000000003 -----\n","Epoch: [143][  0/391]\tTime  0.262 ( 0.262)\tLoss 6.2270e-02 (6.2270e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [143][ 30/391]\tTime  0.177 ( 0.176)\tLoss 2.5983e-02 (4.7018e-02)\tAcc@1  99.22 ( 99.07)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.0429e-02 (4.7242e-02)\tAcc@1  99.22 ( 99.05)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][ 90/391]\tTime  0.174 ( 0.174)\tLoss 6.4533e-02 (4.7871e-02)\tAcc@1  98.44 ( 99.01)\tAcc@5 100.00 ( 99.94)\n","Epoch: [143][120/391]\tTime  0.173 ( 0.174)\tLoss 6.6623e-02 (4.8687e-02)\tAcc@1  97.66 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][150/391]\tTime  0.173 ( 0.174)\tLoss 1.7757e-02 (4.8009e-02)\tAcc@1 100.00 ( 98.93)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][180/391]\tTime  0.175 ( 0.174)\tLoss 5.5339e-02 (4.8385e-02)\tAcc@1  99.22 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][210/391]\tTime  0.173 ( 0.174)\tLoss 2.4702e-02 (4.8177e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][240/391]\tTime  0.172 ( 0.174)\tLoss 3.3343e-02 (4.8224e-02)\tAcc@1  99.22 ( 98.91)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][270/391]\tTime  0.173 ( 0.174)\tLoss 6.7652e-02 (4.7848e-02)\tAcc@1  99.22 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][300/391]\tTime  0.172 ( 0.174)\tLoss 9.1414e-02 (4.7944e-02)\tAcc@1  97.66 ( 98.88)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][330/391]\tTime  0.175 ( 0.174)\tLoss 3.0566e-02 (4.7942e-02)\tAcc@1  99.22 ( 98.88)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][360/391]\tTime  0.174 ( 0.174)\tLoss 2.8583e-02 (4.7718e-02)\tAcc@1 100.00 ( 98.89)\tAcc@5 100.00 ( 99.95)\n","Epoch: [143][390/391]\tTime  0.155 ( 0.174)\tLoss 2.5360e-02 (4.7385e-02)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 98.898 || Acc@5 99.958\n","==> Test Accuracy:  Acc@1 77.730 || Acc@5 94.220\n","==> 72.14 seconds to train this epoch\n","\n","\n","----- epoch: 144, lr: 0.0008000000000000003 -----\n","Epoch: [144][  0/391]\tTime  0.254 ( 0.254)\tLoss 3.7787e-02 (3.7787e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [144][ 30/391]\tTime  0.176 ( 0.176)\tLoss 2.8060e-02 (4.8213e-02)\tAcc@1  99.22 ( 98.82)\tAcc@5 100.00 ( 99.92)\n","Epoch: [144][ 60/391]\tTime  0.174 ( 0.175)\tLoss 4.0773e-02 (5.1001e-02)\tAcc@1  98.44 ( 98.80)\tAcc@5 100.00 ( 99.92)\n","Epoch: [144][ 90/391]\tTime  0.173 ( 0.174)\tLoss 7.4862e-02 (4.9041e-02)\tAcc@1  98.44 ( 98.86)\tAcc@5 100.00 ( 99.92)\n","Epoch: [144][120/391]\tTime  0.175 ( 0.174)\tLoss 6.8783e-02 (4.8462e-02)\tAcc@1  98.44 ( 98.91)\tAcc@5 100.00 ( 99.94)\n","Epoch: [144][150/391]\tTime  0.176 ( 0.174)\tLoss 3.4501e-02 (4.7247e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.95)\n","Epoch: [144][180/391]\tTime  0.175 ( 0.174)\tLoss 1.1372e-01 (4.8055e-02)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 ( 99.94)\n","Epoch: [144][210/391]\tTime  0.172 ( 0.174)\tLoss 2.5756e-02 (4.8452e-02)\tAcc@1  99.22 ( 98.84)\tAcc@5 100.00 ( 99.94)\n","Epoch: [144][240/391]\tTime  0.175 ( 0.174)\tLoss 5.6595e-02 (4.7438e-02)\tAcc@1  99.22 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [144][270/391]\tTime  0.173 ( 0.174)\tLoss 4.5027e-02 (4.7437e-02)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [144][300/391]\tTime  0.175 ( 0.174)\tLoss 8.2226e-02 (4.7227e-02)\tAcc@1  98.44 ( 98.93)\tAcc@5 100.00 ( 99.95)\n","Epoch: [144][330/391]\tTime  0.176 ( 0.174)\tLoss 3.7551e-02 (4.7611e-02)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [144][360/391]\tTime  0.174 ( 0.174)\tLoss 2.5803e-02 (4.7518e-02)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 ( 99.96)\n","Epoch: [144][390/391]\tTime  0.160 ( 0.174)\tLoss 2.4117e-02 (4.7465e-02)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 98.902 || Acc@5 99.960\n","==> Test Accuracy:  Acc@1 77.600 || Acc@5 94.120\n","==> 72.37 seconds to train this epoch\n","\n","\n","----- epoch: 145, lr: 0.0008000000000000003 -----\n","Epoch: [145][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.8798e-02 (1.8798e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [145][ 30/391]\tTime  0.177 ( 0.177)\tLoss 7.5205e-02 (4.1687e-02)\tAcc@1  96.88 ( 99.02)\tAcc@5 100.00 ( 99.97)\n","Epoch: [145][ 60/391]\tTime  0.176 ( 0.176)\tLoss 4.1963e-02 (4.2004e-02)\tAcc@1  98.44 ( 99.01)\tAcc@5 100.00 ( 99.97)\n","Epoch: [145][ 90/391]\tTime  0.177 ( 0.175)\tLoss 3.7192e-02 (4.4307e-02)\tAcc@1 100.00 ( 99.02)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][120/391]\tTime  0.172 ( 0.175)\tLoss 1.7532e-02 (4.4658e-02)\tAcc@1 100.00 ( 99.04)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][150/391]\tTime  0.174 ( 0.175)\tLoss 4.4865e-02 (4.4764e-02)\tAcc@1  98.44 ( 99.01)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][180/391]\tTime  0.173 ( 0.175)\tLoss 2.4214e-02 (4.3932e-02)\tAcc@1 100.00 ( 99.07)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][210/391]\tTime  0.172 ( 0.175)\tLoss 3.0203e-02 (4.4347e-02)\tAcc@1  99.22 ( 99.04)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][240/391]\tTime  0.175 ( 0.175)\tLoss 4.4295e-02 (4.4744e-02)\tAcc@1  99.22 ( 99.01)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][270/391]\tTime  0.175 ( 0.175)\tLoss 5.9551e-02 (4.4749e-02)\tAcc@1  98.44 ( 99.00)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][300/391]\tTime  0.175 ( 0.175)\tLoss 3.4290e-02 (4.4544e-02)\tAcc@1  99.22 ( 99.00)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][330/391]\tTime  0.173 ( 0.175)\tLoss 2.6328e-02 (4.5263e-02)\tAcc@1 100.00 ( 98.97)\tAcc@5 100.00 ( 99.96)\n","Epoch: [145][360/391]\tTime  0.176 ( 0.175)\tLoss 3.9736e-02 (4.5212e-02)\tAcc@1  99.22 ( 98.98)\tAcc@5 100.00 ( 99.95)\n","Epoch: [145][390/391]\tTime  0.159 ( 0.175)\tLoss 1.9315e-02 (4.5605e-02)\tAcc@1 100.00 ( 98.97)\tAcc@5 100.00 ( 99.95)\n","==> Train Accuracy: Acc@1 98.970 || Acc@5 99.954\n","==> Test Accuracy:  Acc@1 77.660 || Acc@5 94.180\n","==> 72.54 seconds to train this epoch\n","\n","\n","----- epoch: 146, lr: 0.0008000000000000003 -----\n","Epoch: [146][  0/391]\tTime  0.264 ( 0.264)\tLoss 3.6330e-02 (3.6330e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [146][ 30/391]\tTime  0.173 ( 0.176)\tLoss 7.1706e-02 (5.1756e-02)\tAcc@1  97.66 ( 98.79)\tAcc@5 100.00 ( 99.90)\n","Epoch: [146][ 60/391]\tTime  0.174 ( 0.175)\tLoss 3.5576e-02 (4.8692e-02)\tAcc@1  99.22 ( 98.89)\tAcc@5 100.00 ( 99.94)\n","Epoch: [146][ 90/391]\tTime  0.173 ( 0.175)\tLoss 5.6476e-02 (4.8441e-02)\tAcc@1  97.66 ( 98.85)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][120/391]\tTime  0.176 ( 0.175)\tLoss 8.4440e-02 (4.8773e-02)\tAcc@1  97.66 ( 98.85)\tAcc@5 100.00 ( 99.94)\n","Epoch: [146][150/391]\tTime  0.173 ( 0.174)\tLoss 5.3597e-02 (4.7371e-02)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][180/391]\tTime  0.174 ( 0.174)\tLoss 3.5159e-02 (4.6941e-02)\tAcc@1  98.44 ( 98.88)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][210/391]\tTime  0.172 ( 0.174)\tLoss 3.5431e-02 (4.6088e-02)\tAcc@1  98.44 ( 98.91)\tAcc@5 100.00 ( 99.96)\n","Epoch: [146][240/391]\tTime  0.175 ( 0.174)\tLoss 3.4053e-02 (4.5896e-02)\tAcc@1 100.00 ( 98.92)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][270/391]\tTime  0.175 ( 0.174)\tLoss 5.4611e-02 (4.5704e-02)\tAcc@1  97.66 ( 98.91)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][300/391]\tTime  0.174 ( 0.174)\tLoss 2.7086e-02 (4.5684e-02)\tAcc@1  99.22 ( 98.94)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][330/391]\tTime  0.174 ( 0.174)\tLoss 3.4959e-02 (4.6019e-02)\tAcc@1  99.22 ( 98.94)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][360/391]\tTime  0.173 ( 0.174)\tLoss 4.4219e-02 (4.5986e-02)\tAcc@1  99.22 ( 98.95)\tAcc@5 100.00 ( 99.95)\n","Epoch: [146][390/391]\tTime  0.155 ( 0.174)\tLoss 2.4845e-02 (4.6062e-02)\tAcc@1 100.00 ( 98.95)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 98.950 || Acc@5 99.956\n","==> Test Accuracy:  Acc@1 77.660 || Acc@5 94.270\n","==> 72.25 seconds to train this epoch\n","\n","\n","----- epoch: 147, lr: 0.0008000000000000003 -----\n","Epoch: [147][  0/391]\tTime  0.257 ( 0.257)\tLoss 4.1959e-02 (4.1959e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [147][ 30/391]\tTime  0.175 ( 0.176)\tLoss 3.3985e-02 (4.7726e-02)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 ( 99.92)\n","Epoch: [147][ 60/391]\tTime  0.174 ( 0.175)\tLoss 8.4610e-03 (4.9059e-02)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 ( 99.94)\n","Epoch: [147][ 90/391]\tTime  0.173 ( 0.174)\tLoss 3.0164e-02 (4.5979e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.96)\n","Epoch: [147][120/391]\tTime  0.174 ( 0.174)\tLoss 1.9896e-02 (4.6653e-02)\tAcc@1 100.00 ( 98.95)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][150/391]\tTime  0.174 ( 0.174)\tLoss 5.5960e-02 (4.7074e-02)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 ( 99.96)\n","Epoch: [147][180/391]\tTime  0.174 ( 0.174)\tLoss 5.1628e-02 (4.5911e-02)\tAcc@1  98.44 ( 98.96)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][210/391]\tTime  0.172 ( 0.174)\tLoss 3.8985e-02 (4.5008e-02)\tAcc@1  99.22 ( 99.01)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][240/391]\tTime  0.175 ( 0.174)\tLoss 5.6907e-02 (4.4779e-02)\tAcc@1  98.44 ( 99.00)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][270/391]\tTime  0.175 ( 0.174)\tLoss 3.9499e-02 (4.4694e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][300/391]\tTime  0.175 ( 0.174)\tLoss 5.4228e-02 (4.4786e-02)\tAcc@1  98.44 ( 99.00)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][330/391]\tTime  0.171 ( 0.174)\tLoss 1.7035e-02 (4.4352e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][360/391]\tTime  0.175 ( 0.174)\tLoss 2.4291e-02 (4.3816e-02)\tAcc@1 100.00 ( 99.03)\tAcc@5 100.00 ( 99.97)\n","Epoch: [147][390/391]\tTime  0.158 ( 0.173)\tLoss 4.1038e-02 (4.3816e-02)\tAcc@1  98.75 ( 99.03)\tAcc@5 100.00 ( 99.97)\n","==> Train Accuracy: Acc@1 99.030 || Acc@5 99.968\n","==> Test Accuracy:  Acc@1 77.960 || Acc@5 94.350\n","==> 72.10 seconds to train this epoch\n","\n","\n","----- epoch: 148, lr: 0.0008000000000000003 -----\n","Epoch: [148][  0/391]\tTime  0.263 ( 0.263)\tLoss 3.3521e-02 (3.3521e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [148][ 30/391]\tTime  0.173 ( 0.176)\tLoss 3.5467e-02 (4.1313e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [148][ 60/391]\tTime  0.176 ( 0.174)\tLoss 4.5194e-02 (4.0436e-02)\tAcc@1  98.44 ( 99.18)\tAcc@5 100.00 (100.00)\n","Epoch: [148][ 90/391]\tTime  0.176 ( 0.174)\tLoss 7.5233e-02 (4.2799e-02)\tAcc@1  97.66 ( 99.09)\tAcc@5 100.00 ( 99.97)\n","Epoch: [148][120/391]\tTime  0.176 ( 0.174)\tLoss 2.5997e-02 (4.4194e-02)\tAcc@1 100.00 ( 99.10)\tAcc@5 100.00 ( 99.97)\n","Epoch: [148][150/391]\tTime  0.171 ( 0.174)\tLoss 3.5595e-02 (4.4314e-02)\tAcc@1  99.22 ( 99.06)\tAcc@5 100.00 ( 99.96)\n","Epoch: [148][180/391]\tTime  0.173 ( 0.174)\tLoss 2.0314e-02 (4.4035e-02)\tAcc@1 100.00 ( 99.05)\tAcc@5 100.00 ( 99.97)\n","Epoch: [148][210/391]\tTime  0.173 ( 0.174)\tLoss 1.7671e-02 (4.3281e-02)\tAcc@1 100.00 ( 99.09)\tAcc@5 100.00 ( 99.96)\n","Epoch: [148][240/391]\tTime  0.171 ( 0.174)\tLoss 3.7257e-02 (4.3320e-02)\tAcc@1  99.22 ( 99.08)\tAcc@5 100.00 ( 99.96)\n","Epoch: [148][270/391]\tTime  0.171 ( 0.174)\tLoss 8.6829e-02 (4.3609e-02)\tAcc@1  96.88 ( 99.06)\tAcc@5 100.00 ( 99.96)\n","Epoch: [148][300/391]\tTime  0.171 ( 0.174)\tLoss 2.5393e-02 (4.3243e-02)\tAcc@1  99.22 ( 99.08)\tAcc@5 100.00 ( 99.96)\n","Epoch: [148][330/391]\tTime  0.176 ( 0.174)\tLoss 3.3017e-02 (4.3022e-02)\tAcc@1  99.22 ( 99.08)\tAcc@5 100.00 ( 99.96)\n","Epoch: [148][360/391]\tTime  0.173 ( 0.174)\tLoss 4.8956e-02 (4.3126e-02)\tAcc@1  98.44 ( 99.05)\tAcc@5 100.00 ( 99.96)\n","Epoch: [148][390/391]\tTime  0.155 ( 0.174)\tLoss 2.2785e-02 (4.3336e-02)\tAcc@1 100.00 ( 99.05)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 99.048 || Acc@5 99.958\n","==> Test Accuracy:  Acc@1 77.740 || Acc@5 94.240\n","==> 72.15 seconds to train this epoch\n","\n","\n","----- epoch: 149, lr: 0.0008000000000000003 -----\n","Epoch: [149][  0/391]\tTime  0.259 ( 0.259)\tLoss 5.2122e-02 (5.2122e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [149][ 30/391]\tTime  0.172 ( 0.176)\tLoss 3.5928e-02 (4.7915e-02)\tAcc@1  99.22 ( 98.87)\tAcc@5 100.00 ( 99.92)\n","Epoch: [149][ 60/391]\tTime  0.173 ( 0.175)\tLoss 2.9766e-02 (4.9223e-02)\tAcc@1  99.22 ( 98.87)\tAcc@5 100.00 ( 99.94)\n","Epoch: [149][ 90/391]\tTime  0.173 ( 0.174)\tLoss 3.5513e-02 (4.8440e-02)\tAcc@1 100.00 ( 98.88)\tAcc@5 100.00 ( 99.95)\n","Epoch: [149][120/391]\tTime  0.172 ( 0.174)\tLoss 2.5992e-02 (4.6971e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.95)\n","Epoch: [149][150/391]\tTime  0.172 ( 0.174)\tLoss 2.4676e-02 (4.5562e-02)\tAcc@1 100.00 ( 98.93)\tAcc@5 100.00 ( 99.96)\n","Epoch: [149][180/391]\tTime  0.173 ( 0.174)\tLoss 4.4827e-02 (4.5839e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.97)\n","Epoch: [149][210/391]\tTime  0.172 ( 0.174)\tLoss 2.1522e-02 (4.5099e-02)\tAcc@1 100.00 ( 98.96)\tAcc@5 100.00 ( 99.97)\n","Epoch: [149][240/391]\tTime  0.174 ( 0.174)\tLoss 4.1586e-02 (4.5014e-02)\tAcc@1  99.22 ( 98.97)\tAcc@5 100.00 ( 99.97)\n","Epoch: [149][270/391]\tTime  0.173 ( 0.174)\tLoss 4.5259e-02 (4.4804e-02)\tAcc@1  99.22 ( 98.99)\tAcc@5 100.00 ( 99.96)\n","Epoch: [149][300/391]\tTime  0.172 ( 0.174)\tLoss 3.6625e-02 (4.4023e-02)\tAcc@1 100.00 ( 99.03)\tAcc@5 100.00 ( 99.96)\n","Epoch: [149][330/391]\tTime  0.173 ( 0.174)\tLoss 4.8340e-02 (4.4499e-02)\tAcc@1 100.00 ( 99.02)\tAcc@5 100.00 ( 99.96)\n","Epoch: [149][360/391]\tTime  0.175 ( 0.174)\tLoss 2.2794e-02 (4.4567e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.96)\n","Epoch: [149][390/391]\tTime  0.155 ( 0.173)\tLoss 3.5594e-02 (4.4196e-02)\tAcc@1  98.75 ( 99.02)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 99.024 || Acc@5 99.960\n","==> Test Accuracy:  Acc@1 77.740 || Acc@5 94.230\n","==> 72.08 seconds to train this epoch\n","\n","Best Top-1 Accuracy: 77.96\n"],"name":"stdout"}]}]}